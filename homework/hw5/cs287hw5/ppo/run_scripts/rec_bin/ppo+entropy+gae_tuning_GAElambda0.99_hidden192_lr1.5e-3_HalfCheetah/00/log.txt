Logging to /home/vincent/workplace/CS_287_-_Advanced_Robotics/homework/hw5/cs287hw5/ppo/run_scripts/data/ppo+entropy+gae_tuning_GAElambda0.99_hidden192_lr1.5e-3_HalfCheetah/00

 ---------------- Iteration 0 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 0              |
| ItrTime                 | 6.65           |
| LossAfter               | 0.038709924    |
| LossBefore              | -1.4191769e-05 |
| Time                    | 6.65           |
| Time-Optimization       | 0.565          |
| Time-SampleProc         | 0.0712         |
| Time-Sampling           | 6              |
| n_timesteps             | 10000          |
| train-AverageDiscoun... | -17.5          |
| train-AverageReturn     | -27.8          |
| train-EnvExecTime       | 2.12           |
| train-MaxReturn         | 40.3           |
| train-MinReturn         | -140           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.69           |
| train-StdReturn         | 33.1           |
--------------------------------------------

 ---------------- Iteration 1 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 1              |
| ItrTime                 | 6.02           |
| LossAfter               | -0.004593599   |
| LossBefore              | -1.4250665e-05 |
| Time                    | 12.7           |
| Time-Optimization       | 0.364          |
| Time-SampleProc         | 0.0457         |
| Time-Sampling           | 5.62           |
| n_timesteps             | 20000          |
| train-AverageDiscoun... | -20            |
| train-AverageReturn     | -32.6          |
| train-EnvExecTime       | 1.99           |
| train-MaxReturn         | 36.1           |
| train-MinReturn         | -122           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.44           |
| train-StdReturn         | 33.7           |
--------------------------------------------

 ---------------- Iteration 2 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 2              |
| ItrTime                 | 6.08           |
| LossAfter               | -0.014736538   |
| LossBefore              | -1.4274263e-05 |
| Time                    | 18.8           |
| Time-Optimization       | 0.333          |
| Time-SampleProc         | 0.047          |
| Time-Sampling           | 5.7            |
| n_timesteps             | 30000          |
| train-AverageDiscoun... | -14.8          |
| train-AverageReturn     | -24.1          |
| train-EnvExecTime       | 2.02           |
| train-MaxReturn         | 47.2           |
| train-MinReturn         | -123           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.49           |
| train-StdReturn         | 31.4           |
--------------------------------------------

 ---------------- Iteration 3 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 3              |
| ItrTime                 | 6.59           |
| LossAfter               | -0.018599413   |
| LossBefore              | -1.4270114e-05 |
| Time                    | 25.4           |
| Time-Optimization       | 0.349          |
| Time-SampleProc         | 0.0632         |
| Time-Sampling           | 6.18           |
| n_timesteps             | 40000          |
| train-AverageDiscoun... | -17.2          |
| train-AverageReturn     | -27.2          |
| train-EnvExecTime       | 2.17           |
| train-MaxReturn         | 87.3           |
| train-MinReturn         | -143           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.81           |
| train-StdReturn         | 35.8           |
--------------------------------------------

 ---------------- Iteration 4 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 4              |
| ItrTime                 | 6.56           |
| LossAfter               | -0.015035995   |
| LossBefore              | -1.4259525e-05 |
| Time                    | 32             |
| Time-Optimization       | 0.423          |
| Time-SampleProc         | 0.0506         |
| Time-Sampling           | 6.08           |
| n_timesteps             | 50000          |
| train-AverageDiscoun... | -16.6          |
| train-AverageReturn     | -26.3          |
| train-EnvExecTime       | 2.15           |
| train-MaxReturn         | 48             |
| train-MinReturn         | -126           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.74           |
| train-StdReturn         | 35.8           |
--------------------------------------------

 ---------------- Iteration 5 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 5              |
| ItrTime                 | 6.08           |
| LossAfter               | -0.018836996   |
| LossBefore              | -1.4228987e-05 |
| Time                    | 38.1           |
| Time-Optimization       | 0.315          |
| Time-SampleProc         | 0.0465         |
| Time-Sampling           | 5.72           |
| n_timesteps             | 60000          |
| train-AverageDiscoun... | -16.4          |
| train-AverageReturn     | -25.6          |
| train-EnvExecTime       | 2.01           |
| train-MaxReturn         | 68.4           |
| train-MinReturn         | -97            |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.52           |
| train-StdReturn         | 31.9           |
--------------------------------------------

 ---------------- Iteration 6 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 6              |
| ItrTime                 | 5.87           |
| LossAfter               | -0.01601828    |
| LossBefore              | -1.4208731e-05 |
| Time                    | 44             |
| Time-Optimization       | 0.243          |
| Time-SampleProc         | 0.0511         |
| Time-Sampling           | 5.58           |
| n_timesteps             | 70000          |
| train-AverageDiscoun... | -16            |
| train-AverageReturn     | -25            |
| train-EnvExecTime       | 1.96           |
| train-MaxReturn         | 33.3           |
| train-MinReturn         | -105           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.42           |
| train-StdReturn         | 28.9           |
--------------------------------------------

 ---------------- Iteration 7 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 7              |
| ItrTime                 | 6.42           |
| LossAfter               | -0.017358366   |
| LossBefore              | -1.4213658e-05 |
| Time                    | 50.5           |
| Time-Optimization       | 0.217          |
| Time-SampleProc         | 0.0494         |
| Time-Sampling           | 6.16           |
| n_timesteps             | 80000          |
| train-AverageDiscoun... | -16.6          |
| train-AverageReturn     | -25.8          |
| train-EnvExecTime       | 2.14           |
| train-MaxReturn         | 32.5           |
| train-MinReturn         | -94.6          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.81           |
| train-StdReturn         | 25.8           |
--------------------------------------------

 ---------------- Iteration 8 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 8              |
| ItrTime                 | 6.28           |
| LossAfter               | -0.01819102    |
| LossBefore              | -1.4177255e-05 |
| Time                    | 56.8           |
| Time-Optimization       | 0.196          |
| Time-SampleProc         | 0.0857         |
| Time-Sampling           | 6              |
| n_timesteps             | 90000          |
| train-AverageDiscoun... | -11.5          |
| train-AverageReturn     | -18.7          |
| train-EnvExecTime       | 2.11           |
| train-MaxReturn         | 67.2           |
| train-MinReturn         | -89.9          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.7            |
| train-StdReturn         | 25.8           |
--------------------------------------------

 ---------------- Iteration 9 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 9              |
| ItrTime                 | 6.27           |
| LossAfter               | -0.017461259   |
| LossBefore              | -1.4164905e-05 |
| Time                    | 63             |
| Time-Optimization       | 0.215          |
| Time-SampleProc         | 0.0469         |
| Time-Sampling           | 6.01           |
| n_timesteps             | 100000         |
| train-AverageDiscoun... | -15.8          |
| train-AverageReturn     | -24.7          |
| train-EnvExecTime       | 2.1            |
| train-MaxReturn         | 43.5           |
| train-MinReturn         | -191           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.72           |
| train-StdReturn         | 33.7           |
--------------------------------------------

 ---------------- Iteration 10 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 10             |
| ItrTime                 | 6.2            |
| LossAfter               | -0.016140068   |
| LossBefore              | -1.4163569e-05 |
| Time                    | 69.3           |
| Time-Optimization       | 0.224          |
| Time-SampleProc         | 0.0542         |
| Time-Sampling           | 5.92           |
| n_timesteps             | 110000         |
| train-AverageDiscoun... | -16.8          |
| train-AverageReturn     | -27.2          |
| train-EnvExecTime       | 2.08           |
| train-MaxReturn         | 25.5           |
| train-MinReturn         | -115           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.65           |
| train-StdReturn         | 28.1           |
--------------------------------------------

 ---------------- Iteration 11 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 11            |
| ItrTime                 | 6.17          |
| LossAfter               | -0.016873289  |
| LossBefore              | -1.415782e-05 |
| Time                    | 75.4          |
| Time-Optimization       | 0.221         |
| Time-SampleProc         | 0.0423        |
| Time-Sampling           | 5.9           |
| n_timesteps             | 120000        |
| train-AverageDiscoun... | -13.8         |
| train-AverageReturn     | -21.5         |
| train-EnvExecTime       | 2.06          |
| train-MaxReturn         | 67.5          |
| train-MinReturn         | -143          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.65          |
| train-StdReturn         | 35.7          |
-------------------------------------------

 ---------------- Iteration 12 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Itr                     | 12              |
| ItrTime                 | 6.13            |
| LossAfter               | -0.01965707     |
| LossBefore              | -1.41138635e-05 |
| Time                    | 81.6            |
| Time-Optimization       | 0.261           |
| Time-SampleProc         | 0.0436          |
| Time-Sampling           | 5.82            |
| n_timesteps             | 130000          |
| train-AverageDiscoun... | -13.7           |
| train-AverageReturn     | -21.6           |
| train-EnvExecTime       | 2.03            |
| train-MaxReturn         | 44.8            |
| train-MinReturn         | -105            |
| train-NumTrajs          | 100             |
| train-PolicyExecTime    | 3.6             |
| train-StdReturn         | 28.9            |
---------------------------------------------

 ---------------- Iteration 13 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 13             |
| ItrTime                 | 6.53           |
| LossAfter               | -0.018589659   |
| LossBefore              | -1.4114575e-05 |
| Time                    | 88.1           |
| Time-Optimization       | 0.212          |
| Time-SampleProc         | 0.0786         |
| Time-Sampling           | 6.24           |
| n_timesteps             | 140000         |
| train-AverageDiscoun... | -16.1          |
| train-AverageReturn     | -25.6          |
| train-EnvExecTime       | 2.17           |
| train-MaxReturn         | 38.6           |
| train-MinReturn         | -141           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.87           |
| train-StdReturn         | 30.4           |
--------------------------------------------

 ---------------- Iteration 14 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 14            |
| ItrTime                 | 6.15          |
| LossAfter               | -0.017922983  |
| LossBefore              | -1.408453e-05 |
| Time                    | 94.3          |
| Time-Optimization       | 0.217         |
| Time-SampleProc         | 0.0462        |
| Time-Sampling           | 5.88          |
| n_timesteps             | 150000        |
| train-AverageDiscoun... | -13.4         |
| train-AverageReturn     | -21.5         |
| train-EnvExecTime       | 2.08          |
| train-MaxReturn         | 51.9          |
| train-MinReturn         | -99.2         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.6           |
| train-StdReturn         | 32.2          |
-------------------------------------------

 ---------------- Iteration 15 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 15             |
| ItrTime                 | 5.99           |
| LossAfter               | -0.017016549   |
| LossBefore              | -1.4048477e-05 |
| Time                    | 100            |
| Time-Optimization       | 0.227          |
| Time-SampleProc         | 0.0433         |
| Time-Sampling           | 5.72           |
| n_timesteps             | 160000         |
| train-AverageDiscoun... | -12.6          |
| train-AverageReturn     | -19.7          |
| train-EnvExecTime       | 2              |
| train-MaxReturn         | 41.6           |
| train-MinReturn         | -130           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.53           |
| train-StdReturn         | 29.1           |
--------------------------------------------

 ---------------- Iteration 16 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 16             |
| ItrTime                 | 6.48           |
| LossAfter               | -0.018269194   |
| LossBefore              | -1.4024774e-05 |
| Time                    | 107            |
| Time-Optimization       | 0.203          |
| Time-SampleProc         | 0.0893         |
| Time-Sampling           | 6.19           |
| n_timesteps             | 170000         |
| train-AverageDiscoun... | -17            |
| train-AverageReturn     | -26.5          |
| train-EnvExecTime       | 2.18           |
| train-MaxReturn         | 77.9           |
| train-MinReturn         | -121           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.81           |
| train-StdReturn         | 35.6           |
--------------------------------------------

 ---------------- Iteration 17 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 17             |
| ItrTime                 | 6.34           |
| LossAfter               | -0.018305892   |
| LossBefore              | -1.3998083e-05 |
| Time                    | 113            |
| Time-Optimization       | 0.217          |
| Time-SampleProc         | 0.084          |
| Time-Sampling           | 6.04           |
| n_timesteps             | 180000         |
| train-AverageDiscoun... | -14.8          |
| train-AverageReturn     | -23.1          |
| train-EnvExecTime       | 2.13           |
| train-MaxReturn         | 55.1           |
| train-MinReturn         | -124           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.71           |
| train-StdReturn         | 28.8           |
--------------------------------------------

 ---------------- Iteration 18 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 18             |
| ItrTime                 | 6.29           |
| LossAfter               | -0.017990418   |
| LossBefore              | -1.3965345e-05 |
| Time                    | 119            |
| Time-Optimization       | 0.218          |
| Time-SampleProc         | 0.0445         |
| Time-Sampling           | 6.03           |
| n_timesteps             | 190000         |
| train-AverageDiscoun... | -14.8          |
| train-AverageReturn     | -22.4          |
| train-EnvExecTime       | 2.11           |
| train-MaxReturn         | 73.4           |
| train-MinReturn         | -95.7          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.73           |
| train-StdReturn         | 32.9           |
--------------------------------------------

 ---------------- Iteration 19 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 19             |
| ItrTime                 | 6.13           |
| LossAfter               | -0.01903115    |
| LossBefore              | -1.3946857e-05 |
| Time                    | 126            |
| Time-Optimization       | 0.211          |
| Time-SampleProc         | 0.0419         |
| Time-Sampling           | 5.88           |
| n_timesteps             | 200000         |
| train-AverageDiscoun... | -12.7          |
| train-AverageReturn     | -20.4          |
| train-EnvExecTime       | 2.05           |
| train-MaxReturn         | 57.6           |
| train-MinReturn         | -98            |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.64           |
| train-StdReturn         | 28             |
--------------------------------------------

 ---------------- Iteration 20 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Itr                     | 20              |
| ItrTime                 | 5.84            |
| LossAfter               | -0.018415887    |
| LossBefore              | -1.39074045e-05 |
| Time                    | 131             |
| Time-Optimization       | 0.211           |
| Time-SampleProc         | 0.0829          |
| Time-Sampling           | 5.55            |
| n_timesteps             | 210000          |
| train-AverageDiscoun... | -10.5           |
| train-AverageReturn     | -16.7           |
| train-EnvExecTime       | 1.93            |
| train-MaxReturn         | 23.8            |
| train-MinReturn         | -101            |
| train-NumTrajs          | 100             |
| train-PolicyExecTime    | 3.42            |
| train-StdReturn         | 25.9            |
---------------------------------------------

 ---------------- Iteration 21 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 21             |
| ItrTime                 | 6.03           |
| LossAfter               | -0.019771881   |
| LossBefore              | -1.3883506e-05 |
| Time                    | 137            |
| Time-Optimization       | 0.236          |
| Time-SampleProc         | 0.0445         |
| Time-Sampling           | 5.75           |
| n_timesteps             | 220000         |
| train-AverageDiscoun... | -15.1          |
| train-AverageReturn     | -22.6          |
| train-EnvExecTime       | 2.01           |
| train-MaxReturn         | 73.7           |
| train-MinReturn         | -117           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.56           |
| train-StdReturn         | 30.8           |
--------------------------------------------

 ---------------- Iteration 22 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 22             |
| ItrTime                 | 6.57           |
| LossAfter               | -0.019414205   |
| LossBefore              | -1.3874998e-05 |
| Time                    | 144            |
| Time-Optimization       | 0.262          |
| Time-SampleProc         | 0.0447         |
| Time-Sampling           | 6.26           |
| n_timesteps             | 230000         |
| train-AverageDiscoun... | -7.63          |
| train-AverageReturn     | -12.9          |
| train-EnvExecTime       | 2.22           |
| train-MaxReturn         | 36.6           |
| train-MinReturn         | -85.3          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.83           |
| train-StdReturn         | 25.6           |
--------------------------------------------

 ---------------- Iteration 23 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 23            |
| ItrTime                 | 6.51          |
| LossAfter               | -0.018320149  |
| LossBefore              | -1.384154e-05 |
| Time                    | 151           |
| Time-Optimization       | 0.213         |
| Time-SampleProc         | 0.0447        |
| Time-Sampling           | 6.25          |
| n_timesteps             | 240000        |
| train-AverageDiscoun... | -8.94         |
| train-AverageReturn     | -15.2         |
| train-EnvExecTime       | 2.2           |
| train-MaxReturn         | 35.8          |
| train-MinReturn         | -106          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.85          |
| train-StdReturn         | 25.1          |
-------------------------------------------

 ---------------- Iteration 24 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 24             |
| ItrTime                 | 6.2            |
| LossAfter               | -0.019606976   |
| LossBefore              | -1.3798899e-05 |
| Time                    | 157            |
| Time-Optimization       | 0.211          |
| Time-SampleProc         | 0.0416         |
| Time-Sampling           | 5.95           |
| n_timesteps             | 250000         |
| train-AverageDiscoun... | -8.94          |
| train-AverageReturn     | -14.7          |
| train-EnvExecTime       | 2.08           |
| train-MaxReturn         | 76.2           |
| train-MinReturn         | -129           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.68           |
| train-StdReturn         | 30.4           |
--------------------------------------------

 ---------------- Iteration 25 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 25             |
| ItrTime                 | 5.96           |
| LossAfter               | -0.018850636   |
| LossBefore              | -1.3782988e-05 |
| Time                    | 163            |
| Time-Optimization       | 0.242          |
| Time-SampleProc         | 0.0448         |
| Time-Sampling           | 5.68           |
| n_timesteps             | 260000         |
| train-AverageDiscoun... | -6.62          |
| train-AverageReturn     | -11.1          |
| train-EnvExecTime       | 1.99           |
| train-MaxReturn         | 44.6           |
| train-MinReturn         | -92.5          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.5            |
| train-StdReturn         | 23.2           |
--------------------------------------------

 ---------------- Iteration 26 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 26             |
| ItrTime                 | 6.46           |
| LossAfter               | -0.017568698   |
| LossBefore              | -1.3755335e-05 |
| Time                    | 169            |
| Time-Optimization       | 0.212          |
| Time-SampleProc         | 0.0449         |
| Time-Sampling           | 6.21           |
| n_timesteps             | 270000         |
| train-AverageDiscoun... | -6.63          |
| train-AverageReturn     | -10.4          |
| train-EnvExecTime       | 2.17           |
| train-MaxReturn         | 54.1           |
| train-MinReturn         | -112           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.83           |
| train-StdReturn         | 25.6           |
--------------------------------------------

 ---------------- Iteration 27 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 27             |
| ItrTime                 | 6.44           |
| LossAfter               | -0.020913651   |
| LossBefore              | -1.3720859e-05 |
| Time                    | 176            |
| Time-Optimization       | 0.24           |
| Time-SampleProc         | 0.0443         |
| Time-Sampling           | 6.16           |
| n_timesteps             | 280000         |
| train-AverageDiscoun... | -6.02          |
| train-AverageReturn     | -9.84          |
| train-EnvExecTime       | 2.16           |
| train-MaxReturn         | 70.4           |
| train-MinReturn         | -94.3          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.8            |
| train-StdReturn         | 25.7           |
--------------------------------------------

 ---------------- Iteration 28 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 28             |
| ItrTime                 | 6.29           |
| LossAfter               | -0.021637848   |
| LossBefore              | -1.3705533e-05 |
| Time                    | 182            |
| Time-Optimization       | 0.227          |
| Time-SampleProc         | 0.0478         |
| Time-Sampling           | 6.02           |
| n_timesteps             | 290000         |
| train-AverageDiscoun... | -12.1          |
| train-AverageReturn     | -19            |
| train-EnvExecTime       | 2.13           |
| train-MaxReturn         | 55.9           |
| train-MinReturn         | -106           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.69           |
| train-StdReturn         | 34.9           |
--------------------------------------------

 ---------------- Iteration 29 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 29             |
| ItrTime                 | 6.37           |
| LossAfter               | -0.019334259   |
| LossBefore              | -1.3689403e-05 |
| Time                    | 188            |
| Time-Optimization       | 0.208          |
| Time-SampleProc         | 0.0517         |
| Time-Sampling           | 6.11           |
| n_timesteps             | 300000         |
| train-AverageDiscoun... | -10.1          |
| train-AverageReturn     | -15.5          |
| train-EnvExecTime       | 2.14           |
| train-MaxReturn         | 48.9           |
| train-MinReturn         | -94.3          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.77           |
| train-StdReturn         | 28             |
--------------------------------------------

 ---------------- Iteration 30 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 30             |
| ItrTime                 | 6.17           |
| LossAfter               | -0.018774204   |
| LossBefore              | -1.3671222e-05 |
| Time                    | 195            |
| Time-Optimization       | 0.224          |
| Time-SampleProc         | 0.0815         |
| Time-Sampling           | 5.87           |
| n_timesteps             | 310000         |
| train-AverageDiscoun... | -11.1          |
| train-AverageReturn     | -17.1          |
| train-EnvExecTime       | 2.06           |
| train-MaxReturn         | 33.4           |
| train-MinReturn         | -105           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.61           |
| train-StdReturn         | 28.5           |
--------------------------------------------

 ---------------- Iteration 31 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 31             |
| ItrTime                 | 6.17           |
| LossAfter               | -0.020125331   |
| LossBefore              | -1.3632532e-05 |
| Time                    | 201            |
| Time-Optimization       | 0.222          |
| Time-SampleProc         | 0.0407         |
| Time-Sampling           | 5.91           |
| n_timesteps             | 320000         |
| train-AverageDiscoun... | -9.29          |
| train-AverageReturn     | -13.9          |
| train-EnvExecTime       | 2.07           |
| train-MaxReturn         | 39.1           |
| train-MinReturn         | -122           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.65           |
| train-StdReturn         | 30.3           |
--------------------------------------------

 ---------------- Iteration 32 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Itr                     | 32              |
| ItrTime                 | 6.02            |
| LossAfter               | -0.021606373    |
| LossBefore              | -1.35826285e-05 |
| Time                    | 207             |
| Time-Optimization       | 0.241           |
| Time-SampleProc         | 0.0485          |
| Time-Sampling           | 5.73            |
| n_timesteps             | 330000          |
| train-AverageDiscoun... | -7.31           |
| train-AverageReturn     | -12.1           |
| train-EnvExecTime       | 2.01            |
| train-MaxReturn         | 34.4            |
| train-MinReturn         | -155            |
| train-NumTrajs          | 100             |
| train-PolicyExecTime    | 3.53            |
| train-StdReturn         | 32.8            |
---------------------------------------------

 ---------------- Iteration 33 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 33             |
| ItrTime                 | 6.47           |
| LossAfter               | -0.021054031   |
| LossBefore              | -1.3545915e-05 |
| Time                    | 213            |
| Time-Optimization       | 0.198          |
| Time-SampleProc         | 0.0856         |
| Time-Sampling           | 6.19           |
| n_timesteps             | 340000         |
| train-AverageDiscoun... | -8.5           |
| train-AverageReturn     | -11.8          |
| train-EnvExecTime       | 2.17           |
| train-MaxReturn         | 36             |
| train-MinReturn         | -110           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.82           |
| train-StdReturn         | 26.9           |
--------------------------------------------

 ---------------- Iteration 34 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 34             |
| ItrTime                 | 6.21           |
| LossAfter               | -0.0201634     |
| LossBefore              | -1.3523861e-05 |
| Time                    | 219            |
| Time-Optimization       | 0.223          |
| Time-SampleProc         | 0.0423         |
| Time-Sampling           | 5.95           |
| n_timesteps             | 350000         |
| train-AverageDiscoun... | -6.23          |
| train-AverageReturn     | -8.7           |
| train-EnvExecTime       | 2.09           |
| train-MaxReturn         | 74.3           |
| train-MinReturn         | -120           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.66           |
| train-StdReturn         | 29.2           |
--------------------------------------------

 ---------------- Iteration 35 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 35             |
| ItrTime                 | 5.98           |
| LossAfter               | -0.02002886    |
| LossBefore              | -1.3487874e-05 |
| Time                    | 225            |
| Time-Optimization       | 0.242          |
| Time-SampleProc         | 0.0436         |
| Time-Sampling           | 5.7            |
| n_timesteps             | 360000         |
| train-AverageDiscoun... | -6.16          |
| train-AverageReturn     | -10.4          |
| train-EnvExecTime       | 2              |
| train-MaxReturn         | 60.2           |
| train-MinReturn         | -122           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.51           |
| train-StdReturn         | 27.6           |
--------------------------------------------

 ---------------- Iteration 36 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 36             |
| ItrTime                 | 6.32           |
| LossAfter               | -0.019973911   |
| LossBefore              | -1.3449494e-05 |
| Time                    | 232            |
| Time-Optimization       | 0.237          |
| Time-SampleProc         | 0.0456         |
| Time-Sampling           | 6.04           |
| n_timesteps             | 370000         |
| train-AverageDiscoun... | -7.09          |
| train-AverageReturn     | -11.4          |
| train-EnvExecTime       | 2.12           |
| train-MaxReturn         | 52.9           |
| train-MinReturn         | -110           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.71           |
| train-StdReturn         | 30.2           |
--------------------------------------------

 ---------------- Iteration 37 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 37             |
| ItrTime                 | 6.33           |
| LossAfter               | -0.020964043   |
| LossBefore              | -1.3423891e-05 |
| Time                    | 238            |
| Time-Optimization       | 0.217          |
| Time-SampleProc         | 0.0516         |
| Time-Sampling           | 6.06           |
| n_timesteps             | 380000         |
| train-AverageDiscoun... | -2.36          |
| train-AverageReturn     | -3.15          |
| train-EnvExecTime       | 2.12           |
| train-MaxReturn         | 65.3           |
| train-MinReturn         | -127           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.74           |
| train-StdReturn         | 26.7           |
--------------------------------------------

 ---------------- Iteration 38 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 38             |
| ItrTime                 | 6.25           |
| LossAfter               | -0.018973758   |
| LossBefore              | -1.3394145e-05 |
| Time                    | 244            |
| Time-Optimization       | 0.224          |
| Time-SampleProc         | 0.0442         |
| Time-Sampling           | 5.98           |
| n_timesteps             | 390000         |
| train-AverageDiscoun... | -1.33          |
| train-AverageReturn     | -2.46          |
| train-EnvExecTime       | 2.09           |
| train-MaxReturn         | 57.2           |
| train-MinReturn         | -65.3          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.68           |
| train-StdReturn         | 23.4           |
--------------------------------------------

 ---------------- Iteration 39 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 39             |
| ItrTime                 | 6.19           |
| LossAfter               | -0.020318117   |
| LossBefore              | -1.3361791e-05 |
| Time                    | 251            |
| Time-Optimization       | 0.232          |
| Time-SampleProc         | 0.0449         |
| Time-Sampling           | 5.91           |
| n_timesteps             | 400000         |
| train-AverageDiscoun... | -3.85          |
| train-AverageReturn     | -7.12          |
| train-EnvExecTime       | 2.07           |
| train-MaxReturn         | 78.3           |
| train-MinReturn         | -106           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.65           |
| train-StdReturn         | 28.1           |
--------------------------------------------

 ---------------- Iteration 40 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 40             |
| ItrTime                 | 6.17           |
| LossAfter               | -0.01983376    |
| LossBefore              | -1.3323811e-05 |
| Time                    | 257            |
| Time-Optimization       | 0.217          |
| Time-SampleProc         | 0.0442         |
| Time-Sampling           | 5.91           |
| n_timesteps             | 410000         |
| train-AverageDiscoun... | -6.72          |
| train-AverageReturn     | -10.7          |
| train-EnvExecTime       | 2.09           |
| train-MaxReturn         | 59.4           |
| train-MinReturn         | -90.7          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.62           |
| train-StdReturn         | 27.7           |
--------------------------------------------

 ---------------- Iteration 41 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 41             |
| ItrTime                 | 6.03           |
| LossAfter               | -0.02067825    |
| LossBefore              | -1.3299258e-05 |
| Time                    | 263            |
| Time-Optimization       | 0.208          |
| Time-SampleProc         | 0.0787         |
| Time-Sampling           | 5.74           |
| n_timesteps             | 420000         |
| train-AverageDiscoun... | -6.69          |
| train-AverageReturn     | -10.2          |
| train-EnvExecTime       | 2              |
| train-MaxReturn         | 47.9           |
| train-MinReturn         | -97.9          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.55           |
| train-StdReturn         | 28.7           |
--------------------------------------------

 ---------------- Iteration 42 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 42            |
| ItrTime                 | 6.46          |
| LossAfter               | -0.019616732  |
| LossBefore              | -1.327419e-05 |
| Time                    | 269           |
| Time-Optimization       | 0.222         |
| Time-SampleProc         | 0.0543        |
| Time-Sampling           | 6.19          |
| n_timesteps             | 430000        |
| train-AverageDiscoun... | -4.72         |
| train-AverageReturn     | -7.45         |
| train-EnvExecTime       | 2.16          |
| train-MaxReturn         | 67.7          |
| train-MinReturn         | -98.9         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.82          |
| train-StdReturn         | 29.4          |
-------------------------------------------

 ---------------- Iteration 43 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 43             |
| ItrTime                 | 6.21           |
| LossAfter               | -0.019251723   |
| LossBefore              | -1.3256583e-05 |
| Time                    | 276            |
| Time-Optimization       | 0.217          |
| Time-SampleProc         | 0.0442         |
| Time-Sampling           | 5.95           |
| n_timesteps             | 440000         |
| train-AverageDiscoun... | -5.26          |
| train-AverageReturn     | -7.73          |
| train-EnvExecTime       | 2.08           |
| train-MaxReturn         | 90.3           |
| train-MinReturn         | -111           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.67           |
| train-StdReturn         | 32.7           |
--------------------------------------------

 ---------------- Iteration 44 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 44            |
| ItrTime                 | 6.08          |
| LossAfter               | -0.01929611   |
| LossBefore              | -1.321343e-05 |
| Time                    | 282           |
| Time-Optimization       | 0.216         |
| Time-SampleProc         | 0.0805        |
| Time-Sampling           | 5.77          |
| n_timesteps             | 450000        |
| train-AverageDiscoun... | -3.36         |
| train-AverageReturn     | -4.06         |
| train-EnvExecTime       | 2.01          |
| train-MaxReturn         | 73            |
| train-MinReturn         | -97.1         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.58          |
| train-StdReturn         | 27.4          |
-------------------------------------------

 ---------------- Iteration 45 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 45             |
| ItrTime                 | 6.35           |
| LossAfter               | -0.020584235   |
| LossBefore              | -1.3181768e-05 |
| Time                    | 288            |
| Time-Optimization       | 0.247          |
| Time-SampleProc         | 0.0547         |
| Time-Sampling           | 6.05           |
| n_timesteps             | 460000         |
| train-AverageDiscoun... | -1.31          |
| train-AverageReturn     | -3.65          |
| train-EnvExecTime       | 2.13           |
| train-MaxReturn         | 50.6           |
| train-MinReturn         | -136           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.72           |
| train-StdReturn         | 28.3           |
--------------------------------------------

 ---------------- Iteration 46 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 46             |
| ItrTime                 | 6.35           |
| LossAfter               | -0.02256241    |
| LossBefore              | -1.3167901e-05 |
| Time                    | 294            |
| Time-Optimization       | 0.202          |
| Time-SampleProc         | 0.0787         |
| Time-Sampling           | 6.07           |
| n_timesteps             | 470000         |
| train-AverageDiscoun... | -3.68          |
| train-AverageReturn     | -4.9           |
| train-EnvExecTime       | 2.13           |
| train-MaxReturn         | 68.7           |
| train-MinReturn         | -107           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.75           |
| train-StdReturn         | 30.2           |
--------------------------------------------

 ---------------- Iteration 47 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Itr                     | 47              |
| ItrTime                 | 6.24            |
| LossAfter               | -0.021229604    |
| LossBefore              | -1.31087645e-05 |
| Time                    | 301             |
| Time-Optimization       | 0.207           |
| Time-SampleProc         | 0.0515          |
| Time-Sampling           | 5.98            |
| n_timesteps             | 480000          |
| train-AverageDiscoun... | -5.09           |
| train-AverageReturn     | -7.99           |
| train-EnvExecTime       | 2.1             |
| train-MaxReturn         | 68.7            |
| train-MinReturn         | -93.1           |
| train-NumTrajs          | 100             |
| train-PolicyExecTime    | 3.68            |
| train-StdReturn         | 29.3            |
---------------------------------------------

 ---------------- Iteration 48 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 48             |
| ItrTime                 | 6.07           |
| LossAfter               | -0.020935431   |
| LossBefore              | -1.3066144e-05 |
| Time                    | 307            |
| Time-Optimization       | 0.232          |
| Time-SampleProc         | 0.0501         |
| Time-Sampling           | 5.78           |
| n_timesteps             | 490000         |
| train-AverageDiscoun... | -3.31          |
| train-AverageReturn     | -4.95          |
| train-EnvExecTime       | 2.02           |
| train-MaxReturn         | 43.9           |
| train-MinReturn         | -105           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.57           |
| train-StdReturn         | 27.4           |
--------------------------------------------

 ---------------- Iteration 49 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 49             |
| ItrTime                 | 6.08           |
| LossAfter               | -0.019963382   |
| LossBefore              | -1.3037996e-05 |
| Time                    | 313            |
| Time-Optimization       | 0.249          |
| Time-SampleProc         | 0.0471         |
| Time-Sampling           | 5.78           |
| n_timesteps             | 500000         |
| train-AverageDiscoun... | -3.91          |
| train-AverageReturn     | -5.67          |
| train-EnvExecTime       | 2.05           |
| train-MaxReturn         | 62             |
| train-MinReturn         | -104           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.54           |
| train-StdReturn         | 29.4           |
--------------------------------------------

 ---------------- Iteration 50 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 50             |
| ItrTime                 | 6.58           |
| LossAfter               | -0.018627489   |
| LossBefore              | -1.2997982e-05 |
| Time                    | 319            |
| Time-Optimization       | 0.207          |
| Time-SampleProc         | 0.0502         |
| Time-Sampling           | 6.32           |
| n_timesteps             | 510000         |
| train-AverageDiscoun... | -0.482         |
| train-AverageReturn     | -1.35          |
| train-EnvExecTime       | 2.23           |
| train-MaxReturn         | 54.2           |
| train-MinReturn         | -79.3          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.88           |
| train-StdReturn         | 27.3           |
--------------------------------------------

 ---------------- Iteration 51 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 51            |
| ItrTime                 | 6.15          |
| LossAfter               | -0.019997604  |
| LossBefore              | -1.296753e-05 |
| Time                    | 326           |
| Time-Optimization       | 0.225         |
| Time-SampleProc         | 0.0475        |
| Time-Sampling           | 5.87          |
| n_timesteps             | 520000        |
| train-AverageDiscoun... | -1.92         |
| train-AverageReturn     | -3.76         |
| train-EnvExecTime       | 2.05          |
| train-MaxReturn         | 50.6          |
| train-MinReturn         | -104          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.63          |
| train-StdReturn         | 27.8          |
-------------------------------------------

 ---------------- Iteration 52 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 52            |
| ItrTime                 | 6.45          |
| LossAfter               | -0.021427207  |
| LossBefore              | -1.294345e-05 |
| Time                    | 332           |
| Time-Optimization       | 0.226         |
| Time-SampleProc         | 0.0453        |
| Time-Sampling           | 6.18          |
| n_timesteps             | 530000        |
| train-AverageDiscoun... | -2.04         |
| train-AverageReturn     | -2.55         |
| train-EnvExecTime       | 2.11          |
| train-MaxReturn         | 59.2          |
| train-MinReturn         | -98.4         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.87          |
| train-StdReturn         | 28.6          |
-------------------------------------------

 ---------------- Iteration 53 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 53             |
| ItrTime                 | 6.55           |
| LossAfter               | -0.01984391    |
| LossBefore              | -1.2918209e-05 |
| Time                    | 339            |
| Time-Optimization       | 0.207          |
| Time-SampleProc         | 0.0456         |
| Time-Sampling           | 6.3            |
| n_timesteps             | 540000         |
| train-AverageDiscoun... | 0.234          |
| train-AverageReturn     | 0.606          |
| train-EnvExecTime       | 2.2            |
| train-MaxReturn         | 70             |
| train-MinReturn         | -87.2          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.89           |
| train-StdReturn         | 23.6           |
--------------------------------------------

 ---------------- Iteration 54 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 54             |
| ItrTime                 | 6.22           |
| LossAfter               | -0.019168973   |
| LossBefore              | -1.2886843e-05 |
| Time                    | 345            |
| Time-Optimization       | 0.215          |
| Time-SampleProc         | 0.0432         |
| Time-Sampling           | 5.96           |
| n_timesteps             | 550000         |
| train-AverageDiscoun... | 1.13           |
| train-AverageReturn     | 2.49           |
| train-EnvExecTime       | 2.07           |
| train-MaxReturn         | 63.3           |
| train-MinReturn         | -97.7          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.69           |
| train-StdReturn         | 25.9           |
--------------------------------------------

 ---------------- Iteration 55 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 55             |
| ItrTime                 | 6.08           |
| LossAfter               | -0.017116755   |
| LossBefore              | -1.2836253e-05 |
| Time                    | 351            |
| Time-Optimization       | 0.242          |
| Time-SampleProc         | 0.0415         |
| Time-Sampling           | 5.8            |
| n_timesteps             | 560000         |
| train-AverageDiscoun... | -0.416         |
| train-AverageReturn     | -0.356         |
| train-EnvExecTime       | 2.03           |
| train-MaxReturn         | 53.6           |
| train-MinReturn         | -72.4          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.58           |
| train-StdReturn         | 25.7           |
--------------------------------------------

 ---------------- Iteration 56 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 56             |
| ItrTime                 | 6.44           |
| LossAfter               | -0.019163014   |
| LossBefore              | -1.2776922e-05 |
| Time                    | 357            |
| Time-Optimization       | 0.23           |
| Time-SampleProc         | 0.0351         |
| Time-Sampling           | 6.17           |
| n_timesteps             | 570000         |
| train-AverageDiscoun... | 1.02           |
| train-AverageReturn     | 0.937          |
| train-EnvExecTime       | 2.17           |
| train-MaxReturn         | 88             |
| train-MinReturn         | -105           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.81           |
| train-StdReturn         | 30.3           |
--------------------------------------------

 ---------------- Iteration 57 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 57             |
| ItrTime                 | 6.46           |
| LossAfter               | -0.020624988   |
| LossBefore              | -1.2755842e-05 |
| Time                    | 364            |
| Time-Optimization       | 0.232          |
| Time-SampleProc         | 0.0483         |
| Time-Sampling           | 6.18           |
| n_timesteps             | 580000         |
| train-AverageDiscoun... | 0.786          |
| train-AverageReturn     | 1.52           |
| train-EnvExecTime       | 2.17           |
| train-MaxReturn         | 103            |
| train-MinReturn         | -91.4          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.8            |
| train-StdReturn         | 28.9           |
--------------------------------------------

 ---------------- Iteration 58 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 58             |
| ItrTime                 | 6.46           |
| LossAfter               | -0.02129391    |
| LossBefore              | -1.2702814e-05 |
| Time                    | 370            |
| Time-Optimization       | 0.224          |
| Time-SampleProc         | 0.0843         |
| Time-Sampling           | 6.15           |
| n_timesteps             | 590000         |
| train-AverageDiscoun... | 4.6            |
| train-AverageReturn     | 7.78           |
| train-EnvExecTime       | 2.17           |
| train-MaxReturn         | 47.9           |
| train-MinReturn         | -65.8          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.77           |
| train-StdReturn         | 22.7           |
--------------------------------------------

 ---------------- Iteration 59 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Itr                     | 59              |
| ItrTime                 | 6.36            |
| LossAfter               | -0.019571735    |
| LossBefore              | -1.26686955e-05 |
| Time                    | 377             |
| Time-Optimization       | 0.225           |
| Time-SampleProc         | 0.0478          |
| Time-Sampling           | 6.08            |
| n_timesteps             | 600000          |
| train-AverageDiscoun... | -2.32           |
| train-AverageReturn     | -3.2            |
| train-EnvExecTime       | 2.14            |
| train-MaxReturn         | 75              |
| train-MinReturn         | -206            |
| train-NumTrajs          | 100             |
| train-PolicyExecTime    | 3.75            |
| train-StdReturn         | 33.7            |
---------------------------------------------

 ---------------- Iteration 60 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 60             |
| ItrTime                 | 6.2            |
| LossAfter               | -0.018930295   |
| LossBefore              | -1.2616744e-05 |
| Time                    | 383            |
| Time-Optimization       | 0.248          |
| Time-SampleProc         | 0.0831         |
| Time-Sampling           | 5.87           |
| n_timesteps             | 610000         |
| train-AverageDiscoun... | 0.883          |
| train-AverageReturn     | 1.74           |
| train-EnvExecTime       | 2.06           |
| train-MaxReturn         | 78.3           |
| train-MinReturn         | -77.7          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.61           |
| train-StdReturn         | 32.4           |
--------------------------------------------

 ---------------- Iteration 61 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 61             |
| ItrTime                 | 6.38           |
| LossAfter               | -0.016521825   |
| LossBefore              | -1.2558917e-05 |
| Time                    | 389            |
| Time-Optimization       | 0.212          |
| Time-SampleProc         | 0.0711         |
| Time-Sampling           | 6.1            |
| n_timesteps             | 620000         |
| train-AverageDiscoun... | 3.67           |
| train-AverageReturn     | 5.72           |
| train-EnvExecTime       | 2.13           |
| train-MaxReturn         | 54.5           |
| train-MinReturn         | -103           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.77           |
| train-StdReturn         | 27.1           |
--------------------------------------------

 ---------------- Iteration 62 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 62             |
| ItrTime                 | 6.26           |
| LossAfter               | -0.016992388   |
| LossBefore              | -1.2540144e-05 |
| Time                    | 396            |
| Time-Optimization       | 0.217          |
| Time-SampleProc         | 0.0841         |
| Time-Sampling           | 5.96           |
| n_timesteps             | 630000         |
| train-AverageDiscoun... | 4.92           |
| train-AverageReturn     | 7.2            |
| train-EnvExecTime       | 2.07           |
| train-MaxReturn         | 54.3           |
| train-MinReturn         | -71.5          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.7            |
| train-StdReturn         | 24             |
--------------------------------------------

 ---------------- Iteration 63 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 63            |
| ItrTime                 | 6.16          |
| LossAfter               | -0.020861873  |
| LossBefore              | -1.250259e-05 |
| Time                    | 402           |
| Time-Optimization       | 0.228         |
| Time-SampleProc         | 0.0459        |
| Time-Sampling           | 5.89          |
| n_timesteps             | 640000        |
| train-AverageDiscoun... | 3.96          |
| train-AverageReturn     | 6.34          |
| train-EnvExecTime       | 2.06          |
| train-MaxReturn         | 65.6          |
| train-MinReturn         | -64           |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.64          |
| train-StdReturn         | 23.6          |
-------------------------------------------

 ---------------- Iteration 64 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 64            |
| ItrTime                 | 6.24          |
| LossAfter               | -0.017155169  |
| LossBefore              | -1.248925e-05 |
| Time                    | 408           |
| Time-Optimization       | 0.207         |
| Time-SampleProc         | 0.0827        |
| Time-Sampling           | 5.95          |
| n_timesteps             | 650000        |
| train-AverageDiscoun... | 3.42          |
| train-AverageReturn     | 5.3           |
| train-EnvExecTime       | 2.11          |
| train-MaxReturn         | 50.6          |
| train-MinReturn         | -85.6         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.65          |
| train-StdReturn         | 26.1          |
-------------------------------------------

 ---------------- Iteration 65 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 65             |
| ItrTime                 | 6.08           |
| LossAfter               | -0.020086301   |
| LossBefore              | -1.2428328e-05 |
| Time                    | 414            |
| Time-Optimization       | 0.256          |
| Time-SampleProc         | 0.0497         |
| Time-Sampling           | 5.77           |
| n_timesteps             | 660000         |
| train-AverageDiscoun... | 4.74           |
| train-AverageReturn     | 7.18           |
| train-EnvExecTime       | 2.02           |
| train-MaxReturn         | 61.9           |
| train-MinReturn         | -57.8          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.56           |
| train-StdReturn         | 22.5           |
--------------------------------------------

 ---------------- Iteration 66 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 66             |
| ItrTime                 | 6.31           |
| LossAfter               | -0.020421442   |
| LossBefore              | -1.2410544e-05 |
| Time                    | 420            |
| Time-Optimization       | 0.243          |
| Time-SampleProc         | 0.0387         |
| Time-Sampling           | 6.03           |
| n_timesteps             | 670000         |
| train-AverageDiscoun... | 8.64           |
| train-AverageReturn     | 12.5           |
| train-EnvExecTime       | 2.13           |
| train-MaxReturn         | 88.6           |
| train-MinReturn         | -105           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.71           |
| train-StdReturn         | 28.2           |
--------------------------------------------

 ---------------- Iteration 67 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 67             |
| ItrTime                 | 6.4            |
| LossAfter               | -0.022462513   |
| LossBefore              | -1.2402219e-05 |
| Time                    | 427            |
| Time-Optimization       | 0.213          |
| Time-SampleProc         | 0.0489         |
| Time-Sampling           | 6.13           |
| n_timesteps             | 680000         |
| train-AverageDiscoun... | 7.8            |
| train-AverageReturn     | 10.6           |
| train-EnvExecTime       | 2.17           |
| train-MaxReturn         | 54.9           |
| train-MinReturn         | -42.1          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.75           |
| train-StdReturn         | 20.9           |
--------------------------------------------

 ---------------- Iteration 68 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 68             |
| ItrTime                 | 6.19           |
| LossAfter               | -0.021051528   |
| LossBefore              | -1.2318467e-05 |
| Time                    | 433            |
| Time-Optimization       | 0.242          |
| Time-SampleProc         | 0.0325         |
| Time-Sampling           | 5.92           |
| n_timesteps             | 690000         |
| train-AverageDiscoun... | 4.58           |
| train-AverageReturn     | 7.26           |
| train-EnvExecTime       | 2.09           |
| train-MaxReturn         | 62.7           |
| train-MinReturn         | -94.5          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.63           |
| train-StdReturn         | 26.6           |
--------------------------------------------

 ---------------- Iteration 69 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 69             |
| ItrTime                 | 6.16           |
| LossAfter               | -0.022007424   |
| LossBefore              | -1.2270602e-05 |
| Time                    | 439            |
| Time-Optimization       | 0.217          |
| Time-SampleProc         | 0.0458         |
| Time-Sampling           | 5.9            |
| n_timesteps             | 700000         |
| train-AverageDiscoun... | 7.18           |
| train-AverageReturn     | 11.2           |
| train-EnvExecTime       | 2.07           |
| train-MaxReturn         | 85.5           |
| train-MinReturn         | -52.6          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.63           |
| train-StdReturn         | 26.1           |
--------------------------------------------

 ---------------- Iteration 70 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 70            |
| ItrTime                 | 6.15          |
| LossAfter               | -0.022071451  |
| LossBefore              | -1.221034e-05 |
| Time                    | 445           |
| Time-Optimization       | 0.24          |
| Time-SampleProc         | 0.0703        |
| Time-Sampling           | 5.84          |
| n_timesteps             | 710000        |
| train-AverageDiscoun... | 6.89          |
| train-AverageReturn     | 11.7          |
| train-EnvExecTime       | 2.03          |
| train-MaxReturn         | 58.9          |
| train-MinReturn         | -73.5         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.62          |
| train-StdReturn         | 28.2          |
-------------------------------------------

 ---------------- Iteration 71 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 71            |
| ItrTime                 | 6.47          |
| LossAfter               | -0.01990777   |
| LossBefore              | -1.217827e-05 |
| Time                    | 452           |
| Time-Optimization       | 0.235         |
| Time-SampleProc         | 0.0394        |
| Time-Sampling           | 6.19          |
| n_timesteps             | 720000        |
| train-AverageDiscoun... | 9.03          |
| train-AverageReturn     | 14.1          |
| train-EnvExecTime       | 2.17          |
| train-MaxReturn         | 60.6          |
| train-MinReturn         | -75           |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.82          |
| train-StdReturn         | 25.2          |
-------------------------------------------

 ---------------- Iteration 72 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 72             |
| ItrTime                 | 6.28           |
| LossAfter               | -0.019145567   |
| LossBefore              | -1.2148035e-05 |
| Time                    | 458            |
| Time-Optimization       | 0.234          |
| Time-SampleProc         | 0.0856         |
| Time-Sampling           | 5.96           |
| n_timesteps             | 730000         |
| train-AverageDiscoun... | 7.04           |
| train-AverageReturn     | 11.2           |
| train-EnvExecTime       | 2.08           |
| train-MaxReturn         | 79.7           |
| train-MinReturn         | -115           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.68           |
| train-StdReturn         | 24.9           |
--------------------------------------------

 ---------------- Iteration 73 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Itr                     | 73              |
| ItrTime                 | 6.27            |
| LossAfter               | -0.018493736    |
| LossBefore              | -1.21156245e-05 |
| Time                    | 464             |
| Time-Optimization       | 0.235           |
| Time-SampleProc         | 0.0415          |
| Time-Sampling           | 5.99            |
| n_timesteps             | 740000          |
| train-AverageDiscoun... | 7.05            |
| train-AverageReturn     | 10.6            |
| train-EnvExecTime       | 2.09            |
| train-MaxReturn         | 55.1            |
| train-MinReturn         | -164            |
| train-NumTrajs          | 100             |
| train-PolicyExecTime    | 3.7             |
| train-StdReturn         | 27.7            |
---------------------------------------------

 ---------------- Iteration 74 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 74             |
| ItrTime                 | 6.05           |
| LossAfter               | -0.022428436   |
| LossBefore              | -1.2094149e-05 |
| Time                    | 470            |
| Time-Optimization       | 0.229          |
| Time-SampleProc         | 0.0441         |
| Time-Sampling           | 5.78           |
| n_timesteps             | 750000         |
| train-AverageDiscoun... | 8.26           |
| train-AverageReturn     | 12.5           |
| train-EnvExecTime       | 2.03           |
| train-MaxReturn         | 70.6           |
| train-MinReturn         | -84.9          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.56           |
| train-StdReturn         | 27.4           |
--------------------------------------------

 ---------------- Iteration 75 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 75             |
| ItrTime                 | 6.39           |
| LossAfter               | -0.019022716   |
| LossBefore              | -1.2071262e-05 |
| Time                    | 477            |
| Time-Optimization       | 0.246          |
| Time-SampleProc         | 0.0469         |
| Time-Sampling           | 6.1            |
| n_timesteps             | 760000         |
| train-AverageDiscoun... | 6.4            |
| train-AverageReturn     | 9.82           |
| train-EnvExecTime       | 2.14           |
| train-MaxReturn         | 95.7           |
| train-MinReturn         | -96.9          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.76           |
| train-StdReturn         | 31.6           |
--------------------------------------------

 ---------------- Iteration 76 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 76             |
| ItrTime                 | 6.48           |
| LossAfter               | -0.018640298   |
| LossBefore              | -1.2043583e-05 |
| Time                    | 483            |
| Time-Optimization       | 0.216          |
| Time-SampleProc         | 0.0444         |
| Time-Sampling           | 6.22           |
| n_timesteps             | 770000         |
| train-AverageDiscoun... | 6.5            |
| train-AverageReturn     | 10.3           |
| train-EnvExecTime       | 2.19           |
| train-MaxReturn         | 79.4           |
| train-MinReturn         | -107           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.82           |
| train-StdReturn         | 32             |
--------------------------------------------

 ---------------- Iteration 77 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 77             |
| ItrTime                 | 5.99           |
| LossAfter               | -0.01889069    |
| LossBefore              | -1.2042952e-05 |
| Time                    | 489            |
| Time-Optimization       | 0.225          |
| Time-SampleProc         | 0.0427         |
| Time-Sampling           | 5.73           |
| n_timesteps             | 780000         |
| train-AverageDiscoun... | 13.1           |
| train-AverageReturn     | 19.3           |
| train-EnvExecTime       | 2              |
| train-MaxReturn         | 63.9           |
| train-MinReturn         | -43            |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.53           |
| train-StdReturn         | 21.9           |
--------------------------------------------

 ---------------- Iteration 78 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 78             |
| ItrTime                 | 6.27           |
| LossAfter               | -0.020652002   |
| LossBefore              | -1.2057373e-05 |
| Time                    | 496            |
| Time-Optimization       | 0.258          |
| Time-SampleProc         | 0.0315         |
| Time-Sampling           | 5.98           |
| n_timesteps             | 790000         |
| train-AverageDiscoun... | 10.9           |
| train-AverageReturn     | 16.7           |
| train-EnvExecTime       | 2.11           |
| train-MaxReturn         | 59.6           |
| train-MinReturn         | -94.3          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.68           |
| train-StdReturn         | 26.9           |
--------------------------------------------

 ---------------- Iteration 79 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 79             |
| ItrTime                 | 6.47           |
| LossAfter               | -0.01948158    |
| LossBefore              | -1.2027139e-05 |
| Time                    | 502            |
| Time-Optimization       | 0.227          |
| Time-SampleProc         | 0.0427         |
| Time-Sampling           | 6.2            |
| n_timesteps             | 800000         |
| train-AverageDiscoun... | 13.2           |
| train-AverageReturn     | 19.6           |
| train-EnvExecTime       | 2.18           |
| train-MaxReturn         | 93.8           |
| train-MinReturn         | -104           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.82           |
| train-StdReturn         | 28.7           |
--------------------------------------------

 ---------------- Iteration 80 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 80             |
| ItrTime                 | 6.22           |
| LossAfter               | -0.02167943    |
| LossBefore              | -1.2018654e-05 |
| Time                    | 508            |
| Time-Optimization       | 0.235          |
| Time-SampleProc         | 0.0468         |
| Time-Sampling           | 5.94           |
| n_timesteps             | 810000         |
| train-AverageDiscoun... | 10.8           |
| train-AverageReturn     | 17.5           |
| train-EnvExecTime       | 2.11           |
| train-MaxReturn         | 145            |
| train-MinReturn         | -51.1          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.63           |
| train-StdReturn         | 27.1           |
--------------------------------------------

 ---------------- Iteration 81 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 81             |
| ItrTime                 | 6.18           |
| LossAfter               | -0.020948362   |
| LossBefore              | -1.1971653e-05 |
| Time                    | 514            |
| Time-Optimization       | 0.217          |
| Time-SampleProc         | 0.0818         |
| Time-Sampling           | 5.88           |
| n_timesteps             | 820000         |
| train-AverageDiscoun... | 11.7           |
| train-AverageReturn     | 17.9           |
| train-EnvExecTime       | 2.08           |
| train-MaxReturn         | 101            |
| train-MinReturn         | -60            |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.6            |
| train-StdReturn         | 26             |
--------------------------------------------

 ---------------- Iteration 82 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 82             |
| ItrTime                 | 6.91           |
| LossAfter               | -0.022044657   |
| LossBefore              | -1.1970766e-05 |
| Time                    | 521            |
| Time-Optimization       | 0.326          |
| Time-SampleProc         | 0.075          |
| Time-Sampling           | 6.51           |
| n_timesteps             | 830000         |
| train-AverageDiscoun... | 10.5           |
| train-AverageReturn     | 15.6           |
| train-EnvExecTime       | 2.23           |
| train-MaxReturn         | 127            |
| train-MinReturn         | -84.7          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.06           |
| train-StdReturn         | 30.8           |
--------------------------------------------

 ---------------- Iteration 83 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 83             |
| ItrTime                 | 6.48           |
| LossAfter               | -0.02112944    |
| LossBefore              | -1.1927046e-05 |
| Time                    | 528            |
| Time-Optimization       | 0.232          |
| Time-SampleProc         | 0.0459         |
| Time-Sampling           | 6.2            |
| n_timesteps             | 840000         |
| train-AverageDiscoun... | 10.6           |
| train-AverageReturn     | 16.3           |
| train-EnvExecTime       | 2.17           |
| train-MaxReturn         | 89.4           |
| train-MinReturn         | -86.6          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.83           |
| train-StdReturn         | 26.6           |
--------------------------------------------

 ---------------- Iteration 84 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 84             |
| ItrTime                 | 6.11           |
| LossAfter               | -0.020603439   |
| LossBefore              | -1.1892848e-05 |
| Time                    | 534            |
| Time-Optimization       | 0.216          |
| Time-SampleProc         | 0.0818         |
| Time-Sampling           | 5.81           |
| n_timesteps             | 850000         |
| train-AverageDiscoun... | 12.2           |
| train-AverageReturn     | 19.8           |
| train-EnvExecTime       | 2.03           |
| train-MaxReturn         | 64.8           |
| train-MinReturn         | -77.1          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.59           |
| train-StdReturn         | 23.4           |
--------------------------------------------

 ---------------- Iteration 85 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 85             |
| ItrTime                 | 6.35           |
| LossAfter               | -0.019916592   |
| LossBefore              | -1.1826292e-05 |
| Time                    | 540            |
| Time-Optimization       | 0.25           |
| Time-SampleProc         | 0.0455         |
| Time-Sampling           | 6.06           |
| n_timesteps             | 860000         |
| train-AverageDiscoun... | 13.9           |
| train-AverageReturn     | 21.2           |
| train-EnvExecTime       | 2.13           |
| train-MaxReturn         | 91             |
| train-MinReturn         | -96.2          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.71           |
| train-StdReturn         | 24.4           |
--------------------------------------------

 ---------------- Iteration 86 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 86             |
| ItrTime                 | 6.34           |
| LossAfter               | -0.017991077   |
| LossBefore              | -1.1771633e-05 |
| Time                    | 547            |
| Time-Optimization       | 0.235          |
| Time-SampleProc         | 0.0432         |
| Time-Sampling           | 6.06           |
| n_timesteps             | 870000         |
| train-AverageDiscoun... | 14.1           |
| train-AverageReturn     | 21.3           |
| train-EnvExecTime       | 2.15           |
| train-MaxReturn         | 77.7           |
| train-MinReturn         | -112           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.71           |
| train-StdReturn         | 26.5           |
--------------------------------------------

 ---------------- Iteration 87 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 87             |
| ItrTime                 | 6.01           |
| LossAfter               | -0.022708535   |
| LossBefore              | -1.1758432e-05 |
| Time                    | 553            |
| Time-Optimization       | 0.217          |
| Time-SampleProc         | 0.0402         |
| Time-Sampling           | 5.76           |
| n_timesteps             | 880000         |
| train-AverageDiscoun... | 17.1           |
| train-AverageReturn     | 26             |
| train-EnvExecTime       | 2.02           |
| train-MaxReturn         | 123            |
| train-MinReturn         | -45.8          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.55           |
| train-StdReturn         | 24.8           |
--------------------------------------------

 ---------------- Iteration 88 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 88             |
| ItrTime                 | 6.19           |
| LossAfter               | -0.016904851   |
| LossBefore              | -1.1710843e-05 |
| Time                    | 559            |
| Time-Optimization       | 0.265          |
| Time-SampleProc         | 0.033          |
| Time-Sampling           | 5.89           |
| n_timesteps             | 890000         |
| train-AverageDiscoun... | 14.9           |
| train-AverageReturn     | 21.8           |
| train-EnvExecTime       | 2.07           |
| train-MaxReturn         | 84.4           |
| train-MinReturn         | -130           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.63           |
| train-StdReturn         | 28.8           |
--------------------------------------------

 ---------------- Iteration 89 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Itr                     | 89              |
| ItrTime                 | 6.44            |
| LossAfter               | -0.018868422    |
| LossBefore              | -1.16920455e-05 |
| Time                    | 565             |
| Time-Optimization       | 0.242           |
| Time-SampleProc         | 0.0524          |
| Time-Sampling           | 6.14            |
| n_timesteps             | 900000          |
| train-AverageDiscoun... | 20              |
| train-AverageReturn     | 30.4            |
| train-EnvExecTime       | 2.16            |
| train-MaxReturn         | 104             |
| train-MinReturn         | -97.6           |
| train-NumTrajs          | 100             |
| train-PolicyExecTime    | 3.78            |
| train-StdReturn         | 27.3            |
---------------------------------------------

 ---------------- Iteration 90 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 90             |
| ItrTime                 | 6.5            |
| LossAfter               | -0.0214469     |
| LossBefore              | -1.1670341e-05 |
| Time                    | 572            |
| Time-Optimization       | 0.216          |
| Time-SampleProc         | 0.0833         |
| Time-Sampling           | 6.2            |
| n_timesteps             | 910000         |
| train-AverageDiscoun... | 16.3           |
| train-AverageReturn     | 25.2           |
| train-EnvExecTime       | 2.18           |
| train-MaxReturn         | 99.2           |
| train-MinReturn         | -55.1          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.81           |
| train-StdReturn         | 28.9           |
--------------------------------------------

 ---------------- Iteration 91 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 91             |
| ItrTime                 | 6.27           |
| LossAfter               | -0.020104684   |
| LossBefore              | -1.1657309e-05 |
| Time                    | 578            |
| Time-Optimization       | 0.228          |
| Time-SampleProc         | 0.0854         |
| Time-Sampling           | 5.95           |
| n_timesteps             | 920000         |
| train-AverageDiscoun... | 17.4           |
| train-AverageReturn     | 26.5           |
| train-EnvExecTime       | 2.11           |
| train-MaxReturn         | 96             |
| train-MinReturn         | -67.7          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.64           |
| train-StdReturn         | 28.8           |
--------------------------------------------

 ---------------- Iteration 92 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 92             |
| ItrTime                 | 6.19           |
| LossAfter               | -0.022455238   |
| LossBefore              | -1.1609879e-05 |
| Time                    | 584            |
| Time-Optimization       | 0.244          |
| Time-SampleProc         | 0.0368         |
| Time-Sampling           | 5.91           |
| n_timesteps             | 930000         |
| train-AverageDiscoun... | 18.6           |
| train-AverageReturn     | 29.2           |
| train-EnvExecTime       | 2.09           |
| train-MaxReturn         | 84.7           |
| train-MinReturn         | -67.2          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.63           |
| train-StdReturn         | 26.6           |
--------------------------------------------

 ---------------- Iteration 93 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 93             |
| ItrTime                 | 6.1            |
| LossAfter               | -0.018095005   |
| LossBefore              | -1.1566652e-05 |
| Time                    | 591            |
| Time-Optimization       | 0.239          |
| Time-SampleProc         | 0.0431         |
| Time-Sampling           | 5.81           |
| n_timesteps             | 940000         |
| train-AverageDiscoun... | 15.9           |
| train-AverageReturn     | 24.6           |
| train-EnvExecTime       | 2.03           |
| train-MaxReturn         | 84.6           |
| train-MinReturn         | -106           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.59           |
| train-StdReturn         | 31.1           |
--------------------------------------------

 ---------------- Iteration 94 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Itr                     | 94              |
| ItrTime                 | 6.38            |
| LossAfter               | -0.018349595    |
| LossBefore              | -1.15349385e-05 |
| Time                    | 597             |
| Time-Optimization       | 0.209           |
| Time-SampleProc         | 0.089           |
| Time-Sampling           | 6.08            |
| n_timesteps             | 950000          |
| train-AverageDiscoun... | 19.5            |
| train-AverageReturn     | 30.1            |
| train-EnvExecTime       | 2.15            |
| train-MaxReturn         | 118             |
| train-MinReturn         | -38.9           |
| train-NumTrajs          | 100             |
| train-PolicyExecTime    | 3.73            |
| train-StdReturn         | 26              |
---------------------------------------------

 ---------------- Iteration 95 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 95            |
| ItrTime                 | 6.35          |
| LossAfter               | -0.02360403   |
| LossBefore              | -1.154204e-05 |
| Time                    | 603           |
| Time-Optimization       | 0.213         |
| Time-SampleProc         | 0.0834        |
| Time-Sampling           | 6.05          |
| n_timesteps             | 960000        |
| train-AverageDiscoun... | 20.4          |
| train-AverageReturn     | 31.7          |
| train-EnvExecTime       | 2.13          |
| train-MaxReturn         | 104           |
| train-MinReturn         | -40.7         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.72          |
| train-StdReturn         | 28.2          |
-------------------------------------------

 ---------------- Iteration 96 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 96             |
| ItrTime                 | 6.02           |
| LossAfter               | -0.019426737   |
| LossBefore              | -1.1491571e-05 |
| Time                    | 609            |
| Time-Optimization       | 0.239          |
| Time-SampleProc         | 0.0306         |
| Time-Sampling           | 5.75           |
| n_timesteps             | 970000         |
| train-AverageDiscoun... | 19.5           |
| train-AverageReturn     | 30.4           |
| train-EnvExecTime       | 2.03           |
| train-MaxReturn         | 89             |
| train-MinReturn         | -38.9          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.54           |
| train-StdReturn         | 24.2           |
--------------------------------------------

 ---------------- Iteration 97 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 97             |
| ItrTime                 | 6.26           |
| LossAfter               | -0.020276869   |
| LossBefore              | -1.1503225e-05 |
| Time                    | 616            |
| Time-Optimization       | 0.238          |
| Time-SampleProc         | 0.0443         |
| Time-Sampling           | 5.98           |
| n_timesteps             | 980000         |
| train-AverageDiscoun... | 16.2           |
| train-AverageReturn     | 24.1           |
| train-EnvExecTime       | 2.09           |
| train-MaxReturn         | 65.5           |
| train-MinReturn         | -57.8          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.69           |
| train-StdReturn         | 24.6           |
--------------------------------------------

 ---------------- Iteration 98 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 98             |
| ItrTime                 | 6.41           |
| LossAfter               | -0.019438874   |
| LossBefore              | -1.1476877e-05 |
| Time                    | 622            |
| Time-Optimization       | 0.23           |
| Time-SampleProc         | 0.0316         |
| Time-Sampling           | 6.15           |
| n_timesteps             | 990000         |
| train-AverageDiscoun... | 22.9           |
| train-AverageReturn     | 34.4           |
| train-EnvExecTime       | 2.17           |
| train-MaxReturn         | 169            |
| train-MinReturn         | -54.3          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.78           |
| train-StdReturn         | 26.4           |
--------------------------------------------

 ---------------- Iteration 99 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 99             |
| ItrTime                 | 6.08           |
| LossAfter               | -0.019443367   |
| LossBefore              | -1.1473032e-05 |
| Time                    | 628            |
| Time-Optimization       | 0.232          |
| Time-SampleProc         | 0.044          |
| Time-Sampling           | 5.81           |
| n_timesteps             | 1000000        |
| train-AverageDiscoun... | 20.2           |
| train-AverageReturn     | 30.4           |
| train-EnvExecTime       | 2.04           |
| train-MaxReturn         | 131            |
| train-MinReturn         | -91.3          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.57           |
| train-StdReturn         | 30.1           |
--------------------------------------------

 ---------------- Iteration 100 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 100            |
| ItrTime                 | 6.09           |
| LossAfter               | -0.02003096    |
| LossBefore              | -1.1414976e-05 |
| Time                    | 634            |
| Time-Optimization       | 0.201          |
| Time-SampleProc         | 0.0873         |
| Time-Sampling           | 5.79           |
| n_timesteps             | 1010000        |
| train-AverageDiscoun... | 19.3           |
| train-AverageReturn     | 30.3           |
| train-EnvExecTime       | 2.04           |
| train-MaxReturn         | 129            |
| train-MinReturn         | -102           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.56           |
| train-StdReturn         | 30.5           |
--------------------------------------------

 ---------------- Iteration 101 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Itr                     | 101             |
| ItrTime                 | 6.01            |
| LossAfter               | -0.016561372    |
| LossBefore              | -1.13906135e-05 |
| Time                    | 640             |
| Time-Optimization       | 0.228           |
| Time-SampleProc         | 0.0408          |
| Time-Sampling           | 5.74            |
| n_timesteps             | 1020000         |
| train-AverageDiscoun... | 22.4            |
| train-AverageReturn     | 34.5            |
| train-EnvExecTime       | 2.03            |
| train-MaxReturn         | 103             |
| train-MinReturn         | -29.3           |
| train-NumTrajs          | 100             |
| train-PolicyExecTime    | 3.52            |
| train-StdReturn         | 22.5            |
---------------------------------------------

 ---------------- Iteration 102 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Itr                     | 102             |
| ItrTime                 | 6.46            |
| LossAfter               | -0.021921095    |
| LossBefore              | -1.13581655e-05 |
| Time                    | 647             |
| Time-Optimization       | 0.226           |
| Time-SampleProc         | 0.0662          |
| Time-Sampling           | 6.17            |
| n_timesteps             | 1030000         |
| train-AverageDiscoun... | 20.1            |
| train-AverageReturn     | 31.5            |
| train-EnvExecTime       | 2.16            |
| train-MaxReturn         | 146             |
| train-MinReturn         | -67.6           |
| train-NumTrajs          | 100             |
| train-PolicyExecTime    | 3.81            |
| train-StdReturn         | 30.2            |
---------------------------------------------

 ---------------- Iteration 103 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Itr                     | 103             |
| ItrTime                 | 6.21            |
| LossAfter               | -0.018293994    |
| LossBefore              | -1.12970465e-05 |
| Time                    | 653             |
| Time-Optimization       | 0.236           |
| Time-SampleProc         | 0.0452          |
| Time-Sampling           | 5.92            |
| n_timesteps             | 1040000         |
| train-AverageDiscoun... | 19.3            |
| train-AverageReturn     | 28.1            |
| train-EnvExecTime       | 2.09            |
| train-MaxReturn         | 93.5            |
| train-MinReturn         | -58.7           |
| train-NumTrajs          | 100             |
| train-PolicyExecTime    | 3.64            |
| train-StdReturn         | 28.1            |
---------------------------------------------

 ---------------- Iteration 104 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 104           |
| ItrTime                 | 6.26          |
| LossAfter               | -0.020745672  |
| LossBefore              | -1.125716e-05 |
| Time                    | 659           |
| Time-Optimization       | 0.225         |
| Time-SampleProc         | 0.0507        |
| Time-Sampling           | 5.99          |
| n_timesteps             | 1050000       |
| train-AverageDiscoun... | 20.7          |
| train-AverageReturn     | 32.2          |
| train-EnvExecTime       | 2.11          |
| train-MaxReturn         | 93.4          |
| train-MinReturn         | -72.3         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.68          |
| train-StdReturn         | 25.9          |
-------------------------------------------

 ---------------- Iteration 105 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 105            |
| ItrTime                 | 6.2            |
| LossAfter               | -0.020034937   |
| LossBefore              | -1.1216455e-05 |
| Time                    | 665            |
| Time-Optimization       | 0.249          |
| Time-SampleProc         | 0.0333         |
| Time-Sampling           | 5.91           |
| n_timesteps             | 1060000        |
| train-AverageDiscoun... | 23             |
| train-AverageReturn     | 34             |
| train-EnvExecTime       | 2.08           |
| train-MaxReturn         | 78.8           |
| train-MinReturn         | -75.6          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.63           |
| train-StdReturn         | 23             |
--------------------------------------------

 ---------------- Iteration 106 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 106            |
| ItrTime                 | 6.83           |
| LossAfter               | -0.019135948   |
| LossBefore              | -1.1156389e-05 |
| Time                    | 672            |
| Time-Optimization       | 0.258          |
| Time-SampleProc         | 0.0348         |
| Time-Sampling           | 6.54           |
| n_timesteps             | 1070000        |
| train-AverageDiscoun... | 25.4           |
| train-AverageReturn     | 37.8           |
| train-EnvExecTime       | 2.31           |
| train-MaxReturn         | 100            |
| train-MinReturn         | -39.7          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.02           |
| train-StdReturn         | 21.2           |
--------------------------------------------

 ---------------- Iteration 107 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Itr                     | 107             |
| ItrTime                 | 6.43            |
| LossAfter               | -0.021963615    |
| LossBefore              | -1.11222225e-05 |
| Time                    | 679             |
| Time-Optimization       | 0.246           |
| Time-SampleProc         | 0.0402          |
| Time-Sampling           | 6.14            |
| n_timesteps             | 1080000         |
| train-AverageDiscoun... | 24.3            |
| train-AverageReturn     | 37.5            |
| train-EnvExecTime       | 2.17            |
| train-MaxReturn         | 128             |
| train-MinReturn         | -61.7           |
| train-NumTrajs          | 100             |
| train-PolicyExecTime    | 3.78            |
| train-StdReturn         | 28              |
---------------------------------------------

 ---------------- Iteration 108 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 108            |
| ItrTime                 | 6.17           |
| LossAfter               | -0.019872516   |
| LossBefore              | -1.1089554e-05 |
| Time                    | 685            |
| Time-Optimization       | 0.283          |
| Time-SampleProc         | 0.0401         |
| Time-Sampling           | 5.85           |
| n_timesteps             | 1090000        |
| train-AverageDiscoun... | 26.1           |
| train-AverageReturn     | 40.3           |
| train-EnvExecTime       | 2.06           |
| train-MaxReturn         | 132            |
| train-MinReturn         | -6.68          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.6            |
| train-StdReturn         | 19.5           |
--------------------------------------------

 ---------------- Iteration 109 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 109            |
| ItrTime                 | 6.18           |
| LossAfter               | -0.020286057   |
| LossBefore              | -1.1052879e-05 |
| Time                    | 691            |
| Time-Optimization       | 0.24           |
| Time-SampleProc         | 0.0423         |
| Time-Sampling           | 5.9            |
| n_timesteps             | 1100000        |
| train-AverageDiscoun... | 23.2           |
| train-AverageReturn     | 34.9           |
| train-EnvExecTime       | 2.07           |
| train-MaxReturn         | 74.1           |
| train-MinReturn         | -26.7          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.63           |
| train-StdReturn         | 19.7           |
--------------------------------------------

 ---------------- Iteration 110 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 110            |
| ItrTime                 | 6.07           |
| LossAfter               | -0.022927763   |
| LossBefore              | -1.1002525e-05 |
| Time                    | 697            |
| Time-Optimization       | 0.244          |
| Time-SampleProc         | 0.0442         |
| Time-Sampling           | 5.79           |
| n_timesteps             | 1110000        |
| train-AverageDiscoun... | 21.3           |
| train-AverageReturn     | 31.6           |
| train-EnvExecTime       | 2.01           |
| train-MaxReturn         | 77.8           |
| train-MinReturn         | -36.3          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.58           |
| train-StdReturn         | 21.4           |
--------------------------------------------

 ---------------- Iteration 111 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 111            |
| ItrTime                 | 6.81           |
| LossAfter               | -0.021555843   |
| LossBefore              | -1.0966326e-05 |
| Time                    | 704            |
| Time-Optimization       | 0.281          |
| Time-SampleProc         | 0.0505         |
| Time-Sampling           | 6.48           |
| n_timesteps             | 1120000        |
| train-AverageDiscoun... | 26.9           |
| train-AverageReturn     | 41.3           |
| train-EnvExecTime       | 2.27           |
| train-MaxReturn         | 130            |
| train-MinReturn         | -40.5          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4              |
| train-StdReturn         | 24.2           |
--------------------------------------------

 ---------------- Iteration 112 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 112            |
| ItrTime                 | 7.14           |
| LossAfter               | -0.023428136   |
| LossBefore              | -1.0960549e-05 |
| Time                    | 711            |
| Time-Optimization       | 0.277          |
| Time-SampleProc         | 0.0907         |
| Time-Sampling           | 6.77           |
| n_timesteps             | 1130000        |
| train-AverageDiscoun... | 23.3           |
| train-AverageReturn     | 35.6           |
| train-EnvExecTime       | 2.39           |
| train-MaxReturn         | 105            |
| train-MinReturn         | -60.6          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.15           |
| train-StdReturn         | 27.3           |
--------------------------------------------

 ---------------- Iteration 113 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 113            |
| ItrTime                 | 7.28           |
| LossAfter               | -0.020248443   |
| LossBefore              | -1.0931987e-05 |
| Time                    | 718            |
| Time-Optimization       | 0.261          |
| Time-SampleProc         | 0.0371         |
| Time-Sampling           | 6.98           |
| n_timesteps             | 1140000        |
| train-AverageDiscoun... | 30.4           |
| train-AverageReturn     | 45             |
| train-EnvExecTime       | 2.37           |
| train-MaxReturn         | 156            |
| train-MinReturn         | -48.2          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.38           |
| train-StdReturn         | 28.5           |
--------------------------------------------

 ---------------- Iteration 114 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 114            |
| ItrTime                 | 6.42           |
| LossAfter               | -0.015911542   |
| LossBefore              | -1.0889559e-05 |
| Time                    | 725            |
| Time-Optimization       | 0.241          |
| Time-SampleProc         | 0.0447         |
| Time-Sampling           | 6.13           |
| n_timesteps             | 1150000        |
| train-AverageDiscoun... | 30.3           |
| train-AverageReturn     | 46.1           |
| train-EnvExecTime       | 2.14           |
| train-MaxReturn         | 140            |
| train-MinReturn         | 1.38           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.8            |
| train-StdReturn         | 23             |
--------------------------------------------

 ---------------- Iteration 115 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 115            |
| ItrTime                 | 6.23           |
| LossAfter               | -0.013933507   |
| LossBefore              | -1.0893303e-05 |
| Time                    | 731            |
| Time-Optimization       | 0.236          |
| Time-SampleProc         | 0.0431         |
| Time-Sampling           | 5.95           |
| n_timesteps             | 1160000        |
| train-AverageDiscoun... | 30.2           |
| train-AverageReturn     | 45             |
| train-EnvExecTime       | 2.1            |
| train-MaxReturn         | 158            |
| train-MinReturn         | -24.5          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.66           |
| train-StdReturn         | 25.2           |
--------------------------------------------

 ---------------- Iteration 116 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 116            |
| ItrTime                 | 6.5            |
| LossAfter               | -0.022711476   |
| LossBefore              | -1.0875505e-05 |
| Time                    | 738            |
| Time-Optimization       | 0.265          |
| Time-SampleProc         | 0.0358         |
| Time-Sampling           | 6.2            |
| n_timesteps             | 1170000        |
| train-AverageDiscoun... | 30.6           |
| train-AverageReturn     | 45.4           |
| train-EnvExecTime       | 2.17           |
| train-MaxReturn         | 192            |
| train-MinReturn         | -27.6          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.82           |
| train-StdReturn         | 26.9           |
--------------------------------------------

 ---------------- Iteration 117 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 117            |
| ItrTime                 | 6.87           |
| LossAfter               | -0.02420786    |
| LossBefore              | -1.0855567e-05 |
| Time                    | 744            |
| Time-Optimization       | 0.253          |
| Time-SampleProc         | 0.0502         |
| Time-Sampling           | 6.57           |
| n_timesteps             | 1180000        |
| train-AverageDiscoun... | 28.3           |
| train-AverageReturn     | 41.8           |
| train-EnvExecTime       | 2.33           |
| train-MaxReturn         | 82.9           |
| train-MinReturn         | -41.1          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.02           |
| train-StdReturn         | 22.1           |
--------------------------------------------

 ---------------- Iteration 118 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 118            |
| ItrTime                 | 6.57           |
| LossAfter               | -0.022333652   |
| LossBefore              | -1.0834546e-05 |
| Time                    | 751            |
| Time-Optimization       | 0.227          |
| Time-SampleProc         | 0.0415         |
| Time-Sampling           | 6.3            |
| n_timesteps             | 1190000        |
| train-AverageDiscoun... | 26.8           |
| train-AverageReturn     | 39.4           |
| train-EnvExecTime       | 2.22           |
| train-MaxReturn         | 101            |
| train-MinReturn         | -78.6          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.88           |
| train-StdReturn         | 26.8           |
--------------------------------------------

 ---------------- Iteration 119 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 119            |
| ItrTime                 | 6.06           |
| LossAfter               | -0.02429042    |
| LossBefore              | -1.0804358e-05 |
| Time                    | 757            |
| Time-Optimization       | 0.225          |
| Time-SampleProc         | 0.044          |
| Time-Sampling           | 5.79           |
| n_timesteps             | 1200000        |
| train-AverageDiscoun... | 28.7           |
| train-AverageReturn     | 43.5           |
| train-EnvExecTime       | 2.03           |
| train-MaxReturn         | 137            |
| train-MinReturn         | -42.6          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.57           |
| train-StdReturn         | 24.2           |
--------------------------------------------

 ---------------- Iteration 120 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 120            |
| ItrTime                 | 6.05           |
| LossAfter               | -0.02178305    |
| LossBefore              | -1.0769232e-05 |
| Time                    | 763            |
| Time-Optimization       | 0.225          |
| Time-SampleProc         | 0.0573         |
| Time-Sampling           | 5.77           |
| n_timesteps             | 1210000        |
| train-AverageDiscoun... | 30             |
| train-AverageReturn     | 45.3           |
| train-EnvExecTime       | 2.03           |
| train-MaxReturn         | 123            |
| train-MinReturn         | -80            |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.55           |
| train-StdReturn         | 25.9           |
--------------------------------------------

 ---------------- Iteration 121 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 121            |
| ItrTime                 | 6.04           |
| LossAfter               | -0.021307763   |
| LossBefore              | -1.0734061e-05 |
| Time                    | 769            |
| Time-Optimization       | 0.233          |
| Time-SampleProc         | 0.0445         |
| Time-Sampling           | 5.77           |
| n_timesteps             | 1220000        |
| train-AverageDiscoun... | 32             |
| train-AverageReturn     | 48             |
| train-EnvExecTime       | 2.02           |
| train-MaxReturn         | 139            |
| train-MinReturn         | -29.9          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.55           |
| train-StdReturn         | 25.2           |
--------------------------------------------

 ---------------- Iteration 122 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 122            |
| ItrTime                 | 6.53           |
| LossAfter               | -0.019971585   |
| LossBefore              | -1.0720137e-05 |
| Time                    | 776            |
| Time-Optimization       | 0.23           |
| Time-SampleProc         | 0.0443         |
| Time-Sampling           | 6.26           |
| n_timesteps             | 1230000        |
| train-AverageDiscoun... | 34.3           |
| train-AverageReturn     | 50.5           |
| train-EnvExecTime       | 2.2            |
| train-MaxReturn         | 167            |
| train-MinReturn         | 1.12           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.85           |
| train-StdReturn         | 22.6           |
--------------------------------------------

 ---------------- Iteration 123 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 123            |
| ItrTime                 | 6.25           |
| LossAfter               | -0.02070444    |
| LossBefore              | -1.0680021e-05 |
| Time                    | 782            |
| Time-Optimization       | 0.224          |
| Time-SampleProc         | 0.059          |
| Time-Sampling           | 5.97           |
| n_timesteps             | 1240000        |
| train-AverageDiscoun... | 31.5           |
| train-AverageReturn     | 47.2           |
| train-EnvExecTime       | 2.1            |
| train-MaxReturn         | 196            |
| train-MinReturn         | -89            |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.67           |
| train-StdReturn         | 34.5           |
--------------------------------------------

 ---------------- Iteration 124 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 124            |
| ItrTime                 | 6.26           |
| LossAfter               | -0.022442997   |
| LossBefore              | -1.0641168e-05 |
| Time                    | 788            |
| Time-Optimization       | 0.22           |
| Time-SampleProc         | 0.0834         |
| Time-Sampling           | 5.96           |
| n_timesteps             | 1250000        |
| train-AverageDiscoun... | 30.6           |
| train-AverageReturn     | 44.6           |
| train-EnvExecTime       | 2.09           |
| train-MaxReturn         | 105            |
| train-MinReturn         | -42.2          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.67           |
| train-StdReturn         | 23.1           |
--------------------------------------------

 ---------------- Iteration 125 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 125            |
| ItrTime                 | 6.2            |
| LossAfter               | -0.01940905    |
| LossBefore              | -1.0632567e-05 |
| Time                    | 795            |
| Time-Optimization       | 0.229          |
| Time-SampleProc         | 0.0466         |
| Time-Sampling           | 5.93           |
| n_timesteps             | 1260000        |
| train-AverageDiscoun... | 31.4           |
| train-AverageReturn     | 47.4           |
| train-EnvExecTime       | 2.09           |
| train-MaxReturn         | 99.2           |
| train-MinReturn         | -8.4           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.64           |
| train-StdReturn         | 19.8           |
--------------------------------------------

 ---------------- Iteration 126 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 126            |
| ItrTime                 | 6.06           |
| LossAfter               | -0.019218989   |
| LossBefore              | -1.0608969e-05 |
| Time                    | 801            |
| Time-Optimization       | 0.225          |
| Time-SampleProc         | 0.0444         |
| Time-Sampling           | 5.79           |
| n_timesteps             | 1270000        |
| train-AverageDiscoun... | 30.9           |
| train-AverageReturn     | 44.9           |
| train-EnvExecTime       | 2.02           |
| train-MaxReturn         | 107            |
| train-MinReturn         | -51.8          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.57           |
| train-StdReturn         | 24.4           |
--------------------------------------------

 ---------------- Iteration 127 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Itr                     | 127             |
| ItrTime                 | 6.07            |
| LossAfter               | -0.020113751    |
| LossBefore              | -1.05836925e-05 |
| Time                    | 807             |
| Time-Optimization       | 0.25            |
| Time-SampleProc         | 0.0464          |
| Time-Sampling           | 5.77            |
| n_timesteps             | 1280000         |
| train-AverageDiscoun... | 30.9            |
| train-AverageReturn     | 45.3            |
| train-EnvExecTime       | 2.03            |
| train-MaxReturn         | 113             |
| train-MinReturn         | -43.9           |
| train-NumTrajs          | 100             |
| train-PolicyExecTime    | 3.55            |
| train-StdReturn         | 23.3            |
---------------------------------------------

 ---------------- Iteration 128 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 128            |
| ItrTime                 | 6.43           |
| LossAfter               | -0.022646895   |
| LossBefore              | -1.0543432e-05 |
| Time                    | 813            |
| Time-Optimization       | 0.244          |
| Time-SampleProc         | 0.0448         |
| Time-Sampling           | 6.14           |
| n_timesteps             | 1290000        |
| train-AverageDiscoun... | 32.8           |
| train-AverageReturn     | 48.8           |
| train-EnvExecTime       | 2.17           |
| train-MaxReturn         | 132            |
| train-MinReturn         | -47.1          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.76           |
| train-StdReturn         | 26.4           |
--------------------------------------------

 ---------------- Iteration 129 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 129            |
| ItrTime                 | 6.2            |
| LossAfter               | -0.022590661   |
| LossBefore              | -1.0514773e-05 |
| Time                    | 819            |
| Time-Optimization       | 0.234          |
| Time-SampleProc         | 0.0829         |
| Time-Sampling           | 5.88           |
| n_timesteps             | 1300000        |
| train-AverageDiscoun... | 31.6           |
| train-AverageReturn     | 46.5           |
| train-EnvExecTime       | 2.07           |
| train-MaxReturn         | 135            |
| train-MinReturn         | -19.1          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.62           |
| train-StdReturn         | 23.8           |
--------------------------------------------

 ---------------- Iteration 130 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 130            |
| ItrTime                 | 6.22           |
| LossAfter               | -0.021970632   |
| LossBefore              | -1.0485825e-05 |
| Time                    | 826            |
| Time-Optimization       | 0.244          |
| Time-SampleProc         | 0.0403         |
| Time-Sampling           | 5.93           |
| n_timesteps             | 1310000        |
| train-AverageDiscoun... | 36.7           |
| train-AverageReturn     | 53.6           |
| train-EnvExecTime       | 2.09           |
| train-MaxReturn         | 152            |
| train-MinReturn         | -21.6          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.65           |
| train-StdReturn         | 25.9           |
--------------------------------------------

 ---------------- Iteration 131 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 131           |
| ItrTime                 | 6.03          |
| LossAfter               | -0.019689031  |
| LossBefore              | -1.042954e-05 |
| Time                    | 832           |
| Time-Optimization       | 0.224         |
| Time-SampleProc         | 0.0724        |
| Time-Sampling           | 5.73          |
| n_timesteps             | 1320000       |
| train-AverageDiscoun... | 34.2          |
| train-AverageReturn     | 50.9          |
| train-EnvExecTime       | 2             |
| train-MaxReturn         | 137           |
| train-MinReturn         | -22.1         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.54          |
| train-StdReturn         | 24.8          |
-------------------------------------------

 ---------------- Iteration 132 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 132            |
| ItrTime                 | 6.06           |
| LossAfter               | -0.018964177   |
| LossBefore              | -1.0380944e-05 |
| Time                    | 838            |
| Time-Optimization       | 0.239          |
| Time-SampleProc         | 0.0325         |
| Time-Sampling           | 5.79           |
| n_timesteps             | 1330000        |
| train-AverageDiscoun... | 34.2           |
| train-AverageReturn     | 50.1           |
| train-EnvExecTime       | 2.02           |
| train-MaxReturn         | 105            |
| train-MinReturn         | -29.1          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.58           |
| train-StdReturn         | 22             |
--------------------------------------------

 ---------------- Iteration 133 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 133            |
| ItrTime                 | 6.24           |
| LossAfter               | -0.01650898    |
| LossBefore              | -1.0367073e-05 |
| Time                    | 844            |
| Time-Optimization       | 0.263          |
| Time-SampleProc         | 0.0438         |
| Time-Sampling           | 5.93           |
| n_timesteps             | 1340000        |
| train-AverageDiscoun... | 36.4           |
| train-AverageReturn     | 53             |
| train-EnvExecTime       | 2.1            |
| train-MaxReturn         | 111            |
| train-MinReturn         | -0.0371        |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.63           |
| train-StdReturn         | 22.5           |
--------------------------------------------

 ---------------- Iteration 134 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 134            |
| ItrTime                 | 6.5            |
| LossAfter               | -0.018041201   |
| LossBefore              | -1.0347285e-05 |
| Time                    | 850            |
| Time-Optimization       | 0.236          |
| Time-SampleProc         | 0.0859         |
| Time-Sampling           | 6.17           |
| n_timesteps             | 1350000        |
| train-AverageDiscoun... | 32.6           |
| train-AverageReturn     | 47.8           |
| train-EnvExecTime       | 2.18           |
| train-MaxReturn         | 97.2           |
| train-MinReturn         | -36.4          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.79           |
| train-StdReturn         | 21.6           |
--------------------------------------------

 ---------------- Iteration 135 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 135            |
| ItrTime                 | 6.48           |
| LossAfter               | -0.022685813   |
| LossBefore              | -1.0312523e-05 |
| Time                    | 857            |
| Time-Optimization       | 0.246          |
| Time-SampleProc         | 0.049          |
| Time-Sampling           | 6.18           |
| n_timesteps             | 1360000        |
| train-AverageDiscoun... | 34.1           |
| train-AverageReturn     | 50.2           |
| train-EnvExecTime       | 2.18           |
| train-MaxReturn         | 110            |
| train-MinReturn         | -72.2          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.8            |
| train-StdReturn         | 28.6           |
--------------------------------------------

 ---------------- Iteration 136 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 136            |
| ItrTime                 | 6.39           |
| LossAfter               | -0.020726439   |
| LossBefore              | -1.0290737e-05 |
| Time                    | 863            |
| Time-Optimization       | 0.243          |
| Time-SampleProc         | 0.0581         |
| Time-Sampling           | 6.09           |
| n_timesteps             | 1370000        |
| train-AverageDiscoun... | 32.8           |
| train-AverageReturn     | 47.5           |
| train-EnvExecTime       | 2.14           |
| train-MaxReturn         | 150            |
| train-MinReturn         | -27.9          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.75           |
| train-StdReturn         | 24.1           |
--------------------------------------------

 ---------------- Iteration 137 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 137            |
| ItrTime                 | 6.45           |
| LossAfter               | -0.022064079   |
| LossBefore              | -1.0289797e-05 |
| Time                    | 870            |
| Time-Optimization       | 0.243          |
| Time-SampleProc         | 0.0887         |
| Time-Sampling           | 6.1            |
| n_timesteps             | 1380000        |
| train-AverageDiscoun... | 34.8           |
| train-AverageReturn     | 51.3           |
| train-EnvExecTime       | 2.14           |
| train-MaxReturn         | 163            |
| train-MinReturn         | -79.5          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.77           |
| train-StdReturn         | 32.2           |
--------------------------------------------

 ---------------- Iteration 138 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 138            |
| ItrTime                 | 6.3            |
| LossAfter               | -0.019126281   |
| LossBefore              | -1.0267549e-05 |
| Time                    | 876            |
| Time-Optimization       | 0.284          |
| Time-SampleProc         | 0.0493         |
| Time-Sampling           | 5.96           |
| n_timesteps             | 1390000        |
| train-AverageDiscoun... | 32.5           |
| train-AverageReturn     | 48.1           |
| train-EnvExecTime       | 2.1            |
| train-MaxReturn         | 84.1           |
| train-MinReturn         | -7.7           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.67           |
| train-StdReturn         | 21.3           |
--------------------------------------------

 ---------------- Iteration 139 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 139            |
| ItrTime                 | 6.06           |
| LossAfter               | -0.020109285   |
| LossBefore              | -1.0256644e-05 |
| Time                    | 882            |
| Time-Optimization       | 0.364          |
| Time-SampleProc         | 0.0447         |
| Time-Sampling           | 5.65           |
| n_timesteps             | 1400000        |
| train-AverageDiscoun... | 36.5           |
| train-AverageReturn     | 52.9           |
| train-EnvExecTime       | 2              |
| train-MaxReturn         | 121            |
| train-MinReturn         | -108           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.45           |
| train-StdReturn         | 25.8           |
--------------------------------------------

 ---------------- Iteration 140 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 140            |
| ItrTime                 | 6.17           |
| LossAfter               | -0.02241254    |
| LossBefore              | -1.0211275e-05 |
| Time                    | 888            |
| Time-Optimization       | 0.304          |
| Time-SampleProc         | 0.0499         |
| Time-Sampling           | 5.82           |
| n_timesteps             | 1410000        |
| train-AverageDiscoun... | 34.6           |
| train-AverageReturn     | 51             |
| train-EnvExecTime       | 2.06           |
| train-MaxReturn         | 152            |
| train-MinReturn         | -49            |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.57           |
| train-StdReturn         | 23.6           |
--------------------------------------------

 ---------------- Iteration 141 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 141           |
| ItrTime                 | 6.42          |
| LossAfter               | -0.021719018  |
| LossBefore              | -1.019749e-05 |
| Time                    | 895           |
| Time-Optimization       | 0.215         |
| Time-SampleProc         | 0.0505        |
| Time-Sampling           | 6.15          |
| n_timesteps             | 1420000       |
| train-AverageDiscoun... | 34.1          |
| train-AverageReturn     | 50.6          |
| train-EnvExecTime       | 2.15          |
| train-MaxReturn         | 80.8          |
| train-MinReturn         | -10.5         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.8           |
| train-StdReturn         | 19            |
-------------------------------------------

 ---------------- Iteration 142 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 142            |
| ItrTime                 | 6.09           |
| LossAfter               | -0.022810698   |
| LossBefore              | -1.0172709e-05 |
| Time                    | 901            |
| Time-Optimization       | 0.227          |
| Time-SampleProc         | 0.0396         |
| Time-Sampling           | 5.83           |
| n_timesteps             | 1430000        |
| train-AverageDiscoun... | 36.3           |
| train-AverageReturn     | 53.3           |
| train-EnvExecTime       | 2.02           |
| train-MaxReturn         | 117            |
| train-MinReturn         | -0.602         |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.61           |
| train-StdReturn         | 21.4           |
--------------------------------------------

 ---------------- Iteration 143 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 143            |
| ItrTime                 | 6.13           |
| LossAfter               | -0.024295334   |
| LossBefore              | -1.0142174e-05 |
| Time                    | 907            |
| Time-Optimization       | 0.241          |
| Time-SampleProc         | 0.0891         |
| Time-Sampling           | 5.8            |
| n_timesteps             | 1440000        |
| train-AverageDiscoun... | 36.5           |
| train-AverageReturn     | 53.9           |
| train-EnvExecTime       | 2.06           |
| train-MaxReturn         | 98.6           |
| train-MinReturn         | -14            |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.55           |
| train-StdReturn         | 22.8           |
--------------------------------------------

 ---------------- Iteration 144 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 144            |
| ItrTime                 | 6.5            |
| LossAfter               | -0.022747958   |
| LossBefore              | -1.0115111e-05 |
| Time                    | 914            |
| Time-Optimization       | 0.241          |
| Time-SampleProc         | 0.0454         |
| Time-Sampling           | 6.21           |
| n_timesteps             | 1450000        |
| train-AverageDiscoun... | 39             |
| train-AverageReturn     | 58             |
| train-EnvExecTime       | 2.16           |
| train-MaxReturn         | 141            |
| train-MinReturn         | -17.6          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.84           |
| train-StdReturn         | 22.4           |
--------------------------------------------

 ---------------- Iteration 145 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 145            |
| ItrTime                 | 6.31           |
| LossAfter               | -0.02077659    |
| LossBefore              | -1.0058411e-05 |
| Time                    | 920            |
| Time-Optimization       | 0.259          |
| Time-SampleProc         | 0.0335         |
| Time-Sampling           | 6.02           |
| n_timesteps             | 1460000        |
| train-AverageDiscoun... | 37             |
| train-AverageReturn     | 55.9           |
| train-EnvExecTime       | 2.11           |
| train-MaxReturn         | 120            |
| train-MinReturn         | -35.3          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.71           |
| train-StdReturn         | 22             |
--------------------------------------------

 ---------------- Iteration 146 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 146           |
| ItrTime                 | 6.26          |
| LossAfter               | -0.02251237   |
| LossBefore              | -9.994802e-06 |
| Time                    | 926           |
| Time-Optimization       | 0.234         |
| Time-SampleProc         | 0.035         |
| Time-Sampling           | 5.99          |
| n_timesteps             | 1470000       |
| train-AverageDiscoun... | 39.6          |
| train-AverageReturn     | 59.3          |
| train-EnvExecTime       | 2.08          |
| train-MaxReturn         | 202           |
| train-MinReturn         | -17.5         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.71          |
| train-StdReturn         | 28.1          |
-------------------------------------------

 ---------------- Iteration 147 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 147          |
| ItrTime                 | 6.96         |
| LossAfter               | -0.024356889 |
| LossBefore              | -9.96083e-06 |
| Time                    | 933          |
| Time-Optimization       | 0.252        |
| Time-SampleProc         | 0.0512       |
| Time-Sampling           | 6.65         |
| n_timesteps             | 1480000      |
| train-AverageDiscoun... | 38.2         |
| train-AverageReturn     | 56.4         |
| train-EnvExecTime       | 2.29         |
| train-MaxReturn         | 102          |
| train-MinReturn         | -9.53        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 4.15         |
| train-StdReturn         | 21           |
------------------------------------------

 ---------------- Iteration 148 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 148           |
| ItrTime                 | 6.6           |
| LossAfter               | -0.02384828   |
| LossBefore              | -9.913275e-06 |
| Time                    | 940           |
| Time-Optimization       | 0.245         |
| Time-SampleProc         | 0.0427        |
| Time-Sampling           | 6.32          |
| n_timesteps             | 1490000       |
| train-AverageDiscoun... | 37.8          |
| train-AverageReturn     | 56.3          |
| train-EnvExecTime       | 2.2           |
| train-MaxReturn         | 147           |
| train-MinReturn         | -59.5         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.91          |
| train-StdReturn         | 24.9          |
-------------------------------------------

 ---------------- Iteration 149 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 149           |
| ItrTime                 | 6.26          |
| LossAfter               | -0.02317038   |
| LossBefore              | -9.892029e-06 |
| Time                    | 946           |
| Time-Optimization       | 0.23          |
| Time-SampleProc         | 0.0497        |
| Time-Sampling           | 5.98          |
| n_timesteps             | 1500000       |
| train-AverageDiscoun... | 38.3          |
| train-AverageReturn     | 56.4          |
| train-EnvExecTime       | 2.09          |
| train-MaxReturn         | 134           |
| train-MinReturn         | -33.8         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.7           |
| train-StdReturn         | 24.1          |
-------------------------------------------

 ---------------- Iteration 150 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 150           |
| ItrTime                 | 6             |
| LossAfter               | -0.019914707  |
| LossBefore              | -9.851995e-06 |
| Time                    | 952           |
| Time-Optimization       | 0.211         |
| Time-SampleProc         | 0.0825        |
| Time-Sampling           | 5.7           |
| n_timesteps             | 1510000       |
| train-AverageDiscoun... | 40.6          |
| train-AverageReturn     | 60            |
| train-EnvExecTime       | 2.01          |
| train-MaxReturn         | 112           |
| train-MinReturn         | -32.1         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.51          |
| train-StdReturn         | 23.4          |
-------------------------------------------

 ---------------- Iteration 151 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 151           |
| ItrTime                 | 6.35          |
| LossAfter               | -0.017517442  |
| LossBefore              | -9.790088e-06 |
| Time                    | 958           |
| Time-Optimization       | 0.248         |
| Time-SampleProc         | 0.045         |
| Time-Sampling           | 6.05          |
| n_timesteps             | 1520000       |
| train-AverageDiscoun... | 40.7          |
| train-AverageReturn     | 59.8          |
| train-EnvExecTime       | 2.14          |
| train-MaxReturn         | 141           |
| train-MinReturn         | -28.2         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.72          |
| train-StdReturn         | 22.4          |
-------------------------------------------

 ---------------- Iteration 152 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 152           |
| ItrTime                 | 6.3           |
| LossAfter               | -0.022026574  |
| LossBefore              | -9.748955e-06 |
| Time                    | 965           |
| Time-Optimization       | 0.234         |
| Time-SampleProc         | 0.0407        |
| Time-Sampling           | 6.03          |
| n_timesteps             | 1530000       |
| train-AverageDiscoun... | 39.6          |
| train-AverageReturn     | 58.6          |
| train-EnvExecTime       | 2.09          |
| train-MaxReturn         | 110           |
| train-MinReturn         | 8.88          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.74          |
| train-StdReturn         | 19.3          |
-------------------------------------------

 ---------------- Iteration 153 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 153           |
| ItrTime                 | 6.24          |
| LossAfter               | -0.021608124  |
| LossBefore              | -9.725358e-06 |
| Time                    | 971           |
| Time-Optimization       | 0.244         |
| Time-SampleProc         | 0.0337        |
| Time-Sampling           | 5.96          |
| n_timesteps             | 1540000       |
| train-AverageDiscoun... | 38.7          |
| train-AverageReturn     | 56.7          |
| train-EnvExecTime       | 2.1           |
| train-MaxReturn         | 157           |
| train-MinReturn         | -65           |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.66          |
| train-StdReturn         | 24.7          |
-------------------------------------------

 ---------------- Iteration 154 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 154            |
| ItrTime                 | 6.28           |
| LossAfter               | -0.018975606   |
| LossBefore              | -9.7230395e-06 |
| Time                    | 977            |
| Time-Optimization       | 0.224          |
| Time-SampleProc         | 0.116          |
| Time-Sampling           | 5.94           |
| n_timesteps             | 1550000        |
| train-AverageDiscoun... | 40.7           |
| train-AverageReturn     | 60.2           |
| train-EnvExecTime       | 2.08           |
| train-MaxReturn         | 144            |
| train-MinReturn         | -30.8          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.67           |
| train-StdReturn         | 22.3           |
--------------------------------------------

 ---------------- Iteration 155 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 155           |
| ItrTime                 | 6.14          |
| LossAfter               | -0.020198302  |
| LossBefore              | -9.686104e-06 |
| Time                    | 983           |
| Time-Optimization       | 0.222         |
| Time-SampleProc         | 0.0449        |
| Time-Sampling           | 5.87          |
| n_timesteps             | 1560000       |
| train-AverageDiscoun... | 40.6          |
| train-AverageReturn     | 59.9          |
| train-EnvExecTime       | 2.07          |
| train-MaxReturn         | 127           |
| train-MinReturn         | -0.955        |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.61          |
| train-StdReturn         | 21.7          |
-------------------------------------------

 ---------------- Iteration 156 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 156          |
| ItrTime                 | 6.05         |
| LossAfter               | -0.020389354 |
| LossBefore              | -9.66398e-06 |
| Time                    | 989          |
| Time-Optimization       | 0.239        |
| Time-SampleProc         | 0.0455       |
| Time-Sampling           | 5.76         |
| n_timesteps             | 1570000      |
| train-AverageDiscoun... | 40           |
| train-AverageReturn     | 59.6         |
| train-EnvExecTime       | 2            |
| train-MaxReturn         | 105          |
| train-MinReturn         | 1.91         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 3.57         |
| train-StdReturn         | 19.9         |
------------------------------------------

 ---------------- Iteration 157 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 157           |
| ItrTime                 | 6.46          |
| LossAfter               | -0.021750623  |
| LossBefore              | -9.678582e-06 |
| Time                    | 996           |
| Time-Optimization       | 0.239         |
| Time-SampleProc         | 0.0879        |
| Time-Sampling           | 6.14          |
| n_timesteps             | 1580000       |
| train-AverageDiscoun... | 39.4          |
| train-AverageReturn     | 58.5          |
| train-EnvExecTime       | 2.15          |
| train-MaxReturn         | 159           |
| train-MinReturn         | -0.813        |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.79          |
| train-StdReturn         | 23.1          |
-------------------------------------------

 ---------------- Iteration 158 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 158           |
| ItrTime                 | 6.27          |
| LossAfter               | -0.019408725  |
| LossBefore              | -9.683968e-06 |
| Time                    | 1e+03         |
| Time-Optimization       | 0.223         |
| Time-SampleProc         | 0.0537        |
| Time-Sampling           | 5.99          |
| n_timesteps             | 1590000       |
| train-AverageDiscoun... | 38            |
| train-AverageReturn     | 56.2          |
| train-EnvExecTime       | 2.09          |
| train-MaxReturn         | 137           |
| train-MinReturn         | -19.7         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.7           |
| train-StdReturn         | 22.6          |
-------------------------------------------

 ---------------- Iteration 159 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 159          |
| ItrTime                 | 6.25         |
| LossAfter               | -0.012008573 |
| LossBefore              | -9.66158e-06 |
| Time                    | 1.01e+03     |
| Time-Optimization       | 0.226        |
| Time-SampleProc         | 0.0449       |
| Time-Sampling           | 5.98         |
| n_timesteps             | 1600000      |
| train-AverageDiscoun... | 39.5         |
| train-AverageReturn     | 58.6         |
| train-EnvExecTime       | 2.08         |
| train-MaxReturn         | 107          |
| train-MinReturn         | -21          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 3.7          |
| train-StdReturn         | 22.6         |
------------------------------------------

 ---------------- Iteration 160 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 160            |
| ItrTime                 | 6.29           |
| LossAfter               | -0.021208297   |
| LossBefore              | -9.6709655e-06 |
| Time                    | 1.01e+03       |
| Time-Optimization       | 0.216          |
| Time-SampleProc         | 0.0524         |
| Time-Sampling           | 6.02           |
| n_timesteps             | 1610000        |
| train-AverageDiscoun... | 40.5           |
| train-AverageReturn     | 59.3           |
| train-EnvExecTime       | 2.11           |
| train-MaxReturn         | 170            |
| train-MinReturn         | -3.51          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.72           |
| train-StdReturn         | 23.9           |
--------------------------------------------

 ---------------- Iteration 161 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 161           |
| ItrTime                 | 6.02          |
| LossAfter               | -0.021779694  |
| LossBefore              | -9.638079e-06 |
| Time                    | 1.02e+03      |
| Time-Optimization       | 0.228         |
| Time-SampleProc         | 0.0297        |
| Time-Sampling           | 5.76          |
| n_timesteps             | 1620000       |
| train-AverageDiscoun... | 40.6          |
| train-AverageReturn     | 60.3          |
| train-EnvExecTime       | 2.02          |
| train-MaxReturn         | 169           |
| train-MinReturn         | -33.1         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.55          |
| train-StdReturn         | 28.8          |
-------------------------------------------

 ---------------- Iteration 162 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 162           |
| ItrTime                 | 6.13          |
| LossAfter               | -0.019517578  |
| LossBefore              | -9.640812e-06 |
| Time                    | 1.03e+03      |
| Time-Optimization       | 0.261         |
| Time-SampleProc         | 0.042         |
| Time-Sampling           | 5.82          |
| n_timesteps             | 1630000       |
| train-AverageDiscoun... | 38.8          |
| train-AverageReturn     | 56.9          |
| train-EnvExecTime       | 2.04          |
| train-MaxReturn         | 109           |
| train-MinReturn         | -47.2         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.59          |
| train-StdReturn         | 25            |
-------------------------------------------

 ---------------- Iteration 163 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 163           |
| ItrTime                 | 6.48          |
| LossAfter               | -0.02092919   |
| LossBefore              | -9.598858e-06 |
| Time                    | 1.03e+03      |
| Time-Optimization       | 0.238         |
| Time-SampleProc         | 0.0495        |
| Time-Sampling           | 6.19          |
| n_timesteps             | 1640000       |
| train-AverageDiscoun... | 38.3          |
| train-AverageReturn     | 56.1          |
| train-EnvExecTime       | 2.19          |
| train-MaxReturn         | 102           |
| train-MinReturn         | -73.1         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.8           |
| train-StdReturn         | 25.2          |
-------------------------------------------

 ---------------- Iteration 164 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 164            |
| ItrTime                 | 6.51           |
| LossAfter               | -0.01861881    |
| LossBefore              | -9.5413725e-06 |
| Time                    | 1.04e+03       |
| Time-Optimization       | 0.235          |
| Time-SampleProc         | 0.0381         |
| Time-Sampling           | 6.23           |
| n_timesteps             | 1650000        |
| train-AverageDiscoun... | 43.1           |
| train-AverageReturn     | 64.5           |
| train-EnvExecTime       | 2.19           |
| train-MaxReturn         | 172            |
| train-MinReturn         | -5.93          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.84           |
| train-StdReturn         | 25.2           |
--------------------------------------------

 ---------------- Iteration 165 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 165           |
| ItrTime                 | 6.16          |
| LossAfter               | -0.02215199   |
| LossBefore              | -9.529637e-06 |
| Time                    | 1.05e+03      |
| Time-Optimization       | 0.226         |
| Time-SampleProc         | 0.0444        |
| Time-Sampling           | 5.89          |
| n_timesteps             | 1660000       |
| train-AverageDiscoun... | 40.6          |
| train-AverageReturn     | 59.8          |
| train-EnvExecTime       | 2.08          |
| train-MaxReturn         | 110           |
| train-MinReturn         | -49.8         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.62          |
| train-StdReturn         | 22.7          |
-------------------------------------------

 ---------------- Iteration 166 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 166           |
| ItrTime                 | 6.25          |
| LossAfter               | -0.020674925  |
| LossBefore              | -9.479527e-06 |
| Time                    | 1.05e+03      |
| Time-Optimization       | 0.219         |
| Time-SampleProc         | 0.0552        |
| Time-Sampling           | 5.97          |
| n_timesteps             | 1670000       |
| train-AverageDiscoun... | 40.8          |
| train-AverageReturn     | 61.2          |
| train-EnvExecTime       | 2.09          |
| train-MaxReturn         | 99.8          |
| train-MinReturn         | 6.06          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.68          |
| train-StdReturn         | 20.3          |
-------------------------------------------

 ---------------- Iteration 167 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 167           |
| ItrTime                 | 6.24          |
| LossAfter               | -0.019170992  |
| LossBefore              | -9.436251e-06 |
| Time                    | 1.06e+03      |
| Time-Optimization       | 0.223         |
| Time-SampleProc         | 0.0574        |
| Time-Sampling           | 5.96          |
| n_timesteps             | 1680000       |
| train-AverageDiscoun... | 42.5          |
| train-AverageReturn     | 62.4          |
| train-EnvExecTime       | 2.1           |
| train-MaxReturn         | 108           |
| train-MinReturn         | -66           |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.67          |
| train-StdReturn         | 23.3          |
-------------------------------------------

 ---------------- Iteration 168 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 168           |
| ItrTime                 | 6.06          |
| LossAfter               | -0.019795582  |
| LossBefore              | -9.426131e-06 |
| Time                    | 1.06e+03      |
| Time-Optimization       | 0.217         |
| Time-SampleProc         | 0.051         |
| Time-Sampling           | 5.79          |
| n_timesteps             | 1690000       |
| train-AverageDiscoun... | 38.8          |
| train-AverageReturn     | 57            |
| train-EnvExecTime       | 2.04          |
| train-MaxReturn         | 102           |
| train-MinReturn         | 11.5          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.56          |
| train-StdReturn         | 19.1          |
-------------------------------------------

 ---------------- Iteration 169 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 169           |
| ItrTime                 | 6.04          |
| LossAfter               | -0.017766554  |
| LossBefore              | -9.397444e-06 |
| Time                    | 1.07e+03      |
| Time-Optimization       | 0.224         |
| Time-SampleProc         | 0.0441        |
| Time-Sampling           | 5.77          |
| n_timesteps             | 1700000       |
| train-AverageDiscoun... | 42.3          |
| train-AverageReturn     | 63            |
| train-EnvExecTime       | 2.04          |
| train-MaxReturn         | 124           |
| train-MinReturn         | 18.6          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.54          |
| train-StdReturn         | 20.9          |
-------------------------------------------

 ---------------- Iteration 170 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 170           |
| ItrTime                 | 6.02          |
| LossAfter               | -0.022826532  |
| LossBefore              | -9.359204e-06 |
| Time                    | 1.08e+03      |
| Time-Optimization       | 0.217         |
| Time-SampleProc         | 0.0503        |
| Time-Sampling           | 5.75          |
| n_timesteps             | 1710000       |
| train-AverageDiscoun... | 43.2          |
| train-AverageReturn     | 63.9          |
| train-EnvExecTime       | 2.03          |
| train-MaxReturn         | 102           |
| train-MinReturn         | -71.4         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.53          |
| train-StdReturn         | 25.2          |
-------------------------------------------

 ---------------- Iteration 171 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 171           |
| ItrTime                 | 6.45          |
| LossAfter               | -0.017967002  |
| LossBefore              | -9.328424e-06 |
| Time                    | 1.08e+03      |
| Time-Optimization       | 0.249         |
| Time-SampleProc         | 0.0559        |
| Time-Sampling           | 6.15          |
| n_timesteps             | 1720000       |
| train-AverageDiscoun... | 45.2          |
| train-AverageReturn     | 66.9          |
| train-EnvExecTime       | 2.15          |
| train-MaxReturn         | 135           |
| train-MinReturn         | 7.48          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.8           |
| train-StdReturn         | 20.4          |
-------------------------------------------

 ---------------- Iteration 172 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 172          |
| ItrTime                 | 6.34         |
| LossAfter               | -0.020803455 |
| LossBefore              | -9.27341e-06 |
| Time                    | 1.09e+03     |
| Time-Optimization       | 0.223        |
| Time-SampleProc         | 0.0422       |
| Time-Sampling           | 6.08         |
| n_timesteps             | 1730000      |
| train-AverageDiscoun... | 45.2         |
| train-AverageReturn     | 67.2         |
| train-EnvExecTime       | 2.14         |
| train-MaxReturn         | 143          |
| train-MinReturn         | -43.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 3.74         |
| train-StdReturn         | 26.3         |
------------------------------------------

 ---------------- Iteration 173 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 173           |
| ItrTime                 | 6.12          |
| LossAfter               | -0.023372184  |
| LossBefore              | -9.256777e-06 |
| Time                    | 1.1e+03       |
| Time-Optimization       | 0.246         |
| Time-SampleProc         | 0.042         |
| Time-Sampling           | 5.83          |
| n_timesteps             | 1740000       |
| train-AverageDiscoun... | 45            |
| train-AverageReturn     | 66.9          |
| train-EnvExecTime       | 2.05          |
| train-MaxReturn         | 180           |
| train-MinReturn         | 6.18          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.58          |
| train-StdReturn         | 26.2          |
-------------------------------------------

 ---------------- Iteration 174 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 174           |
| ItrTime                 | 6.27          |
| LossAfter               | -0.024056932  |
| LossBefore              | -9.227115e-06 |
| Time                    | 1.1e+03       |
| Time-Optimization       | 0.238         |
| Time-SampleProc         | 0.0434        |
| Time-Sampling           | 5.99          |
| n_timesteps             | 1750000       |
| train-AverageDiscoun... | 43.8          |
| train-AverageReturn     | 65.3          |
| train-EnvExecTime       | 2.11          |
| train-MaxReturn         | 143           |
| train-MinReturn         | -33.3         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.68          |
| train-StdReturn         | 24.5          |
-------------------------------------------

 ---------------- Iteration 175 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 175           |
| ItrTime                 | 6             |
| LossAfter               | -0.021596165  |
| LossBefore              | -9.184347e-06 |
| Time                    | 1.11e+03      |
| Time-Optimization       | 0.228         |
| Time-SampleProc         | 0.0685        |
| Time-Sampling           | 5.71          |
| n_timesteps             | 1760000       |
| train-AverageDiscoun... | 41.2          |
| train-AverageReturn     | 60.9          |
| train-EnvExecTime       | 2.01          |
| train-MaxReturn         | 110           |
| train-MinReturn         | -26.9         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.51          |
| train-StdReturn         | 23.1          |
-------------------------------------------

 ---------------- Iteration 176 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 176           |
| ItrTime                 | 6.04          |
| LossAfter               | -0.020895425  |
| LossBefore              | -9.162853e-06 |
| Time                    | 1.11e+03      |
| Time-Optimization       | 0.23          |
| Time-SampleProc         | 0.0295        |
| Time-Sampling           | 5.78          |
| n_timesteps             | 1770000       |
| train-AverageDiscoun... | 42.8          |
| train-AverageReturn     | 62.6          |
| train-EnvExecTime       | 2.02          |
| train-MaxReturn         | 150           |
| train-MinReturn         | -58.1         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.57          |
| train-StdReturn         | 27.7          |
-------------------------------------------

 ---------------- Iteration 177 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 177            |
| ItrTime                 | 6.66           |
| LossAfter               | -0.019211004   |
| LossBefore              | -9.1150005e-06 |
| Time                    | 1.12e+03       |
| Time-Optimization       | 0.259          |
| Time-SampleProc         | 0.0476         |
| Time-Sampling           | 6.35           |
| n_timesteps             | 1780000        |
| train-AverageDiscoun... | 45.8           |
| train-AverageReturn     | 68.1           |
| train-EnvExecTime       | 2.18           |
| train-MaxReturn         | 161            |
| train-MinReturn         | -30.6          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.96           |
| train-StdReturn         | 26.7           |
--------------------------------------------

 ---------------- Iteration 178 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 178           |
| ItrTime                 | 6.79          |
| LossAfter               | -0.022412632  |
| LossBefore              | -9.101325e-06 |
| Time                    | 1.13e+03      |
| Time-Optimization       | 0.231         |
| Time-SampleProc         | 0.0517        |
| Time-Sampling           | 6.51          |
| n_timesteps             | 1790000       |
| train-AverageDiscoun... | 44            |
| train-AverageReturn     | 66.5          |
| train-EnvExecTime       | 2.25          |
| train-MaxReturn         | 154           |
| train-MinReturn         | 12.4          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 4.05          |
| train-StdReturn         | 19.7          |
-------------------------------------------

 ---------------- Iteration 179 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 179           |
| ItrTime                 | 6.31          |
| LossAfter               | -0.020249203  |
| LossBefore              | -9.095052e-06 |
| Time                    | 1.13e+03      |
| Time-Optimization       | 0.219         |
| Time-SampleProc         | 0.0839        |
| Time-Sampling           | 6.01          |
| n_timesteps             | 1800000       |
| train-AverageDiscoun... | 42            |
| train-AverageReturn     | 62.4          |
| train-EnvExecTime       | 2.1           |
| train-MaxReturn         | 169           |
| train-MinReturn         | -47           |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.71          |
| train-StdReturn         | 31.9          |
-------------------------------------------

 ---------------- Iteration 180 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 180           |
| ItrTime                 | 6.21          |
| LossAfter               | -0.017253097  |
| LossBefore              | -9.074187e-06 |
| Time                    | 1.14e+03      |
| Time-Optimization       | 0.243         |
| Time-SampleProc         | 0.0398        |
| Time-Sampling           | 5.93          |
| n_timesteps             | 1810000       |
| train-AverageDiscoun... | 46.4          |
| train-AverageReturn     | 69.3          |
| train-EnvExecTime       | 2.09          |
| train-MaxReturn         | 161           |
| train-MinReturn         | -19.5         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.64          |
| train-StdReturn         | 24.4          |
-------------------------------------------

 ---------------- Iteration 181 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 181           |
| ItrTime                 | 6.22          |
| LossAfter               | -0.020083662  |
| LossBefore              | -9.073765e-06 |
| Time                    | 1.15e+03      |
| Time-Optimization       | 0.225         |
| Time-SampleProc         | 0.0409        |
| Time-Sampling           | 5.96          |
| n_timesteps             | 1820000       |
| train-AverageDiscoun... | 43.3          |
| train-AverageReturn     | 63.4          |
| train-EnvExecTime       | 2.1           |
| train-MaxReturn         | 129           |
| train-MinReturn         | -60.5         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.66          |
| train-StdReturn         | 29.2          |
-------------------------------------------

 ---------------- Iteration 182 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 182           |
| ItrTime                 | 6.22          |
| LossAfter               | -0.020442422  |
| LossBefore              | -9.062416e-06 |
| Time                    | 1.15e+03      |
| Time-Optimization       | 0.227         |
| Time-SampleProc         | 0.044         |
| Time-Sampling           | 5.95          |
| n_timesteps             | 1830000       |
| train-AverageDiscoun... | 46.5          |
| train-AverageReturn     | 69.4          |
| train-EnvExecTime       | 2.1           |
| train-MaxReturn         | 166           |
| train-MinReturn         | -21.2         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.65          |
| train-StdReturn         | 25.6          |
-------------------------------------------

 ---------------- Iteration 183 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 183           |
| ItrTime                 | 6.12          |
| LossAfter               | -0.022979613  |
| LossBefore              | -9.078643e-06 |
| Time                    | 1.16e+03      |
| Time-Optimization       | 0.218         |
| Time-SampleProc         | 0.0427        |
| Time-Sampling           | 5.86          |
| n_timesteps             | 1840000       |
| train-AverageDiscoun... | 46.1          |
| train-AverageReturn     | 68.1          |
| train-EnvExecTime       | 2.04          |
| train-MaxReturn         | 169           |
| train-MinReturn         | -46.4         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.62          |
| train-StdReturn         | 25.2          |
-------------------------------------------

 ---------------- Iteration 184 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 184           |
| ItrTime                 | 6.18          |
| LossAfter               | -0.023248974  |
| LossBefore              | -9.044805e-06 |
| Time                    | 1.16e+03      |
| Time-Optimization       | 0.247         |
| Time-SampleProc         | 0.0483        |
| Time-Sampling           | 5.89          |
| n_timesteps             | 1850000       |
| train-AverageDiscoun... | 43.7          |
| train-AverageReturn     | 65.1          |
| train-EnvExecTime       | 2.08          |
| train-MaxReturn         | 127           |
| train-MinReturn         | -48.5         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.61          |
| train-StdReturn         | 23.4          |
-------------------------------------------

 ---------------- Iteration 185 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 185          |
| ItrTime                 | 6.44         |
| LossAfter               | -0.020816969 |
| LossBefore              | -9.01437e-06 |
| Time                    | 1.17e+03     |
| Time-Optimization       | 0.236        |
| Time-SampleProc         | 0.0541       |
| Time-Sampling           | 6.15         |
| n_timesteps             | 1860000      |
| train-AverageDiscoun... | 44.2         |
| train-AverageReturn     | 66.6         |
| train-EnvExecTime       | 2.14         |
| train-MaxReturn         | 129          |
| train-MinReturn         | -25.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 3.81         |
| train-StdReturn         | 22           |
------------------------------------------

 ---------------- Iteration 186 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 186           |
| ItrTime                 | 6.45          |
| LossAfter               | -0.015236125  |
| LossBefore              | -8.983665e-06 |
| Time                    | 1.18e+03      |
| Time-Optimization       | 0.229         |
| Time-SampleProc         | 0.0523        |
| Time-Sampling           | 6.16          |
| n_timesteps             | 1870000       |
| train-AverageDiscoun... | 48.2          |
| train-AverageReturn     | 72.7          |
| train-EnvExecTime       | 2.18          |
| train-MaxReturn         | 196           |
| train-MinReturn         | 16.4          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.78          |
| train-StdReturn         | 27.8          |
-------------------------------------------

 ---------------- Iteration 187 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 187           |
| ItrTime                 | 6.47          |
| LossAfter               | -0.023049142  |
| LossBefore              | -8.935335e-06 |
| Time                    | 1.18e+03      |
| Time-Optimization       | 0.219         |
| Time-SampleProc         | 0.0335        |
| Time-Sampling           | 6.22          |
| n_timesteps             | 1880000       |
| train-AverageDiscoun... | 44.5          |
| train-AverageReturn     | 66.4          |
| train-EnvExecTime       | 2.18          |
| train-MaxReturn         | 134           |
| train-MinReturn         | -89           |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.83          |
| train-StdReturn         | 29.1          |
-------------------------------------------

 ---------------- Iteration 188 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 188           |
| ItrTime                 | 6.28          |
| LossAfter               | -0.024455894  |
| LossBefore              | -8.922879e-06 |
| Time                    | 1.19e+03      |
| Time-Optimization       | 0.229         |
| Time-SampleProc         | 0.0487        |
| Time-Sampling           | 6             |
| n_timesteps             | 1890000       |
| train-AverageDiscoun... | 44.7          |
| train-AverageReturn     | 66.3          |
| train-EnvExecTime       | 2.1           |
| train-MaxReturn         | 114           |
| train-MinReturn         | -50.4         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.71          |
| train-StdReturn         | 22.3          |
-------------------------------------------

 ---------------- Iteration 189 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 189           |
| ItrTime                 | 6.02          |
| LossAfter               | -0.019920548  |
| LossBefore              | -8.871824e-06 |
| Time                    | 1.2e+03       |
| Time-Optimization       | 0.232         |
| Time-SampleProc         | 0.0443        |
| Time-Sampling           | 5.75          |
| n_timesteps             | 1900000       |
| train-AverageDiscoun... | 45.6          |
| train-AverageReturn     | 68.8          |
| train-EnvExecTime       | 2.02          |
| train-MaxReturn         | 159           |
| train-MinReturn         | -48           |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.54          |
| train-StdReturn         | 27.8          |
-------------------------------------------

 ---------------- Iteration 190 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 190           |
| ItrTime                 | 6.36          |
| LossAfter               | -0.020275783  |
| LossBefore              | -8.847048e-06 |
| Time                    | 1.2e+03       |
| Time-Optimization       | 0.247         |
| Time-SampleProc         | 0.0479        |
| Time-Sampling           | 6.06          |
| n_timesteps             | 1910000       |
| train-AverageDiscoun... | 48.1          |
| train-AverageReturn     | 70.9          |
| train-EnvExecTime       | 2.14          |
| train-MaxReturn         | 122           |
| train-MinReturn         | -0.886        |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.72          |
| train-StdReturn         | 20.2          |
-------------------------------------------

 ---------------- Iteration 191 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 191           |
| ItrTime                 | 6.36          |
| LossAfter               | -0.022269925  |
| LossBefore              | -8.851688e-06 |
| Time                    | 1.21e+03      |
| Time-Optimization       | 0.223         |
| Time-SampleProc         | 0.0419        |
| Time-Sampling           | 6.1           |
| n_timesteps             | 1920000       |
| train-AverageDiscoun... | 48.5          |
| train-AverageReturn     | 72.7          |
| train-EnvExecTime       | 2.14          |
| train-MaxReturn         | 169           |
| train-MinReturn         | -48.1         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.76          |
| train-StdReturn         | 28.1          |
-------------------------------------------

 ---------------- Iteration 192 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 192           |
| ItrTime                 | 6.01          |
| LossAfter               | -0.022210466  |
| LossBefore              | -8.845912e-06 |
| Time                    | 1.22e+03      |
| Time-Optimization       | 0.232         |
| Time-SampleProc         | 0.0397        |
| Time-Sampling           | 5.74          |
| n_timesteps             | 1930000       |
| train-AverageDiscoun... | 46.9          |
| train-AverageReturn     | 70.2          |
| train-EnvExecTime       | 2.01          |
| train-MaxReturn         | 118           |
| train-MinReturn         | -22           |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.54          |
| train-StdReturn         | 25.7          |
-------------------------------------------

 ---------------- Iteration 193 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 193           |
| ItrTime                 | 6.28          |
| LossAfter               | -0.021508053  |
| LossBefore              | -8.830648e-06 |
| Time                    | 1.22e+03      |
| Time-Optimization       | 0.236         |
| Time-SampleProc         | 0.0464        |
| Time-Sampling           | 5.99          |
| n_timesteps             | 1940000       |
| train-AverageDiscoun... | 47.4          |
| train-AverageReturn     | 71.3          |
| train-EnvExecTime       | 2.09          |
| train-MaxReturn         | 162           |
| train-MinReturn         | 18.9          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.71          |
| train-StdReturn         | 24.9          |
-------------------------------------------

 ---------------- Iteration 194 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 194           |
| ItrTime                 | 6.48          |
| LossAfter               | -0.023578685  |
| LossBefore              | -8.809106e-06 |
| Time                    | 1.23e+03      |
| Time-Optimization       | 0.213         |
| Time-SampleProc         | 0.0696        |
| Time-Sampling           | 6.19          |
| n_timesteps             | 1950000       |
| train-AverageDiscoun... | 48.5          |
| train-AverageReturn     | 73.6          |
| train-EnvExecTime       | 2.19          |
| train-MaxReturn         | 158           |
| train-MinReturn         | -8.82         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.8           |
| train-StdReturn         | 28.3          |
-------------------------------------------

 ---------------- Iteration 195 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 195           |
| ItrTime                 | 6.21          |
| LossAfter               | -0.021468552  |
| LossBefore              | -8.801391e-06 |
| Time                    | 1.23e+03      |
| Time-Optimization       | 0.245         |
| Time-SampleProc         | 0.0429        |
| Time-Sampling           | 5.93          |
| n_timesteps             | 1960000       |
| train-AverageDiscoun... | 46.3          |
| train-AverageReturn     | 69.9          |
| train-EnvExecTime       | 2.08          |
| train-MaxReturn         | 127           |
| train-MinReturn         | -39.6         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.64          |
| train-StdReturn         | 25.4          |
-------------------------------------------

 ---------------- Iteration 196 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 196           |
| ItrTime                 | 6.25          |
| LossAfter               | -0.020177636  |
| LossBefore              | -8.760097e-06 |
| Time                    | 1.24e+03      |
| Time-Optimization       | 0.24          |
| Time-SampleProc         | 0.0454        |
| Time-Sampling           | 5.96          |
| n_timesteps             | 1970000       |
| train-AverageDiscoun... | 46.8          |
| train-AverageReturn     | 69.6          |
| train-EnvExecTime       | 2.1           |
| train-MaxReturn         | 129           |
| train-MinReturn         | 3             |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.67          |
| train-StdReturn         | 21.6          |
-------------------------------------------

 ---------------- Iteration 197 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 197           |
| ItrTime                 | 6.67          |
| LossAfter               | -0.022599855  |
| LossBefore              | -8.711939e-06 |
| Time                    | 1.25e+03      |
| Time-Optimization       | 0.227         |
| Time-SampleProc         | 0.0867        |
| Time-Sampling           | 6.36          |
| n_timesteps             | 1980000       |
| train-AverageDiscoun... | 47.7          |
| train-AverageReturn     | 71.9          |
| train-EnvExecTime       | 2.23          |
| train-MaxReturn         | 136           |
| train-MinReturn         | -5.72         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.92          |
| train-StdReturn         | 25.9          |
-------------------------------------------

 ---------------- Iteration 198 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 198          |
| ItrTime                 | 6.48         |
| LossAfter               | -0.023322936 |
| LossBefore              | -8.68365e-06 |
| Time                    | 1.25e+03     |
| Time-Optimization       | 0.23         |
| Time-SampleProc         | 0.0699       |
| Time-Sampling           | 6.18         |
| n_timesteps             | 1990000      |
| train-AverageDiscoun... | 45.5         |
| train-AverageReturn     | 68           |
| train-EnvExecTime       | 2.18         |
| train-MaxReturn         | 136          |
| train-MinReturn         | -70.7        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 3.79         |
| train-StdReturn         | 30.1         |
------------------------------------------

 ---------------- Iteration 199 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 199           |
| ItrTime                 | 6.2           |
| LossAfter               | -0.021474987  |
| LossBefore              | -8.661907e-06 |
| Time                    | 1.26e+03      |
| Time-Optimization       | 0.243         |
| Time-SampleProc         | 0.0464        |
| Time-Sampling           | 5.91          |
| n_timesteps             | 2000000       |
| train-AverageDiscoun... | 48.4          |
| train-AverageReturn     | 72.7          |
| train-EnvExecTime       | 2.08          |
| train-MaxReturn         | 141           |
| train-MinReturn         | -23.1         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.64          |
| train-StdReturn         | 25.9          |
-------------------------------------------

 ---------------- Iteration 200 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 200           |
| ItrTime                 | 6.29          |
| LossAfter               | -0.025128482  |
| LossBefore              | -8.663097e-06 |
| Time                    | 1.27e+03      |
| Time-Optimization       | 0.24          |
| Time-SampleProc         | 0.0455        |
| Time-Sampling           | 6             |
| n_timesteps             | 2010000       |
| train-AverageDiscoun... | 50.2          |
| train-AverageReturn     | 75.4          |
| train-EnvExecTime       | 2.09          |
| train-MaxReturn         | 154           |
| train-MinReturn         | -19.6         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.71          |
| train-StdReturn         | 23            |
-------------------------------------------

 ---------------- Iteration 201 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 201            |
| ItrTime                 | 6.28           |
| LossAfter               | -0.019278867   |
| LossBefore              | -8.6228365e-06 |
| Time                    | 1.27e+03       |
| Time-Optimization       | 0.214          |
| Time-SampleProc         | 0.0849         |
| Time-Sampling           | 5.98           |
| n_timesteps             | 2020000        |
| train-AverageDiscoun... | 49.3           |
| train-AverageReturn     | 74.4           |
| train-EnvExecTime       | 2.08           |
| train-MaxReturn         | 156            |
| train-MinReturn         | -7.76          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.7            |
| train-StdReturn         | 22.8           |
--------------------------------------------

 ---------------- Iteration 202 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 202            |
| ItrTime                 | 6.08           |
| LossAfter               | -0.019255884   |
| LossBefore              | -8.6247055e-06 |
| Time                    | 1.28e+03       |
| Time-Optimization       | 0.212          |
| Time-SampleProc         | 0.0815         |
| Time-Sampling           | 5.78           |
| n_timesteps             | 2030000        |
| train-AverageDiscoun... | 52.2           |
| train-AverageReturn     | 79.2           |
| train-EnvExecTime       | 2.02           |
| train-MaxReturn         | 201            |
| train-MinReturn         | 7.14           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.56           |
| train-StdReturn         | 27.5           |
--------------------------------------------

 ---------------- Iteration 203 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 203           |
| ItrTime                 | 6.23          |
| LossAfter               | -0.021156743  |
| LossBefore              | -8.597355e-06 |
| Time                    | 1.28e+03      |
| Time-Optimization       | 0.255         |
| Time-SampleProc         | 0.0439        |
| Time-Sampling           | 5.93          |
| n_timesteps             | 2040000       |
| train-AverageDiscoun... | 46.4          |
| train-AverageReturn     | 69.6          |
| train-EnvExecTime       | 2.06          |
| train-MaxReturn         | 124           |
| train-MinReturn         | -54.7         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.68          |
| train-StdReturn         | 26.3          |
-------------------------------------------

 ---------------- Iteration 204 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 204           |
| ItrTime                 | 6.4           |
| LossAfter               | -0.021596937  |
| LossBefore              | -8.556962e-06 |
| Time                    | 1.29e+03      |
| Time-Optimization       | 0.234         |
| Time-SampleProc         | 0.0319        |
| Time-Sampling           | 6.13          |
| n_timesteps             | 2050000       |
| train-AverageDiscoun... | 47.7          |
| train-AverageReturn     | 71.1          |
| train-EnvExecTime       | 2.15          |
| train-MaxReturn         | 147           |
| train-MinReturn         | -34.3         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.79          |
| train-StdReturn         | 24.9          |
-------------------------------------------

 ---------------- Iteration 205 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 205           |
| ItrTime                 | 6.26          |
| LossAfter               | -0.017861998  |
| LossBefore              | -8.488542e-06 |
| Time                    | 1.3e+03       |
| Time-Optimization       | 0.22          |
| Time-SampleProc         | 0.0896        |
| Time-Sampling           | 5.95          |
| n_timesteps             | 2060000       |
| train-AverageDiscoun... | 50.8          |
| train-AverageReturn     | 77.7          |
| train-EnvExecTime       | 2.08          |
| train-MaxReturn         | 143           |
| train-MinReturn         | 13.9          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.68          |
| train-StdReturn         | 19.5          |
-------------------------------------------

 ---------------- Iteration 206 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 206           |
| ItrTime                 | 6.27          |
| LossAfter               | -0.018626666  |
| LossBefore              | -8.443966e-06 |
| Time                    | 1.3e+03       |
| Time-Optimization       | 0.225         |
| Time-SampleProc         | 0.0882        |
| Time-Sampling           | 5.95          |
| n_timesteps             | 2070000       |
| train-AverageDiscoun... | 52.4          |
| train-AverageReturn     | 79.3          |
| train-EnvExecTime       | 2.09          |
| train-MaxReturn         | 162           |
| train-MinReturn         | 5.68          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.66          |
| train-StdReturn         | 24.5          |
-------------------------------------------

 ---------------- Iteration 207 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 207           |
| ItrTime                 | 6.24          |
| LossAfter               | -0.014092653  |
| LossBefore              | -8.410459e-06 |
| Time                    | 1.31e+03      |
| Time-Optimization       | 0.217         |
| Time-SampleProc         | 0.0863        |
| Time-Sampling           | 5.93          |
| n_timesteps             | 2080000       |
| train-AverageDiscoun... | 48.6          |
| train-AverageReturn     | 73.6          |
| train-EnvExecTime       | 2.1           |
| train-MaxReturn         | 137           |
| train-MinReturn         | -26.4         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.64          |
| train-StdReturn         | 23.8          |
-------------------------------------------

 ---------------- Iteration 208 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 208           |
| ItrTime                 | 6.15          |
| LossAfter               | -0.017582215  |
| LossBefore              | -8.392174e-06 |
| Time                    | 1.32e+03      |
| Time-Optimization       | 0.232         |
| Time-SampleProc         | 0.0397        |
| Time-Sampling           | 5.88          |
| n_timesteps             | 2090000       |
| train-AverageDiscoun... | 48.9          |
| train-AverageReturn     | 73.3          |
| train-EnvExecTime       | 2.07          |
| train-MaxReturn         | 118           |
| train-MinReturn         | 24.8          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.61          |
| train-StdReturn         | 20.1          |
-------------------------------------------

 ---------------- Iteration 209 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 209           |
| ItrTime                 | 6.29          |
| LossAfter               | -0.013888475  |
| LossBefore              | -8.375564e-06 |
| Time                    | 1.32e+03      |
| Time-Optimization       | 0.245         |
| Time-SampleProc         | 0.0545        |
| Time-Sampling           | 5.99          |
| n_timesteps             | 2100000       |
| train-AverageDiscoun... | 48.7          |
| train-AverageReturn     | 73.6          |
| train-EnvExecTime       | 2.11          |
| train-MaxReturn         | 142           |
| train-MinReturn         | 11.9          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.68          |
| train-StdReturn         | 21.9          |
-------------------------------------------

 ---------------- Iteration 210 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 210           |
| ItrTime                 | 6.3           |
| LossAfter               | -0.018969944  |
| LossBefore              | -8.325784e-06 |
| Time                    | 1.33e+03      |
| Time-Optimization       | 0.232         |
| Time-SampleProc         | 0.048         |
| Time-Sampling           | 6.02          |
| n_timesteps             | 2110000       |
| train-AverageDiscoun... | 49.6          |
| train-AverageReturn     | 75.5          |
| train-EnvExecTime       | 2.13          |
| train-MaxReturn         | 119           |
| train-MinReturn         | 17.7          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.69          |
| train-StdReturn         | 20            |
-------------------------------------------

 ---------------- Iteration 211 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 211           |
| ItrTime                 | 6.02          |
| LossAfter               | -0.021024805  |
| LossBefore              | -8.300893e-06 |
| Time                    | 1.33e+03      |
| Time-Optimization       | 0.235         |
| Time-SampleProc         | 0.0415        |
| Time-Sampling           | 5.74          |
| n_timesteps             | 2120000       |
| train-AverageDiscoun... | 51            |
| train-AverageReturn     | 78.1          |
| train-EnvExecTime       | 2.02          |
| train-MaxReturn         | 122           |
| train-MinReturn         | 20.3          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.53          |
| train-StdReturn         | 17.6          |
-------------------------------------------

 ---------------- Iteration 212 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 212           |
| ItrTime                 | 6.28          |
| LossAfter               | -0.018408725  |
| LossBefore              | -8.269997e-06 |
| Time                    | 1.34e+03      |
| Time-Optimization       | 0.24          |
| Time-SampleProc         | 0.0542        |
| Time-Sampling           | 5.98          |
| n_timesteps             | 2130000       |
| train-AverageDiscoun... | 48.6          |
| train-AverageReturn     | 74.6          |
| train-EnvExecTime       | 2.1           |
| train-MaxReturn         | 167           |
| train-MinReturn         | -30.2         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.69          |
| train-StdReturn         | 27.7          |
-------------------------------------------

 ---------------- Iteration 213 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 213           |
| ItrTime                 | 6.41          |
| LossAfter               | -0.02360581   |
| LossBefore              | -8.233661e-06 |
| Time                    | 1.35e+03      |
| Time-Optimization       | 0.232         |
| Time-SampleProc         | 0.0394        |
| Time-Sampling           | 6.14          |
| n_timesteps             | 2140000       |
| train-AverageDiscoun... | 50.4          |
| train-AverageReturn     | 77            |
| train-EnvExecTime       | 2.16          |
| train-MaxReturn         | 156           |
| train-MinReturn         | -44           |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.78          |
| train-StdReturn         | 27.2          |
-------------------------------------------

 ---------------- Iteration 214 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 214           |
| ItrTime                 | 6.02          |
| LossAfter               | -0.01880578   |
| LossBefore              | -8.211233e-06 |
| Time                    | 1.35e+03      |
| Time-Optimization       | 0.225         |
| Time-SampleProc         | 0.0434        |
| Time-Sampling           | 5.75          |
| n_timesteps             | 2150000       |
| train-AverageDiscoun... | 48.5          |
| train-AverageReturn     | 73.2          |
| train-EnvExecTime       | 2.02          |
| train-MaxReturn         | 161           |
| train-MinReturn         | -47.9         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.54          |
| train-StdReturn         | 26.4          |
-------------------------------------------

 ---------------- Iteration 215 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 215           |
| ItrTime                 | 6.06          |
| LossAfter               | -0.01791755   |
| LossBefore              | -8.215146e-06 |
| Time                    | 1.36e+03      |
| Time-Optimization       | 0.23          |
| Time-SampleProc         | 0.0889        |
| Time-Sampling           | 5.74          |
| n_timesteps             | 2160000       |
| train-AverageDiscoun... | 53            |
| train-AverageReturn     | 80.5          |
| train-EnvExecTime       | 2.02          |
| train-MaxReturn         | 150           |
| train-MinReturn         | 35.8          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.53          |
| train-StdReturn         | 22            |
-------------------------------------------

 ---------------- Iteration 216 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 216           |
| ItrTime                 | 7             |
| LossAfter               | -0.016579485  |
| LossBefore              | -8.157001e-06 |
| Time                    | 1.37e+03      |
| Time-Optimization       | 0.266         |
| Time-SampleProc         | 0.0601        |
| Time-Sampling           | 6.67          |
| n_timesteps             | 2170000       |
| train-AverageDiscoun... | 48.8          |
| train-AverageReturn     | 75.4          |
| train-EnvExecTime       | 2.35          |
| train-MaxReturn         | 150           |
| train-MinReturn         | -19.2         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 4.1           |
| train-StdReturn         | 25.9          |
-------------------------------------------

 ---------------- Iteration 217 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 217           |
| ItrTime                 | 6.78          |
| LossAfter               | -0.018095724  |
| LossBefore              | -8.137541e-06 |
| Time                    | 1.37e+03      |
| Time-Optimization       | 0.251         |
| Time-SampleProc         | 0.0448        |
| Time-Sampling           | 6.49          |
| n_timesteps             | 2180000       |
| train-AverageDiscoun... | 51.4          |
| train-AverageReturn     | 78.9          |
| train-EnvExecTime       | 2.31          |
| train-MaxReturn         | 209           |
| train-MinReturn         | 8.72          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.96          |
| train-StdReturn         | 25.6          |
-------------------------------------------

 ---------------- Iteration 218 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 218          |
| ItrTime                 | 6.41         |
| LossAfter               | -0.020203762 |
| LossBefore              | -8.07656e-06 |
| Time                    | 1.38e+03     |
| Time-Optimization       | 0.208        |
| Time-SampleProc         | 0.0812       |
| Time-Sampling           | 6.12         |
| n_timesteps             | 2190000      |
| train-AverageDiscoun... | 48.8         |
| train-AverageReturn     | 74.8         |
| train-EnvExecTime       | 2.14         |
| train-MaxReturn         | 157          |
| train-MinReturn         | -6.11        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 3.78         |
| train-StdReturn         | 23           |
------------------------------------------

 ---------------- Iteration 219 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 219           |
| ItrTime                 | 6.21          |
| LossAfter               | -0.02262059   |
| LossBefore              | -8.042865e-06 |
| Time                    | 1.39e+03      |
| Time-Optimization       | 0.223         |
| Time-SampleProc         | 0.0854        |
| Time-Sampling           | 5.91          |
| n_timesteps             | 2200000       |
| train-AverageDiscoun... | 52.4          |
| train-AverageReturn     | 79.6          |
| train-EnvExecTime       | 2.06          |
| train-MaxReturn         | 131           |
| train-MinReturn         | 31.8          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.65          |
| train-StdReturn         | 20.4          |
-------------------------------------------

 ---------------- Iteration 220 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 220           |
| ItrTime                 | 6.24          |
| LossAfter               | -0.018378133  |
| LossBefore              | -7.991516e-06 |
| Time                    | 1.39e+03      |
| Time-Optimization       | 0.242         |
| Time-SampleProc         | 0.0446        |
| Time-Sampling           | 5.95          |
| n_timesteps             | 2210000       |
| train-AverageDiscoun... | 52.9          |
| train-AverageReturn     | 81.2          |
| train-EnvExecTime       | 2.1           |
| train-MaxReturn         | 155           |
| train-MinReturn         | -97.5         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.66          |
| train-StdReturn         | 28.3          |
-------------------------------------------

 ---------------- Iteration 221 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 221           |
| ItrTime                 | 6.22          |
| LossAfter               | -0.02110942   |
| LossBefore              | -7.956329e-06 |
| Time                    | 1.4e+03       |
| Time-Optimization       | 0.238         |
| Time-SampleProc         | 0.0468        |
| Time-Sampling           | 5.94          |
| n_timesteps             | 2220000       |
| train-AverageDiscoun... | 50.2          |
| train-AverageReturn     | 77.6          |
| train-EnvExecTime       | 2.09          |
| train-MaxReturn         | 176           |
| train-MinReturn         | -71.3         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.65          |
| train-StdReturn         | 29.5          |
-------------------------------------------

 ---------------- Iteration 222 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 222           |
| ItrTime                 | 6.05          |
| LossAfter               | -0.019909687  |
| LossBefore              | -7.933022e-06 |
| Time                    | 1.4e+03       |
| Time-Optimization       | 0.23          |
| Time-SampleProc         | 0.0563        |
| Time-Sampling           | 5.76          |
| n_timesteps             | 2230000       |
| train-AverageDiscoun... | 50.7          |
| train-AverageReturn     | 77.3          |
| train-EnvExecTime       | 2.02          |
| train-MaxReturn         | 188           |
| train-MinReturn         | 25.4          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.55          |
| train-StdReturn         | 25.1          |
-------------------------------------------

 ---------------- Iteration 223 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 223            |
| ItrTime                 | 6.06           |
| LossAfter               | -0.019112656   |
| LossBefore              | -7.9203455e-06 |
| Time                    | 1.41e+03       |
| Time-Optimization       | 0.216          |
| Time-SampleProc         | 0.0831         |
| Time-Sampling           | 5.76           |
| n_timesteps             | 2240000        |
| train-AverageDiscoun... | 54.3           |
| train-AverageReturn     | 82.7           |
| train-EnvExecTime       | 2.03           |
| train-MaxReturn         | 126            |
| train-MinReturn         | -31.6          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.54           |
| train-StdReturn         | 23.5           |
--------------------------------------------

 ---------------- Iteration 224 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 224           |
| ItrTime                 | 6.17          |
| LossAfter               | -0.018070575  |
| LossBefore              | -7.884618e-06 |
| Time                    | 1.42e+03      |
| Time-Optimization       | 0.256         |
| Time-SampleProc         | 0.0455        |
| Time-Sampling           | 5.87          |
| n_timesteps             | 2250000       |
| train-AverageDiscoun... | 53.8          |
| train-AverageReturn     | 82.5          |
| train-EnvExecTime       | 2.06          |
| train-MaxReturn         | 147           |
| train-MinReturn         | 34.6          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.61          |
| train-StdReturn         | 18.7          |
-------------------------------------------

 ---------------- Iteration 225 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 225           |
| ItrTime                 | 6.49          |
| LossAfter               | -0.016954953  |
| LossBefore              | -7.846179e-06 |
| Time                    | 1.42e+03      |
| Time-Optimization       | 0.252         |
| Time-SampleProc         | 0.0489        |
| Time-Sampling           | 6.18          |
| n_timesteps             | 2260000       |
| train-AverageDiscoun... | 53.6          |
| train-AverageReturn     | 83            |
| train-EnvExecTime       | 2.18          |
| train-MaxReturn         | 125           |
| train-MinReturn         | -54.5         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.8           |
| train-StdReturn         | 25.5          |
-------------------------------------------

 ---------------- Iteration 226 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 226           |
| ItrTime                 | 6.46          |
| LossAfter               | -0.022471799  |
| LossBefore              | -7.830557e-06 |
| Time                    | 1.43e+03      |
| Time-Optimization       | 0.227         |
| Time-SampleProc         | 0.0857        |
| Time-Sampling           | 6.15          |
| n_timesteps             | 2270000       |
| train-AverageDiscoun... | 54.9          |
| train-AverageReturn     | 84.4          |
| train-EnvExecTime       | 2.17          |
| train-MaxReturn         | 201           |
| train-MinReturn         | -37.1         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.77          |
| train-StdReturn         | 27            |
-------------------------------------------

 ---------------- Iteration 227 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 227           |
| ItrTime                 | 6.26          |
| LossAfter               | -0.020816393  |
| LossBefore              | -7.821838e-06 |
| Time                    | 1.44e+03      |
| Time-Optimization       | 0.245         |
| Time-SampleProc         | 0.0504        |
| Time-Sampling           | 5.97          |
| n_timesteps             | 2280000       |
| train-AverageDiscoun... | 53.8          |
| train-AverageReturn     | 83            |
| train-EnvExecTime       | 2.09          |
| train-MaxReturn         | 155           |
| train-MinReturn         | 43.7          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.68          |
| train-StdReturn         | 22.4          |
-------------------------------------------

 ---------------- Iteration 228 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 228           |
| ItrTime                 | 6.28          |
| LossAfter               | -0.01940107   |
| LossBefore              | -7.811341e-06 |
| Time                    | 1.44e+03      |
| Time-Optimization       | 0.238         |
| Time-SampleProc         | 0.044         |
| Time-Sampling           | 6             |
| n_timesteps             | 2290000       |
| train-AverageDiscoun... | 54.5          |
| train-AverageReturn     | 84.3          |
| train-EnvExecTime       | 2.12          |
| train-MaxReturn         | 178           |
| train-MinReturn         | 45.8          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.68          |
| train-StdReturn         | 20.5          |
-------------------------------------------

 ---------------- Iteration 229 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 229           |
| ItrTime                 | 6.04          |
| LossAfter               | -0.020465717  |
| LossBefore              | -7.785522e-06 |
| Time                    | 1.45e+03      |
| Time-Optimization       | 0.224         |
| Time-SampleProc         | 0.0429        |
| Time-Sampling           | 5.78          |
| n_timesteps             | 2300000       |
| train-AverageDiscoun... | 53.6          |
| train-AverageReturn     | 82.3          |
| train-EnvExecTime       | 2.03          |
| train-MaxReturn         | 149           |
| train-MinReturn         | 15            |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.55          |
| train-StdReturn         | 22.8          |
-------------------------------------------

 ---------------- Iteration 230 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 230           |
| ItrTime                 | 6.35          |
| LossAfter               | -0.021587975  |
| LossBefore              | -7.792552e-06 |
| Time                    | 1.45e+03      |
| Time-Optimization       | 0.242         |
| Time-SampleProc         | 0.0911        |
| Time-Sampling           | 6.01          |
| n_timesteps             | 2310000       |
| train-AverageDiscoun... | 54.8          |
| train-AverageReturn     | 84.3          |
| train-EnvExecTime       | 2.12          |
| train-MaxReturn         | 237           |
| train-MinReturn         | 13.4          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.69          |
| train-StdReturn         | 28.6          |
-------------------------------------------

 ---------------- Iteration 231 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 231           |
| ItrTime                 | 6.45          |
| LossAfter               | -0.019874008  |
| LossBefore              | -7.734118e-06 |
| Time                    | 1.46e+03      |
| Time-Optimization       | 0.225         |
| Time-SampleProc         | 0.0508        |
| Time-Sampling           | 6.18          |
| n_timesteps             | 2320000       |
| train-AverageDiscoun... | 54.9          |
| train-AverageReturn     | 84.6          |
| train-EnvExecTime       | 2.18          |
| train-MaxReturn         | 168           |
| train-MinReturn         | 16.5          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.79          |
| train-StdReturn         | 22.7          |
-------------------------------------------

 ---------------- Iteration 232 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 232           |
| ItrTime                 | 6.08          |
| LossAfter               | -0.02068129   |
| LossBefore              | -7.700558e-06 |
| Time                    | 1.47e+03      |
| Time-Optimization       | 0.221         |
| Time-SampleProc         | 0.0452        |
| Time-Sampling           | 5.81          |
| n_timesteps             | 2330000       |
| train-AverageDiscoun... | 51.4          |
| train-AverageReturn     | 79.3          |
| train-EnvExecTime       | 2.03          |
| train-MaxReturn         | 121           |
| train-MinReturn         | 4.96          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.59          |
| train-StdReturn         | 23.4          |
-------------------------------------------

 ---------------- Iteration 233 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 233           |
| ItrTime                 | 6.34          |
| LossAfter               | -0.020845799  |
| LossBefore              | -7.659776e-06 |
| Time                    | 1.47e+03      |
| Time-Optimization       | 0.228         |
| Time-SampleProc         | 0.0861        |
| Time-Sampling           | 6.02          |
| n_timesteps             | 2340000       |
| train-AverageDiscoun... | 56.8          |
| train-AverageReturn     | 87.6          |
| train-EnvExecTime       | 2.12          |
| train-MaxReturn         | 146           |
| train-MinReturn         | 27.7          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.7           |
| train-StdReturn         | 18.6          |
-------------------------------------------

 ---------------- Iteration 234 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 234           |
| ItrTime                 | 6.41          |
| LossAfter               | -0.017333388  |
| LossBefore              | -7.596101e-06 |
| Time                    | 1.48e+03      |
| Time-Optimization       | 0.212         |
| Time-SampleProc         | 0.0836        |
| Time-Sampling           | 6.12          |
| n_timesteps             | 2350000       |
| train-AverageDiscoun... | 54.4          |
| train-AverageReturn     | 84            |
| train-EnvExecTime       | 2.17          |
| train-MaxReturn         | 138           |
| train-MinReturn         | -98.1         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.75          |
| train-StdReturn         | 28.9          |
-------------------------------------------

 ---------------- Iteration 235 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 235           |
| ItrTime                 | 6.21          |
| LossAfter               | -0.017544117  |
| LossBefore              | -7.569858e-06 |
| Time                    | 1.49e+03      |
| Time-Optimization       | 0.248         |
| Time-SampleProc         | 0.0459        |
| Time-Sampling           | 5.92          |
| n_timesteps             | 2360000       |
| train-AverageDiscoun... | 54.6          |
| train-AverageReturn     | 84.2          |
| train-EnvExecTime       | 2.09          |
| train-MaxReturn         | 132           |
| train-MinReturn         | 44.1          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.63          |
| train-StdReturn         | 19.6          |
-------------------------------------------

 ---------------- Iteration 236 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 236            |
| ItrTime                 | 6.22           |
| LossAfter               | -0.017910536   |
| LossBefore              | -7.5420694e-06 |
| Time                    | 1.49e+03       |
| Time-Optimization       | 0.202          |
| Time-SampleProc         | 0.0901         |
| Time-Sampling           | 5.92           |
| n_timesteps             | 2370000        |
| train-AverageDiscoun... | 57.6           |
| train-AverageReturn     | 89.1           |
| train-EnvExecTime       | 2.09           |
| train-MaxReturn         | 172            |
| train-MinReturn         | 39             |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.63           |
| train-StdReturn         | 21.8           |
--------------------------------------------

 ---------------- Iteration 237 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 237            |
| ItrTime                 | 6.05           |
| LossAfter               | -0.014210217   |
| LossBefore              | -7.5289395e-06 |
| Time                    | 1.5e+03        |
| Time-Optimization       | 0.24           |
| Time-SampleProc         | 0.0458         |
| Time-Sampling           | 5.76           |
| n_timesteps             | 2380000        |
| train-AverageDiscoun... | 55.5           |
| train-AverageReturn     | 85.7           |
| train-EnvExecTime       | 2.04           |
| train-MaxReturn         | 194            |
| train-MinReturn         | -18.9          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.53           |
| train-StdReturn         | 25.5           |
--------------------------------------------

 ---------------- Iteration 238 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 238           |
| ItrTime                 | 6.38          |
| LossAfter               | -0.020325622  |
| LossBefore              | -7.481389e-06 |
| Time                    | 1.51e+03      |
| Time-Optimization       | 0.235         |
| Time-SampleProc         | 0.0596        |
| Time-Sampling           | 6.09          |
| n_timesteps             | 2390000       |
| train-AverageDiscoun... | 56.5          |
| train-AverageReturn     | 86.8          |
| train-EnvExecTime       | 2.15          |
| train-MaxReturn         | 148           |
| train-MinReturn         | -22.4         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.73          |
| train-StdReturn         | 24.7          |
-------------------------------------------

 ---------------- Iteration 239 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 239            |
| ItrTime                 | 6.21           |
| LossAfter               | -0.016780771   |
| LossBefore              | -7.4610493e-06 |
| Time                    | 1.51e+03       |
| Time-Optimization       | 0.228          |
| Time-SampleProc         | 0.0364         |
| Time-Sampling           | 5.95           |
| n_timesteps             | 2400000        |
| train-AverageDiscoun... | 56.2           |
| train-AverageReturn     | 87.3           |
| train-EnvExecTime       | 2.09           |
| train-MaxReturn         | 137            |
| train-MinReturn         | 28.1           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.67           |
| train-StdReturn         | 19.9           |
--------------------------------------------

 ---------------- Iteration 240 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 240            |
| ItrTime                 | 6.27           |
| LossAfter               | -0.020014273   |
| LossBefore              | -7.4374793e-06 |
| Time                    | 1.52e+03       |
| Time-Optimization       | 0.232          |
| Time-SampleProc         | 0.0429         |
| Time-Sampling           | 5.99           |
| n_timesteps             | 2410000        |
| train-AverageDiscoun... | 59.6           |
| train-AverageReturn     | 92.1           |
| train-EnvExecTime       | 2.11           |
| train-MaxReturn         | 180            |
| train-MinReturn         | 26             |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.67           |
| train-StdReturn         | 22.9           |
--------------------------------------------

 ---------------- Iteration 241 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 241           |
| ItrTime                 | 6.23          |
| LossAfter               | -0.022163643  |
| LossBefore              | -7.397742e-06 |
| Time                    | 1.52e+03      |
| Time-Optimization       | 0.225         |
| Time-SampleProc         | 0.0333        |
| Time-Sampling           | 5.97          |
| n_timesteps             | 2420000       |
| train-AverageDiscoun... | 55.1          |
| train-AverageReturn     | 85.4          |
| train-EnvExecTime       | 2.1           |
| train-MaxReturn         | 153           |
| train-MinReturn         | -44.7         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.68          |
| train-StdReturn         | 24.7          |
-------------------------------------------

 ---------------- Iteration 242 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 242            |
| ItrTime                 | 6.05           |
| LossAfter               | -0.020677742   |
| LossBefore              | -7.3863453e-06 |
| Time                    | 1.53e+03       |
| Time-Optimization       | 0.239          |
| Time-SampleProc         | 0.0304         |
| Time-Sampling           | 5.78           |
| n_timesteps             | 2430000        |
| train-AverageDiscoun... | 59.3           |
| train-AverageReturn     | 90.9           |
| train-EnvExecTime       | 2.03           |
| train-MaxReturn         | 174            |
| train-MinReturn         | 14             |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.56           |
| train-StdReturn         | 23.2           |
--------------------------------------------

 ---------------- Iteration 243 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 243           |
| ItrTime                 | 6.55          |
| LossAfter               | -0.019591877  |
| LossBefore              | -7.362843e-06 |
| Time                    | 1.54e+03      |
| Time-Optimization       | 0.236         |
| Time-SampleProc         | 0.0467        |
| Time-Sampling           | 6.27          |
| n_timesteps             | 2440000       |
| train-AverageDiscoun... | 57.6          |
| train-AverageReturn     | 89.8          |
| train-EnvExecTime       | 2.17          |
| train-MaxReturn         | 214           |
| train-MinReturn         | -8.27         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.89          |
| train-StdReturn         | 25.8          |
-------------------------------------------

 ---------------- Iteration 244 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 244            |
| ItrTime                 | 6.6            |
| LossAfter               | -0.016732976   |
| LossBefore              | -7.3461633e-06 |
| Time                    | 1.54e+03       |
| Time-Optimization       | 0.249          |
| Time-SampleProc         | 0.043          |
| Time-Sampling           | 6.3            |
| n_timesteps             | 2450000        |
| train-AverageDiscoun... | 57.7           |
| train-AverageReturn     | 89.8           |
| train-EnvExecTime       | 2.2            |
| train-MaxReturn         | 203            |
| train-MinReturn         | 17.6           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.89           |
| train-StdReturn         | 26.1           |
--------------------------------------------

 ---------------- Iteration 245 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 245            |
| ItrTime                 | 6.53           |
| LossAfter               | -0.017302776   |
| LossBefore              | -7.3392966e-06 |
| Time                    | 1.55e+03       |
| Time-Optimization       | 0.256          |
| Time-SampleProc         | 0.0352         |
| Time-Sampling           | 6.23           |
| n_timesteps             | 2460000        |
| train-AverageDiscoun... | 59.6           |
| train-AverageReturn     | 91.6           |
| train-EnvExecTime       | 2.19           |
| train-MaxReturn         | 131            |
| train-MinReturn         | 18.5           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.84           |
| train-StdReturn         | 20.6           |
--------------------------------------------

 ---------------- Iteration 246 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 246            |
| ItrTime                 | 6.46           |
| LossAfter               | -0.018939814   |
| LossBefore              | -7.2994153e-06 |
| Time                    | 1.56e+03       |
| Time-Optimization       | 0.24           |
| Time-SampleProc         | 0.0457         |
| Time-Sampling           | 6.17           |
| n_timesteps             | 2470000        |
| train-AverageDiscoun... | 57.4           |
| train-AverageReturn     | 87.9           |
| train-EnvExecTime       | 2.19           |
| train-MaxReturn         | 128            |
| train-MinReturn         | 31.3           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.78           |
| train-StdReturn         | 18.5           |
--------------------------------------------

 ---------------- Iteration 247 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 247           |
| ItrTime                 | 6.47          |
| LossAfter               | -0.020745581  |
| LossBefore              | -7.282601e-06 |
| Time                    | 1.56e+03      |
| Time-Optimization       | 0.242         |
| Time-SampleProc         | 0.0476        |
| Time-Sampling           | 6.18          |
| n_timesteps             | 2480000       |
| train-AverageDiscoun... | 59.4          |
| train-AverageReturn     | 92.5          |
| train-EnvExecTime       | 2.17          |
| train-MaxReturn         | 152           |
| train-MinReturn         | -57.6         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.81          |
| train-StdReturn         | 25.2          |
-------------------------------------------

 ---------------- Iteration 248 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 248           |
| ItrTime                 | 6.29          |
| LossAfter               | -0.020543009  |
| LossBefore              | -7.289683e-06 |
| Time                    | 1.57e+03      |
| Time-Optimization       | 0.206         |
| Time-SampleProc         | 0.0826        |
| Time-Sampling           | 5.99          |
| n_timesteps             | 2490000       |
| train-AverageDiscoun... | 57.4          |
| train-AverageReturn     | 88.9          |
| train-EnvExecTime       | 2.1           |
| train-MaxReturn         | 152           |
| train-MinReturn         | -8.84         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.7           |
| train-StdReturn         | 24.9          |
-------------------------------------------

 ---------------- Iteration 249 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 249           |
| ItrTime                 | 6.02          |
| LossAfter               | -0.020199666  |
| LossBefore              | -7.271406e-06 |
| Time                    | 1.57e+03      |
| Time-Optimization       | 0.23          |
| Time-SampleProc         | 0.0447        |
| Time-Sampling           | 5.74          |
| n_timesteps             | 2500000       |
| train-AverageDiscoun... | 57.2          |
| train-AverageReturn     | 89.2          |
| train-EnvExecTime       | 2.01          |
| train-MaxReturn         | 158           |
| train-MinReturn         | 11.8          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.54          |
| train-StdReturn         | 22.5          |
-------------------------------------------

 ---------------- Iteration 250 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 250            |
| ItrTime                 | 6.4            |
| LossAfter               | -0.019367687   |
| LossBefore              | -7.2196435e-06 |
| Time                    | 1.58e+03       |
| Time-Optimization       | 0.238          |
| Time-SampleProc         | 0.0485         |
| Time-Sampling           | 6.11           |
| n_timesteps             | 2510000        |
| train-AverageDiscoun... | 57.4           |
| train-AverageReturn     | 88.7           |
| train-EnvExecTime       | 2.16           |
| train-MaxReturn         | 145            |
| train-MinReturn         | 20.3           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.75           |
| train-StdReturn         | 21.2           |
--------------------------------------------

 ---------------- Iteration 251 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 251            |
| ItrTime                 | 6.25           |
| LossAfter               | -0.020631462   |
| LossBefore              | -7.2077846e-06 |
| Time                    | 1.59e+03       |
| Time-Optimization       | 0.237          |
| Time-SampleProc         | 0.0425         |
| Time-Sampling           | 5.97           |
| n_timesteps             | 2520000        |
| train-AverageDiscoun... | 56.9           |
| train-AverageReturn     | 87.8           |
| train-EnvExecTime       | 2.1            |
| train-MaxReturn         | 150            |
| train-MinReturn         | -5.96          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.67           |
| train-StdReturn         | 22.2           |
--------------------------------------------

 ---------------- Iteration 252 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 252            |
| ItrTime                 | 6.32           |
| LossAfter               | -0.020695163   |
| LossBefore              | -7.1513177e-06 |
| Time                    | 1.59e+03       |
| Time-Optimization       | 0.239          |
| Time-SampleProc         | 0.0455         |
| Time-Sampling           | 6.03           |
| n_timesteps             | 2530000        |
| train-AverageDiscoun... | 58.5           |
| train-AverageReturn     | 90.1           |
| train-EnvExecTime       | 2.13           |
| train-MaxReturn         | 139            |
| train-MinReturn         | 18.3           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.7            |
| train-StdReturn         | 19.7           |
--------------------------------------------

 ---------------- Iteration 253 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 253          |
| ItrTime                 | 6.34         |
| LossAfter               | -0.021679921 |
| LossBefore              | -7.14102e-06 |
| Time                    | 1.6e+03      |
| Time-Optimization       | 0.239        |
| Time-SampleProc         | 0.0846       |
| Time-Sampling           | 6.01         |
| n_timesteps             | 2540000      |
| train-AverageDiscoun... | 57.6         |
| train-AverageReturn     | 88.5         |
| train-EnvExecTime       | 2.09         |
| train-MaxReturn         | 130          |
| train-MinReturn         | -5.31        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 3.72         |
| train-StdReturn         | 21.5         |
------------------------------------------

 ---------------- Iteration 254 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 254            |
| ItrTime                 | 6.86           |
| LossAfter               | -0.022797843   |
| LossBefore              | -7.0734905e-06 |
| Time                    | 1.61e+03       |
| Time-Optimization       | 0.234          |
| Time-SampleProc         | 0.0898         |
| Time-Sampling           | 6.54           |
| n_timesteps             | 2550000        |
| train-AverageDiscoun... | 53.1           |
| train-AverageReturn     | 82.9           |
| train-EnvExecTime       | 2.29           |
| train-MaxReturn         | 138            |
| train-MinReturn         | -62.4          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.03           |
| train-StdReturn         | 28.3           |
--------------------------------------------

 ---------------- Iteration 255 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 255            |
| ItrTime                 | 6.4            |
| LossAfter               | -0.017931595   |
| LossBefore              | -7.0468427e-06 |
| Time                    | 1.61e+03       |
| Time-Optimization       | 0.229          |
| Time-SampleProc         | 0.052          |
| Time-Sampling           | 6.12           |
| n_timesteps             | 2560000        |
| train-AverageDiscoun... | 59.1           |
| train-AverageReturn     | 91.5           |
| train-EnvExecTime       | 2.13           |
| train-MaxReturn         | 147            |
| train-MinReturn         | -6.2           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.79           |
| train-StdReturn         | 21.8           |
--------------------------------------------

 ---------------- Iteration 256 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 256            |
| ItrTime                 | 6.04           |
| LossAfter               | -0.022637988   |
| LossBefore              | -7.0304313e-06 |
| Time                    | 1.62e+03       |
| Time-Optimization       | 0.219          |
| Time-SampleProc         | 0.0441         |
| Time-Sampling           | 5.78           |
| n_timesteps             | 2570000        |
| train-AverageDiscoun... | 60.3           |
| train-AverageReturn     | 93.4           |
| train-EnvExecTime       | 2.03           |
| train-MaxReturn         | 156            |
| train-MinReturn         | -8.23          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.56           |
| train-StdReturn         | 21.7           |
--------------------------------------------

 ---------------- Iteration 257 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 257           |
| ItrTime                 | 6.08          |
| LossAfter               | -0.021057835  |
| LossBefore              | -7.002309e-06 |
| Time                    | 1.63e+03      |
| Time-Optimization       | 0.226         |
| Time-SampleProc         | 0.0487        |
| Time-Sampling           | 5.81          |
| n_timesteps             | 2580000       |
| train-AverageDiscoun... | 55.3          |
| train-AverageReturn     | 86            |
| train-EnvExecTime       | 2.04          |
| train-MaxReturn         | 182           |
| train-MinReturn         | -74.6         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.58          |
| train-StdReturn         | 32            |
-------------------------------------------

 ---------------- Iteration 258 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 258           |
| ItrTime                 | 6.06          |
| LossAfter               | -0.022295963  |
| LossBefore              | -6.973719e-06 |
| Time                    | 1.63e+03      |
| Time-Optimization       | 0.233         |
| Time-SampleProc         | 0.0456        |
| Time-Sampling           | 5.78          |
| n_timesteps             | 2590000       |
| train-AverageDiscoun... | 59.8          |
| train-AverageReturn     | 92.4          |
| train-EnvExecTime       | 2.03          |
| train-MaxReturn         | 221           |
| train-MinReturn         | -14.8         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.55          |
| train-StdReturn         | 26.5          |
-------------------------------------------

 ---------------- Iteration 259 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 259            |
| ItrTime                 | 6.43           |
| LossAfter               | -0.021091342   |
| LossBefore              | -6.9256635e-06 |
| Time                    | 1.64e+03       |
| Time-Optimization       | 0.252          |
| Time-SampleProc         | 0.0422         |
| Time-Sampling           | 6.13           |
| n_timesteps             | 2600000        |
| train-AverageDiscoun... | 57.8           |
| train-AverageReturn     | 89.8           |
| train-EnvExecTime       | 2.17           |
| train-MaxReturn         | 168            |
| train-MinReturn         | -14.6          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.76           |
| train-StdReturn         | 27.1           |
--------------------------------------------

 ---------------- Iteration 260 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 260           |
| ItrTime                 | 6.22          |
| LossAfter               | -0.014544963  |
| LossBefore              | -6.908839e-06 |
| Time                    | 1.64e+03      |
| Time-Optimization       | 0.229         |
| Time-SampleProc         | 0.0454        |
| Time-Sampling           | 5.95          |
| n_timesteps             | 2610000       |
| train-AverageDiscoun... | 60.4          |
| train-AverageReturn     | 93.2          |
| train-EnvExecTime       | 2.07          |
| train-MaxReturn         | 131           |
| train-MinReturn         | -39.8         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.68          |
| train-StdReturn         | 23.6          |
-------------------------------------------

 ---------------- Iteration 261 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 261            |
| ItrTime                 | 6.04           |
| LossAfter               | -0.017909462   |
| LossBefore              | -6.9200996e-06 |
| Time                    | 1.65e+03       |
| Time-Optimization       | 0.241          |
| Time-SampleProc         | 0.0446         |
| Time-Sampling           | 5.75           |
| n_timesteps             | 2620000        |
| train-AverageDiscoun... | 59.5           |
| train-AverageReturn     | 92.7           |
| train-EnvExecTime       | 2.01           |
| train-MaxReturn         | 147            |
| train-MinReturn         | 16.2           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.56           |
| train-StdReturn         | 22.5           |
--------------------------------------------

 ---------------- Iteration 262 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 262           |
| ItrTime                 | 6.1           |
| LossAfter               | -0.019265145  |
| LossBefore              | -6.862354e-06 |
| Time                    | 1.66e+03      |
| Time-Optimization       | 0.23          |
| Time-SampleProc         | 0.0409        |
| Time-Sampling           | 5.83          |
| n_timesteps             | 2630000       |
| train-AverageDiscoun... | 62.8          |
| train-AverageReturn     | 96.9          |
| train-EnvExecTime       | 2.07          |
| train-MaxReturn         | 141           |
| train-MinReturn         | 16.1          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.57          |
| train-StdReturn         | 20.8          |
-------------------------------------------

 ---------------- Iteration 263 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 263           |
| ItrTime                 | 6.34          |
| LossAfter               | -0.02060531   |
| LossBefore              | -6.827144e-06 |
| Time                    | 1.66e+03      |
| Time-Optimization       | 0.239         |
| Time-SampleProc         | 0.0886        |
| Time-Sampling           | 6.01          |
| n_timesteps             | 2640000       |
| train-AverageDiscoun... | 57.5          |
| train-AverageReturn     | 89.8          |
| train-EnvExecTime       | 2.12          |
| train-MaxReturn         | 154           |
| train-MinReturn         | -15.1         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.7           |
| train-StdReturn         | 23.9          |
-------------------------------------------

 ---------------- Iteration 264 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 264           |
| ItrTime                 | 6.36          |
| LossAfter               | -0.01940523   |
| LossBefore              | -6.848659e-06 |
| Time                    | 1.67e+03      |
| Time-Optimization       | 0.235         |
| Time-SampleProc         | 0.0539        |
| Time-Sampling           | 6.07          |
| n_timesteps             | 2650000       |
| train-AverageDiscoun... | 65.2          |
| train-AverageReturn     | 101           |
| train-EnvExecTime       | 2.13          |
| train-MaxReturn         | 179           |
| train-MinReturn         | 58.3          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.74          |
| train-StdReturn         | 21.8          |
-------------------------------------------

 ---------------- Iteration 265 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 265            |
| ItrTime                 | 6.05           |
| LossAfter               | -0.018298537   |
| LossBefore              | -6.7909855e-06 |
| Time                    | 1.68e+03       |
| Time-Optimization       | 0.23           |
| Time-SampleProc         | 0.0554         |
| Time-Sampling           | 5.76           |
| n_timesteps             | 2660000        |
| train-AverageDiscoun... | 59.5           |
| train-AverageReturn     | 92.1           |
| train-EnvExecTime       | 2.03           |
| train-MaxReturn         | 166            |
| train-MinReturn         | -61.9          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.55           |
| train-StdReturn         | 26.4           |
--------------------------------------------

 ---------------- Iteration 266 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 266            |
| ItrTime                 | 6.19           |
| LossAfter               | -0.023237905   |
| LossBefore              | -6.7456594e-06 |
| Time                    | 1.68e+03       |
| Time-Optimization       | 0.248          |
| Time-SampleProc         | 0.0521         |
| Time-Sampling           | 5.89           |
| n_timesteps             | 2670000        |
| train-AverageDiscoun... | 58.6           |
| train-AverageReturn     | 92.3           |
| train-EnvExecTime       | 2.06           |
| train-MaxReturn         | 166            |
| train-MinReturn         | -25.5          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.64           |
| train-StdReturn         | 23.8           |
--------------------------------------------

 ---------------- Iteration 267 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 267           |
| ItrTime                 | 6.4           |
| LossAfter               | -0.020523662  |
| LossBefore              | -6.698797e-06 |
| Time                    | 1.69e+03      |
| Time-Optimization       | 0.251         |
| Time-SampleProc         | 0.0905        |
| Time-Sampling           | 6.06          |
| n_timesteps             | 2680000       |
| train-AverageDiscoun... | 61.2          |
| train-AverageReturn     | 95.3          |
| train-EnvExecTime       | 2.14          |
| train-MaxReturn         | 141           |
| train-MinReturn         | 33.2          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.71          |
| train-StdReturn         | 19.7          |
-------------------------------------------

 ---------------- Iteration 268 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 268           |
| ItrTime                 | 6.15          |
| LossAfter               | -0.020750688  |
| LossBefore              | -6.681556e-06 |
| Time                    | 1.69e+03      |
| Time-Optimization       | 0.29          |
| Time-SampleProc         | 0.0996        |
| Time-Sampling           | 5.76          |
| n_timesteps             | 2690000       |
| train-AverageDiscoun... | 59.6          |
| train-AverageReturn     | 93.5          |
| train-EnvExecTime       | 2.04          |
| train-MaxReturn         | 157           |
| train-MinReturn         | 25.7          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.52          |
| train-StdReturn         | 20.4          |
-------------------------------------------

 ---------------- Iteration 269 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 269           |
| ItrTime                 | 6.06          |
| LossAfter               | -0.02036262   |
| LossBefore              | -6.665528e-06 |
| Time                    | 1.7e+03       |
| Time-Optimization       | 0.336         |
| Time-SampleProc         | 0.0762        |
| Time-Sampling           | 5.65          |
| n_timesteps             | 2700000       |
| train-AverageDiscoun... | 60.3          |
| train-AverageReturn     | 93.8          |
| train-EnvExecTime       | 2             |
| train-MaxReturn         | 171           |
| train-MinReturn         | 30.5          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.45          |
| train-StdReturn         | 22.4          |
-------------------------------------------

 ---------------- Iteration 270 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 270            |
| ItrTime                 | 6.51           |
| LossAfter               | -0.021916103   |
| LossBefore              | -6.6469242e-06 |
| Time                    | 1.71e+03       |
| Time-Optimization       | 0.327          |
| Time-SampleProc         | 0.0475         |
| Time-Sampling           | 6.14           |
| n_timesteps             | 2710000        |
| train-AverageDiscoun... | 59.1           |
| train-AverageReturn     | 92.4           |
| train-EnvExecTime       | 2.18           |
| train-MaxReturn         | 146            |
| train-MinReturn         | 8.3            |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.76           |
| train-StdReturn         | 19             |
--------------------------------------------

 ---------------- Iteration 271 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 271            |
| ItrTime                 | 6.53           |
| LossAfter               | -0.020663168   |
| LossBefore              | -6.6576117e-06 |
| Time                    | 1.71e+03       |
| Time-Optimization       | 0.33           |
| Time-SampleProc         | 0.0855         |
| Time-Sampling           | 6.11           |
| n_timesteps             | 2720000        |
| train-AverageDiscoun... | 62.6           |
| train-AverageReturn     | 96.9           |
| train-EnvExecTime       | 2.17           |
| train-MaxReturn         | 153            |
| train-MinReturn         | -41.6          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.75           |
| train-StdReturn         | 23.5           |
--------------------------------------------

 ---------------- Iteration 272 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 272           |
| ItrTime                 | 6.52          |
| LossAfter               | -0.02237987   |
| LossBefore              | -6.609715e-06 |
| Time                    | 1.72e+03      |
| Time-Optimization       | 0.272         |
| Time-SampleProc         | 0.0552        |
| Time-Sampling           | 6.2           |
| n_timesteps             | 2730000       |
| train-AverageDiscoun... | 60            |
| train-AverageReturn     | 92.4          |
| train-EnvExecTime       | 2.18          |
| train-MaxReturn         | 135           |
| train-MinReturn         | 4.47          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.81          |
| train-StdReturn         | 23.4          |
-------------------------------------------

 ---------------- Iteration 273 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 273            |
| ItrTime                 | 7.12           |
| LossAfter               | -0.02293602    |
| LossBefore              | -6.6044545e-06 |
| Time                    | 1.73e+03       |
| Time-Optimization       | 0.232          |
| Time-SampleProc         | 0.0482         |
| Time-Sampling           | 6.84           |
| n_timesteps             | 2740000        |
| train-AverageDiscoun... | 62.2           |
| train-AverageReturn     | 97.1           |
| train-EnvExecTime       | 2.31           |
| train-MaxReturn         | 142            |
| train-MinReturn         | 62.8           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.3            |
| train-StdReturn         | 17.4           |
--------------------------------------------

 ---------------- Iteration 274 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 274            |
| ItrTime                 | 6.05           |
| LossAfter               | -0.024104243   |
| LossBefore              | -6.6076177e-06 |
| Time                    | 1.73e+03       |
| Time-Optimization       | 0.249          |
| Time-SampleProc         | 0.0415         |
| Time-Sampling           | 5.75           |
| n_timesteps             | 2750000        |
| train-AverageDiscoun... | 60.4           |
| train-AverageReturn     | 93.6           |
| train-EnvExecTime       | 1.99           |
| train-MaxReturn         | 192            |
| train-MinReturn         | 9.35           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.57           |
| train-StdReturn         | 25.7           |
--------------------------------------------

 ---------------- Iteration 275 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 275           |
| ItrTime                 | 6.41          |
| LossAfter               | -0.023606252  |
| LossBefore              | -6.575052e-06 |
| Time                    | 1.74e+03      |
| Time-Optimization       | 0.227         |
| Time-SampleProc         | 0.0814        |
| Time-Sampling           | 6.1           |
| n_timesteps             | 2760000       |
| train-AverageDiscoun... | 63.2          |
| train-AverageReturn     | 98.1          |
| train-EnvExecTime       | 2.14          |
| train-MaxReturn         | 170           |
| train-MinReturn         | 53.9          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.76          |
| train-StdReturn         | 21.9          |
-------------------------------------------

 ---------------- Iteration 276 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 276           |
| ItrTime                 | 6.48          |
| LossAfter               | -0.016291892  |
| LossBefore              | -6.571323e-06 |
| Time                    | 1.75e+03      |
| Time-Optimization       | 0.205         |
| Time-SampleProc         | 0.0859        |
| Time-Sampling           | 6.19          |
| n_timesteps             | 2770000       |
| train-AverageDiscoun... | 61.7          |
| train-AverageReturn     | 96.6          |
| train-EnvExecTime       | 2.18          |
| train-MaxReturn         | 148           |
| train-MinReturn         | 46.2          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.81          |
| train-StdReturn         | 18.4          |
-------------------------------------------

 ---------------- Iteration 277 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 277            |
| ItrTime                 | 6.27           |
| LossAfter               | -0.024276793   |
| LossBefore              | -6.5391973e-06 |
| Time                    | 1.75e+03       |
| Time-Optimization       | 0.233          |
| Time-SampleProc         | 0.0462         |
| Time-Sampling           | 5.99           |
| n_timesteps             | 2780000        |
| train-AverageDiscoun... | 59.7           |
| train-AverageReturn     | 92.1           |
| train-EnvExecTime       | 2.11           |
| train-MaxReturn         | 133            |
| train-MinReturn         | 15.7           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.68           |
| train-StdReturn         | 21.1           |
--------------------------------------------

 ---------------- Iteration 278 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 278           |
| ItrTime                 | 6.81          |
| LossAfter               | -0.01989083   |
| LossBefore              | -6.503946e-06 |
| Time                    | 1.76e+03      |
| Time-Optimization       | 0.223         |
| Time-SampleProc         | 0.086         |
| Time-Sampling           | 6.49          |
| n_timesteps             | 2790000       |
| train-AverageDiscoun... | 60.5          |
| train-AverageReturn     | 94.5          |
| train-EnvExecTime       | 2.28          |
| train-MaxReturn         | 139           |
| train-MinReturn         | 49.5          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 4.01          |
| train-StdReturn         | 16.1          |
-------------------------------------------

 ---------------- Iteration 279 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 279           |
| ItrTime                 | 6.48          |
| LossAfter               | -0.02129545   |
| LossBefore              | -6.495218e-06 |
| Time                    | 1.77e+03      |
| Time-Optimization       | 0.216         |
| Time-SampleProc         | 0.0447        |
| Time-Sampling           | 6.22          |
| n_timesteps             | 2800000       |
| train-AverageDiscoun... | 60.9          |
| train-AverageReturn     | 95.1          |
| train-EnvExecTime       | 2.17          |
| train-MaxReturn         | 147           |
| train-MinReturn         | 2.21          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.85          |
| train-StdReturn         | 21.2          |
-------------------------------------------

 ---------------- Iteration 280 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 280            |
| ItrTime                 | 6.23           |
| LossAfter               | -0.021240998   |
| LossBefore              | -6.4482224e-06 |
| Time                    | 1.77e+03       |
| Time-Optimization       | 0.231          |
| Time-SampleProc         | 0.0468         |
| Time-Sampling           | 5.95           |
| n_timesteps             | 2810000        |
| train-AverageDiscoun... | 61.2           |
| train-AverageReturn     | 94.8           |
| train-EnvExecTime       | 2.09           |
| train-MaxReturn         | 158            |
| train-MinReturn         | -16.1          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.67           |
| train-StdReturn         | 24.3           |
--------------------------------------------

 ---------------- Iteration 281 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 281           |
| ItrTime                 | 6.19          |
| LossAfter               | -0.014825894  |
| LossBefore              | -6.436072e-06 |
| Time                    | 1.78e+03      |
| Time-Optimization       | 0.219         |
| Time-SampleProc         | 0.0639        |
| Time-Sampling           | 5.91          |
| n_timesteps             | 2820000       |
| train-AverageDiscoun... | 62.4          |
| train-AverageReturn     | 97.2          |
| train-EnvExecTime       | 2.07          |
| train-MaxReturn         | 156           |
| train-MinReturn         | 56.6          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.64          |
| train-StdReturn         | 18.3          |
-------------------------------------------

 ---------------- Iteration 282 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 282           |
| ItrTime                 | 6.05          |
| LossAfter               | -0.020183763  |
| LossBefore              | -6.416359e-06 |
| Time                    | 1.78e+03      |
| Time-Optimization       | 0.235         |
| Time-SampleProc         | 0.0362        |
| Time-Sampling           | 5.78          |
| n_timesteps             | 2830000       |
| train-AverageDiscoun... | 61.4          |
| train-AverageReturn     | 95.7          |
| train-EnvExecTime       | 2.03          |
| train-MaxReturn         | 189           |
| train-MinReturn         | -3.35         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.56          |
| train-StdReturn         | 23.6          |
-------------------------------------------

 ---------------- Iteration 283 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 283            |
| ItrTime                 | 6.5            |
| LossAfter               | -0.01911146    |
| LossBefore              | -6.3901407e-06 |
| Time                    | 1.79e+03       |
| Time-Optimization       | 0.218          |
| Time-SampleProc         | 0.0487         |
| Time-Sampling           | 6.23           |
| n_timesteps             | 2840000        |
| train-AverageDiscoun... | 61.5           |
| train-AverageReturn     | 95.8           |
| train-EnvExecTime       | 2.2            |
| train-MaxReturn         | 155            |
| train-MinReturn         | 48.7           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.82           |
| train-StdReturn         | 20.4           |
--------------------------------------------

 ---------------- Iteration 284 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 284            |
| ItrTime                 | 6.14           |
| LossAfter               | -0.022460755   |
| LossBefore              | -6.3415305e-06 |
| Time                    | 1.8e+03        |
| Time-Optimization       | 0.215          |
| Time-SampleProc         | 0.0444         |
| Time-Sampling           | 5.88           |
| n_timesteps             | 2850000        |
| train-AverageDiscoun... | 65.1           |
| train-AverageReturn     | 101            |
| train-EnvExecTime       | 2.06           |
| train-MaxReturn         | 166            |
| train-MinReturn         | 57.4           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.63           |
| train-StdReturn         | 18.6           |
--------------------------------------------

 ---------------- Iteration 285 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 285            |
| ItrTime                 | 6.02           |
| LossAfter               | -0.021445187   |
| LossBefore              | -6.3075163e-06 |
| Time                    | 1.8e+03        |
| Time-Optimization       | 0.221          |
| Time-SampleProc         | 0.0403         |
| Time-Sampling           | 5.76           |
| n_timesteps             | 2860000        |
| train-AverageDiscoun... | 64.2           |
| train-AverageReturn     | 100            |
| train-EnvExecTime       | 2.01           |
| train-MaxReturn         | 140            |
| train-MinReturn         | 55.6           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.55           |
| train-StdReturn         | 18.6           |
--------------------------------------------

 ---------------- Iteration 286 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 286           |
| ItrTime                 | 6.48          |
| LossAfter               | -0.020735012  |
| LossBefore              | -6.258436e-06 |
| Time                    | 1.81e+03      |
| Time-Optimization       | 0.221         |
| Time-SampleProc         | 0.0695        |
| Time-Sampling           | 6.19          |
| n_timesteps             | 2870000       |
| train-AverageDiscoun... | 63.4          |
| train-AverageReturn     | 98.3          |
| train-EnvExecTime       | 2.17          |
| train-MaxReturn         | 172           |
| train-MinReturn         | 56.5          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.82          |
| train-StdReturn         | 19.7          |
-------------------------------------------

 ---------------- Iteration 287 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 287            |
| ItrTime                 | 6.35           |
| LossAfter               | -0.01858778    |
| LossBefore              | -6.2491713e-06 |
| Time                    | 1.82e+03       |
| Time-Optimization       | 0.218          |
| Time-SampleProc         | 0.0466         |
| Time-Sampling           | 6.08           |
| n_timesteps             | 2880000        |
| train-AverageDiscoun... | 61.1           |
| train-AverageReturn     | 95.3           |
| train-EnvExecTime       | 2.14           |
| train-MaxReturn         | 143            |
| train-MinReturn         | -20.7          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.75           |
| train-StdReturn         | 21.8           |
--------------------------------------------

 ---------------- Iteration 288 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 288            |
| ItrTime                 | 6.33           |
| LossAfter               | -0.016715564   |
| LossBefore              | -6.2517515e-06 |
| Time                    | 1.82e+03       |
| Time-Optimization       | 0.212          |
| Time-SampleProc         | 0.0867         |
| Time-Sampling           | 6.03           |
| n_timesteps             | 2890000        |
| train-AverageDiscoun... | 63.9           |
| train-AverageReturn     | 100            |
| train-EnvExecTime       | 2.12           |
| train-MaxReturn         | 150            |
| train-MinReturn         | 29             |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.71           |
| train-StdReturn         | 19.5           |
--------------------------------------------

 ---------------- Iteration 289 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 289            |
| ItrTime                 | 6.28           |
| LossAfter               | -0.017882772   |
| LossBefore              | -6.2041927e-06 |
| Time                    | 1.83e+03       |
| Time-Optimization       | 0.23           |
| Time-SampleProc         | 0.0431         |
| Time-Sampling           | 6              |
| n_timesteps             | 2900000        |
| train-AverageDiscoun... | 64.4           |
| train-AverageReturn     | 100            |
| train-EnvExecTime       | 2.1            |
| train-MaxReturn         | 192            |
| train-MinReturn         | 42.1           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.71           |
| train-StdReturn         | 22.1           |
--------------------------------------------

 ---------------- Iteration 290 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 290            |
| ItrTime                 | 6.22           |
| LossAfter               | -0.018581813   |
| LossBefore              | -6.1555193e-06 |
| Time                    | 1.83e+03       |
| Time-Optimization       | 0.203          |
| Time-SampleProc         | 0.0827         |
| Time-Sampling           | 5.93           |
| n_timesteps             | 2910000        |
| train-AverageDiscoun... | 63.4           |
| train-AverageReturn     | 98.4           |
| train-EnvExecTime       | 2.06           |
| train-MaxReturn         | 140            |
| train-MinReturn         | -11            |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.66           |
| train-StdReturn         | 21             |
--------------------------------------------

 ---------------- Iteration 291 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 291           |
| ItrTime                 | 6.09          |
| LossAfter               | -0.018137129  |
| LossBefore              | -6.162036e-06 |
| Time                    | 1.84e+03      |
| Time-Optimization       | 0.219         |
| Time-SampleProc         | 0.0421        |
| Time-Sampling           | 5.83          |
| n_timesteps             | 2920000       |
| train-AverageDiscoun... | 62.3          |
| train-AverageReturn     | 97.9          |
| train-EnvExecTime       | 2.06          |
| train-MaxReturn         | 150           |
| train-MinReturn         | -0.804        |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.59          |
| train-StdReturn         | 21.5          |
-------------------------------------------

 ---------------- Iteration 292 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 292           |
| ItrTime                 | 5.98          |
| LossAfter               | -0.017431729  |
| LossBefore              | -6.142196e-06 |
| Time                    | 1.85e+03      |
| Time-Optimization       | 0.239         |
| Time-SampleProc         | 0.0419        |
| Time-Sampling           | 5.7           |
| n_timesteps             | 2930000       |
| train-AverageDiscoun... | 60.9          |
| train-AverageReturn     | 95.6          |
| train-EnvExecTime       | 2             |
| train-MaxReturn         | 179           |
| train-MinReturn         | -22           |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.51          |
| train-StdReturn         | 23            |
-------------------------------------------

 ---------------- Iteration 293 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 293            |
| ItrTime                 | 6.44           |
| LossAfter               | -0.008523204   |
| LossBefore              | -6.1167266e-06 |
| Time                    | 1.85e+03       |
| Time-Optimization       | 0.243          |
| Time-SampleProc         | 0.0437         |
| Time-Sampling           | 6.15           |
| n_timesteps             | 2940000        |
| train-AverageDiscoun... | 64.2           |
| train-AverageReturn     | 100            |
| train-EnvExecTime       | 2.16           |
| train-MaxReturn         | 162            |
| train-MinReturn         | -42.4          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.78           |
| train-StdReturn         | 24.3           |
--------------------------------------------

 ---------------- Iteration 294 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 294           |
| ItrTime                 | 6.37          |
| LossAfter               | -0.011047304  |
| LossBefore              | -6.099553e-06 |
| Time                    | 1.86e+03      |
| Time-Optimization       | 0.195         |
| Time-SampleProc         | 0.082         |
| Time-Sampling           | 6.08          |
| n_timesteps             | 2950000       |
| train-AverageDiscoun... | 62.7          |
| train-AverageReturn     | 98.6          |
| train-EnvExecTime       | 2.14          |
| train-MaxReturn         | 165           |
| train-MinReturn         | 24.6          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.75          |
| train-StdReturn         | 20.3          |
-------------------------------------------

 ---------------- Iteration 295 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 295           |
| ItrTime                 | 6.27          |
| LossAfter               | -0.013231741  |
| LossBefore              | -6.085882e-06 |
| Time                    | 1.87e+03      |
| Time-Optimization       | 0.236         |
| Time-SampleProc         | 0.0452        |
| Time-Sampling           | 5.98          |
| n_timesteps             | 2960000       |
| train-AverageDiscoun... | 65.3          |
| train-AverageReturn     | 102           |
| train-EnvExecTime       | 2.11          |
| train-MaxReturn         | 205           |
| train-MinReturn         | 18.6          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.68          |
| train-StdReturn         | 23.1          |
-------------------------------------------

 ---------------- Iteration 296 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 296            |
| ItrTime                 | 6.24           |
| LossAfter               | -0.011995304   |
| LossBefore              | -6.0534217e-06 |
| Time                    | 1.87e+03       |
| Time-Optimization       | 0.229          |
| Time-SampleProc         | 0.0402         |
| Time-Sampling           | 5.97           |
| n_timesteps             | 2970000        |
| train-AverageDiscoun... | 64.3           |
| train-AverageReturn     | 101            |
| train-EnvExecTime       | 2.1            |
| train-MaxReturn         | 157            |
| train-MinReturn         | -1.2           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.68           |
| train-StdReturn         | 23.6           |
--------------------------------------------

 ---------------- Iteration 297 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 297           |
| ItrTime                 | 6.14          |
| LossAfter               | -0.019552909  |
| LossBefore              | -5.992487e-06 |
| Time                    | 1.88e+03      |
| Time-Optimization       | 0.224         |
| Time-SampleProc         | 0.0448        |
| Time-Sampling           | 5.87          |
| n_timesteps             | 2980000       |
| train-AverageDiscoun... | 63            |
| train-AverageReturn     | 99.3          |
| train-EnvExecTime       | 2.06          |
| train-MaxReturn         | 208           |
| train-MinReturn         | 31.1          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.61          |
| train-StdReturn         | 22.3          |
-------------------------------------------

 ---------------- Iteration 298 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 298            |
| ItrTime                 | 6.1            |
| LossAfter               | -0.01815992    |
| LossBefore              | -6.0070497e-06 |
| Time                    | 1.88e+03       |
| Time-Optimization       | 0.214          |
| Time-SampleProc         | 0.101          |
| Time-Sampling           | 5.78           |
| n_timesteps             | 2990000        |
| train-AverageDiscoun... | 66.2           |
| train-AverageReturn     | 104            |
| train-EnvExecTime       | 2.03           |
| train-MaxReturn         | 166            |
| train-MinReturn         | -0.575         |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.57           |
| train-StdReturn         | 24.5           |
--------------------------------------------

 ---------------- Iteration 299 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 299           |
| ItrTime                 | 6.6           |
| LossAfter               | -0.012137781  |
| LossBefore              | -5.964287e-06 |
| Time                    | 1.89e+03      |
| Time-Optimization       | 0.235         |
| Time-SampleProc         | 0.046         |
| Time-Sampling           | 6.32          |
| n_timesteps             | 3000000       |
| train-AverageDiscoun... | 61.8          |
| train-AverageReturn     | 97.5          |
| train-EnvExecTime       | 2.23          |
| train-MaxReturn         | 205           |
| train-MinReturn         | -9.88         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.88          |
| train-StdReturn         | 26.7          |
-------------------------------------------
Training finished
