Logging to /home/vincent/workplace/CS_287_-_Advanced_Robotics/homework/hw5/cs287hw5/ppo/run_scripts/data/ppo+entropy+gae_tuning_GAElambda0.99_hidden192_e1e-6_Swimmer/01

 ---------------- Iteration 0 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 0              |
| ItrTime                 | 6.04           |
| LossAfter               | 0.005066491    |
| LossBefore              | -1.4158867e-06 |
| Time                    | 6.04           |
| Time-Optimization       | 0.371          |
| Time-SampleProc         | 0.129          |
| Time-Sampling           | 5.53           |
| n_timesteps             | 10000          |
| train-AverageDiscoun... | 4.7            |
| train-AverageReturn     | 7.81           |
| train-EnvExecTime       | 1.86           |
| train-MaxReturn         | 25.6           |
| train-MinReturn         | -11            |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.48           |
| train-StdReturn         | 7.81           |
--------------------------------------------

 ---------------- Iteration 1 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 1              |
| ItrTime                 | 5.62           |
| LossAfter               | 0.01209819     |
| LossBefore              | -1.4183481e-06 |
| Time                    | 11.7           |
| Time-Optimization       | 0.232          |
| Time-SampleProc         | 0.0402         |
| Time-Sampling           | 5.35           |
| n_timesteps             | 20000          |
| train-AverageDiscoun... | 5.55           |
| train-AverageReturn     | 9.19           |
| train-EnvExecTime       | 1.83           |
| train-MaxReturn         | 27.5           |
| train-MinReturn         | -3.85          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.33           |
| train-StdReturn         | 6.98           |
--------------------------------------------

 ---------------- Iteration 2 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 2              |
| ItrTime                 | 5.6            |
| LossAfter               | -0.005395123   |
| LossBefore              | -1.4212062e-06 |
| Time                    | 17.3           |
| Time-Optimization       | 0.282          |
| Time-SampleProc         | 0.0872         |
| Time-Sampling           | 5.23           |
| n_timesteps             | 30000          |
| train-AverageDiscoun... | 6.75           |
| train-AverageReturn     | 11             |
| train-EnvExecTime       | 1.82           |
| train-MaxReturn         | 26.4           |
| train-MinReturn         | -5.52          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.22           |
| train-StdReturn         | 7.3            |
--------------------------------------------

 ---------------- Iteration 3 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 3              |
| ItrTime                 | 5.63           |
| LossAfter               | -0.009071367   |
| LossBefore              | -1.4203548e-06 |
| Time                    | 22.9           |
| Time-Optimization       | 0.317          |
| Time-SampleProc         | 0.143          |
| Time-Sampling           | 5.17           |
| n_timesteps             | 40000          |
| train-AverageDiscoun... | 10.3           |
| train-AverageReturn     | 15.5           |
| train-EnvExecTime       | 1.83           |
| train-MaxReturn         | 33.3           |
| train-MinReturn         | -10.6          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.16           |
| train-StdReturn         | 8.12           |
--------------------------------------------

 ---------------- Iteration 4 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 4              |
| ItrTime                 | 5.67           |
| LossAfter               | -0.007153989   |
| LossBefore              | -1.4113612e-06 |
| Time                    | 28.6           |
| Time-Optimization       | 0.378          |
| Time-SampleProc         | 0.0887         |
| Time-Sampling           | 5.21           |
| n_timesteps             | 50000          |
| train-AverageDiscoun... | 15.6           |
| train-AverageReturn     | 21.9           |
| train-EnvExecTime       | 1.86           |
| train-MaxReturn         | 31.8           |
| train-MinReturn         | -1.71          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.16           |
| train-StdReturn         | 5.94           |
--------------------------------------------

 ---------------- Iteration 5 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 5              |
| ItrTime                 | 5.67           |
| LossAfter               | -0.006199216   |
| LossBefore              | -1.4049215e-06 |
| Time                    | 34.3           |
| Time-Optimization       | 0.379          |
| Time-SampleProc         | 0.0385         |
| Time-Sampling           | 5.25           |
| n_timesteps             | 60000          |
| train-AverageDiscoun... | 17.7           |
| train-AverageReturn     | 24.9           |
| train-EnvExecTime       | 1.88           |
| train-MaxReturn         | 34             |
| train-MinReturn         | -1.23          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.19           |
| train-StdReturn         | 5.07           |
--------------------------------------------

 ---------------- Iteration 6 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 6              |
| ItrTime                 | 9.08           |
| LossAfter               | -0.0061016628  |
| LossBefore              | -1.4099301e-06 |
| Time                    | 43.4           |
| Time-Optimization       | 0.297          |
| Time-SampleProc         | 0.0355         |
| Time-Sampling           | 8.75           |
| n_timesteps             | 70000          |
| train-AverageDiscoun... | 19.4           |
| train-AverageReturn     | 25.9           |
| train-EnvExecTime       | 3.16           |
| train-MaxReturn         | 33.2           |
| train-MinReturn         | -1.89          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 5.3            |
| train-StdReturn         | 4.5            |
--------------------------------------------

 ---------------- Iteration 7 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 7              |
| ItrTime                 | 5.55           |
| LossAfter               | -0.0020370553  |
| LossBefore              | -1.4035295e-06 |
| Time                    | 49             |
| Time-Optimization       | 0.203          |
| Time-SampleProc         | 0.0351         |
| Time-Sampling           | 5.32           |
| n_timesteps             | 80000          |
| train-AverageDiscoun... | 20.2           |
| train-AverageReturn     | 26.4           |
| train-EnvExecTime       | 1.91           |
| train-MaxReturn         | 33             |
| train-MinReturn         | -5.31          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.23           |
| train-StdReturn         | 4.93           |
--------------------------------------------

 ---------------- Iteration 8 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 8              |
| ItrTime                 | 9.13           |
| LossAfter               | -0.003665264   |
| LossBefore              | -1.3969304e-06 |
| Time                    | 58.1           |
| Time-Optimization       | 0.192          |
| Time-SampleProc         | 0.0342         |
| Time-Sampling           | 8.9            |
| n_timesteps             | 90000          |
| train-AverageDiscoun... | 20.7           |
| train-AverageReturn     | 26.8           |
| train-EnvExecTime       | 3.23           |
| train-MaxReturn         | 31.3           |
| train-MinReturn         | 19.4           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 5.39           |
| train-StdReturn         | 2.58           |
--------------------------------------------

 ---------------- Iteration 9 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 9              |
| ItrTime                 | 5.85           |
| LossAfter               | -0.003109541   |
| LossBefore              | -1.4064578e-06 |
| Time                    | 63.9           |
| Time-Optimization       | 0.286          |
| Time-SampleProc         | 0.0636         |
| Time-Sampling           | 5.5            |
| n_timesteps             | 100000         |
| train-AverageDiscoun... | 21             |
| train-AverageReturn     | 27.2           |
| train-EnvExecTime       | 1.98           |
| train-MaxReturn         | 31.5           |
| train-MinReturn         | 16.8           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.33           |
| train-StdReturn         | 2.64           |
--------------------------------------------

 ---------------- Iteration 10 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 10             |
| ItrTime                 | 7.7            |
| LossAfter               | -0.0033777126  |
| LossBefore              | -1.3902412e-06 |
| Time                    | 71.7           |
| Time-Optimization       | 0.393          |
| Time-SampleProc         | 0.0346         |
| Time-Sampling           | 7.27           |
| n_timesteps             | 110000         |
| train-AverageDiscoun... | 21.6           |
| train-AverageReturn     | 27.6           |
| train-EnvExecTime       | 2.59           |
| train-MaxReturn         | 34.1           |
| train-MinReturn         | 16.1           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.44           |
| train-StdReturn         | 2.19           |
--------------------------------------------

 ---------------- Iteration 11 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 11             |
| ItrTime                 | 5.61           |
| LossAfter               | -0.0037194306  |
| LossBefore              | -1.3849578e-06 |
| Time                    | 77.3           |
| Time-Optimization       | 0.371          |
| Time-SampleProc         | 0.0349         |
| Time-Sampling           | 5.2            |
| n_timesteps             | 120000         |
| train-AverageDiscoun... | 21.4           |
| train-AverageReturn     | 27             |
| train-EnvExecTime       | 1.89           |
| train-MaxReturn         | 35.6           |
| train-MinReturn         | 1.19           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.13           |
| train-StdReturn         | 3.8            |
--------------------------------------------

 ---------------- Iteration 12 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 12             |
| ItrTime                 | 5.8            |
| LossAfter               | -0.0023568165  |
| LossBefore              | -1.3858584e-06 |
| Time                    | 83.1           |
| Time-Optimization       | 0.426          |
| Time-SampleProc         | 0.0379         |
| Time-Sampling           | 5.34           |
| n_timesteps             | 130000         |
| train-AverageDiscoun... | 21.7           |
| train-AverageReturn     | 27.4           |
| train-EnvExecTime       | 1.93           |
| train-MaxReturn         | 31.8           |
| train-MinReturn         | -3.55          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.22           |
| train-StdReturn         | 4.58           |
--------------------------------------------

 ---------------- Iteration 13 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 13             |
| ItrTime                 | 5.65           |
| LossAfter               | -0.0032012372  |
| LossBefore              | -1.3691716e-06 |
| Time                    | 88.8           |
| Time-Optimization       | 0.398          |
| Time-SampleProc         | 0.0344         |
| Time-Sampling           | 5.22           |
| n_timesteps             | 140000         |
| train-AverageDiscoun... | 22.3           |
| train-AverageReturn     | 28             |
| train-EnvExecTime       | 1.91           |
| train-MaxReturn         | 32.9           |
| train-MinReturn         | 20.5           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.13           |
| train-StdReturn         | 2.17           |
--------------------------------------------

 ---------------- Iteration 14 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 14             |
| ItrTime                 | 5.73           |
| LossAfter               | -0.001941104   |
| LossBefore              | -1.3796102e-06 |
| Time                    | 94.5           |
| Time-Optimization       | 0.395          |
| Time-SampleProc         | 0.0552         |
| Time-Sampling           | 5.28           |
| n_timesteps             | 150000         |
| train-AverageDiscoun... | 22.1           |
| train-AverageReturn     | 27.6           |
| train-EnvExecTime       | 1.92           |
| train-MaxReturn         | 32.1           |
| train-MinReturn         | -5.35          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.18           |
| train-StdReturn         | 4.08           |
--------------------------------------------

 ---------------- Iteration 15 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 15             |
| ItrTime                 | 6.74           |
| LossAfter               | -0.0032800375  |
| LossBefore              | -1.3683546e-06 |
| Time                    | 101            |
| Time-Optimization       | 0.447          |
| Time-SampleProc         | 0.0519         |
| Time-Sampling           | 6.24           |
| n_timesteps             | 160000         |
| train-AverageDiscoun... | 22.5           |
| train-AverageReturn     | 28.3           |
| train-EnvExecTime       | 2.23           |
| train-MaxReturn         | 32             |
| train-MinReturn         | 18.6           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.8            |
| train-StdReturn         | 1.94           |
--------------------------------------------

 ---------------- Iteration 16 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 16             |
| ItrTime                 | 7.17           |
| LossAfter               | -0.0028740142  |
| LossBefore              | -1.3681147e-06 |
| Time                    | 108            |
| Time-Optimization       | 0.418          |
| Time-SampleProc         | 0.0473         |
| Time-Sampling           | 6.7            |
| n_timesteps             | 170000         |
| train-AverageDiscoun... | 22.1           |
| train-AverageReturn     | 27.6           |
| train-EnvExecTime       | 2.44           |
| train-MaxReturn         | 32.1           |
| train-MinReturn         | -2.08          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.04           |
| train-StdReturn         | 4.18           |
--------------------------------------------

 ---------------- Iteration 17 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 17             |
| ItrTime                 | 6.59           |
| LossAfter               | -0.0039272774  |
| LossBefore              | -1.3579981e-06 |
| Time                    | 115            |
| Time-Optimization       | 0.259          |
| Time-SampleProc         | 0.0424         |
| Time-Sampling           | 6.29           |
| n_timesteps             | 180000         |
| train-AverageDiscoun... | 22.4           |
| train-AverageReturn     | 28.1           |
| train-EnvExecTime       | 2.31           |
| train-MaxReturn         | 32             |
| train-MinReturn         | 17.2           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.77           |
| train-StdReturn         | 2.68           |
--------------------------------------------

 ---------------- Iteration 18 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 18             |
| ItrTime                 | 5.62           |
| LossAfter               | -0.0028619193  |
| LossBefore              | -1.3576754e-06 |
| Time                    | 121            |
| Time-Optimization       | 0.201          |
| Time-SampleProc         | 0.0516         |
| Time-Sampling           | 5.37           |
| n_timesteps             | 190000         |
| train-AverageDiscoun... | 22.5           |
| train-AverageReturn     | 27.9           |
| train-EnvExecTime       | 1.94           |
| train-MaxReturn         | 32.6           |
| train-MinReturn         | 6.01           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.24           |
| train-StdReturn         | 3.69           |
--------------------------------------------

 ---------------- Iteration 19 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 19             |
| ItrTime                 | 5.72           |
| LossAfter               | -0.0036142452  |
| LossBefore              | -1.3488615e-06 |
| Time                    | 126            |
| Time-Optimization       | 0.195          |
| Time-SampleProc         | 0.0669         |
| Time-Sampling           | 5.46           |
| n_timesteps             | 200000         |
| train-AverageDiscoun... | 22.9           |
| train-AverageReturn     | 28.4           |
| train-EnvExecTime       | 1.96           |
| train-MaxReturn         | 32.4           |
| train-MinReturn         | 1.11           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.32           |
| train-StdReturn         | 4.22           |
--------------------------------------------

 ---------------- Iteration 20 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 20             |
| ItrTime                 | 10             |
| LossAfter               | -0.0039862175  |
| LossBefore              | -1.3439263e-06 |
| Time                    | 136            |
| Time-Optimization       | 0.192          |
| Time-SampleProc         | 0.0492         |
| Time-Sampling           | 9.77           |
| n_timesteps             | 210000         |
| train-AverageDiscoun... | 22.7           |
| train-AverageReturn     | 28.5           |
| train-EnvExecTime       | 3.55           |
| train-MaxReturn         | 32.1           |
| train-MinReturn         | 14.2           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 5.91           |
| train-StdReturn         | 2.81           |
--------------------------------------------

 ---------------- Iteration 21 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 21             |
| ItrTime                 | 5.73           |
| LossAfter               | -0.0025176913  |
| LossBefore              | -1.3480093e-06 |
| Time                    | 142            |
| Time-Optimization       | 0.2            |
| Time-SampleProc         | 0.0344         |
| Time-Sampling           | 5.49           |
| n_timesteps             | 220000         |
| train-AverageDiscoun... | 22.9           |
| train-AverageReturn     | 28.3           |
| train-EnvExecTime       | 2.01           |
| train-MaxReturn         | 33.7           |
| train-MinReturn         | 1.04           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.3            |
| train-StdReturn         | 3.96           |
--------------------------------------------

 ---------------- Iteration 22 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 22             |
| ItrTime                 | 5.66           |
| LossAfter               | -0.0034289695  |
| LossBefore              | -1.3296783e-06 |
| Time                    | 148            |
| Time-Optimization       | 0.206          |
| Time-SampleProc         | 0.0443         |
| Time-Sampling           | 5.41           |
| n_timesteps             | 230000         |
| train-AverageDiscoun... | 23             |
| train-AverageReturn     | 28.7           |
| train-EnvExecTime       | 1.93           |
| train-MaxReturn         | 32             |
| train-MinReturn         | 19.9           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.3            |
| train-StdReturn         | 1.96           |
--------------------------------------------

 ---------------- Iteration 23 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 23             |
| ItrTime                 | 9.16           |
| LossAfter               | -0.0031940083  |
| LossBefore              | -1.3329043e-06 |
| Time                    | 157            |
| Time-Optimization       | 0.208          |
| Time-SampleProc         | 0.0347         |
| Time-Sampling           | 8.91           |
| n_timesteps             | 240000         |
| train-AverageDiscoun... | 23.4           |
| train-AverageReturn     | 29.1           |
| train-EnvExecTime       | 3.23           |
| train-MaxReturn         | 32.3           |
| train-MinReturn         | 23.6           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 5.41           |
| train-StdReturn         | 1.35           |
--------------------------------------------

 ---------------- Iteration 24 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 24             |
| ItrTime                 | 5.81           |
| LossAfter               | -0.0029910237  |
| LossBefore              | -1.3308883e-06 |
| Time                    | 163            |
| Time-Optimization       | 0.226          |
| Time-SampleProc         | 0.038          |
| Time-Sampling           | 5.55           |
| n_timesteps             | 250000         |
| train-AverageDiscoun... | 23.4           |
| train-AverageReturn     | 29.1           |
| train-EnvExecTime       | 1.98           |
| train-MaxReturn         | 32.3           |
| train-MinReturn         | 22.9           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.38           |
| train-StdReturn         | 1.38           |
--------------------------------------------

 ---------------- Iteration 25 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 25             |
| ItrTime                 | 10.6           |
| LossAfter               | -0.0013725627  |
| LossBefore              | -1.3281503e-06 |
| Time                    | 173            |
| Time-Optimization       | 0.241          |
| Time-SampleProc         | 0.047          |
| Time-Sampling           | 10.3           |
| n_timesteps             | 260000         |
| train-AverageDiscoun... | 23.9           |
| train-AverageReturn     | 29.6           |
| train-EnvExecTime       | 3.77           |
| train-MaxReturn         | 33.3           |
| train-MinReturn         | 26.5           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 6.2            |
| train-StdReturn         | 1.4            |
--------------------------------------------

 ---------------- Iteration 26 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 26             |
| ItrTime                 | 7.73           |
| LossAfter               | -0.0020462293  |
| LossBefore              | -1.3098628e-06 |
| Time                    | 181            |
| Time-Optimization       | 0.213          |
| Time-SampleProc         | 0.0365         |
| Time-Sampling           | 7.48           |
| n_timesteps             | 270000         |
| train-AverageDiscoun... | 23.8           |
| train-AverageReturn     | 29.5           |
| train-EnvExecTime       | 2.7            |
| train-MaxReturn         | 32.8           |
| train-MinReturn         | 26.3           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.53           |
| train-StdReturn         | 1.46           |
--------------------------------------------

 ---------------- Iteration 27 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 27             |
| ItrTime                 | 6.09           |
| LossAfter               | -0.0054640584  |
| LossBefore              | -1.3081399e-06 |
| Time                    | 187            |
| Time-Optimization       | 0.204          |
| Time-SampleProc         | 0.0398         |
| Time-Sampling           | 5.84           |
| n_timesteps             | 280000         |
| train-AverageDiscoun... | 23.9           |
| train-AverageReturn     | 29.6           |
| train-EnvExecTime       | 2.07           |
| train-MaxReturn         | 32.7           |
| train-MinReturn         | 25             |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.58           |
| train-StdReturn         | 1.67           |
--------------------------------------------

 ---------------- Iteration 28 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 28             |
| ItrTime                 | 5.91           |
| LossAfter               | 0.0015409312   |
| LossBefore              | -1.3069408e-06 |
| Time                    | 193            |
| Time-Optimization       | 0.219          |
| Time-SampleProc         | 0.0387         |
| Time-Sampling           | 5.66           |
| n_timesteps             | 290000         |
| train-AverageDiscoun... | 24.2           |
| train-AverageReturn     | 30             |
| train-EnvExecTime       | 2.03           |
| train-MaxReturn         | 33.9           |
| train-MinReturn         | 26.1           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.44           |
| train-StdReturn         | 1.48           |
--------------------------------------------

 ---------------- Iteration 29 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 29             |
| ItrTime                 | 7.38           |
| LossAfter               | -0.005582407   |
| LossBefore              | -1.3003242e-06 |
| Time                    | 201            |
| Time-Optimization       | 0.227          |
| Time-SampleProc         | 0.0353         |
| Time-Sampling           | 7.12           |
| n_timesteps             | 300000         |
| train-AverageDiscoun... | 24.2           |
| train-AverageReturn     | 30.1           |
| train-EnvExecTime       | 2.53           |
| train-MaxReturn         | 32.9           |
| train-MinReturn         | 25.3           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.37           |
| train-StdReturn         | 1.51           |
--------------------------------------------

 ---------------- Iteration 30 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 30             |
| ItrTime                 | 7.2            |
| LossAfter               | -0.0041836794  |
| LossBefore              | -1.2945325e-06 |
| Time                    | 208            |
| Time-Optimization       | 0.214          |
| Time-SampleProc         | 0.0867         |
| Time-Sampling           | 6.9            |
| n_timesteps             | 310000         |
| train-AverageDiscoun... | 24.2           |
| train-AverageReturn     | 30.2           |
| train-EnvExecTime       | 2.51           |
| train-MaxReturn         | 33.6           |
| train-MinReturn         | 26             |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.17           |
| train-StdReturn         | 1.35           |
--------------------------------------------

 ---------------- Iteration 31 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 31             |
| ItrTime                 | 7.07           |
| LossAfter               | -0.002240898   |
| LossBefore              | -1.2844188e-06 |
| Time                    | 215            |
| Time-Optimization       | 0.228          |
| Time-SampleProc         | 0.0564         |
| Time-Sampling           | 6.79           |
| n_timesteps             | 320000         |
| train-AverageDiscoun... | 24.3           |
| train-AverageReturn     | 30.2           |
| train-EnvExecTime       | 2.46           |
| train-MaxReturn         | 33.6           |
| train-MinReturn         | 25.6           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.1            |
| train-StdReturn         | 1.39           |
--------------------------------------------

 ---------------- Iteration 32 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 32             |
| ItrTime                 | 7.24           |
| LossAfter               | -0.003998917   |
| LossBefore              | -1.2831889e-06 |
| Time                    | 222            |
| Time-Optimization       | 0.293          |
| Time-SampleProc         | 0.045          |
| Time-Sampling           | 6.9            |
| n_timesteps             | 330000         |
| train-AverageDiscoun... | 24.2           |
| train-AverageReturn     | 30.2           |
| train-EnvExecTime       | 2.5            |
| train-MaxReturn         | 34.2           |
| train-MinReturn         | 26.6           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.16           |
| train-StdReturn         | 1.62           |
--------------------------------------------

 ---------------- Iteration 33 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 33             |
| ItrTime                 | 7.3            |
| LossAfter               | -0.0037886444  |
| LossBefore              | -1.2737321e-06 |
| Time                    | 229            |
| Time-Optimization       | 0.226          |
| Time-SampleProc         | 0.0968         |
| Time-Sampling           | 6.97           |
| n_timesteps             | 340000         |
| train-AverageDiscoun... | 24.4           |
| train-AverageReturn     | 30.4           |
| train-EnvExecTime       | 2.53           |
| train-MaxReturn         | 33.2           |
| train-MinReturn         | 26.8           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.22           |
| train-StdReturn         | 1.41           |
--------------------------------------------

 ---------------- Iteration 34 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 34             |
| ItrTime                 | 6.77           |
| LossAfter               | -0.002538239   |
| LossBefore              | -1.2737237e-06 |
| Time                    | 236            |
| Time-Optimization       | 0.191          |
| Time-SampleProc         | 0.0472         |
| Time-Sampling           | 6.53           |
| n_timesteps             | 350000         |
| train-AverageDiscoun... | 24.6           |
| train-AverageReturn     | 30.7           |
| train-EnvExecTime       | 2.3            |
| train-MaxReturn         | 33.7           |
| train-MinReturn         | 27.1           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.02           |
| train-StdReturn         | 1.44           |
--------------------------------------------

 ---------------- Iteration 35 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 35             |
| ItrTime                 | 5.97           |
| LossAfter               | -0.001484307   |
| LossBefore              | -1.2726694e-06 |
| Time                    | 242            |
| Time-Optimization       | 0.217          |
| Time-SampleProc         | 0.0338         |
| Time-Sampling           | 5.72           |
| n_timesteps             | 360000         |
| train-AverageDiscoun... | 24.4           |
| train-AverageReturn     | 30.6           |
| train-EnvExecTime       | 2.04           |
| train-MaxReturn         | 34.8           |
| train-MinReturn         | 27             |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.5            |
| train-StdReturn         | 1.53           |
--------------------------------------------

 ---------------- Iteration 36 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 36             |
| ItrTime                 | 7.91           |
| LossAfter               | -0.0030780607  |
| LossBefore              | -1.2593546e-06 |
| Time                    | 250            |
| Time-Optimization       | 0.202          |
| Time-SampleProc         | 0.039          |
| Time-Sampling           | 7.67           |
| n_timesteps             | 370000         |
| train-AverageDiscoun... | 25             |
| train-AverageReturn     | 31.3           |
| train-EnvExecTime       | 2.78           |
| train-MaxReturn         | 35.1           |
| train-MinReturn         | 27.5           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.65           |
| train-StdReturn         | 1.5            |
--------------------------------------------

 ---------------- Iteration 37 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 37            |
| ItrTime                 | 5.75          |
| LossAfter               | -0.0011696888 |
| LossBefore              | -1.249417e-06 |
| Time                    | 256           |
| Time-Optimization       | 0.212         |
| Time-SampleProc         | 0.0384        |
| Time-Sampling           | 5.5           |
| n_timesteps             | 380000        |
| train-AverageDiscoun... | 25            |
| train-AverageReturn     | 31.4          |
| train-EnvExecTime       | 1.98          |
| train-MaxReturn         | 34.7          |
| train-MinReturn         | 27.4          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.34          |
| train-StdReturn         | 1.53          |
-------------------------------------------

 ---------------- Iteration 38 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 38             |
| ItrTime                 | 6.25           |
| LossAfter               | -0.0026106567  |
| LossBefore              | -1.2511806e-06 |
| Time                    | 262            |
| Time-Optimization       | 0.209          |
| Time-SampleProc         | 0.0386         |
| Time-Sampling           | 6              |
| n_timesteps             | 390000         |
| train-AverageDiscoun... | 24.9           |
| train-AverageReturn     | 31.3           |
| train-EnvExecTime       | 2.11           |
| train-MaxReturn         | 34.9           |
| train-MinReturn         | 27.8           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.69           |
| train-StdReturn         | 1.52           |
--------------------------------------------

 ---------------- Iteration 39 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 39            |
| ItrTime                 | 6.09          |
| LossAfter               | -0.0037535403 |
| LossBefore              | -1.232312e-06 |
| Time                    | 268           |
| Time-Optimization       | 0.208         |
| Time-SampleProc         | 0.0397        |
| Time-Sampling           | 5.84          |
| n_timesteps             | 400000        |
| train-AverageDiscoun... | 25.1          |
| train-AverageReturn     | 31.6          |
| train-EnvExecTime       | 2.08          |
| train-MaxReturn         | 34.7          |
| train-MinReturn         | 27.8          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.57          |
| train-StdReturn         | 1.47          |
-------------------------------------------

 ---------------- Iteration 40 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 40             |
| ItrTime                 | 7.23           |
| LossAfter               | -0.0036032829  |
| LossBefore              | -1.2390238e-06 |
| Time                    | 276            |
| Time-Optimization       | 0.234          |
| Time-SampleProc         | 0.106          |
| Time-Sampling           | 6.89           |
| n_timesteps             | 410000         |
| train-AverageDiscoun... | 25.2           |
| train-AverageReturn     | 31.7           |
| train-EnvExecTime       | 2.5            |
| train-MaxReturn         | 34.7           |
| train-MinReturn         | 28             |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.16           |
| train-StdReturn         | 1.45           |
--------------------------------------------

 ---------------- Iteration 41 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 41             |
| ItrTime                 | 7.69           |
| LossAfter               | 0.00037172541  |
| LossBefore              | -1.2308059e-06 |
| Time                    | 283            |
| Time-Optimization       | 0.272          |
| Time-SampleProc         | 0.0573         |
| Time-Sampling           | 7.36           |
| n_timesteps             | 420000         |
| train-AverageDiscoun... | 25.3           |
| train-AverageReturn     | 31.9           |
| train-EnvExecTime       | 2.66           |
| train-MaxReturn         | 35.8           |
| train-MinReturn         | 27.9           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.46           |
| train-StdReturn         | 1.74           |
--------------------------------------------

 ---------------- Iteration 42 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 42             |
| ItrTime                 | 9.61           |
| LossAfter               | -0.0030867793  |
| LossBefore              | -1.2297108e-06 |
| Time                    | 293            |
| Time-Optimization       | 0.209          |
| Time-SampleProc         | 0.0735         |
| Time-Sampling           | 9.32           |
| n_timesteps             | 430000         |
| train-AverageDiscoun... | 25.1           |
| train-AverageReturn     | 31.7           |
| train-EnvExecTime       | 3.28           |
| train-MaxReturn         | 35.4           |
| train-MinReturn         | 27.4           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 5.73           |
| train-StdReturn         | 1.64           |
--------------------------------------------

 ---------------- Iteration 43 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 43             |
| ItrTime                 | 6.27           |
| LossAfter               | -0.0015151539  |
| LossBefore              | -1.2065873e-06 |
| Time                    | 299            |
| Time-Optimization       | 0.226          |
| Time-SampleProc         | 0.0393         |
| Time-Sampling           | 6              |
| n_timesteps             | 440000         |
| train-AverageDiscoun... | 25.4           |
| train-AverageReturn     | 32.1           |
| train-EnvExecTime       | 2.12           |
| train-MaxReturn         | 35.4           |
| train-MinReturn         | 28.3           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.68           |
| train-StdReturn         | 1.49           |
--------------------------------------------

 ---------------- Iteration 44 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 44             |
| ItrTime                 | 5.9            |
| LossAfter               | -0.0009916009  |
| LossBefore              | -1.2129339e-06 |
| Time                    | 305            |
| Time-Optimization       | 0.205          |
| Time-SampleProc         | 0.0403         |
| Time-Sampling           | 5.66           |
| n_timesteps             | 450000         |
| train-AverageDiscoun... | 25.5           |
| train-AverageReturn     | 32.3           |
| train-EnvExecTime       | 2.02           |
| train-MaxReturn         | 35.2           |
| train-MinReturn         | 27.7           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.44           |
| train-StdReturn         | 1.65           |
--------------------------------------------

 ---------------- Iteration 45 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 45             |
| ItrTime                 | 6.16           |
| LossAfter               | -0.0011362751  |
| LossBefore              | -1.2237024e-06 |
| Time                    | 311            |
| Time-Optimization       | 0.201          |
| Time-SampleProc         | 0.0748         |
| Time-Sampling           | 5.88           |
| n_timesteps             | 460000         |
| train-AverageDiscoun... | 25.5           |
| train-AverageReturn     | 32.3           |
| train-EnvExecTime       | 2.11           |
| train-MaxReturn         | 36.1           |
| train-MinReturn         | 28.5           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.58           |
| train-StdReturn         | 1.67           |
--------------------------------------------

 ---------------- Iteration 46 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 46             |
| ItrTime                 | 6.94           |
| LossAfter               | -0.0011230486  |
| LossBefore              | -1.2048547e-06 |
| Time                    | 318            |
| Time-Optimization       | 0.32           |
| Time-SampleProc         | 0.0643         |
| Time-Sampling           | 6.55           |
| n_timesteps             | 470000         |
| train-AverageDiscoun... | 25.7           |
| train-AverageReturn     | 32.5           |
| train-EnvExecTime       | 2.3            |
| train-MaxReturn         | 36.3           |
| train-MinReturn         | 28.8           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.03           |
| train-StdReturn         | 1.49           |
--------------------------------------------

 ---------------- Iteration 47 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 47             |
| ItrTime                 | 9.22           |
| LossAfter               | -0.00260061    |
| LossBefore              | -1.1999491e-06 |
| Time                    | 327            |
| Time-Optimization       | 0.321          |
| Time-SampleProc         | 0.0596         |
| Time-Sampling           | 8.84           |
| n_timesteps             | 480000         |
| train-AverageDiscoun... | 25.6           |
| train-AverageReturn     | 32.4           |
| train-EnvExecTime       | 3.22           |
| train-MaxReturn         | 36.3           |
| train-MinReturn         | 27.1           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 5.33           |
| train-StdReturn         | 1.8            |
--------------------------------------------

 ---------------- Iteration 48 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 48             |
| ItrTime                 | 6.57           |
| LossAfter               | -0.0021488357  |
| LossBefore              | -1.1959866e-06 |
| Time                    | 334            |
| Time-Optimization       | 0.219          |
| Time-SampleProc         | 0.0251         |
| Time-Sampling           | 6.32           |
| n_timesteps             | 490000         |
| train-AverageDiscoun... | 25.5           |
| train-AverageReturn     | 32.3           |
| train-EnvExecTime       | 2.3            |
| train-MaxReturn         | 35.9           |
| train-MinReturn         | 28.9           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.81           |
| train-StdReturn         | 1.55           |
--------------------------------------------

 ---------------- Iteration 49 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 49             |
| ItrTime                 | 5.92           |
| LossAfter               | -0.00241087    |
| LossBefore              | -1.1904722e-06 |
| Time                    | 340            |
| Time-Optimization       | 0.214          |
| Time-SampleProc         | 0.0423         |
| Time-Sampling           | 5.66           |
| n_timesteps             | 500000         |
| train-AverageDiscoun... | 25.4           |
| train-AverageReturn     | 32.3           |
| train-EnvExecTime       | 2.08           |
| train-MaxReturn         | 35.6           |
| train-MinReturn         | 26.5           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.39           |
| train-StdReturn         | 1.64           |
--------------------------------------------

 ---------------- Iteration 50 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 50             |
| ItrTime                 | 6              |
| LossAfter               | -0.0008268936  |
| LossBefore              | -1.1822254e-06 |
| Time                    | 346            |
| Time-Optimization       | 0.224          |
| Time-SampleProc         | 0.0399         |
| Time-Sampling           | 5.74           |
| n_timesteps             | 510000         |
| train-AverageDiscoun... | 25.5           |
| train-AverageReturn     | 32.3           |
| train-EnvExecTime       | 2.09           |
| train-MaxReturn         | 35.7           |
| train-MinReturn         | 28.6           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.45           |
| train-StdReturn         | 1.5            |
--------------------------------------------

 ---------------- Iteration 51 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 51             |
| ItrTime                 | 5.86           |
| LossAfter               | -0.003010938   |
| LossBefore              | -1.1771702e-06 |
| Time                    | 352            |
| Time-Optimization       | 0.201          |
| Time-SampleProc         | 0.041          |
| Time-Sampling           | 5.62           |
| n_timesteps             | 520000         |
| train-AverageDiscoun... | 25.4           |
| train-AverageReturn     | 32.3           |
| train-EnvExecTime       | 2.06           |
| train-MaxReturn         | 35.3           |
| train-MinReturn         | 28.8           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.37           |
| train-StdReturn         | 1.43           |
--------------------------------------------

 ---------------- Iteration 52 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 52             |
| ItrTime                 | 7.07           |
| LossAfter               | -0.0031928502  |
| LossBefore              | -1.1723066e-06 |
| Time                    | 359            |
| Time-Optimization       | 0.263          |
| Time-SampleProc         | 0.0478         |
| Time-Sampling           | 6.76           |
| n_timesteps             | 530000         |
| train-AverageDiscoun... | 25.8           |
| train-AverageReturn     | 32.6           |
| train-EnvExecTime       | 2.43           |
| train-MaxReturn         | 36.6           |
| train-MinReturn         | 28.5           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.11           |
| train-StdReturn         | 1.55           |
--------------------------------------------

 ---------------- Iteration 53 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 53             |
| ItrTime                 | 6.64           |
| LossAfter               | -0.002085447   |
| LossBefore              | -1.1651043e-06 |
| Time                    | 366            |
| Time-Optimization       | 0.218          |
| Time-SampleProc         | 0.0454         |
| Time-Sampling           | 6.38           |
| n_timesteps             | 540000         |
| train-AverageDiscoun... | 25.6           |
| train-AverageReturn     | 32.5           |
| train-EnvExecTime       | 2.31           |
| train-MaxReturn         | 35.9           |
| train-MinReturn         | 28.3           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.85           |
| train-StdReturn         | 1.52           |
--------------------------------------------

 ---------------- Iteration 54 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 54            |
| ItrTime                 | 5.93          |
| LossAfter               | -0.0012824791 |
| LossBefore              | -1.157265e-06 |
| Time                    | 371           |
| Time-Optimization       | 0.218         |
| Time-SampleProc         | 0.0385        |
| Time-Sampling           | 5.67          |
| n_timesteps             | 550000        |
| train-AverageDiscoun... | 25.5          |
| train-AverageReturn     | 32.4          |
| train-EnvExecTime       | 2.05          |
| train-MaxReturn         | 36.1          |
| train-MinReturn         | 28.7          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.43          |
| train-StdReturn         | 1.58          |
-------------------------------------------

 ---------------- Iteration 55 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 55             |
| ItrTime                 | 6.04           |
| LossAfter               | -0.0004841698  |
| LossBefore              | -1.1600866e-06 |
| Time                    | 378            |
| Time-Optimization       | 0.245          |
| Time-SampleProc         | 0.0373         |
| Time-Sampling           | 5.76           |
| n_timesteps             | 560000         |
| train-AverageDiscoun... | 25.4           |
| train-AverageReturn     | 32.3           |
| train-EnvExecTime       | 2.09           |
| train-MaxReturn         | 35.8           |
| train-MinReturn         | 28.5           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.48           |
| train-StdReturn         | 1.5            |
--------------------------------------------

 ---------------- Iteration 56 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 56             |
| ItrTime                 | 5.94           |
| LossAfter               | -0.0021595128  |
| LossBefore              | -1.1505526e-06 |
| Time                    | 383            |
| Time-Optimization       | 0.194          |
| Time-SampleProc         | 0.0789         |
| Time-Sampling           | 5.67           |
| n_timesteps             | 570000         |
| train-AverageDiscoun... | 25.6           |
| train-AverageReturn     | 32.5           |
| train-EnvExecTime       | 2.06           |
| train-MaxReturn         | 35.9           |
| train-MinReturn         | 29.1           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.41           |
| train-StdReturn         | 1.53           |
--------------------------------------------

 ---------------- Iteration 57 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 57             |
| ItrTime                 | 7.11           |
| LossAfter               | -0.0026666601  |
| LossBefore              | -1.1407136e-06 |
| Time                    | 391            |
| Time-Optimization       | 0.315          |
| Time-SampleProc         | 0.0622         |
| Time-Sampling           | 6.73           |
| n_timesteps             | 580000         |
| train-AverageDiscoun... | 25.6           |
| train-AverageReturn     | 32.5           |
| train-EnvExecTime       | 2.44           |
| train-MaxReturn         | 35.9           |
| train-MinReturn         | 29.3           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.07           |
| train-StdReturn         | 1.42           |
--------------------------------------------

 ---------------- Iteration 58 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 58             |
| ItrTime                 | 7.02           |
| LossAfter               | -0.0033727866  |
| LossBefore              | -1.1354865e-06 |
| Time                    | 398            |
| Time-Optimization       | 0.239          |
| Time-SampleProc         | 0.0253         |
| Time-Sampling           | 6.76           |
| n_timesteps             | 590000         |
| train-AverageDiscoun... | 25.6           |
| train-AverageReturn     | 32.6           |
| train-EnvExecTime       | 2.41           |
| train-MaxReturn         | 37.3           |
| train-MinReturn         | 28.8           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.12           |
| train-StdReturn         | 1.61           |
--------------------------------------------

 ---------------- Iteration 59 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 59             |
| ItrTime                 | 6.07           |
| LossAfter               | -0.0014096112  |
| LossBefore              | -1.1303287e-06 |
| Time                    | 404            |
| Time-Optimization       | 0.229          |
| Time-SampleProc         | 0.0429         |
| Time-Sampling           | 5.8            |
| n_timesteps             | 600000         |
| train-AverageDiscoun... | 25.9           |
| train-AverageReturn     | 32.9           |
| train-EnvExecTime       | 2.07           |
| train-MaxReturn         | 36.3           |
| train-MinReturn         | 30             |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.53           |
| train-StdReturn         | 1.49           |
--------------------------------------------

 ---------------- Iteration 60 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 60             |
| ItrTime                 | 6              |
| LossAfter               | -0.0010222769  |
| LossBefore              | -1.1143254e-06 |
| Time                    | 410            |
| Time-Optimization       | 0.215          |
| Time-SampleProc         | 0.0353         |
| Time-Sampling           | 5.75           |
| n_timesteps             | 610000         |
| train-AverageDiscoun... | 25.8           |
| train-AverageReturn     | 32.8           |
| train-EnvExecTime       | 2.07           |
| train-MaxReturn         | 36.7           |
| train-MinReturn         | 29.2           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.49           |
| train-StdReturn         | 1.53           |
--------------------------------------------

 ---------------- Iteration 61 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 61             |
| ItrTime                 | 5.92           |
| LossAfter               | -0.0018233288  |
| LossBefore              | -1.1225214e-06 |
| Time                    | 416            |
| Time-Optimization       | 0.235          |
| Time-SampleProc         | 0.0392         |
| Time-Sampling           | 5.65           |
| n_timesteps             | 620000         |
| train-AverageDiscoun... | 25.8           |
| train-AverageReturn     | 32.9           |
| train-EnvExecTime       | 2.07           |
| train-MaxReturn         | 36.4           |
| train-MinReturn         | 29.6           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.39           |
| train-StdReturn         | 1.43           |
--------------------------------------------

 ---------------- Iteration 62 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 62            |
| ItrTime                 | 6.96          |
| LossAfter               | -0.0033689614 |
| LossBefore              | -1.108688e-06 |
| Time                    | 423           |
| Time-Optimization       | 0.231         |
| Time-SampleProc         | 0.0507        |
| Time-Sampling           | 6.68          |
| n_timesteps             | 630000        |
| train-AverageDiscoun... | 26            |
| train-AverageReturn     | 33.1          |
| train-EnvExecTime       | 2.41          |
| train-MaxReturn         | 36.3          |
| train-MinReturn         | 29.7          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 4.05          |
| train-StdReturn         | 1.42          |
-------------------------------------------

 ---------------- Iteration 63 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 63             |
| ItrTime                 | 7.09           |
| LossAfter               | 0.0037778958   |
| LossBefore              | -1.1043084e-06 |
| Time                    | 430            |
| Time-Optimization       | 0.214          |
| Time-SampleProc         | 0.0387         |
| Time-Sampling           | 6.84           |
| n_timesteps             | 640000         |
| train-AverageDiscoun... | 25.9           |
| train-AverageReturn     | 33             |
| train-EnvExecTime       | 2.46           |
| train-MaxReturn         | 36.2           |
| train-MinReturn         | 29.9           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.15           |
| train-StdReturn         | 1.48           |
--------------------------------------------

 ---------------- Iteration 64 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 64             |
| ItrTime                 | 6.1            |
| LossAfter               | 0.0012785689   |
| LossBefore              | -1.1050873e-06 |
| Time                    | 436            |
| Time-Optimization       | 0.196          |
| Time-SampleProc         | 0.0724         |
| Time-Sampling           | 5.83           |
| n_timesteps             | 650000         |
| train-AverageDiscoun... | 25.9           |
| train-AverageReturn     | 33.1           |
| train-EnvExecTime       | 2.09           |
| train-MaxReturn         | 36.2           |
| train-MinReturn         | 30.1           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.55           |
| train-StdReturn         | 1.51           |
--------------------------------------------

 ---------------- Iteration 65 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 65             |
| ItrTime                 | 6.31           |
| LossAfter               | 0.0024566615   |
| LossBefore              | -1.1042623e-06 |
| Time                    | 442            |
| Time-Optimization       | 0.218          |
| Time-SampleProc         | 0.0406         |
| Time-Sampling           | 6.05           |
| n_timesteps             | 660000         |
| train-AverageDiscoun... | 26             |
| train-AverageReturn     | 33.2           |
| train-EnvExecTime       | 2.15           |
| train-MaxReturn         | 36.3           |
| train-MinReturn         | 29             |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.68           |
| train-StdReturn         | 1.54           |
--------------------------------------------

 ---------------- Iteration 66 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 66             |
| ItrTime                 | 6              |
| LossAfter               | 0.00042408632  |
| LossBefore              | -1.0910285e-06 |
| Time                    | 448            |
| Time-Optimization       | 0.224          |
| Time-SampleProc         | 0.0416         |
| Time-Sampling           | 5.73           |
| n_timesteps             | 670000         |
| train-AverageDiscoun... | 25.7           |
| train-AverageReturn     | 32.8           |
| train-EnvExecTime       | 2.06           |
| train-MaxReturn         | 36.8           |
| train-MinReturn         | 29.5           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.48           |
| train-StdReturn         | 1.49           |
--------------------------------------------

 ---------------- Iteration 67 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 67             |
| ItrTime                 | 7.52           |
| LossAfter               | -0.0046608886  |
| LossBefore              | -1.0994646e-06 |
| Time                    | 456            |
| Time-Optimization       | 0.263          |
| Time-SampleProc         | 0.105          |
| Time-Sampling           | 7.15           |
| n_timesteps             | 680000         |
| train-AverageDiscoun... | 26             |
| train-AverageReturn     | 33.1           |
| train-EnvExecTime       | 2.55           |
| train-MaxReturn         | 36.6           |
| train-MinReturn         | 29.3           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.36           |
| train-StdReturn         | 1.55           |
--------------------------------------------

 ---------------- Iteration 68 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 68             |
| ItrTime                 | 8.28           |
| LossAfter               | -0.0012395873  |
| LossBefore              | -1.0829065e-06 |
| Time                    | 464            |
| Time-Optimization       | 0.239          |
| Time-SampleProc         | 0.0828         |
| Time-Sampling           | 7.95           |
| n_timesteps             | 690000         |
| train-AverageDiscoun... | 26.1           |
| train-AverageReturn     | 33.3           |
| train-EnvExecTime       | 2.87           |
| train-MaxReturn         | 36.8           |
| train-MinReturn         | 29.7           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.82           |
| train-StdReturn         | 1.48           |
--------------------------------------------

 ---------------- Iteration 69 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 69             |
| ItrTime                 | 5.95           |
| LossAfter               | -0.0027317738  |
| LossBefore              | -1.0778037e-06 |
| Time                    | 470            |
| Time-Optimization       | 0.229          |
| Time-SampleProc         | 0.0404         |
| Time-Sampling           | 5.68           |
| n_timesteps             | 700000         |
| train-AverageDiscoun... | 26.2           |
| train-AverageReturn     | 33.4           |
| train-EnvExecTime       | 2.05           |
| train-MaxReturn         | 37.2           |
| train-MinReturn         | 30             |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.44           |
| train-StdReturn         | 1.62           |
--------------------------------------------

 ---------------- Iteration 70 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 70            |
| ItrTime                 | 5.84          |
| LossAfter               | -0.003551618  |
| LossBefore              | -1.084034e-06 |
| Time                    | 476           |
| Time-Optimization       | 0.212         |
| Time-SampleProc         | 0.0384        |
| Time-Sampling           | 5.59          |
| n_timesteps             | 710000        |
| train-AverageDiscoun... | 26.1          |
| train-AverageReturn     | 33.4          |
| train-EnvExecTime       | 2             |
| train-MaxReturn         | 37.7          |
| train-MinReturn         | 29.6          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.4           |
| train-StdReturn         | 1.49          |
-------------------------------------------

 ---------------- Iteration 71 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 71             |
| ItrTime                 | 5.95           |
| LossAfter               | -0.0027905072  |
| LossBefore              | -1.0709523e-06 |
| Time                    | 482            |
| Time-Optimization       | 0.199          |
| Time-SampleProc         | 0.0575         |
| Time-Sampling           | 5.7            |
| n_timesteps             | 720000         |
| train-AverageDiscoun... | 26             |
| train-AverageReturn     | 33.2           |
| train-EnvExecTime       | 2.07           |
| train-MaxReturn         | 37.3           |
| train-MinReturn         | 29.4           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.43           |
| train-StdReturn         | 1.45           |
--------------------------------------------

 ---------------- Iteration 72 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 72            |
| ItrTime                 | 6.53          |
| LossAfter               | 0.0022075668  |
| LossBefore              | -1.066414e-06 |
| Time                    | 488           |
| Time-Optimization       | 0.232         |
| Time-SampleProc         | 0.0443        |
| Time-Sampling           | 6.26          |
| n_timesteps             | 730000        |
| train-AverageDiscoun... | 26.1          |
| train-AverageReturn     | 33.3          |
| train-EnvExecTime       | 2.26          |
| train-MaxReturn         | 37.5          |
| train-MinReturn         | 28.9          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.79          |
| train-StdReturn         | 1.78          |
-------------------------------------------

 ---------------- Iteration 73 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 73             |
| ItrTime                 | 7.66           |
| LossAfter               | 0.0016034195   |
| LossBefore              | -1.0744926e-06 |
| Time                    | 496            |
| Time-Optimization       | 0.269          |
| Time-SampleProc         | 0.0546         |
| Time-Sampling           | 7.34           |
| n_timesteps             | 740000         |
| train-AverageDiscoun... | 26             |
| train-AverageReturn     | 33.3           |
| train-EnvExecTime       | 2.67           |
| train-MaxReturn         | 37.2           |
| train-MinReturn         | 29.4           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.43           |
| train-StdReturn         | 1.55           |
--------------------------------------------

 ---------------- Iteration 74 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 74             |
| ItrTime                 | 6.24           |
| LossAfter               | 0.003595221    |
| LossBefore              | -1.0639488e-06 |
| Time                    | 502            |
| Time-Optimization       | 0.21           |
| Time-SampleProc         | 0.0471         |
| Time-Sampling           | 5.98           |
| n_timesteps             | 750000         |
| train-AverageDiscoun... | 26             |
| train-AverageReturn     | 33.3           |
| train-EnvExecTime       | 2.2            |
| train-MaxReturn         | 37             |
| train-MinReturn         | 29.7           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.58           |
| train-StdReturn         | 1.38           |
--------------------------------------------

 ---------------- Iteration 75 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 75            |
| ItrTime                 | 6.18          |
| LossAfter               | 0.0038957593  |
| LossBefore              | -1.058779e-06 |
| Time                    | 508           |
| Time-Optimization       | 0.218         |
| Time-SampleProc         | 0.0394        |
| Time-Sampling           | 5.92          |
| n_timesteps             | 760000        |
| train-AverageDiscoun... | 26.2          |
| train-AverageReturn     | 33.5          |
| train-EnvExecTime       | 2.15          |
| train-MaxReturn         | 36.6          |
| train-MinReturn         | 29.7          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.57          |
| train-StdReturn         | 1.51          |
-------------------------------------------

 ---------------- Iteration 76 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 76             |
| ItrTime                 | 6.06           |
| LossAfter               | -0.0028853114  |
| LossBefore              | -1.0592897e-06 |
| Time                    | 514            |
| Time-Optimization       | 0.215          |
| Time-SampleProc         | 0.0437         |
| Time-Sampling           | 5.8            |
| n_timesteps             | 770000         |
| train-AverageDiscoun... | 26.1           |
| train-AverageReturn     | 33.4           |
| train-EnvExecTime       | 2.09           |
| train-MaxReturn         | 36.3           |
| train-MinReturn         | 28.9           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.52           |
| train-StdReturn         | 1.49           |
--------------------------------------------

 ---------------- Iteration 77 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 77             |
| ItrTime                 | 5.94           |
| LossAfter               | 0.013315475    |
| LossBefore              | -1.0458938e-06 |
| Time                    | 520            |
| Time-Optimization       | 0.225          |
| Time-SampleProc         | 0.0269         |
| Time-Sampling           | 5.69           |
| n_timesteps             | 780000         |
| train-AverageDiscoun... | 26             |
| train-AverageReturn     | 33.3           |
| train-EnvExecTime       | 2.05           |
| train-MaxReturn         | 36.8           |
| train-MinReturn         | 29             |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.45           |
| train-StdReturn         | 1.58           |
--------------------------------------------

 ---------------- Iteration 78 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 78             |
| ItrTime                 | 7.09           |
| LossAfter               | 0.010960262    |
| LossBefore              | -1.0453595e-06 |
| Time                    | 528            |
| Time-Optimization       | 0.27           |
| Time-SampleProc         | 0.0555         |
| Time-Sampling           | 6.76           |
| n_timesteps             | 790000         |
| train-AverageDiscoun... | 26.1           |
| train-AverageReturn     | 33.4           |
| train-EnvExecTime       | 2.49           |
| train-MaxReturn         | 37.7           |
| train-MinReturn         | 30.2           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.05           |
| train-StdReturn         | 1.57           |
--------------------------------------------

 ---------------- Iteration 79 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 79             |
| ItrTime                 | 7.94           |
| LossAfter               | 0.0066684796   |
| LossBefore              | -1.0378577e-06 |
| Time                    | 535            |
| Time-Optimization       | 0.229          |
| Time-SampleProc         | 0.048          |
| Time-Sampling           | 7.66           |
| n_timesteps             | 800000         |
| train-AverageDiscoun... | 26.3           |
| train-AverageReturn     | 33.6           |
| train-EnvExecTime       | 2.78           |
| train-MaxReturn         | 36.5           |
| train-MinReturn         | 30.2           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.63           |
| train-StdReturn         | 1.38           |
--------------------------------------------

 ---------------- Iteration 80 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 80           |
| ItrTime                 | 6.86         |
| LossAfter               | 0.0024799935 |
| LossBefore              | -1.0404e-06  |
| Time                    | 542          |
| Time-Optimization       | 0.208        |
| Time-SampleProc         | 0.0451       |
| Time-Sampling           | 6.6          |
| n_timesteps             | 810000       |
| train-AverageDiscoun... | 26.2         |
| train-AverageReturn     | 33.3         |
| train-EnvExecTime       | 2.41         |
| train-MaxReturn         | 36.3         |
| train-MinReturn         | 29.5         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 3.97         |
| train-StdReturn         | 1.52         |
------------------------------------------

 ---------------- Iteration 81 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 81             |
| ItrTime                 | 6.29           |
| LossAfter               | -0.00026068895 |
| LossBefore              | -1.0224966e-06 |
| Time                    | 549            |
| Time-Optimization       | 0.207          |
| Time-SampleProc         | 0.0401         |
| Time-Sampling           | 6.04           |
| n_timesteps             | 820000         |
| train-AverageDiscoun... | 26             |
| train-AverageReturn     | 33.2           |
| train-EnvExecTime       | 2.19           |
| train-MaxReturn         | 37.4           |
| train-MinReturn         | 29.7           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.63           |
| train-StdReturn         | 1.53           |
--------------------------------------------

 ---------------- Iteration 82 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 82             |
| ItrTime                 | 5.95           |
| LossAfter               | 0.009255287    |
| LossBefore              | -1.0216335e-06 |
| Time                    | 555            |
| Time-Optimization       | 0.204          |
| Time-SampleProc         | 0.0397         |
| Time-Sampling           | 5.71           |
| n_timesteps             | 830000         |
| train-AverageDiscoun... | 26             |
| train-AverageReturn     | 33.3           |
| train-EnvExecTime       | 2.08           |
| train-MaxReturn         | 37.2           |
| train-MinReturn         | 29.8           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.44           |
| train-StdReturn         | 1.5            |
--------------------------------------------

 ---------------- Iteration 83 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 83             |
| ItrTime                 | 6.04           |
| LossAfter               | -0.0017990834  |
| LossBefore              | -1.0290341e-06 |
| Time                    | 561            |
| Time-Optimization       | 0.21           |
| Time-SampleProc         | 0.06           |
| Time-Sampling           | 5.77           |
| n_timesteps             | 840000         |
| train-AverageDiscoun... | 26.2           |
| train-AverageReturn     | 33.4           |
| train-EnvExecTime       | 2.08           |
| train-MaxReturn         | 36.7           |
| train-MinReturn         | 30.1           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.5            |
| train-StdReturn         | 1.47           |
--------------------------------------------

 ---------------- Iteration 84 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 84             |
| ItrTime                 | 5.99           |
| LossAfter               | -0.0011436121  |
| LossBefore              | -1.0176931e-06 |
| Time                    | 567            |
| Time-Optimization       | 0.208          |
| Time-SampleProc         | 0.0716         |
| Time-Sampling           | 5.71           |
| n_timesteps             | 850000         |
| train-AverageDiscoun... | 26.3           |
| train-AverageReturn     | 33.5           |
| train-EnvExecTime       | 2.07           |
| train-MaxReturn         | 36.2           |
| train-MinReturn         | 30.4           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.45           |
| train-StdReturn         | 1.35           |
--------------------------------------------

 ---------------- Iteration 85 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 85             |
| ItrTime                 | 6.28           |
| LossAfter               | -0.0019436114  |
| LossBefore              | -1.0125565e-06 |
| Time                    | 573            |
| Time-Optimization       | 0.234          |
| Time-SampleProc         | 0.0381         |
| Time-Sampling           | 6.01           |
| n_timesteps             | 860000         |
| train-AverageDiscoun... | 26.1           |
| train-AverageReturn     | 33.4           |
| train-EnvExecTime       | 2.19           |
| train-MaxReturn         | 36.4           |
| train-MinReturn         | 29.9           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.61           |
| train-StdReturn         | 1.22           |
--------------------------------------------

 ---------------- Iteration 86 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 86             |
| ItrTime                 | 6.36           |
| LossAfter               | -0.00030613938 |
| LossBefore              | -1.0153913e-06 |
| Time                    | 579            |
| Time-Optimization       | 0.221          |
| Time-SampleProc         | 0.051          |
| Time-Sampling           | 6.08           |
| n_timesteps             | 870000         |
| train-AverageDiscoun... | 26.1           |
| train-AverageReturn     | 33.3           |
| train-EnvExecTime       | 2.2            |
| train-MaxReturn         | 37             |
| train-MinReturn         | 30.5           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.68           |
| train-StdReturn         | 1.41           |
--------------------------------------------

 ---------------- Iteration 87 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 87             |
| ItrTime                 | 6.32           |
| LossAfter               | -0.0012754676  |
| LossBefore              | -1.0132754e-06 |
| Time                    | 586            |
| Time-Optimization       | 0.222          |
| Time-SampleProc         | 0.0449         |
| Time-Sampling           | 6.06           |
| n_timesteps             | 880000         |
| train-AverageDiscoun... | 26.4           |
| train-AverageReturn     | 33.6           |
| train-EnvExecTime       | 2.19           |
| train-MaxReturn         | 37.3           |
| train-MinReturn         | 29.5           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.67           |
| train-StdReturn         | 1.51           |
--------------------------------------------

 ---------------- Iteration 88 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 88            |
| ItrTime                 | 6.24          |
| LossAfter               | 0.002387147   |
| LossBefore              | -1.004419e-06 |
| Time                    | 592           |
| Time-Optimization       | 0.229         |
| Time-SampleProc         | 0.0424        |
| Time-Sampling           | 5.97          |
| n_timesteps             | 890000        |
| train-AverageDiscoun... | 26.1          |
| train-AverageReturn     | 33.4          |
| train-EnvExecTime       | 2.17          |
| train-MaxReturn         | 37.5          |
| train-MinReturn         | 29.5          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.6           |
| train-StdReturn         | 1.51          |
-------------------------------------------

 ---------------- Iteration 89 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 89             |
| ItrTime                 | 6.79           |
| LossAfter               | -0.00092906225 |
| LossBefore              | -1.0021125e-06 |
| Time                    | 599            |
| Time-Optimization       | 0.194          |
| Time-SampleProc         | 0.0812         |
| Time-Sampling           | 6.51           |
| n_timesteps             | 900000         |
| train-AverageDiscoun... | 26             |
| train-AverageReturn     | 33.3           |
| train-EnvExecTime       | 2.39           |
| train-MaxReturn         | 37             |
| train-MinReturn         | 29.8           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.91           |
| train-StdReturn         | 1.53           |
--------------------------------------------

 ---------------- Iteration 90 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 90             |
| ItrTime                 | 6.58           |
| LossAfter               | -0.0044511408  |
| LossBefore              | -1.0034296e-06 |
| Time                    | 605            |
| Time-Optimization       | 0.229          |
| Time-SampleProc         | 0.0377         |
| Time-Sampling           | 6.32           |
| n_timesteps             | 910000         |
| train-AverageDiscoun... | 26.2           |
| train-AverageReturn     | 33.6           |
| train-EnvExecTime       | 2.28           |
| train-MaxReturn         | 36.6           |
| train-MinReturn         | 29.9           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.82           |
| train-StdReturn         | 1.48           |
--------------------------------------------

 ---------------- Iteration 91 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 91            |
| ItrTime                 | 6.47          |
| LossAfter               | 0.0011584722  |
| LossBefore              | -9.940383e-07 |
| Time                    | 612           |
| Time-Optimization       | 0.207         |
| Time-SampleProc         | 0.0521        |
| Time-Sampling           | 6.21          |
| n_timesteps             | 920000        |
| train-AverageDiscoun... | 26.4          |
| train-AverageReturn     | 33.8          |
| train-EnvExecTime       | 2.25          |
| train-MaxReturn         | 38            |
| train-MinReturn         | 30.3          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.76          |
| train-StdReturn         | 1.44          |
-------------------------------------------

 ---------------- Iteration 92 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 92            |
| ItrTime                 | 6.62          |
| LossAfter               | 0.007821642   |
| LossBefore              | -9.845493e-07 |
| Time                    | 618           |
| Time-Optimization       | 0.187         |
| Time-SampleProc         | 0.0782        |
| Time-Sampling           | 6.34          |
| n_timesteps             | 930000        |
| train-AverageDiscoun... | 26.3          |
| train-AverageReturn     | 33.7          |
| train-EnvExecTime       | 2.33          |
| train-MaxReturn         | 37.5          |
| train-MinReturn         | 30            |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.81          |
| train-StdReturn         | 1.51          |
-------------------------------------------

 ---------------- Iteration 93 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 93            |
| ItrTime                 | 6.28          |
| LossAfter               | 0.010580485   |
| LossBefore              | -9.943451e-07 |
| Time                    | 625           |
| Time-Optimization       | 0.231         |
| Time-SampleProc         | 0.0849        |
| Time-Sampling           | 5.96          |
| n_timesteps             | 940000        |
| train-AverageDiscoun... | 26.2          |
| train-AverageReturn     | 33.6          |
| train-EnvExecTime       | 2.15          |
| train-MaxReturn         | 37.2          |
| train-MinReturn         | 30.1          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.62          |
| train-StdReturn         | 1.43          |
-------------------------------------------

 ---------------- Iteration 94 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 94            |
| ItrTime                 | 6.72          |
| LossAfter               | -0.0011573281 |
| LossBefore              | -9.899619e-07 |
| Time                    | 631           |
| Time-Optimization       | 0.212         |
| Time-SampleProc         | 0.0448        |
| Time-Sampling           | 6.47          |
| n_timesteps             | 950000        |
| train-AverageDiscoun... | 26.2          |
| train-AverageReturn     | 33.6          |
| train-EnvExecTime       | 2.37          |
| train-MaxReturn         | 37.1          |
| train-MinReturn         | 29.8          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.88          |
| train-StdReturn         | 1.36          |
-------------------------------------------

 ---------------- Iteration 95 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 95            |
| ItrTime                 | 6.41          |
| LossAfter               | -0.0019770458 |
| LossBefore              | -9.861125e-07 |
| Time                    | 638           |
| Time-Optimization       | 0.222         |
| Time-SampleProc         | 0.0399        |
| Time-Sampling           | 6.15          |
| n_timesteps             | 960000        |
| train-AverageDiscoun... | 26.4          |
| train-AverageReturn     | 33.8          |
| train-EnvExecTime       | 2.2           |
| train-MaxReturn         | 36.8          |
| train-MinReturn         | 30.7          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.75          |
| train-StdReturn         | 1.37          |
-------------------------------------------

 ---------------- Iteration 96 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 96           |
| ItrTime                 | 6.48         |
| LossAfter               | 0.0018177484 |
| LossBefore              | -9.81294e-07 |
| Time                    | 644          |
| Time-Optimization       | 0.237        |
| Time-SampleProc         | 0.044        |
| Time-Sampling           | 6.2          |
| n_timesteps             | 970000       |
| train-AverageDiscoun... | 26.4         |
| train-AverageReturn     | 33.8         |
| train-EnvExecTime       | 2.26         |
| train-MaxReturn         | 37           |
| train-MinReturn         | 30.5         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 3.73         |
| train-StdReturn         | 1.47         |
------------------------------------------

 ---------------- Iteration 97 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 97            |
| ItrTime                 | 6.74          |
| LossAfter               | 0.0044494425  |
| LossBefore              | -9.757634e-07 |
| Time                    | 651           |
| Time-Optimization       | 0.218         |
| Time-SampleProc         | 0.0428        |
| Time-Sampling           | 6.48          |
| n_timesteps             | 980000        |
| train-AverageDiscoun... | 26.4          |
| train-AverageReturn     | 33.9          |
| train-EnvExecTime       | 2.35          |
| train-MaxReturn         | 37.1          |
| train-MinReturn         | 30.9          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.91          |
| train-StdReturn         | 1.52          |
-------------------------------------------

 ---------------- Iteration 98 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 98            |
| ItrTime                 | 6.62          |
| LossAfter               | 0.00027278363 |
| LossBefore              | -9.730197e-07 |
| Time                    | 658           |
| Time-Optimization       | 0.237         |
| Time-SampleProc         | 0.0444        |
| Time-Sampling           | 6.34          |
| n_timesteps             | 990000        |
| train-AverageDiscoun... | 26.4          |
| train-AverageReturn     | 33.8          |
| train-EnvExecTime       | 2.3           |
| train-MaxReturn         | 37.5          |
| train-MinReturn         | 29.6          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.83          |
| train-StdReturn         | 1.54          |
-------------------------------------------

 ---------------- Iteration 99 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 99            |
| ItrTime                 | 6.54          |
| LossAfter               | 0.005427197   |
| LossBefore              | -9.869731e-07 |
| Time                    | 664           |
| Time-Optimization       | 0.223         |
| Time-SampleProc         | 0.0416        |
| Time-Sampling           | 6.28          |
| n_timesteps             | 1000000       |
| train-AverageDiscoun... | 26.2          |
| train-AverageReturn     | 33.6          |
| train-EnvExecTime       | 2.27          |
| train-MaxReturn         | 36.8          |
| train-MinReturn         | 30            |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.79          |
| train-StdReturn         | 1.49          |
-------------------------------------------

 ---------------- Iteration 100 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 100           |
| ItrTime                 | 6.44          |
| LossAfter               | -0.0014897072 |
| LossBefore              | -9.675753e-07 |
| Time                    | 671           |
| Time-Optimization       | 0.209         |
| Time-SampleProc         | 0.0673        |
| Time-Sampling           | 6.17          |
| n_timesteps             | 1010000       |
| train-AverageDiscoun... | 26.3          |
| train-AverageReturn     | 33.8          |
| train-EnvExecTime       | 2.21          |
| train-MaxReturn         | 37.5          |
| train-MinReturn         | 29.7          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.75          |
| train-StdReturn         | 1.53          |
-------------------------------------------

 ---------------- Iteration 101 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 101           |
| ItrTime                 | 6.3           |
| LossAfter               | -0.0012969847 |
| LossBefore              | -9.546876e-07 |
| Time                    | 677           |
| Time-Optimization       | 0.225         |
| Time-SampleProc         | 0.0414        |
| Time-Sampling           | 6.03          |
| n_timesteps             | 1020000       |
| train-AverageDiscoun... | 26.5          |
| train-AverageReturn     | 33.9          |
| train-EnvExecTime       | 2.2           |
| train-MaxReturn         | 37.1          |
| train-MinReturn         | 29.7          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.63          |
| train-StdReturn         | 1.53          |
-------------------------------------------

 ---------------- Iteration 102 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 102           |
| ItrTime                 | 6.3           |
| LossAfter               | 0.001742235   |
| LossBefore              | -9.689434e-07 |
| Time                    | 683           |
| Time-Optimization       | 0.219         |
| Time-SampleProc         | 0.0513        |
| Time-Sampling           | 6.03          |
| n_timesteps             | 1030000       |
| train-AverageDiscoun... | 26.7          |
| train-AverageReturn     | 34.2          |
| train-EnvExecTime       | 2.19          |
| train-MaxReturn         | 37.5          |
| train-MinReturn         | 30.6          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.64          |
| train-StdReturn         | 1.4           |
-------------------------------------------

 ---------------- Iteration 103 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 103           |
| ItrTime                 | 6.4           |
| LossAfter               | -0.0011900887 |
| LossBefore              | -9.647682e-07 |
| Time                    | 690           |
| Time-Optimization       | 0.211         |
| Time-SampleProc         | 0.0781        |
| Time-Sampling           | 6.11          |
| n_timesteps             | 1040000       |
| train-AverageDiscoun... | 26.3          |
| train-AverageReturn     | 33.8          |
| train-EnvExecTime       | 2.21          |
| train-MaxReturn         | 37.9          |
| train-MinReturn         | 30.1          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.7           |
| train-StdReturn         | 1.64          |
-------------------------------------------

 ---------------- Iteration 104 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 104           |
| ItrTime                 | 6.14          |
| LossAfter               | -0.0009544108 |
| LossBefore              | -9.566895e-07 |
| Time                    | 696           |
| Time-Optimization       | 0.22          |
| Time-SampleProc         | 0.038         |
| Time-Sampling           | 5.89          |
| n_timesteps             | 1050000       |
| train-AverageDiscoun... | 26.4          |
| train-AverageReturn     | 33.9          |
| train-EnvExecTime       | 2.12          |
| train-MaxReturn         | 37.1          |
| train-MinReturn         | 30.6          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.56          |
| train-StdReturn         | 1.27          |
-------------------------------------------

 ---------------- Iteration 105 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 105           |
| ItrTime                 | 6.57          |
| LossAfter               | -0.0013002268 |
| LossBefore              | -9.604516e-07 |
| Time                    | 702           |
| Time-Optimization       | 0.195         |
| Time-SampleProc         | 0.0822        |
| Time-Sampling           | 6.29          |
| n_timesteps             | 1060000       |
| train-AverageDiscoun... | 26.6          |
| train-AverageReturn     | 34.1          |
| train-EnvExecTime       | 2.27          |
| train-MaxReturn         | 37.6          |
| train-MinReturn         | 29.1          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.82          |
| train-StdReturn         | 1.65          |
-------------------------------------------

 ---------------- Iteration 106 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 106            |
| ItrTime                 | 7.34           |
| LossAfter               | -0.0024098183  |
| LossBefore              | -9.5353164e-07 |
| Time                    | 710            |
| Time-Optimization       | 0.229          |
| Time-SampleProc         | 0.0603         |
| Time-Sampling           | 7.05           |
| n_timesteps             | 1070000        |
| train-AverageDiscoun... | 26.5           |
| train-AverageReturn     | 34             |
| train-EnvExecTime       | 2.57           |
| train-MaxReturn         | 37             |
| train-MinReturn         | 30.6           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.23           |
| train-StdReturn         | 1.51           |
--------------------------------------------

 ---------------- Iteration 107 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 107            |
| ItrTime                 | 6.76           |
| LossAfter               | -0.00066667964 |
| LossBefore              | -9.4070924e-07 |
| Time                    | 717            |
| Time-Optimization       | 0.207          |
| Time-SampleProc         | 0.0803         |
| Time-Sampling           | 6.47           |
| n_timesteps             | 1080000        |
| train-AverageDiscoun... | 26.6           |
| train-AverageReturn     | 34.1           |
| train-EnvExecTime       | 2.35           |
| train-MaxReturn         | 37.3           |
| train-MinReturn         | 30.8           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.91           |
| train-StdReturn         | 1.63           |
--------------------------------------------

 ---------------- Iteration 108 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 108           |
| ItrTime                 | 6.39          |
| LossAfter               | -0.0008133802 |
| LossBefore              | -9.472137e-07 |
| Time                    | 723           |
| Time-Optimization       | 0.19          |
| Time-SampleProc         | 0.0779        |
| Time-Sampling           | 6.12          |
| n_timesteps             | 1090000       |
| train-AverageDiscoun... | 26.4          |
| train-AverageReturn     | 33.8          |
| train-EnvExecTime       | 2.22          |
| train-MaxReturn         | 38.1          |
| train-MinReturn         | 30.1          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.7           |
| train-StdReturn         | 1.58          |
-------------------------------------------

 ---------------- Iteration 109 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 109           |
| ItrTime                 | 6.08          |
| LossAfter               | 0.00022301673 |
| LossBefore              | -9.49954e-07  |
| Time                    | 729           |
| Time-Optimization       | 0.214         |
| Time-SampleProc         | 0.0489        |
| Time-Sampling           | 5.81          |
| n_timesteps             | 1100000       |
| train-AverageDiscoun... | 26.2          |
| train-AverageReturn     | 33.7          |
| train-EnvExecTime       | 2.11          |
| train-MaxReturn         | 37.5          |
| train-MinReturn         | 29.4          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.49          |
| train-StdReturn         | 1.58          |
-------------------------------------------

 ---------------- Iteration 110 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 110           |
| ItrTime                 | 5.93          |
| LossAfter               | -0.0029933448 |
| LossBefore              | -9.460467e-07 |
| Time                    | 735           |
| Time-Optimization       | 0.22          |
| Time-SampleProc         | 0.0409        |
| Time-Sampling           | 5.67          |
| n_timesteps             | 1110000       |
| train-AverageDiscoun... | 26.4          |
| train-AverageReturn     | 34            |
| train-EnvExecTime       | 2.06          |
| train-MaxReturn         | 36.8          |
| train-MinReturn         | 29.9          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.43          |
| train-StdReturn         | 1.52          |
-------------------------------------------

 ---------------- Iteration 111 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 111            |
| ItrTime                 | 6.77           |
| LossAfter               | -0.0033559708  |
| LossBefore              | -9.2234245e-07 |
| Time                    | 742            |
| Time-Optimization       | 0.257          |
| Time-SampleProc         | 0.0458         |
| Time-Sampling           | 6.47           |
| n_timesteps             | 1120000        |
| train-AverageDiscoun... | 26.4           |
| train-AverageReturn     | 33.9           |
| train-EnvExecTime       | 2.34           |
| train-MaxReturn         | 37.3           |
| train-MinReturn         | 30.6           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.91           |
| train-StdReturn         | 1.44           |
--------------------------------------------

 ---------------- Iteration 112 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 112            |
| ItrTime                 | 7.59           |
| LossAfter               | 0.00094583543  |
| LossBefore              | -9.2447243e-07 |
| Time                    | 749            |
| Time-Optimization       | 0.256          |
| Time-SampleProc         | 0.0355         |
| Time-Sampling           | 7.3            |
| n_timesteps             | 1130000        |
| train-AverageDiscoun... | 26.3           |
| train-AverageReturn     | 33.8           |
| train-EnvExecTime       | 2.56           |
| train-MaxReturn         | 36.9           |
| train-MinReturn         | 30.4           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.5            |
| train-StdReturn         | 1.49           |
--------------------------------------------

 ---------------- Iteration 113 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 113           |
| ItrTime                 | 6.56          |
| LossAfter               | -0.0004837505 |
| LossBefore              | -9.260664e-07 |
| Time                    | 756           |
| Time-Optimization       | 0.24          |
| Time-SampleProc         | 0.0437        |
| Time-Sampling           | 6.28          |
| n_timesteps             | 1140000       |
| train-AverageDiscoun... | 26.7          |
| train-AverageReturn     | 34.2          |
| train-EnvExecTime       | 2.26          |
| train-MaxReturn         | 37.8          |
| train-MinReturn         | 31.2          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.81          |
| train-StdReturn         | 1.37          |
-------------------------------------------

 ---------------- Iteration 114 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 114            |
| ItrTime                 | 6.42           |
| LossAfter               | -0.0013578876  |
| LossBefore              | -9.2712844e-07 |
| Time                    | 762            |
| Time-Optimization       | 0.219          |
| Time-SampleProc         | 0.0873         |
| Time-Sampling           | 6.11           |
| n_timesteps             | 1150000        |
| train-AverageDiscoun... | 26.3           |
| train-AverageReturn     | 33.8           |
| train-EnvExecTime       | 2.24           |
| train-MaxReturn         | 37.2           |
| train-MinReturn         | 30.6           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.66           |
| train-StdReturn         | 1.48           |
--------------------------------------------

 ---------------- Iteration 115 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 115           |
| ItrTime                 | 6.23          |
| LossAfter               | 0.00045297598 |
| LossBefore              | -9.206255e-07 |
| Time                    | 769           |
| Time-Optimization       | 0.224         |
| Time-SampleProc         | 0.0414        |
| Time-Sampling           | 5.96          |
| n_timesteps             | 1160000       |
| train-AverageDiscoun... | 26.4          |
| train-AverageReturn     | 33.9          |
| train-EnvExecTime       | 2.16          |
| train-MaxReturn         | 37            |
| train-MinReturn         | 30.3          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.6           |
| train-StdReturn         | 1.55          |
-------------------------------------------

 ---------------- Iteration 116 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 116            |
| ItrTime                 | 6.53           |
| LossAfter               | -0.00035419522 |
| LossBefore              | -9.2462807e-07 |
| Time                    | 775            |
| Time-Optimization       | 0.218          |
| Time-SampleProc         | 0.0405         |
| Time-Sampling           | 6.27           |
| n_timesteps             | 1170000        |
| train-AverageDiscoun... | 26.6           |
| train-AverageReturn     | 34.2           |
| train-EnvExecTime       | 2.27           |
| train-MaxReturn         | 37.9           |
| train-MinReturn         | 30.4           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.79           |
| train-StdReturn         | 1.56           |
--------------------------------------------

 ---------------- Iteration 117 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 117           |
| ItrTime                 | 6.33          |
| LossAfter               | -0.0024472373 |
| LossBefore              | -9.355719e-07 |
| Time                    | 782           |
| Time-Optimization       | 0.225         |
| Time-SampleProc         | 0.0373        |
| Time-Sampling           | 6.06          |
| n_timesteps             | 1180000       |
| train-AverageDiscoun... | 26.7          |
| train-AverageReturn     | 34.2          |
| train-EnvExecTime       | 2.2           |
| train-MaxReturn         | 37.6          |
| train-MinReturn         | 29.9          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.66          |
| train-StdReturn         | 1.55          |
-------------------------------------------

 ---------------- Iteration 118 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 118           |
| ItrTime                 | 6.13          |
| LossAfter               | -0.0017725481 |
| LossBefore              | -9.188167e-07 |
| Time                    | 788           |
| Time-Optimization       | 0.25          |
| Time-SampleProc         | 0.0349        |
| Time-Sampling           | 5.84          |
| n_timesteps             | 1190000       |
| train-AverageDiscoun... | 26.5          |
| train-AverageReturn     | 34            |
| train-EnvExecTime       | 2.14          |
| train-MaxReturn         | 37.2          |
| train-MinReturn         | 30.9          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.51          |
| train-StdReturn         | 1.25          |
-------------------------------------------

 ---------------- Iteration 119 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 119           |
| ItrTime                 | 6.49          |
| LossAfter               | -0.001739911  |
| LossBefore              | -9.087659e-07 |
| Time                    | 794           |
| Time-Optimization       | 0.227         |
| Time-SampleProc         | 0.0425        |
| Time-Sampling           | 6.22          |
| n_timesteps             | 1200000       |
| train-AverageDiscoun... | 26.6          |
| train-AverageReturn     | 34.1          |
| train-EnvExecTime       | 2.27          |
| train-MaxReturn         | 38            |
| train-MinReturn         | 30.9          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.75          |
| train-StdReturn         | 1.6           |
-------------------------------------------

 ---------------- Iteration 120 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 120           |
| ItrTime                 | 6.55          |
| LossAfter               | 0.0011845914  |
| LossBefore              | -9.090543e-07 |
| Time                    | 801           |
| Time-Optimization       | 0.204         |
| Time-SampleProc         | 0.0663        |
| Time-Sampling           | 6.28          |
| n_timesteps             | 1210000       |
| train-AverageDiscoun... | 26.5          |
| train-AverageReturn     | 34.1          |
| train-EnvExecTime       | 2.28          |
| train-MaxReturn         | 37.1          |
| train-MinReturn         | 30.9          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.79          |
| train-StdReturn         | 1.42          |
-------------------------------------------

 ---------------- Iteration 121 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 121            |
| ItrTime                 | 6.22           |
| LossAfter               | -0.0007360834  |
| LossBefore              | -9.1307794e-07 |
| Time                    | 807            |
| Time-Optimization       | 0.213          |
| Time-SampleProc         | 0.0444         |
| Time-Sampling           | 5.96           |
| n_timesteps             | 1220000        |
| train-AverageDiscoun... | 26.6           |
| train-AverageReturn     | 34.1           |
| train-EnvExecTime       | 2.19           |
| train-MaxReturn         | 37             |
| train-MinReturn         | 31.1           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.57           |
| train-StdReturn         | 1.46           |
--------------------------------------------

 ---------------- Iteration 122 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 122           |
| ItrTime                 | 6.26          |
| LossAfter               | -0.0032446529 |
| LossBefore              | -9.00474e-07  |
| Time                    | 813           |
| Time-Optimization       | 0.227         |
| Time-SampleProc         | 0.0397        |
| Time-Sampling           | 6             |
| n_timesteps             | 1230000       |
| train-AverageDiscoun... | 26.6          |
| train-AverageReturn     | 34.1          |
| train-EnvExecTime       | 2.16          |
| train-MaxReturn         | 37.7          |
| train-MinReturn         | 30.3          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.64          |
| train-StdReturn         | 1.5           |
-------------------------------------------

 ---------------- Iteration 123 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 123           |
| ItrTime                 | 6.18          |
| LossAfter               | -0.0007297153 |
| LossBefore              | -9.08075e-07  |
| Time                    | 819           |
| Time-Optimization       | 0.226         |
| Time-SampleProc         | 0.0399        |
| Time-Sampling           | 5.91          |
| n_timesteps             | 1240000       |
| train-AverageDiscoun... | 26.6          |
| train-AverageReturn     | 34.1          |
| train-EnvExecTime       | 2.14          |
| train-MaxReturn         | 37.8          |
| train-MinReturn         | 31.4          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.57          |
| train-StdReturn         | 1.39          |
-------------------------------------------

 ---------------- Iteration 124 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 124           |
| ItrTime                 | 7.16          |
| LossAfter               | 0.0021157651  |
| LossBefore              | -8.915995e-07 |
| Time                    | 827           |
| Time-Optimization       | 0.224         |
| Time-SampleProc         | 0.0928        |
| Time-Sampling           | 6.84          |
| n_timesteps             | 1250000       |
| train-AverageDiscoun... | 26.5          |
| train-AverageReturn     | 34            |
| train-EnvExecTime       | 2.47          |
| train-MaxReturn         | 37.2          |
| train-MinReturn         | 30.6          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 4.15          |
| train-StdReturn         | 1.52          |
-------------------------------------------

 ---------------- Iteration 125 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 125            |
| ItrTime                 | 7.15           |
| LossAfter               | -0.0004191855  |
| LossBefore              | -8.9677434e-07 |
| Time                    | 834            |
| Time-Optimization       | 0.237          |
| Time-SampleProc         | 0.0457         |
| Time-Sampling           | 6.86           |
| n_timesteps             | 1260000        |
| train-AverageDiscoun... | 26.8           |
| train-AverageReturn     | 34.4           |
| train-EnvExecTime       | 2.49           |
| train-MaxReturn         | 37.7           |
| train-MinReturn         | 30.2           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.15           |
| train-StdReturn         | 1.58           |
--------------------------------------------

 ---------------- Iteration 126 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 126            |
| ItrTime                 | 6.89           |
| LossAfter               | -0.00082977297 |
| LossBefore              | -8.8885366e-07 |
| Time                    | 841            |
| Time-Optimization       | 0.226          |
| Time-SampleProc         | 0.0287         |
| Time-Sampling           | 6.64           |
| n_timesteps             | 1270000        |
| train-AverageDiscoun... | 26.5           |
| train-AverageReturn     | 34.1           |
| train-EnvExecTime       | 2.41           |
| train-MaxReturn         | 37.5           |
| train-MinReturn         | 30.5           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.99           |
| train-StdReturn         | 1.52           |
--------------------------------------------

 ---------------- Iteration 127 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 127            |
| ItrTime                 | 6.51           |
| LossAfter               | 0.00044569475  |
| LossBefore              | -8.9621204e-07 |
| Time                    | 847            |
| Time-Optimization       | 0.2            |
| Time-SampleProc         | 0.0753         |
| Time-Sampling           | 6.24           |
| n_timesteps             | 1280000        |
| train-AverageDiscoun... | 26.4           |
| train-AverageReturn     | 33.9           |
| train-EnvExecTime       | 2.28           |
| train-MaxReturn         | 36.9           |
| train-MinReturn         | 30.8           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.75           |
| train-StdReturn         | 1.43           |
--------------------------------------------

 ---------------- Iteration 128 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 128            |
| ItrTime                 | 6.22           |
| LossAfter               | 0.015009751    |
| LossBefore              | -8.8386736e-07 |
| Time                    | 853            |
| Time-Optimization       | 0.206          |
| Time-SampleProc         | 0.0795         |
| Time-Sampling           | 5.94           |
| n_timesteps             | 1290000        |
| train-AverageDiscoun... | 26.7           |
| train-AverageReturn     | 34.2           |
| train-EnvExecTime       | 2.16           |
| train-MaxReturn         | 37.1           |
| train-MinReturn         | 30.7           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.57           |
| train-StdReturn         | 1.42           |
--------------------------------------------

 ---------------- Iteration 129 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 129           |
| ItrTime                 | 6.22          |
| LossAfter               | 0.0057924134  |
| LossBefore              | -8.897508e-07 |
| Time                    | 860           |
| Time-Optimization       | 0.221         |
| Time-SampleProc         | 0.0376        |
| Time-Sampling           | 5.96          |
| n_timesteps             | 1300000       |
| train-AverageDiscoun... | 26.4          |
| train-AverageReturn     | 34            |
| train-EnvExecTime       | 2.17          |
| train-MaxReturn         | 38.2          |
| train-MinReturn         | 30.6          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.59          |
| train-StdReturn         | 1.36          |
-------------------------------------------

 ---------------- Iteration 130 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 130           |
| ItrTime                 | 6.28          |
| LossAfter               | -0.0014549791 |
| LossBefore              | -8.928945e-07 |
| Time                    | 866           |
| Time-Optimization       | 0.22          |
| Time-SampleProc         | 0.036         |
| Time-Sampling           | 6.03          |
| n_timesteps             | 1310000       |
| train-AverageDiscoun... | 26.7          |
| train-AverageReturn     | 34.2          |
| train-EnvExecTime       | 2.19          |
| train-MaxReturn         | 37.4          |
| train-MinReturn         | 30.7          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.64          |
| train-StdReturn         | 1.37          |
-------------------------------------------

 ---------------- Iteration 131 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 131           |
| ItrTime                 | 6.28          |
| LossAfter               | 0.0012714928  |
| LossBefore              | -8.774854e-07 |
| Time                    | 872           |
| Time-Optimization       | 0.216         |
| Time-SampleProc         | 0.0408        |
| Time-Sampling           | 6.03          |
| n_timesteps             | 1320000       |
| train-AverageDiscoun... | 26.9          |
| train-AverageReturn     | 34.4          |
| train-EnvExecTime       | 2.18          |
| train-MaxReturn         | 37.8          |
| train-MinReturn         | 31.9          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.65          |
| train-StdReturn         | 1.32          |
-------------------------------------------

 ---------------- Iteration 132 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 132            |
| ItrTime                 | 6.42           |
| LossAfter               | 0.007678527    |
| LossBefore              | -8.8276926e-07 |
| Time                    | 879            |
| Time-Optimization       | 0.209          |
| Time-SampleProc         | 0.0407         |
| Time-Sampling           | 6.17           |
| n_timesteps             | 1330000        |
| train-AverageDiscoun... | 26.6           |
| train-AverageReturn     | 34.1           |
| train-EnvExecTime       | 2.25           |
| train-MaxReturn         | 38             |
| train-MinReturn         | 30.8           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.72           |
| train-StdReturn         | 1.4            |
--------------------------------------------

 ---------------- Iteration 133 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 133           |
| ItrTime                 | 8.5           |
| LossAfter               | 0.0018838232  |
| LossBefore              | -8.763653e-07 |
| Time                    | 887           |
| Time-Optimization       | 0.191         |
| Time-SampleProc         | 0.0811        |
| Time-Sampling           | 8.23          |
| n_timesteps             | 1340000       |
| train-AverageDiscoun... | 26.4          |
| train-AverageReturn     | 33.9          |
| train-EnvExecTime       | 3.01          |
| train-MaxReturn         | 37.5          |
| train-MinReturn         | 30.4          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 4.95          |
| train-StdReturn         | 1.49          |
-------------------------------------------

 ---------------- Iteration 134 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 134           |
| ItrTime                 | 7.47          |
| LossAfter               | 0.004374639   |
| LossBefore              | -8.588772e-07 |
| Time                    | 895           |
| Time-Optimization       | 0.222         |
| Time-SampleProc         | 0.0832        |
| Time-Sampling           | 7.16          |
| n_timesteps             | 1350000       |
| train-AverageDiscoun... | 26.6          |
| train-AverageReturn     | 34.1          |
| train-EnvExecTime       | 2.51          |
| train-MaxReturn         | 37.4          |
| train-MinReturn         | 30.9          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 4.42          |
| train-StdReturn         | 1.35          |
-------------------------------------------

 ---------------- Iteration 135 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 135            |
| ItrTime                 | 7.16           |
| LossAfter               | 0.005968955    |
| LossBefore              | -8.7994965e-07 |
| Time                    | 902            |
| Time-Optimization       | 0.285          |
| Time-SampleProc         | 0.0904         |
| Time-Sampling           | 6.79           |
| n_timesteps             | 1360000        |
| train-AverageDiscoun... | 26.5           |
| train-AverageReturn     | 34             |
| train-EnvExecTime       | 2.44           |
| train-MaxReturn         | 37.2           |
| train-MinReturn         | 30.4           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.12           |
| train-StdReturn         | 1.58           |
--------------------------------------------

 ---------------- Iteration 136 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 136           |
| ItrTime                 | 6.85          |
| LossAfter               | 0.02050071    |
| LossBefore              | -8.648453e-07 |
| Time                    | 909           |
| Time-Optimization       | 0.218         |
| Time-SampleProc         | 0.0376        |
| Time-Sampling           | 6.6           |
| n_timesteps             | 1370000       |
| train-AverageDiscoun... | 26.6          |
| train-AverageReturn     | 34.2          |
| train-EnvExecTime       | 2.4           |
| train-MaxReturn         | 37.8          |
| train-MinReturn         | 30.5          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.98          |
| train-StdReturn         | 1.43          |
-------------------------------------------

 ---------------- Iteration 137 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 137            |
| ItrTime                 | 6.48           |
| LossAfter               | 0.008235635    |
| LossBefore              | -8.7635004e-07 |
| Time                    | 915            |
| Time-Optimization       | 0.284          |
| Time-SampleProc         | 0.04           |
| Time-Sampling           | 6.16           |
| n_timesteps             | 1380000        |
| train-AverageDiscoun... | 26.8           |
| train-AverageReturn     | 34.4           |
| train-EnvExecTime       | 2.22           |
| train-MaxReturn         | 37.8           |
| train-MinReturn         | 31             |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.72           |
| train-StdReturn         | 1.44           |
--------------------------------------------

 ---------------- Iteration 138 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 138            |
| ItrTime                 | 6.89           |
| LossAfter               | 0.019286485    |
| LossBefore              | -8.6460756e-07 |
| Time                    | 922            |
| Time-Optimization       | 0.209          |
| Time-SampleProc         | 0.0749         |
| Time-Sampling           | 6.61           |
| n_timesteps             | 1390000        |
| train-AverageDiscoun... | 26.3           |
| train-AverageReturn     | 33.9           |
| train-EnvExecTime       | 2.34           |
| train-MaxReturn         | 37.5           |
| train-MinReturn         | 30             |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.05           |
| train-StdReturn         | 1.6            |
--------------------------------------------

 ---------------- Iteration 139 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 139           |
| ItrTime                 | 6.39          |
| LossAfter               | 0.009429972   |
| LossBefore              | -8.586251e-07 |
| Time                    | 929           |
| Time-Optimization       | 0.228         |
| Time-SampleProc         | 0.0424        |
| Time-Sampling           | 6.11          |
| n_timesteps             | 1400000       |
| train-AverageDiscoun... | 26.7          |
| train-AverageReturn     | 34.4          |
| train-EnvExecTime       | 2.19          |
| train-MaxReturn         | 37.9          |
| train-MinReturn         | 30.7          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.71          |
| train-StdReturn         | 1.53          |
-------------------------------------------

 ---------------- Iteration 140 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 140           |
| ItrTime                 | 6.27          |
| LossAfter               | 0.0034415491  |
| LossBefore              | -8.597034e-07 |
| Time                    | 935           |
| Time-Optimization       | 0.23          |
| Time-SampleProc         | 0.0413        |
| Time-Sampling           | 6             |
| n_timesteps             | 1410000       |
| train-AverageDiscoun... | 26.4          |
| train-AverageReturn     | 34            |
| train-EnvExecTime       | 2.17          |
| train-MaxReturn         | 37.5          |
| train-MinReturn         | 29.9          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.63          |
| train-StdReturn         | 1.62          |
-------------------------------------------

 ---------------- Iteration 141 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 141            |
| ItrTime                 | 6.3            |
| LossAfter               | 0.0062108454   |
| LossBefore              | -8.5948216e-07 |
| Time                    | 941            |
| Time-Optimization       | 0.227          |
| Time-SampleProc         | 0.0522         |
| Time-Sampling           | 6.03           |
| n_timesteps             | 1420000        |
| train-AverageDiscoun... | 26.5           |
| train-AverageReturn     | 34.1           |
| train-EnvExecTime       | 2.17           |
| train-MaxReturn         | 38             |
| train-MinReturn         | 30.4           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.66           |
| train-StdReturn         | 1.58           |
--------------------------------------------

 ---------------- Iteration 142 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 142           |
| ItrTime                 | 6.67          |
| LossAfter               | 0.0027380877  |
| LossBefore              | -8.644662e-07 |
| Time                    | 948           |
| Time-Optimization       | 0.242         |
| Time-SampleProc         | 0.0447        |
| Time-Sampling           | 6.38          |
| n_timesteps             | 1430000       |
| train-AverageDiscoun... | 26.9          |
| train-AverageReturn     | 34.5          |
| train-EnvExecTime       | 2.3           |
| train-MaxReturn         | 38.5          |
| train-MinReturn         | 30.8          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.87          |
| train-StdReturn         | 1.52          |
-------------------------------------------

 ---------------- Iteration 143 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 143            |
| ItrTime                 | 6.74           |
| LossAfter               | -0.0029216164  |
| LossBefore              | -8.6292135e-07 |
| Time                    | 955            |
| Time-Optimization       | 0.255          |
| Time-SampleProc         | 0.0446         |
| Time-Sampling           | 6.44           |
| n_timesteps             | 1440000        |
| train-AverageDiscoun... | 26.4           |
| train-AverageReturn     | 34             |
| train-EnvExecTime       | 2.35           |
| train-MaxReturn         | 38.2           |
| train-MinReturn         | 30.6           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.88           |
| train-StdReturn         | 1.6            |
--------------------------------------------

 ---------------- Iteration 144 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 144           |
| ItrTime                 | 6.91          |
| LossAfter               | 0.00033301752 |
| LossBefore              | -8.552935e-07 |
| Time                    | 961           |
| Time-Optimization       | 0.237         |
| Time-SampleProc         | 0.0438        |
| Time-Sampling           | 6.63          |
| n_timesteps             | 1450000       |
| train-AverageDiscoun... | 26.7          |
| train-AverageReturn     | 34.3          |
| train-EnvExecTime       | 2.36          |
| train-MaxReturn         | 39            |
| train-MinReturn         | 30.2          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 4.03          |
| train-StdReturn         | 1.66          |
-------------------------------------------

 ---------------- Iteration 145 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 145            |
| ItrTime                 | 6.33           |
| LossAfter               | -6.0554463e-05 |
| LossBefore              | -8.575442e-07  |
| Time                    | 968            |
| Time-Optimization       | 0.221          |
| Time-SampleProc         | 0.0403         |
| Time-Sampling           | 6.07           |
| n_timesteps             | 1460000        |
| train-AverageDiscoun... | 26.4           |
| train-AverageReturn     | 34             |
| train-EnvExecTime       | 2.2            |
| train-MaxReturn         | 37.7           |
| train-MinReturn         | 31             |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.67           |
| train-StdReturn         | 1.54           |
--------------------------------------------

 ---------------- Iteration 146 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 146           |
| ItrTime                 | 6.38          |
| LossAfter               | -0.0014699788 |
| LossBefore              | -8.557829e-07 |
| Time                    | 974           |
| Time-Optimization       | 0.218         |
| Time-SampleProc         | 0.0442        |
| Time-Sampling           | 6.12          |
| n_timesteps             | 1470000       |
| train-AverageDiscoun... | 26.7          |
| train-AverageReturn     | 34.3          |
| train-EnvExecTime       | 2.23          |
| train-MaxReturn         | 37.5          |
| train-MinReturn         | 29.7          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.68          |
| train-StdReturn         | 1.59          |
-------------------------------------------

 ---------------- Iteration 147 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 147           |
| ItrTime                 | 6.39          |
| LossAfter               | -0.0011557897 |
| LossBefore              | -8.414569e-07 |
| Time                    | 981           |
| Time-Optimization       | 0.234         |
| Time-SampleProc         | 0.0457        |
| Time-Sampling           | 6.11          |
| n_timesteps             | 1480000       |
| train-AverageDiscoun... | 26.8          |
| train-AverageReturn     | 34.4          |
| train-EnvExecTime       | 2.21          |
| train-MaxReturn         | 38.2          |
| train-MinReturn         | 29.8          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.7           |
| train-StdReturn         | 1.74          |
-------------------------------------------

 ---------------- Iteration 148 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 148            |
| ItrTime                 | 6.41           |
| LossAfter               | -0.00029395145 |
| LossBefore              | -8.3393724e-07 |
| Time                    | 987            |
| Time-Optimization       | 0.244          |
| Time-SampleProc         | 0.0427         |
| Time-Sampling           | 6.12           |
| n_timesteps             | 1490000        |
| train-AverageDiscoun... | 26.8           |
| train-AverageReturn     | 34.4           |
| train-EnvExecTime       | 2.2            |
| train-MaxReturn         | 37.3           |
| train-MinReturn         | 30.7           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.71           |
| train-StdReturn         | 1.65           |
--------------------------------------------

 ---------------- Iteration 149 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 149           |
| ItrTime                 | 6.54          |
| LossAfter               | -0.0012494199 |
| LossBefore              | -8.3088e-07   |
| Time                    | 994           |
| Time-Optimization       | 0.235         |
| Time-SampleProc         | 0.0456        |
| Time-Sampling           | 6.26          |
| n_timesteps             | 1500000       |
| train-AverageDiscoun... | 26.7          |
| train-AverageReturn     | 34.3          |
| train-EnvExecTime       | 2.27          |
| train-MaxReturn         | 37.5          |
| train-MinReturn         | 30.3          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.78          |
| train-StdReturn         | 1.5           |
-------------------------------------------

 ---------------- Iteration 150 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 150            |
| ItrTime                 | 6.65           |
| LossAfter               | -8.6476764e-05 |
| LossBefore              | -8.4658234e-07 |
| Time                    | 1e+03          |
| Time-Optimization       | 0.203          |
| Time-SampleProc         | 0.0781         |
| Time-Sampling           | 6.37           |
| n_timesteps             | 1510000        |
| train-AverageDiscoun... | 26.5           |
| train-AverageReturn     | 34.1           |
| train-EnvExecTime       | 2.31           |
| train-MaxReturn         | 38.5           |
| train-MinReturn         | 30.8           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.85           |
| train-StdReturn         | 1.62           |
--------------------------------------------

 ---------------- Iteration 151 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 151           |
| ItrTime                 | 6.39          |
| LossAfter               | -0.0021320516 |
| LossBefore              | -8.422476e-07 |
| Time                    | 1.01e+03      |
| Time-Optimization       | 0.213         |
| Time-SampleProc         | 0.0787        |
| Time-Sampling           | 6.09          |
| n_timesteps             | 1520000       |
| train-AverageDiscoun... | 26.8          |
| train-AverageReturn     | 34.4          |
| train-EnvExecTime       | 2.21          |
| train-MaxReturn         | 37.8          |
| train-MinReturn         | 31.5          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.68          |
| train-StdReturn         | 1.43          |
-------------------------------------------

 ---------------- Iteration 152 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 152            |
| ItrTime                 | 6.46           |
| LossAfter               | -0.0026386762  |
| LossBefore              | -8.4199036e-07 |
| Time                    | 1.01e+03       |
| Time-Optimization       | 0.228          |
| Time-SampleProc         | 0.0432         |
| Time-Sampling           | 6.19           |
| n_timesteps             | 1530000        |
| train-AverageDiscoun... | 27             |
| train-AverageReturn     | 34.6           |
| train-EnvExecTime       | 2.25           |
| train-MaxReturn         | 37.5           |
| train-MinReturn         | 31.4           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.72           |
| train-StdReturn         | 1.41           |
--------------------------------------------

 ---------------- Iteration 153 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 153           |
| ItrTime                 | 6.76          |
| LossAfter               | -0.0014726367 |
| LossBefore              | -8.378666e-07 |
| Time                    | 1.02e+03      |
| Time-Optimization       | 0.216         |
| Time-SampleProc         | 0.0591        |
| Time-Sampling           | 6.48          |
| n_timesteps             | 1540000       |
| train-AverageDiscoun... | 26.4          |
| train-AverageReturn     | 34            |
| train-EnvExecTime       | 2.35          |
| train-MaxReturn         | 37            |
| train-MinReturn         | 30.5          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.92          |
| train-StdReturn         | 1.45          |
-------------------------------------------

 ---------------- Iteration 154 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 154           |
| ItrTime                 | 6.2           |
| LossAfter               | -0.0012030656 |
| LossBefore              | -8.356826e-07 |
| Time                    | 1.03e+03      |
| Time-Optimization       | 0.222         |
| Time-SampleProc         | 0.0463        |
| Time-Sampling           | 5.93          |
| n_timesteps             | 1550000       |
| train-AverageDiscoun... | 26.7          |
| train-AverageReturn     | 34.4          |
| train-EnvExecTime       | 2.17          |
| train-MaxReturn         | 37.7          |
| train-MinReturn         | 30.2          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.57          |
| train-StdReturn         | 1.5           |
-------------------------------------------

 ---------------- Iteration 155 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 155            |
| ItrTime                 | 6.47           |
| LossAfter               | 0.0052672303   |
| LossBefore              | -8.2754946e-07 |
| Time                    | 1.03e+03       |
| Time-Optimization       | 0.223          |
| Time-SampleProc         | 0.0373         |
| Time-Sampling           | 6.21           |
| n_timesteps             | 1560000        |
| train-AverageDiscoun... | 26.7           |
| train-AverageReturn     | 34.4           |
| train-EnvExecTime       | 2.27           |
| train-MaxReturn         | 37.5           |
| train-MinReturn         | 31             |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.73           |
| train-StdReturn         | 1.53           |
--------------------------------------------

 ---------------- Iteration 156 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 156            |
| ItrTime                 | 6.57           |
| LossAfter               | 0.0026280012   |
| LossBefore              | -8.2520955e-07 |
| Time                    | 1.04e+03       |
| Time-Optimization       | 0.228          |
| Time-SampleProc         | 0.0446         |
| Time-Sampling           | 6.3            |
| n_timesteps             | 1570000        |
| train-AverageDiscoun... | 26.7           |
| train-AverageReturn     | 34.4           |
| train-EnvExecTime       | 2.25           |
| train-MaxReturn         | 37.5           |
| train-MinReturn         | 31.8           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.84           |
| train-StdReturn         | 1.31           |
--------------------------------------------

 ---------------- Iteration 157 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 157           |
| ItrTime                 | 6.71          |
| LossAfter               | 0.0063614156  |
| LossBefore              | -8.134002e-07 |
| Time                    | 1.05e+03      |
| Time-Optimization       | 0.242         |
| Time-SampleProc         | 0.0449        |
| Time-Sampling           | 6.43          |
| n_timesteps             | 1580000       |
| train-AverageDiscoun... | 26.8          |
| train-AverageReturn     | 34.5          |
| train-EnvExecTime       | 2.34          |
| train-MaxReturn         | 37.8          |
| train-MinReturn         | 29.9          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.87          |
| train-StdReturn         | 1.56          |
-------------------------------------------

 ---------------- Iteration 158 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 158           |
| ItrTime                 | 6.63          |
| LossAfter               | 0.0043638507  |
| LossBefore              | -8.093548e-07 |
| Time                    | 1.05e+03      |
| Time-Optimization       | 0.233         |
| Time-SampleProc         | 0.0438        |
| Time-Sampling           | 6.36          |
| n_timesteps             | 1590000       |
| train-AverageDiscoun... | 26.9          |
| train-AverageReturn     | 34.5          |
| train-EnvExecTime       | 2.3           |
| train-MaxReturn         | 37.9          |
| train-MinReturn         | 30.8          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.84          |
| train-StdReturn         | 1.61          |
-------------------------------------------

 ---------------- Iteration 159 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 159            |
| ItrTime                 | 6.4            |
| LossAfter               | 0.0050815167   |
| LossBefore              | -8.1797646e-07 |
| Time                    | 1.06e+03       |
| Time-Optimization       | 0.226          |
| Time-SampleProc         | 0.0436         |
| Time-Sampling           | 6.13           |
| n_timesteps             | 1600000        |
| train-AverageDiscoun... | 26.7           |
| train-AverageReturn     | 34.3           |
| train-EnvExecTime       | 2.22           |
| train-MaxReturn         | 38             |
| train-MinReturn         | 31.5           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.71           |
| train-StdReturn         | 1.48           |
--------------------------------------------

 ---------------- Iteration 160 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 160            |
| ItrTime                 | 7.22           |
| LossAfter               | 0.0033815862   |
| LossBefore              | -8.1397343e-07 |
| Time                    | 1.07e+03       |
| Time-Optimization       | 0.206          |
| Time-SampleProc         | 0.0509         |
| Time-Sampling           | 6.97           |
| n_timesteps             | 1610000        |
| train-AverageDiscoun... | 26.8           |
| train-AverageReturn     | 34.4           |
| train-EnvExecTime       | 2.54           |
| train-MaxReturn         | 37.8           |
| train-MinReturn         | 30.5           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.2            |
| train-StdReturn         | 1.59           |
--------------------------------------------

 ---------------- Iteration 161 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 161            |
| ItrTime                 | 6.39           |
| LossAfter               | 0.016570857    |
| LossBefore              | -8.0157326e-07 |
| Time                    | 1.07e+03       |
| Time-Optimization       | 0.241          |
| Time-SampleProc         | 0.0389         |
| Time-Sampling           | 6.11           |
| n_timesteps             | 1620000        |
| train-AverageDiscoun... | 26.4           |
| train-AverageReturn     | 34             |
| train-EnvExecTime       | 2.2            |
| train-MaxReturn         | 38.6           |
| train-MinReturn         | 30.8           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.71           |
| train-StdReturn         | 1.42           |
--------------------------------------------

 ---------------- Iteration 162 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 162            |
| ItrTime                 | 6.38           |
| LossAfter               | -0.00059876445 |
| LossBefore              | -7.957637e-07  |
| Time                    | 1.08e+03       |
| Time-Optimization       | 0.225          |
| Time-SampleProc         | 0.0391         |
| Time-Sampling           | 6.12           |
| n_timesteps             | 1630000        |
| train-AverageDiscoun... | 26.8           |
| train-AverageReturn     | 34.3           |
| train-EnvExecTime       | 2.21           |
| train-MaxReturn         | 37.7           |
| train-MinReturn         | 30.5           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.71           |
| train-StdReturn         | 1.46           |
--------------------------------------------

 ---------------- Iteration 163 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 163            |
| ItrTime                 | 6.76           |
| LossAfter               | 0.005259447    |
| LossBefore              | -8.1870735e-07 |
| Time                    | 1.09e+03       |
| Time-Optimization       | 0.229          |
| Time-SampleProc         | 0.0363         |
| Time-Sampling           | 6.49           |
| n_timesteps             | 1640000        |
| train-AverageDiscoun... | 26.5           |
| train-AverageReturn     | 34.1           |
| train-EnvExecTime       | 2.35           |
| train-MaxReturn         | 37.6           |
| train-MinReturn         | 30.9           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.91           |
| train-StdReturn         | 1.61           |
--------------------------------------------

 ---------------- Iteration 164 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 164           |
| ItrTime                 | 6.54          |
| LossAfter               | -0.0008450381 |
| LossBefore              | -8.062938e-07 |
| Time                    | 1.09e+03      |
| Time-Optimization       | 0.223         |
| Time-SampleProc         | 0.035         |
| Time-Sampling           | 6.28          |
| n_timesteps             | 1650000       |
| train-AverageDiscoun... | 26.5          |
| train-AverageReturn     | 34.1          |
| train-EnvExecTime       | 2.29          |
| train-MaxReturn         | 38.2          |
| train-MinReturn         | 30.1          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.78          |
| train-StdReturn         | 1.54          |
-------------------------------------------

 ---------------- Iteration 165 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 165            |
| ItrTime                 | 6.27           |
| LossAfter               | 0.0050582755   |
| LossBefore              | -8.0947444e-07 |
| Time                    | 1.1e+03        |
| Time-Optimization       | 0.206          |
| Time-SampleProc         | 0.0714         |
| Time-Sampling           | 6              |
| n_timesteps             | 1660000        |
| train-AverageDiscoun... | 26.4           |
| train-AverageReturn     | 33.9           |
| train-EnvExecTime       | 2.18           |
| train-MaxReturn         | 37.3           |
| train-MinReturn         | 30             |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.62           |
| train-StdReturn         | 1.36           |
--------------------------------------------

 ---------------- Iteration 166 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 166            |
| ItrTime                 | 6.22           |
| LossAfter               | 0.0023536603   |
| LossBefore              | -7.9934836e-07 |
| Time                    | 1.1e+03        |
| Time-Optimization       | 0.217          |
| Time-SampleProc         | 0.0436         |
| Time-Sampling           | 5.96           |
| n_timesteps             | 1670000        |
| train-AverageDiscoun... | 26.7           |
| train-AverageReturn     | 34.3           |
| train-EnvExecTime       | 2.17           |
| train-MaxReturn         | 37.7           |
| train-MinReturn         | 30.5           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.59           |
| train-StdReturn         | 1.57           |
--------------------------------------------

 ---------------- Iteration 167 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 167            |
| ItrTime                 | 6.33           |
| LossAfter               | 0.005051664    |
| LossBefore              | -8.0646413e-07 |
| Time                    | 1.11e+03       |
| Time-Optimization       | 0.21           |
| Time-SampleProc         | 0.0397         |
| Time-Sampling           | 6.08           |
| n_timesteps             | 1680000        |
| train-AverageDiscoun... | 26.7           |
| train-AverageReturn     | 34.3           |
| train-EnvExecTime       | 2.22           |
| train-MaxReturn         | 38.8           |
| train-MinReturn         | 29.9           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.66           |
| train-StdReturn         | 1.65           |
--------------------------------------------

 ---------------- Iteration 168 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 168           |
| ItrTime                 | 6.25          |
| LossAfter               | -0.0018792322 |
| LossBefore              | -7.971476e-07 |
| Time                    | 1.12e+03      |
| Time-Optimization       | 0.234         |
| Time-SampleProc         | 0.0292        |
| Time-Sampling           | 5.98          |
| n_timesteps             | 1690000       |
| train-AverageDiscoun... | 26.8          |
| train-AverageReturn     | 34.4          |
| train-EnvExecTime       | 2.19          |
| train-MaxReturn         | 38.3          |
| train-MinReturn         | 31.3          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.59          |
| train-StdReturn         | 1.5           |
-------------------------------------------

 ---------------- Iteration 169 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 169           |
| ItrTime                 | 6.36          |
| LossAfter               | 0.0005698181  |
| LossBefore              | -8.114564e-07 |
| Time                    | 1.12e+03      |
| Time-Optimization       | 0.202         |
| Time-SampleProc         | 0.0792        |
| Time-Sampling           | 6.07          |
| n_timesteps             | 1700000       |
| train-AverageDiscoun... | 26.7          |
| train-AverageReturn     | 34.3          |
| train-EnvExecTime       | 2.22          |
| train-MaxReturn         | 38.2          |
| train-MinReturn         | 30.6          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.65          |
| train-StdReturn         | 1.65          |
-------------------------------------------

 ---------------- Iteration 170 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 170            |
| ItrTime                 | 6.23           |
| LossAfter               | -0.0007345147  |
| LossBefore              | -7.9512046e-07 |
| Time                    | 1.13e+03       |
| Time-Optimization       | 0.21           |
| Time-SampleProc         | 0.0298         |
| Time-Sampling           | 5.99           |
| n_timesteps             | 1710000        |
| train-AverageDiscoun... | 26.7           |
| train-AverageReturn     | 34.2           |
| train-EnvExecTime       | 2.17           |
| train-MaxReturn         | 38.1           |
| train-MinReturn         | 30.8           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.62           |
| train-StdReturn         | 1.55           |
--------------------------------------------

 ---------------- Iteration 171 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 171           |
| ItrTime                 | 6.24          |
| LossAfter               | -0.0019116437 |
| LossBefore              | -8.083966e-07 |
| Time                    | 1.14e+03      |
| Time-Optimization       | 0.209         |
| Time-SampleProc         | 0.0787        |
| Time-Sampling           | 5.95          |
| n_timesteps             | 1720000       |
| train-AverageDiscoun... | 26.6          |
| train-AverageReturn     | 34.2          |
| train-EnvExecTime       | 2.17          |
| train-MaxReturn         | 38.4          |
| train-MinReturn         | 31.1          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.59          |
| train-StdReturn         | 1.51          |
-------------------------------------------

 ---------------- Iteration 172 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 172           |
| ItrTime                 | 6.27          |
| LossAfter               | -0.0010958526 |
| LossBefore              | -8.13703e-07  |
| Time                    | 1.14e+03      |
| Time-Optimization       | 0.23          |
| Time-SampleProc         | 0.0386        |
| Time-Sampling           | 6             |
| n_timesteps             | 1730000       |
| train-AverageDiscoun... | 26.8          |
| train-AverageReturn     | 34.4          |
| train-EnvExecTime       | 2.2           |
| train-MaxReturn         | 38.3          |
| train-MinReturn         | 31.6          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.6           |
| train-StdReturn         | 1.52          |
-------------------------------------------

 ---------------- Iteration 173 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 173            |
| ItrTime                 | 6.19           |
| LossAfter               | -0.00010590258 |
| LossBefore              | -7.9246104e-07 |
| Time                    | 1.15e+03       |
| Time-Optimization       | 0.219          |
| Time-SampleProc         | 0.0377         |
| Time-Sampling           | 5.93           |
| n_timesteps             | 1740000        |
| train-AverageDiscoun... | 26.7           |
| train-AverageReturn     | 34.3           |
| train-EnvExecTime       | 2.15           |
| train-MaxReturn         | 38.1           |
| train-MinReturn         | 30.5           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.58           |
| train-StdReturn         | 1.77           |
--------------------------------------------

 ---------------- Iteration 174 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 174            |
| ItrTime                 | 6.25           |
| LossAfter               | 0.004648397    |
| LossBefore              | -8.0205075e-07 |
| Time                    | 1.15e+03       |
| Time-Optimization       | 0.222          |
| Time-SampleProc         | 0.0358         |
| Time-Sampling           | 5.99           |
| n_timesteps             | 1750000        |
| train-AverageDiscoun... | 26.8           |
| train-AverageReturn     | 34.4           |
| train-EnvExecTime       | 2.19           |
| train-MaxReturn         | 37.8           |
| train-MinReturn         | 30.5           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.6            |
| train-StdReturn         | 1.76           |
--------------------------------------------

 ---------------- Iteration 175 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 175           |
| ItrTime                 | 7.15          |
| LossAfter               | -0.0020033354 |
| LossBefore              | -8.019705e-07 |
| Time                    | 1.16e+03      |
| Time-Optimization       | 0.227         |
| Time-SampleProc         | 0.0356        |
| Time-Sampling           | 6.89          |
| n_timesteps             | 1760000       |
| train-AverageDiscoun... | 26.7          |
| train-AverageReturn     | 34.2          |
| train-EnvExecTime       | 2.52          |
| train-MaxReturn         | 38.2          |
| train-MinReturn         | 31.5          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 4.13          |
| train-StdReturn         | 1.46          |
-------------------------------------------

 ---------------- Iteration 176 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 176            |
| ItrTime                 | 6.65           |
| LossAfter               | -0.0021759614  |
| LossBefore              | -7.8906237e-07 |
| Time                    | 1.17e+03       |
| Time-Optimization       | 0.21           |
| Time-SampleProc         | 0.0334         |
| Time-Sampling           | 6.41           |
| n_timesteps             | 1770000        |
| train-AverageDiscoun... | 26.6           |
| train-AverageReturn     | 34.2           |
| train-EnvExecTime       | 2.33           |
| train-MaxReturn         | 36.7           |
| train-MinReturn         | 31.8           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.86           |
| train-StdReturn         | 1.17           |
--------------------------------------------

 ---------------- Iteration 177 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Itr                     | 177             |
| ItrTime                 | 6.21            |
| LossAfter               | -0.000113206755 |
| LossBefore              | -7.9533754e-07  |
| Time                    | 1.17e+03        |
| Time-Optimization       | 0.199           |
| Time-SampleProc         | 0.113           |
| Time-Sampling           | 5.89            |
| n_timesteps             | 1780000         |
| train-AverageDiscoun... | 26.6            |
| train-AverageReturn     | 34.2            |
| train-EnvExecTime       | 2.15            |
| train-MaxReturn         | 38              |
| train-MinReturn         | 31.1            |
| train-NumTrajs          | 100             |
| train-PolicyExecTime    | 3.55            |
| train-StdReturn         | 1.58            |
---------------------------------------------

 ---------------- Iteration 178 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 178            |
| ItrTime                 | 6.39           |
| LossAfter               | -0.00027461734 |
| LossBefore              | -7.7389166e-07 |
| Time                    | 1.18e+03       |
| Time-Optimization       | 0.195          |
| Time-SampleProc         | 0.0966         |
| Time-Sampling           | 6.1            |
| n_timesteps             | 1790000        |
| train-AverageDiscoun... | 26.8           |
| train-AverageReturn     | 34.3           |
| train-EnvExecTime       | 2.22           |
| train-MaxReturn         | 37.5           |
| train-MinReturn         | 31.4           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.68           |
| train-StdReturn         | 1.51           |
--------------------------------------------

 ---------------- Iteration 179 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 179           |
| ItrTime                 | 6.3           |
| LossAfter               | 0.006692817   |
| LossBefore              | -7.932143e-07 |
| Time                    | 1.19e+03      |
| Time-Optimization       | 0.212         |
| Time-SampleProc         | 0.0388        |
| Time-Sampling           | 6.05          |
| n_timesteps             | 1800000       |
| train-AverageDiscoun... | 27            |
| train-AverageReturn     | 34.6          |
| train-EnvExecTime       | 2.21          |
| train-MaxReturn         | 38.1          |
| train-MinReturn         | 31            |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.63          |
| train-StdReturn         | 1.63          |
-------------------------------------------

 ---------------- Iteration 180 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 180            |
| ItrTime                 | 6.25           |
| LossAfter               | -0.00085772946 |
| LossBefore              | -7.9762884e-07 |
| Time                    | 1.19e+03       |
| Time-Optimization       | 0.192          |
| Time-SampleProc         | 0.0638         |
| Time-Sampling           | 5.99           |
| n_timesteps             | 1810000        |
| train-AverageDiscoun... | 27             |
| train-AverageReturn     | 34.6           |
| train-EnvExecTime       | 2.17           |
| train-MaxReturn         | 37.9           |
| train-MinReturn         | 31.3           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.61           |
| train-StdReturn         | 1.55           |
--------------------------------------------

 ---------------- Iteration 181 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 181           |
| ItrTime                 | 6.21          |
| LossAfter               | -0.0004210037 |
| LossBefore              | -7.693584e-07 |
| Time                    | 1.2e+03       |
| Time-Optimization       | 0.201         |
| Time-SampleProc         | 0.0761        |
| Time-Sampling           | 5.94          |
| n_timesteps             | 1820000       |
| train-AverageDiscoun... | 26.7          |
| train-AverageReturn     | 34.3          |
| train-EnvExecTime       | 2.16          |
| train-MaxReturn         | 39            |
| train-MinReturn         | 30.6          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.57          |
| train-StdReturn         | 1.43          |
-------------------------------------------

 ---------------- Iteration 182 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 182           |
| ItrTime                 | 6.27          |
| LossAfter               | -0.0006746257 |
| LossBefore              | -7.810304e-07 |
| Time                    | 1.21e+03      |
| Time-Optimization       | 0.227         |
| Time-SampleProc         | 0.0423        |
| Time-Sampling           | 6             |
| n_timesteps             | 1830000       |
| train-AverageDiscoun... | 26.8          |
| train-AverageReturn     | 34.4          |
| train-EnvExecTime       | 2.16          |
| train-MaxReturn         | 37.5          |
| train-MinReturn         | 31.1          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.64          |
| train-StdReturn         | 1.5           |
-------------------------------------------

 ---------------- Iteration 183 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 183           |
| ItrTime                 | 6.01          |
| LossAfter               | 0.0017060795  |
| LossBefore              | -7.927575e-07 |
| Time                    | 1.21e+03      |
| Time-Optimization       | 0.216         |
| Time-SampleProc         | 0.0446        |
| Time-Sampling           | 5.75          |
| n_timesteps             | 1840000       |
| train-AverageDiscoun... | 26.7          |
| train-AverageReturn     | 34.3          |
| train-EnvExecTime       | 2.09          |
| train-MaxReturn         | 37.8          |
| train-MinReturn         | 30.1          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.46          |
| train-StdReturn         | 1.58          |
-------------------------------------------

 ---------------- Iteration 184 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 184            |
| ItrTime                 | 6.45           |
| LossAfter               | 8.2958795e-05  |
| LossBefore              | -7.8999534e-07 |
| Time                    | 1.22e+03       |
| Time-Optimization       | 0.226          |
| Time-SampleProc         | 0.0853         |
| Time-Sampling           | 6.14           |
| n_timesteps             | 1850000        |
| train-AverageDiscoun... | 26.5           |
| train-AverageReturn     | 34.2           |
| train-EnvExecTime       | 2.24           |
| train-MaxReturn         | 37.4           |
| train-MinReturn         | 30.9           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.7            |
| train-StdReturn         | 1.44           |
--------------------------------------------

 ---------------- Iteration 185 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 185            |
| ItrTime                 | 6.63           |
| LossAfter               | -0.00044933666 |
| LossBefore              | -7.7848335e-07 |
| Time                    | 1.23e+03       |
| Time-Optimization       | 0.212          |
| Time-SampleProc         | 0.0369         |
| Time-Sampling           | 6.38           |
| n_timesteps             | 1860000        |
| train-AverageDiscoun... | 26.8           |
| train-AverageReturn     | 34.4           |
| train-EnvExecTime       | 2.32           |
| train-MaxReturn         | 37.4           |
| train-MinReturn         | 31.5           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.84           |
| train-StdReturn         | 1.45           |
--------------------------------------------

 ---------------- Iteration 186 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 186           |
| ItrTime                 | 6.17          |
| LossAfter               | 0.0052097524  |
| LossBefore              | -7.694711e-07 |
| Time                    | 1.23e+03      |
| Time-Optimization       | 0.208         |
| Time-SampleProc         | 0.0473        |
| Time-Sampling           | 5.91          |
| n_timesteps             | 1870000       |
| train-AverageDiscoun... | 26.9          |
| train-AverageReturn     | 34.5          |
| train-EnvExecTime       | 2.17          |
| train-MaxReturn         | 37.6          |
| train-MinReturn         | 30.8          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.54          |
| train-StdReturn         | 1.58          |
-------------------------------------------

 ---------------- Iteration 187 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 187           |
| ItrTime                 | 6.23          |
| LossAfter               | 0.0043196706  |
| LossBefore              | -7.680225e-07 |
| Time                    | 1.24e+03      |
| Time-Optimization       | 0.211         |
| Time-SampleProc         | 0.0419        |
| Time-Sampling           | 5.97          |
| n_timesteps             | 1880000       |
| train-AverageDiscoun... | 26.7          |
| train-AverageReturn     | 34.3          |
| train-EnvExecTime       | 2.17          |
| train-MaxReturn         | 37.7          |
| train-MinReturn         | 31.2          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.61          |
| train-StdReturn         | 1.55          |
-------------------------------------------

 ---------------- Iteration 188 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 188            |
| ItrTime                 | 6.18           |
| LossAfter               | -0.0010273245  |
| LossBefore              | -7.7820334e-07 |
| Time                    | 1.24e+03       |
| Time-Optimization       | 0.236          |
| Time-SampleProc         | 0.041          |
| Time-Sampling           | 5.9            |
| n_timesteps             | 1890000        |
| train-AverageDiscoun... | 26.7           |
| train-AverageReturn     | 34.4           |
| train-EnvExecTime       | 2.16           |
| train-MaxReturn         | 37.6           |
| train-MinReturn         | 31.2           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.55           |
| train-StdReturn         | 1.53           |
--------------------------------------------

 ---------------- Iteration 189 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 189            |
| ItrTime                 | 6.37           |
| LossAfter               | 0.0006907982   |
| LossBefore              | -7.7529666e-07 |
| Time                    | 1.25e+03       |
| Time-Optimization       | 0.217          |
| Time-SampleProc         | 0.0497         |
| Time-Sampling           | 6.1            |
| n_timesteps             | 1900000        |
| train-AverageDiscoun... | 26.8           |
| train-AverageReturn     | 34.4           |
| train-EnvExecTime       | 2.2            |
| train-MaxReturn         | 37.2           |
| train-MinReturn         | 31             |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.7            |
| train-StdReturn         | 1.53           |
--------------------------------------------

 ---------------- Iteration 190 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 190            |
| ItrTime                 | 6.24           |
| LossAfter               | 0.0026420394   |
| LossBefore              | -7.7072696e-07 |
| Time                    | 1.26e+03       |
| Time-Optimization       | 0.215          |
| Time-SampleProc         | 0.0406         |
| Time-Sampling           | 5.98           |
| n_timesteps             | 1910000        |
| train-AverageDiscoun... | 26.8           |
| train-AverageReturn     | 34.4           |
| train-EnvExecTime       | 2.18           |
| train-MaxReturn         | 37.7           |
| train-MinReturn         | 30.8           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.6            |
| train-StdReturn         | 1.43           |
--------------------------------------------

 ---------------- Iteration 191 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 191            |
| ItrTime                 | 6.33           |
| LossAfter               | 0.0028025403   |
| LossBefore              | -7.6031023e-07 |
| Time                    | 1.26e+03       |
| Time-Optimization       | 0.214          |
| Time-SampleProc         | 0.0518         |
| Time-Sampling           | 6.06           |
| n_timesteps             | 1920000        |
| train-AverageDiscoun... | 26.6           |
| train-AverageReturn     | 34.3           |
| train-EnvExecTime       | 2.23           |
| train-MaxReturn         | 38             |
| train-MinReturn         | 30.3           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.63           |
| train-StdReturn         | 1.5            |
--------------------------------------------

 ---------------- Iteration 192 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 192            |
| ItrTime                 | 7.22           |
| LossAfter               | -0.0015531937  |
| LossBefore              | -7.6343025e-07 |
| Time                    | 1.27e+03       |
| Time-Optimization       | 0.193          |
| Time-SampleProc         | 0.0758         |
| Time-Sampling           | 6.95           |
| n_timesteps             | 1930000        |
| train-AverageDiscoun... | 26.9           |
| train-AverageReturn     | 34.5           |
| train-EnvExecTime       | 2.56           |
| train-MaxReturn         | 38.7           |
| train-MinReturn         | 30.9           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.17           |
| train-StdReturn         | 1.59           |
--------------------------------------------

 ---------------- Iteration 193 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 193           |
| ItrTime                 | 6.7           |
| LossAfter               | 0.00020755253 |
| LossBefore              | -7.637362e-07 |
| Time                    | 1.28e+03      |
| Time-Optimization       | 0.207         |
| Time-SampleProc         | 0.0457        |
| Time-Sampling           | 6.44          |
| n_timesteps             | 1940000       |
| train-AverageDiscoun... | 26.9          |
| train-AverageReturn     | 34.5          |
| train-EnvExecTime       | 2.35          |
| train-MaxReturn         | 38.2          |
| train-MinReturn         | 31.2          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.88          |
| train-StdReturn         | 1.58          |
-------------------------------------------

 ---------------- Iteration 194 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 194           |
| ItrTime                 | 6.18          |
| LossAfter               | 0.0018535698  |
| LossBefore              | -7.524567e-07 |
| Time                    | 1.28e+03      |
| Time-Optimization       | 0.209         |
| Time-SampleProc         | 0.0417        |
| Time-Sampling           | 5.93          |
| n_timesteps             | 1950000       |
| train-AverageDiscoun... | 26.6          |
| train-AverageReturn     | 34.2          |
| train-EnvExecTime       | 2.15          |
| train-MaxReturn         | 38.2          |
| train-MinReturn         | 30.3          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.59          |
| train-StdReturn         | 1.52          |
-------------------------------------------

 ---------------- Iteration 195 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 195          |
| ItrTime                 | 5.97         |
| LossAfter               | 0.0070744627 |
| LossBefore              | -7.6713e-07  |
| Time                    | 1.29e+03     |
| Time-Optimization       | 0.213        |
| Time-SampleProc         | 0.0423       |
| Time-Sampling           | 5.71         |
| n_timesteps             | 1960000      |
| train-AverageDiscoun... | 26.9         |
| train-AverageReturn     | 34.5         |
| train-EnvExecTime       | 2.07         |
| train-MaxReturn         | 38.1         |
| train-MinReturn         | 31           |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 3.45         |
| train-StdReturn         | 1.62         |
------------------------------------------

 ---------------- Iteration 196 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 196           |
| ItrTime                 | 6.54          |
| LossAfter               | 0.00937448    |
| LossBefore              | -7.586971e-07 |
| Time                    | 1.3e+03       |
| Time-Optimization       | 0.222         |
| Time-SampleProc         | 0.0445        |
| Time-Sampling           | 6.27          |
| n_timesteps             | 1970000       |
| train-AverageDiscoun... | 26.9          |
| train-AverageReturn     | 34.5          |
| train-EnvExecTime       | 2.3           |
| train-MaxReturn         | 38.5          |
| train-MinReturn         | 31.6          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.76          |
| train-StdReturn         | 1.4           |
-------------------------------------------

 ---------------- Iteration 197 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 197            |
| ItrTime                 | 10             |
| LossAfter               | -0.00049912254 |
| LossBefore              | -7.7319993e-07 |
| Time                    | 1.31e+03       |
| Time-Optimization       | 0.22           |
| Time-SampleProc         | 0.0373         |
| Time-Sampling           | 9.74           |
| n_timesteps             | 1980000        |
| train-AverageDiscoun... | 26.6           |
| train-AverageReturn     | 34.2           |
| train-EnvExecTime       | 3.58           |
| train-MaxReturn         | 37.6           |
| train-MinReturn         | 30.5           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 5.86           |
| train-StdReturn         | 1.5            |
--------------------------------------------

 ---------------- Iteration 198 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 198           |
| ItrTime                 | 5.86          |
| LossAfter               | 0.0010248903  |
| LossBefore              | -7.466482e-07 |
| Time                    | 1.31e+03      |
| Time-Optimization       | 0.205         |
| Time-SampleProc         | 0.0806        |
| Time-Sampling           | 5.57          |
| n_timesteps             | 1990000       |
| train-AverageDiscoun... | 26.7          |
| train-AverageReturn     | 34.3          |
| train-EnvExecTime       | 2             |
| train-MaxReturn         | 38.1          |
| train-MinReturn         | 30.8          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.37          |
| train-StdReturn         | 1.56          |
-------------------------------------------

 ---------------- Iteration 199 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 199           |
| ItrTime                 | 5.97          |
| LossAfter               | 0.003985863   |
| LossBefore              | -7.568079e-07 |
| Time                    | 1.32e+03      |
| Time-Optimization       | 0.215         |
| Time-SampleProc         | 0.0386        |
| Time-Sampling           | 5.72          |
| n_timesteps             | 2000000       |
| train-AverageDiscoun... | 26.9          |
| train-AverageReturn     | 34.6          |
| train-EnvExecTime       | 2.07          |
| train-MaxReturn         | 38.4          |
| train-MinReturn         | 31.2          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.46          |
| train-StdReturn         | 1.45          |
-------------------------------------------

 ---------------- Iteration 200 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 200            |
| ItrTime                 | 5.82           |
| LossAfter               | -0.00090862525 |
| LossBefore              | -7.485033e-07  |
| Time                    | 1.32e+03       |
| Time-Optimization       | 0.211          |
| Time-SampleProc         | 0.0384         |
| Time-Sampling           | 5.57           |
| n_timesteps             | 2010000        |
| train-AverageDiscoun... | 26.5           |
| train-AverageReturn     | 34.2           |
| train-EnvExecTime       | 2.01           |
| train-MaxReturn         | 38.4           |
| train-MinReturn         | 30.6           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.37           |
| train-StdReturn         | 1.64           |
--------------------------------------------

 ---------------- Iteration 201 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 201            |
| ItrTime                 | 5.86           |
| LossAfter               | -0.0006391224  |
| LossBefore              | -7.4410246e-07 |
| Time                    | 1.33e+03       |
| Time-Optimization       | 0.218          |
| Time-SampleProc         | 0.0566         |
| Time-Sampling           | 5.59           |
| n_timesteps             | 2020000        |
| train-AverageDiscoun... | 26.8           |
| train-AverageReturn     | 34.5           |
| train-EnvExecTime       | 2.03           |
| train-MaxReturn         | 37.8           |
| train-MinReturn         | 30.7           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.38           |
| train-StdReturn         | 1.52           |
--------------------------------------------

 ---------------- Iteration 202 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 202           |
| ItrTime                 | 6.81          |
| LossAfter               | -0.001672079  |
| LossBefore              | -7.369696e-07 |
| Time                    | 1.34e+03      |
| Time-Optimization       | 0.207         |
| Time-SampleProc         | 0.0909        |
| Time-Sampling           | 6.51          |
| n_timesteps             | 2030000       |
| train-AverageDiscoun... | 26.9          |
| train-AverageReturn     | 34.6          |
| train-EnvExecTime       | 2.38          |
| train-MaxReturn         | 37.5          |
| train-MinReturn         | 30.3          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.92          |
| train-StdReturn         | 1.48          |
-------------------------------------------

 ---------------- Iteration 203 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 203            |
| ItrTime                 | 8.45           |
| LossAfter               | -0.0010190291  |
| LossBefore              | -7.4912316e-07 |
| Time                    | 1.34e+03       |
| Time-Optimization       | 0.266          |
| Time-SampleProc         | 0.0492         |
| Time-Sampling           | 8.14           |
| n_timesteps             | 2040000        |
| train-AverageDiscoun... | 26.8           |
| train-AverageReturn     | 34.4           |
| train-EnvExecTime       | 2.95           |
| train-MaxReturn         | 37.8           |
| train-MinReturn         | 31.3           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.92           |
| train-StdReturn         | 1.47           |
--------------------------------------------

 ---------------- Iteration 204 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 204           |
| ItrTime                 | 9.78          |
| LossAfter               | -0.0011240981 |
| LossBefore              | -7.388118e-07 |
| Time                    | 1.35e+03      |
| Time-Optimization       | 0.202         |
| Time-SampleProc         | 0.0782        |
| Time-Sampling           | 9.5           |
| n_timesteps             | 2050000       |
| train-AverageDiscoun... | 26.9          |
| train-AverageReturn     | 34.5          |
| train-EnvExecTime       | 3.49          |
| train-MaxReturn         | 38.6          |
| train-MinReturn         | 31.3          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 5.7           |
| train-StdReturn         | 1.49          |
-------------------------------------------

 ---------------- Iteration 205 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 205            |
| ItrTime                 | 5.67           |
| LossAfter               | -0.0007117054  |
| LossBefore              | -7.3269473e-07 |
| Time                    | 1.36e+03       |
| Time-Optimization       | 0.187          |
| Time-SampleProc         | 0.0711         |
| Time-Sampling           | 5.41           |
| n_timesteps             | 2060000        |
| train-AverageDiscoun... | 26.8           |
| train-AverageReturn     | 34.5           |
| train-EnvExecTime       | 1.96           |
| train-MaxReturn         | 37.6           |
| train-MinReturn         | 30.6           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.28           |
| train-StdReturn         | 1.6            |
--------------------------------------------

 ---------------- Iteration 206 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 206           |
| ItrTime                 | 5.81          |
| LossAfter               | 0.00012737911 |
| LossBefore              | -7.35865e-07  |
| Time                    | 1.37e+03      |
| Time-Optimization       | 0.201         |
| Time-SampleProc         | 0.0678        |
| Time-Sampling           | 5.54          |
| n_timesteps             | 2070000       |
| train-AverageDiscoun... | 26.8          |
| train-AverageReturn     | 34.5          |
| train-EnvExecTime       | 2.05          |
| train-MaxReturn         | 37.1          |
| train-MinReturn         | 31.2          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.31          |
| train-StdReturn         | 1.38          |
-------------------------------------------

 ---------------- Iteration 207 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 207            |
| ItrTime                 | 5.82           |
| LossAfter               | -0.002908147   |
| LossBefore              | -7.3292586e-07 |
| Time                    | 1.37e+03       |
| Time-Optimization       | 0.221          |
| Time-SampleProc         | 0.0386         |
| Time-Sampling           | 5.56           |
| n_timesteps             | 2080000        |
| train-AverageDiscoun... | 27.1           |
| train-AverageReturn     | 34.7           |
| train-EnvExecTime       | 2.02           |
| train-MaxReturn         | 38.5           |
| train-MinReturn         | 32             |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.35           |
| train-StdReturn         | 1.39           |
--------------------------------------------

 ---------------- Iteration 208 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 208           |
| ItrTime                 | 5.98          |
| LossAfter               | 0.00015185407 |
| LossBefore              | -7.362654e-07 |
| Time                    | 1.38e+03      |
| Time-Optimization       | 0.236         |
| Time-SampleProc         | 0.0488        |
| Time-Sampling           | 5.69          |
| n_timesteps             | 2090000       |
| train-AverageDiscoun... | 26.9          |
| train-AverageReturn     | 34.6          |
| train-EnvExecTime       | 2.09          |
| train-MaxReturn         | 37.5          |
| train-MinReturn         | 31.6          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.41          |
| train-StdReturn         | 1.49          |
-------------------------------------------

 ---------------- Iteration 209 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 209            |
| ItrTime                 | 7.07           |
| LossAfter               | -0.0006266646  |
| LossBefore              | -7.0521855e-07 |
| Time                    | 1.38e+03       |
| Time-Optimization       | 0.241          |
| Time-SampleProc         | 0.0449         |
| Time-Sampling           | 6.78           |
| n_timesteps             | 2100000        |
| train-AverageDiscoun... | 26.6           |
| train-AverageReturn     | 34.3           |
| train-EnvExecTime       | 2.46           |
| train-MaxReturn         | 37.1           |
| train-MinReturn         | 30.3           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.1            |
| train-StdReturn         | 1.41           |
--------------------------------------------

 ---------------- Iteration 210 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 210            |
| ItrTime                 | 7.9            |
| LossAfter               | -0.00018823272 |
| LossBefore              | -7.2063193e-07 |
| Time                    | 1.39e+03       |
| Time-Optimization       | 0.256          |
| Time-SampleProc         | 0.065          |
| Time-Sampling           | 7.58           |
| n_timesteps             | 2110000        |
| train-AverageDiscoun... | 26.9           |
| train-AverageReturn     | 34.6           |
| train-EnvExecTime       | 2.78           |
| train-MaxReturn         | 38.7           |
| train-MinReturn         | 31.2           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.55           |
| train-StdReturn         | 1.56           |
--------------------------------------------

 ---------------- Iteration 211 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 211            |
| ItrTime                 | 8.21           |
| LossAfter               | 0.005391748    |
| LossBefore              | -7.1068024e-07 |
| Time                    | 1.4e+03        |
| Time-Optimization       | 0.188          |
| Time-SampleProc         | 0.0759         |
| Time-Sampling           | 7.95           |
| n_timesteps             | 2120000        |
| train-AverageDiscoun... | 27             |
| train-AverageReturn     | 34.7           |
| train-EnvExecTime       | 2.88           |
| train-MaxReturn         | 38.9           |
| train-MinReturn         | 31.7           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.81           |
| train-StdReturn         | 1.29           |
--------------------------------------------

 ---------------- Iteration 212 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 212            |
| ItrTime                 | 5.66           |
| LossAfter               | 0.0073675746   |
| LossBefore              | -7.2750527e-07 |
| Time                    | 1.41e+03       |
| Time-Optimization       | 0.205          |
| Time-SampleProc         | 0.0393         |
| Time-Sampling           | 5.42           |
| n_timesteps             | 2130000        |
| train-AverageDiscoun... | 26.8           |
| train-AverageReturn     | 34.5           |
| train-EnvExecTime       | 1.98           |
| train-MaxReturn         | 37.9           |
| train-MinReturn         | 30.7           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.25           |
| train-StdReturn         | 1.36           |
--------------------------------------------

 ---------------- Iteration 213 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 213           |
| ItrTime                 | 5.77          |
| LossAfter               | 0.0037015867  |
| LossBefore              | -7.070662e-07 |
| Time                    | 1.41e+03      |
| Time-Optimization       | 0.219         |
| Time-SampleProc         | 0.045         |
| Time-Sampling           | 5.5           |
| n_timesteps             | 2140000       |
| train-AverageDiscoun... | 26.9          |
| train-AverageReturn     | 34.6          |
| train-EnvExecTime       | 1.98          |
| train-MaxReturn         | 38.4          |
| train-MinReturn         | 31.4          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.33          |
| train-StdReturn         | 1.46          |
-------------------------------------------

 ---------------- Iteration 214 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 214           |
| ItrTime                 | 5.97          |
| LossAfter               | 0.0013586961  |
| LossBefore              | -7.030246e-07 |
| Time                    | 1.42e+03      |
| Time-Optimization       | 0.21          |
| Time-SampleProc         | 0.0529        |
| Time-Sampling           | 5.71          |
| n_timesteps             | 2150000       |
| train-AverageDiscoun... | 26.9          |
| train-AverageReturn     | 34.6          |
| train-EnvExecTime       | 2.09          |
| train-MaxReturn         | 38.2          |
| train-MinReturn         | 30.8          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.42          |
| train-StdReturn         | 1.49          |
-------------------------------------------

 ---------------- Iteration 215 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 215            |
| ItrTime                 | 6.28           |
| LossAfter               | -0.00014702429 |
| LossBefore              | -7.203019e-07  |
| Time                    | 1.42e+03       |
| Time-Optimization       | 0.264          |
| Time-SampleProc         | 0.107          |
| Time-Sampling           | 5.91           |
| n_timesteps             | 2160000        |
| train-AverageDiscoun... | 26.8           |
| train-AverageReturn     | 34.5           |
| train-EnvExecTime       | 2.15           |
| train-MaxReturn         | 37.6           |
| train-MinReturn         | 31             |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.56           |
| train-StdReturn         | 1.55           |
--------------------------------------------

 ---------------- Iteration 216 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 216            |
| ItrTime                 | 8.23           |
| LossAfter               | 7.620556e-05   |
| LossBefore              | -6.9479063e-07 |
| Time                    | 1.43e+03       |
| Time-Optimization       | 0.209          |
| Time-SampleProc         | 0.0431         |
| Time-Sampling           | 7.98           |
| n_timesteps             | 2170000        |
| train-AverageDiscoun... | 27             |
| train-AverageReturn     | 34.7           |
| train-EnvExecTime       | 2.92           |
| train-MaxReturn         | 38.3           |
| train-MinReturn         | 31.5           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 4.8            |
| train-StdReturn         | 1.47           |
--------------------------------------------

 ---------------- Iteration 217 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 217            |
| ItrTime                 | 5.85           |
| LossAfter               | -0.0022370727  |
| LossBefore              | -6.9988835e-07 |
| Time                    | 1.44e+03       |
| Time-Optimization       | 0.208          |
| Time-SampleProc         | 0.0364         |
| Time-Sampling           | 5.61           |
| n_timesteps             | 2180000        |
| train-AverageDiscoun... | 26.7           |
| train-AverageReturn     | 34.4           |
| train-EnvExecTime       | 2.03           |
| train-MaxReturn         | 38.2           |
| train-MinReturn         | 30.7           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.39           |
| train-StdReturn         | 1.48           |
--------------------------------------------

 ---------------- Iteration 218 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 218            |
| ItrTime                 | 5.95           |
| LossAfter               | -0.0014782336  |
| LossBefore              | -6.8932724e-07 |
| Time                    | 1.44e+03       |
| Time-Optimization       | 0.228          |
| Time-SampleProc         | 0.0447         |
| Time-Sampling           | 5.67           |
| n_timesteps             | 2190000        |
| train-AverageDiscoun... | 27.2           |
| train-AverageReturn     | 35             |
| train-EnvExecTime       | 2.04           |
| train-MaxReturn         | 37.8           |
| train-MinReturn         | 30.9           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.44           |
| train-StdReturn         | 1.49           |
--------------------------------------------

 ---------------- Iteration 219 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 219            |
| ItrTime                 | 5.94           |
| LossAfter               | -0.00060840964 |
| LossBefore              | -6.882126e-07  |
| Time                    | 1.45e+03       |
| Time-Optimization       | 0.221          |
| Time-SampleProc         | 0.0361         |
| Time-Sampling           | 5.69           |
| n_timesteps             | 2200000        |
| train-AverageDiscoun... | 27.1           |
| train-AverageReturn     | 34.9           |
| train-EnvExecTime       | 2.05           |
| train-MaxReturn         | 38             |
| train-MinReturn         | 30.8           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.44           |
| train-StdReturn         | 1.44           |
--------------------------------------------

 ---------------- Iteration 220 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 220            |
| ItrTime                 | 5.83           |
| LossAfter               | -0.0029094357  |
| LossBefore              | -6.8600724e-07 |
| Time                    | 1.46e+03       |
| Time-Optimization       | 0.211          |
| Time-SampleProc         | 0.0587         |
| Time-Sampling           | 5.56           |
| n_timesteps             | 2210000        |
| train-AverageDiscoun... | 27             |
| train-AverageReturn     | 34.7           |
| train-EnvExecTime       | 2.03           |
| train-MaxReturn         | 38.6           |
| train-MinReturn         | 31.3           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.34           |
| train-StdReturn         | 1.48           |
--------------------------------------------

 ---------------- Iteration 221 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 221            |
| ItrTime                 | 6.23           |
| LossAfter               | 0.0074658133   |
| LossBefore              | -6.9734966e-07 |
| Time                    | 1.46e+03       |
| Time-Optimization       | 0.221          |
| Time-SampleProc         | 0.0851         |
| Time-Sampling           | 5.92           |
| n_timesteps             | 2220000        |
| train-AverageDiscoun... | 27.1           |
| train-AverageReturn     | 34.9           |
| train-EnvExecTime       | 2.18           |
| train-MaxReturn         | 38.4           |
| train-MinReturn         | 31.1           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 3.54           |
| train-StdReturn         | 1.55           |
--------------------------------------------

 ---------------- Iteration 222 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 222           |
| ItrTime                 | 7.02          |
| LossAfter               | 0.0014326042  |
| LossBefore              | -6.862341e-07 |
| Time                    | 1.47e+03      |
| Time-Optimization       | 0.224         |
| Time-SampleProc         | 0.0892        |
| Time-Sampling           | 6.71          |
| n_timesteps             | 2230000       |
| train-AverageDiscoun... | 27.4          |
| train-AverageReturn     | 35.1          |
| train-EnvExecTime       | 2.48          |
| train-MaxReturn         | 38.6          |
| train-MinReturn         | 32.3          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 4.01          |
| train-StdReturn         | 1.47          |
-------------------------------------------

 ---------------- Iteration 223 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
