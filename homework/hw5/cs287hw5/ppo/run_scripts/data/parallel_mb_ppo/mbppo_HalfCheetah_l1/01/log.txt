Logging to /home/vincent/workplace/CS_287_-_Advanced_Robotics/homework/hw5/cs287hw5/ppo/run_scripts/data/parallel_mb_ppo/mbppo_HalfCheetah_l1//01

 ---------------- Iteration 0 ----------------
Obtaining random samples from the environment...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 0 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 1 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 2 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 3 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 4 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 5 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 6 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 7 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 8 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 9 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.117          |
| Data-EnvSampler-Poli... | 0.0359         |
| Data-EnvTrajs-Averag... | -48.1          |
| Data-EnvTrajs-MaxReturn | -15.6          |
| Data-EnvTrajs-MinReturn | -98.1          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 27.1           |
| Data-TimeEnvSampleProc  | 0.000469       |
| Data-TimeEnvSampling    | 0.162          |
| Iteration               | 0              |
| ItrTime                 | 7.49           |
| LossAfter               | -0.015855905   |
| LossBefore              | -1.4199104e-05 |
| Model-TimeModelFit      | 2.53           |
| ModelSampler-n_times... | 40000          |
| Policy-AverageAbsPol... | 0.9828688      |
| Policy-AverageDiscou... | 3.86e+03       |
| Policy-AveragePolicyStd | 1.0011048      |
| Policy-AverageReturn    | 1.11e+04       |
| Policy-MaxReturn        | 1.13e+04       |
| Policy-MinReturn        | 1.08e+04       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 138            |
| Policy-TimeAlgoOpt      | 0.835          |
| Policy-TimeSampleProc   | 0.388          |
| Policy-TimeSampling     | 3.55           |
| Policy-TimeStep         | 4.79           |
| Time                    | 7.49           |
| n_timesteps             | 1000           |
--------------------------------------------

 ---------------- Iteration 1 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 10 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 11 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 12 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 13 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 14 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 15 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 16 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 17 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 18 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 19 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.249         |
| Data-EnvSampler-Poli... | 0.7           |
| Data-EnvTrajs-Averag... | -83.9         |
| Data-EnvTrajs-MaxReturn | -26.7         |
| Data-EnvTrajs-MinReturn | -146          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 46.7          |
| Data-TimeEnvSampleProc  | 0.000551      |
| Data-TimeEnvSampling    | 0.971         |
| Iteration               | 1             |
| ItrTime                 | 6.93          |
| LossAfter               | -0.015370989  |
| LossBefore              | -1.406359e-05 |
| Model-TimeModelFit      | 3.53          |
| ModelSampler-n_times... | 80000         |
| Policy-AverageAbsPol... | 0.6758881     |
| Policy-AverageDiscou... | -89.8         |
| Policy-AveragePolicyStd | 0.98873925    |
| Policy-AverageReturn    | -211          |
| Policy-MaxReturn        | -165          |
| Policy-MinReturn        | -267          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 26.3          |
| Policy-TimeAlgoOpt      | 0.554         |
| Policy-TimeSampleProc   | 0.324         |
| Policy-TimeSampling     | 1.52          |
| Policy-TimeStep         | 2.42          |
| Time                    | 14.6          |
| n_timesteps             | 2000          |
-------------------------------------------

 ---------------- Iteration 2 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 20 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 21 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 22 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 23 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 24 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 25 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 26 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 27 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 28 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 29 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.276         |
| Data-EnvSampler-Poli... | 0.7           |
| Data-EnvTrajs-Averag... | -41.8         |
| Data-EnvTrajs-MaxReturn | 7.07          |
| Data-EnvTrajs-MinReturn | -89.8         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 32            |
| Data-TimeEnvSampleProc  | 0.000586      |
| Data-TimeEnvSampling    | 1             |
| Iteration               | 2             |
| ItrTime                 | 9.14          |
| LossAfter               | -0.013175311  |
| LossBefore              | -1.356103e-05 |
| Model-TimeModelFit      | 5.82          |
| ModelSampler-n_times... | 120000        |
| Policy-AverageAbsPol... | 0.5484819     |
| Policy-AverageDiscou... | -44.7         |
| Policy-AveragePolicyStd | 0.9403386     |
| Policy-AverageReturn    | -97.8         |
| Policy-MaxReturn        | -55.2         |
| Policy-MinReturn        | -133          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 18.8          |
| Policy-TimeAlgoOpt      | 0.519         |
| Policy-TimeSampleProc   | 0.368         |
| Policy-TimeSampling     | 1.38          |
| Policy-TimeStep         | 2.31          |
| Time                    | 23.7          |
| n_timesteps             | 3000          |
-------------------------------------------

 ---------------- Iteration 3 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 30 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 31 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 32 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 33 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 34 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 35 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 36 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 37 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 38 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 39 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.332         |
| Data-EnvSampler-Poli... | 0.797         |
| Data-EnvTrajs-Averag... | -65.5         |
| Data-EnvTrajs-MaxReturn | -7.37         |
| Data-EnvTrajs-MinReturn | -186          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 62.4          |
| Data-TimeEnvSampleProc  | 0.000537      |
| Data-TimeEnvSampling    | 1.16          |
| Iteration               | 3             |
| ItrTime                 | 11.5          |
| LossAfter               | -0.018123608  |
| LossBefore              | -1.304282e-05 |
| Model-TimeModelFit      | 7.62          |
| ModelSampler-n_times... | 160000        |
| Policy-AverageAbsPol... | 0.67702234    |
| Policy-AverageDiscou... | 13.4          |
| Policy-AveragePolicyStd | 0.8929938     |
| Policy-AverageReturn    | 95            |
| Policy-MaxReturn        | 148           |
| Policy-MinReturn        | 34            |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 22.5          |
| Policy-TimeAlgoOpt      | 0.599         |
| Policy-TimeSampleProc   | 0.462         |
| Policy-TimeSampling     | 1.62          |
| Policy-TimeStep         | 2.73          |
| Time                    | 35.2          |
| n_timesteps             | 4000          |
-------------------------------------------

 ---------------- Iteration 4 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 40 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 41 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 42 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 43 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 44 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 45 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 46 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 47 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 48 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 49 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.357          |
| Data-EnvSampler-Poli... | 0.75           |
| Data-EnvTrajs-Averag... | -89.3          |
| Data-EnvTrajs-MaxReturn | -47.2          |
| Data-EnvTrajs-MinReturn | -120           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 32.3           |
| Data-TimeEnvSampleProc  | 0.000547       |
| Data-TimeEnvSampling    | 1.14           |
| Iteration               | 4              |
| ItrTime                 | 13.1           |
| LossAfter               | -0.013846753   |
| LossBefore              | -1.2796822e-05 |
| Model-TimeModelFit      | 9.53           |
| ModelSampler-n_times... | 200000         |
| Policy-AverageAbsPol... | 0.5122837      |
| Policy-AverageDiscou... | -5.31          |
| Policy-AveragePolicyStd | 0.8695937      |
| Policy-AverageReturn    | -4.77          |
| Policy-MaxReturn        | 23.2           |
| Policy-MinReturn        | -52.2          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 22.5           |
| Policy-TimeAlgoOpt      | 0.569          |
| Policy-TimeSampleProc   | 0.376          |
| Policy-TimeSampling     | 1.41           |
| Policy-TimeStep         | 2.39           |
| Time                    | 48.3           |
| n_timesteps             | 5000           |
--------------------------------------------

 ---------------- Iteration 5 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 50 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 51 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 52 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 53 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 54 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 55 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 56 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 57 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 58 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 59 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.398          |
| Data-EnvSampler-Poli... | 0.94           |
| Data-EnvTrajs-Averag... | -57.2          |
| Data-EnvTrajs-MaxReturn | -24.9          |
| Data-EnvTrajs-MinReturn | -80            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 24.1           |
| Data-TimeEnvSampleProc  | 0.000684       |
| Data-TimeEnvSampling    | 1.38           |
| Iteration               | 5              |
| ItrTime                 | 16.1           |
| LossAfter               | -0.011958898   |
| LossBefore              | -1.2606399e-05 |
| Model-TimeModelFit      | 12.2           |
| ModelSampler-n_times... | 240000         |
| Policy-AverageAbsPol... | 0.4592574      |
| Policy-AverageDiscou... | -64.4          |
| Policy-AveragePolicyStd | 0.8539761      |
| Policy-AverageReturn    | -152           |
| Policy-MaxReturn        | -77.6          |
| Policy-MinReturn        | -205           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 31.5           |
| Policy-TimeAlgoOpt      | 0.536          |
| Policy-TimeSampleProc   | 0.552          |
| Policy-TimeSampling     | 1.44           |
| Policy-TimeStep         | 2.56           |
| Time                    | 64.5           |
| n_timesteps             | 6000           |
--------------------------------------------

 ---------------- Iteration 6 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 60 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 61 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 62 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 63 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 64 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 65 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 66 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 67 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 68 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 69 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.313          |
| Data-EnvSampler-Poli... | 0.785          |
| Data-EnvTrajs-Averag... | -42.9          |
| Data-EnvTrajs-MaxReturn | -22.2          |
| Data-EnvTrajs-MinReturn | -87.5          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 22.9           |
| Data-TimeEnvSampleProc  | 0.000872       |
| Data-TimeEnvSampling    | 1.13           |
| Iteration               | 6              |
| ItrTime                 | 17.9           |
| LossAfter               | -0.014367704   |
| LossBefore              | -1.2439409e-05 |
| Model-TimeModelFit      | 13.9           |
| ModelSampler-n_times... | 280000         |
| Policy-AverageAbsPol... | 0.53238386     |
| Policy-AverageDiscou... | -72.5          |
| Policy-AveragePolicyStd | 0.83848405     |
| Policy-AverageReturn    | -223           |
| Policy-MaxReturn        | -120           |
| Policy-MinReturn        | -373           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 63.4           |
| Policy-TimeAlgoOpt      | 0.67           |
| Policy-TimeSampleProc   | 0.446          |
| Policy-TimeSampling     | 1.63           |
| Policy-TimeStep         | 2.81           |
| Time                    | 82.3           |
| n_timesteps             | 7000           |
--------------------------------------------

 ---------------- Iteration 7 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 70 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 71 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 72 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 73 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 74 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 75 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 76 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 77 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 78 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 79 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.412         |
| Data-EnvSampler-Poli... | 0.892         |
| Data-EnvTrajs-Averag... | -12.6         |
| Data-EnvTrajs-MaxReturn | 42.7          |
| Data-EnvTrajs-MinReturn | -90.6         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 44            |
| Data-TimeEnvSampleProc  | 0.000781      |
| Data-TimeEnvSampling    | 1.34          |
| Iteration               | 7             |
| ItrTime                 | 20.4          |
| LossAfter               | -0.016502699  |
| LossBefore              | -1.220594e-05 |
| Model-TimeModelFit      | 16.4          |
| ModelSampler-n_times... | 320000        |
| Policy-AverageAbsPol... | 0.48484376    |
| Policy-AverageDiscou... | 13.2          |
| Policy-AveragePolicyStd | 0.81921047    |
| Policy-AverageReturn    | 32.4          |
| Policy-MaxReturn        | 197           |
| Policy-MinReturn        | -58.8         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 58.2          |
| Policy-TimeAlgoOpt      | 0.598         |
| Policy-TimeSampleProc   | 0.348         |
| Policy-TimeSampling     | 1.55          |
| Policy-TimeStep         | 2.6           |
| Time                    | 103           |
| n_timesteps             | 8000          |
-------------------------------------------

 ---------------- Iteration 8 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 80 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 81 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 82 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 83 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 84 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 85 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 86 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 87 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 88 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 89 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.405          |
| Data-EnvSampler-Poli... | 0.854          |
| Data-EnvTrajs-Averag... | -53.4          |
| Data-EnvTrajs-MaxReturn | -7.6           |
| Data-EnvTrajs-MinReturn | -98            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 34.6           |
| Data-TimeEnvSampleProc  | 0.00127        |
| Data-TimeEnvSampling    | 1.3            |
| Iteration               | 8              |
| ItrTime                 | 23.1           |
| LossAfter               | -0.014384674   |
| LossBefore              | -1.1989728e-05 |
| Model-TimeModelFit      | 19.4           |
| ModelSampler-n_times... | 360000         |
| Policy-AverageAbsPol... | 0.4719567      |
| Policy-AverageDiscou... | -43.2          |
| Policy-AveragePolicyStd | 0.8031966      |
| Policy-AverageReturn    | -84.8          |
| Policy-MaxReturn        | -9.42          |
| Policy-MinReturn        | -164           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 40.8           |
| Policy-TimeAlgoOpt      | 0.594          |
| Policy-TimeSampleProc   | 0.351          |
| Policy-TimeSampling     | 1.43           |
| Policy-TimeStep         | 2.4            |
| Time                    | 126            |
| n_timesteps             | 9000           |
--------------------------------------------

 ---------------- Iteration 9 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 90 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 91 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 92 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 93 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 94 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 95 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 96 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 97 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 98 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 99 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.354          |
| Data-EnvSampler-Poli... | 0.858          |
| Data-EnvTrajs-Averag... | -64.9          |
| Data-EnvTrajs-MaxReturn | -15.7          |
| Data-EnvTrajs-MinReturn | -122           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 37.7           |
| Data-TimeEnvSampleProc  | 0.00127        |
| Data-TimeEnvSampling    | 1.25           |
| Iteration               | 9              |
| ItrTime                 | 24.5           |
| LossAfter               | -0.012972595   |
| LossBefore              | -1.1869911e-05 |
| Model-TimeModelFit      | 20.8           |
| ModelSampler-n_times... | 400000         |
| Policy-AverageAbsPol... | 0.5149147      |
| Policy-AverageDiscou... | -28.9          |
| Policy-AveragePolicyStd | 0.7919969      |
| Policy-AverageReturn    | -62.1          |
| Policy-MaxReturn        | 40.7           |
| Policy-MinReturn        | -147           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 43.2           |
| Policy-TimeAlgoOpt      | 0.598          |
| Policy-TimeSampleProc   | 0.341          |
| Policy-TimeSampling     | 1.44           |
| Policy-TimeStep         | 2.43           |
| Time                    | 150            |
| n_timesteps             | 10000          |
--------------------------------------------

 ---------------- Iteration 10 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 100 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 101 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 102 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 103 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 104 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 105 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 106 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 107 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 108 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 109 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.374          |
| Data-EnvSampler-Poli... | 0.865          |
| Data-EnvTrajs-Averag... | -21.2          |
| Data-EnvTrajs-MaxReturn | 44.1           |
| Data-EnvTrajs-MinReturn | -81.6          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 40.5           |
| Data-TimeEnvSampleProc  | 0.00121        |
| Data-TimeEnvSampling    | 1.27           |
| Iteration               | 10             |
| ItrTime                 | 27.7           |
| LossAfter               | -0.014598434   |
| LossBefore              | -1.1630745e-05 |
| Model-TimeModelFit      | 23.7           |
| ModelSampler-n_times... | 440000         |
| Policy-AverageAbsPol... | 0.59848684     |
| Policy-AverageDiscou... | -6.25          |
| Policy-AveragePolicyStd | 0.7744733      |
| Policy-AverageReturn    | 4.46           |
| Policy-MaxReturn        | 164            |
| Policy-MinReturn        | -103           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 65.7           |
| Policy-TimeAlgoOpt      | 0.656          |
| Policy-TimeSampleProc   | 0.379          |
| Policy-TimeSampling     | 1.61           |
| Policy-TimeStep         | 2.69           |
| Time                    | 178            |
| n_timesteps             | 11000          |
--------------------------------------------

 ---------------- Iteration 11 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 110 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 111 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 112 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 113 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 114 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 115 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 116 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 117 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 118 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 119 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.367          |
| Data-EnvSampler-Poli... | 0.875          |
| Data-EnvTrajs-Averag... | 0.32           |
| Data-EnvTrajs-MaxReturn | 104            |
| Data-EnvTrajs-MinReturn | -85.7          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 71             |
| Data-TimeEnvSampleProc  | 0.000574       |
| Data-TimeEnvSampling    | 1.29           |
| Iteration               | 11             |
| ItrTime                 | 30.9           |
| LossAfter               | -0.017673815   |
| LossBefore              | -1.1384281e-05 |
| Model-TimeModelFit      | 26.6           |
| ModelSampler-n_times... | 480000         |
| Policy-AverageAbsPol... | 0.57298446     |
| Policy-AverageDiscou... | -13.5          |
| Policy-AveragePolicyStd | 0.7563         |
| Policy-AverageReturn    | -20.2          |
| Policy-MaxReturn        | 30.1           |
| Policy-MinReturn        | -66.1          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 26.8           |
| Policy-TimeAlgoOpt      | 0.612          |
| Policy-TimeSampleProc   | 0.529          |
| Policy-TimeSampling     | 1.76           |
| Policy-TimeStep         | 2.93           |
| Time                    | 209            |
| n_timesteps             | 12000          |
--------------------------------------------

 ---------------- Iteration 12 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 120 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 121 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 122 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 123 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 124 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 125 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 126 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 127 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 128 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 129 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.343          |
| Data-EnvSampler-Poli... | 0.817          |
| Data-EnvTrajs-Averag... | -39.8          |
| Data-EnvTrajs-MaxReturn | 29.1           |
| Data-EnvTrajs-MinReturn | -106           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 43.8           |
| Data-TimeEnvSampleProc  | 0.000967       |
| Data-TimeEnvSampling    | 1.2            |
| Iteration               | 12             |
| ItrTime                 | 32.3           |
| LossAfter               | -0.0174099     |
| LossBefore              | -1.1233861e-05 |
| Model-TimeModelFit      | 28.5           |
| ModelSampler-n_times... | 520000         |
| Policy-AverageAbsPol... | 0.5873582      |
| Policy-AverageDiscou... | -32.3          |
| Policy-AveragePolicyStd | 0.74403876     |
| Policy-AverageReturn    | -78.7          |
| Policy-MaxReturn        | 57.7           |
| Policy-MinReturn        | -227           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 71.4           |
| Policy-TimeAlgoOpt      | 0.591          |
| Policy-TimeSampleProc   | 0.428          |
| Policy-TimeSampling     | 1.54           |
| Policy-TimeStep         | 2.62           |
| Time                    | 241            |
| n_timesteps             | 13000          |
--------------------------------------------

 ---------------- Iteration 13 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 130 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 131 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 132 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 133 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 134 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 135 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 136 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 137 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 138 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 139 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.346          |
| Data-EnvSampler-Poli... | 0.854          |
| Data-EnvTrajs-Averag... | -0.155         |
| Data-EnvTrajs-MaxReturn | 54.6           |
| Data-EnvTrajs-MinReturn | -45.4          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 35.4           |
| Data-TimeEnvSampleProc  | 0.00121        |
| Data-TimeEnvSampling    | 1.23           |
| Iteration               | 13             |
| ItrTime                 | 33.2           |
| LossAfter               | -0.016250553   |
| LossBefore              | -1.0964788e-05 |
| Model-TimeModelFit      | 29.4           |
| ModelSampler-n_times... | 560000         |
| Policy-AverageAbsPol... | 0.5832878      |
| Policy-AverageDiscou... | 7.42           |
| Policy-AveragePolicyStd | 0.7252212      |
| Policy-AverageReturn    | 11.4           |
| Policy-MaxReturn        | 61.1           |
| Policy-MinReturn        | -17.2          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 22.6           |
| Policy-TimeAlgoOpt      | 0.612          |
| Policy-TimeSampleProc   | 0.428          |
| Policy-TimeSampling     | 1.48           |
| Policy-TimeStep         | 2.56           |
| Time                    | 275            |
| n_timesteps             | 14000          |
--------------------------------------------

 ---------------- Iteration 14 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 140 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 141 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 142 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 143 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 144 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 145 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 146 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 147 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 148 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 149 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.372          |
| Data-EnvSampler-Poli... | 0.898          |
| Data-EnvTrajs-Averag... | -24.4          |
| Data-EnvTrajs-MaxReturn | 3.31           |
| Data-EnvTrajs-MinReturn | -44.7          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 16.7           |
| Data-TimeEnvSampleProc  | 0.000613       |
| Data-TimeEnvSampling    | 1.31           |
| Iteration               | 14             |
| ItrTime                 | 32.3           |
| LossAfter               | -0.018867435   |
| LossBefore              | -1.0851556e-05 |
| Model-TimeModelFit      | 28.4           |
| ModelSampler-n_times... | 600000         |
| Policy-AverageAbsPol... | 0.6069435      |
| Policy-AverageDiscou... | -3.26          |
| Policy-AveragePolicyStd | 0.7173592      |
| Policy-AverageReturn    | 83             |
| Policy-MaxReturn        | 768            |
| Policy-MinReturn        | -189           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 260            |
| Policy-TimeAlgoOpt      | 0.629          |
| Policy-TimeSampleProc   | 0.434          |
| Policy-TimeSampling     | 1.52           |
| Policy-TimeStep         | 2.65           |
| Time                    | 307            |
| n_timesteps             | 15000          |
--------------------------------------------

 ---------------- Iteration 15 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 150 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 151 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 152 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 153 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 154 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 155 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 156 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 157 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 158 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 159 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.357          |
| Data-EnvSampler-Poli... | 0.883          |
| Data-EnvTrajs-Averag... | 16.9           |
| Data-EnvTrajs-MaxReturn | 87.4           |
| Data-EnvTrajs-MinReturn | -11.5          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 35.8           |
| Data-TimeEnvSampleProc  | 0.000902       |
| Data-TimeEnvSampling    | 1.27           |
| Iteration               | 15             |
| ItrTime                 | 33.4           |
| LossAfter               | -0.016554138   |
| LossBefore              | -1.0674233e-05 |
| Model-TimeModelFit      | 29.5           |
| ModelSampler-n_times... | 640000         |
| Policy-AverageAbsPol... | 0.6256765      |
| Policy-AverageDiscou... | -21.2          |
| Policy-AveragePolicyStd | 0.7051592      |
| Policy-AverageReturn    | -41.8          |
| Policy-MaxReturn        | 43.1           |
| Policy-MinReturn        | -117           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 49.5           |
| Policy-TimeAlgoOpt      | 0.661          |
| Policy-TimeSampleProc   | 0.342          |
| Policy-TimeSampling     | 1.65           |
| Policy-TimeStep         | 2.68           |
| Time                    | 340            |
| n_timesteps             | 16000          |
--------------------------------------------

 ---------------- Iteration 16 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 160 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 161 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 162 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 163 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 164 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 165 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 166 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 167 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 168 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 169 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.392          |
| Data-EnvSampler-Poli... | 0.981          |
| Data-EnvTrajs-Averag... | 3.92           |
| Data-EnvTrajs-MaxReturn | 44.2           |
| Data-EnvTrajs-MinReturn | -37.2          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 30.9           |
| Data-TimeEnvSampleProc  | 0.00105        |
| Data-TimeEnvSampling    | 1.41           |
| Iteration               | 16             |
| ItrTime                 | 34             |
| LossAfter               | -0.020103304   |
| LossBefore              | -1.0611783e-05 |
| Model-TimeModelFit      | 29.3           |
| ModelSampler-n_times... | 680000         |
| Policy-AverageAbsPol... | 0.65250254     |
| Policy-AverageDiscou... | 670            |
| Policy-AveragePolicyStd | 0.69749707     |
| Policy-AverageReturn    | 2.84e+03       |
| Policy-MaxReturn        | 7.28e+03       |
| Policy-MinReturn        | 773            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.63e+03       |
| Policy-TimeAlgoOpt      | 0.691          |
| Policy-TimeSampleProc   | 0.629          |
| Policy-TimeSampling     | 1.92           |
| Policy-TimeStep         | 3.29           |
| Time                    | 374            |
| n_timesteps             | 17000          |
--------------------------------------------

 ---------------- Iteration 17 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 170 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 171 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 172 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 173 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 174 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 175 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 176 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 177 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 178 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 179 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.397          |
| Data-EnvSampler-Poli... | 0.959          |
| Data-EnvTrajs-Averag... | 78.2           |
| Data-EnvTrajs-MaxReturn | 175            |
| Data-EnvTrajs-MinReturn | -27.6          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 66.6           |
| Data-TimeEnvSampleProc  | 0.00103        |
| Data-TimeEnvSampling    | 1.39           |
| Iteration               | 17             |
| ItrTime                 | 34.2           |
| LossAfter               | -0.018082028   |
| LossBefore              | -1.0375968e-05 |
| Model-TimeModelFit      | 29.8           |
| ModelSampler-n_times... | 720000         |
| Policy-AverageAbsPol... | 0.83414584     |
| Policy-AverageDiscou... | 139            |
| Policy-AveragePolicyStd | 0.68318653     |
| Policy-AverageReturn    | 373            |
| Policy-MaxReturn        | 517            |
| Policy-MinReturn        | 284            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 59.6           |
| Policy-TimeAlgoOpt      | 0.694          |
| Policy-TimeSampleProc   | 0.419          |
| Policy-TimeSampling     | 1.77           |
| Policy-TimeStep         | 2.93           |
| Time                    | 409            |
| n_timesteps             | 18000          |
--------------------------------------------

 ---------------- Iteration 18 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 180 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 181 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 182 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 183 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 184 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 185 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 186 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 187 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 188 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 189 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.438          |
| Data-EnvSampler-Poli... | 1.02           |
| Data-EnvTrajs-Averag... | 69             |
| Data-EnvTrajs-MaxReturn | 128            |
| Data-EnvTrajs-MinReturn | 17.8           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 38.8           |
| Data-TimeEnvSampleProc  | 0.00118        |
| Data-TimeEnvSampling    | 1.5            |
| Iteration               | 18             |
| ItrTime                 | 34.8           |
| LossAfter               | -0.017963557   |
| LossBefore              | -1.0153494e-05 |
| Model-TimeModelFit      | 30.4           |
| ModelSampler-n_times... | 760000         |
| Policy-AverageAbsPol... | 0.86107767     |
| Policy-AverageDiscou... | 29.7           |
| Policy-AveragePolicyStd | 0.669274       |
| Policy-AverageReturn    | 94.1           |
| Policy-MaxReturn        | 168            |
| Policy-MinReturn        | -16.2          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 46.9           |
| Policy-TimeAlgoOpt      | 0.65           |
| Policy-TimeSampleProc   | 0.432          |
| Policy-TimeSampling     | 1.82           |
| Policy-TimeStep         | 2.95           |
| Time                    | 443            |
| n_timesteps             | 19000          |
--------------------------------------------

 ---------------- Iteration 19 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 190 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 191 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 192 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 193 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 194 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 195 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 196 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 197 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 198 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 199 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Data-EnvSampler-EnvE... | 0.374        |
| Data-EnvSampler-Poli... | 0.898        |
| Data-EnvTrajs-Averag... | 93.5         |
| Data-EnvTrajs-MaxReturn | 118          |
| Data-EnvTrajs-MinReturn | 64.4         |
| Data-EnvTrajs-NumTrajs  | 5            |
| Data-EnvTrajs-StdReturn | 18.1         |
| Data-TimeEnvSampleProc  | 0.000922     |
| Data-TimeEnvSampling    | 1.31         |
| Iteration               | 19           |
| ItrTime                 | 34.4         |
| LossAfter               | -0.014761428 |
| LossBefore              | -9.93905e-06 |
| Model-TimeModelFit      | 30.3         |
| ModelSampler-n_times... | 800000       |
| Policy-AverageAbsPol... | 0.82306623   |
| Policy-AverageDiscou... | 17.1         |
| Policy-AveragePolicyStd | 0.6532361    |
| Policy-AverageReturn    | 40.5         |
| Policy-MaxReturn        | 107          |
| Policy-MinReturn        | -9.76        |
| Policy-NumTrajs         | 20           |
| Policy-StdReturn        | 34.4         |
| Policy-TimeAlgoOpt      | 0.622        |
| Policy-TimeSampleProc   | 0.46         |
| Policy-TimeSampling     | 1.65         |
| Policy-TimeStep         | 2.78         |
| Time                    | 478          |
| n_timesteps             | 20000        |
------------------------------------------

 ---------------- Iteration 20 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 200 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 201 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 202 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 203 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 204 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 205 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 206 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 207 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 208 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 209 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.377         |
| Data-EnvSampler-Poli... | 0.878         |
| Data-EnvTrajs-Averag... | 70.9          |
| Data-EnvTrajs-MaxReturn | 120           |
| Data-EnvTrajs-MinReturn | -2.91         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 40.2          |
| Data-TimeEnvSampleProc  | 0.0007        |
| Data-TimeEnvSampling    | 1.29          |
| Iteration               | 20            |
| ItrTime                 | 35.6          |
| LossAfter               | -0.017465573  |
| LossBefore              | -9.751394e-06 |
| Model-TimeModelFit      | 31.3          |
| ModelSampler-n_times... | 840000        |
| Policy-AverageAbsPol... | 0.8292569     |
| Policy-AverageDiscou... | 10            |
| Policy-AveragePolicyStd | 0.64152056    |
| Policy-AverageReturn    | 46.8          |
| Policy-MaxReturn        | 215           |
| Policy-MinReturn        | -30.6         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 58.1          |
| Policy-TimeAlgoOpt      | 0.676         |
| Policy-TimeSampleProc   | 0.515         |
| Policy-TimeSampling     | 1.77          |
| Policy-TimeStep         | 3.02          |
| Time                    | 513           |
| n_timesteps             | 21000         |
-------------------------------------------

 ---------------- Iteration 21 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 210 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 211 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 212 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 213 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 214 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 215 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 216 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 217 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 218 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 219 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.406         |
| Data-EnvSampler-Poli... | 0.939         |
| Data-EnvTrajs-Averag... | 129           |
| Data-EnvTrajs-MaxReturn | 167           |
| Data-EnvTrajs-MinReturn | 103           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 22.9          |
| Data-TimeEnvSampleProc  | 0.00114       |
| Data-TimeEnvSampling    | 1.38          |
| Iteration               | 21            |
| ItrTime                 | 36.2          |
| LossAfter               | -0.016250256  |
| LossBefore              | -9.517171e-06 |
| Model-TimeModelFit      | 31.9          |
| ModelSampler-n_times... | 880000        |
| Policy-AverageAbsPol... | 0.8222592     |
| Policy-AverageDiscou... | 16.4          |
| Policy-AveragePolicyStd | 0.62534213    |
| Policy-AverageReturn    | 47.4          |
| Policy-MaxReturn        | 136           |
| Policy-MinReturn        | -49.3         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 49.5          |
| Policy-TimeAlgoOpt      | 0.69          |
| Policy-TimeSampleProc   | 0.452         |
| Policy-TimeSampling     | 1.74          |
| Policy-TimeStep         | 2.9           |
| Time                    | 550           |
| n_timesteps             | 22000         |
-------------------------------------------

 ---------------- Iteration 22 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 220 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 221 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 222 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 223 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 224 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 225 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 226 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 227 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 228 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 229 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.371          |
| Data-EnvSampler-Poli... | 0.98           |
| Data-EnvTrajs-Averag... | 79.3           |
| Data-EnvTrajs-MaxReturn | 129            |
| Data-EnvTrajs-MinReturn | 35.7           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 30.1           |
| Data-TimeEnvSampleProc  | 0.00115        |
| Data-TimeEnvSampling    | 1.39           |
| Iteration               | 22             |
| ItrTime                 | 35.2           |
| LossAfter               | -0.0140516     |
| LossBefore              | -9.3995795e-06 |
| Model-TimeModelFit      | 31.1           |
| ModelSampler-n_times... | 920000         |
| Policy-AverageAbsPol... | 0.8885079      |
| Policy-AverageDiscou... | 70.7           |
| Policy-AveragePolicyStd | 0.6204565      |
| Policy-AverageReturn    | 200            |
| Policy-MaxReturn        | 386            |
| Policy-MinReturn        | -217           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 122            |
| Policy-TimeAlgoOpt      | 0.607          |
| Policy-TimeSampleProc   | 0.519          |
| Policy-TimeSampling     | 1.63           |
| Policy-TimeStep         | 2.79           |
| Time                    | 585            |
| n_timesteps             | 23000          |
--------------------------------------------

 ---------------- Iteration 23 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 230 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 231 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 232 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 233 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 234 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 235 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 236 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 237 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 238 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 239 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.37          |
| Data-EnvSampler-Poli... | 1.01          |
| Data-EnvTrajs-Averag... | 78.5          |
| Data-EnvTrajs-MaxReturn | 126           |
| Data-EnvTrajs-MinReturn | 19            |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 34.6          |
| Data-TimeEnvSampleProc  | 0.00106       |
| Data-TimeEnvSampling    | 1.43          |
| Iteration               | 23            |
| ItrTime                 | 36.1          |
| LossAfter               | -0.013934449  |
| LossBefore              | -9.187219e-06 |
| Model-TimeModelFit      | 31.8          |
| ModelSampler-n_times... | 960000        |
| Policy-AverageAbsPol... | 0.85847324    |
| Policy-AverageDiscou... | -19.8         |
| Policy-AveragePolicyStd | 0.6069702     |
| Policy-AverageReturn    | -24.1         |
| Policy-MaxReturn        | 95.4          |
| Policy-MinReturn        | -112          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 53.3          |
| Policy-TimeAlgoOpt      | 0.656         |
| Policy-TimeSampleProc   | 0.457         |
| Policy-TimeSampling     | 1.69          |
| Policy-TimeStep         | 2.86          |
| Time                    | 621           |
| n_timesteps             | 24000         |
-------------------------------------------

 ---------------- Iteration 24 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 240 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 241 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 242 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 243 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 244 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 245 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 246 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 247 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 248 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 249 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.363         |
| Data-EnvSampler-Poli... | 0.909         |
| Data-EnvTrajs-Averag... | 127           |
| Data-EnvTrajs-MaxReturn | 228           |
| Data-EnvTrajs-MinReturn | 85.8          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 54.7          |
| Data-TimeEnvSampleProc  | 0.000697      |
| Data-TimeEnvSampling    | 1.31          |
| Iteration               | 24            |
| ItrTime                 | 36            |
| LossAfter               | -0.01998351   |
| LossBefore              | -8.987317e-06 |
| Model-TimeModelFit      | 31.5          |
| ModelSampler-n_times... | 1000000       |
| Policy-AverageAbsPol... | 0.86482924    |
| Policy-AverageDiscou... | 27.7          |
| Policy-AveragePolicyStd | 0.59398675    |
| Policy-AverageReturn    | 97.4          |
| Policy-MaxReturn        | 203           |
| Policy-MinReturn        | -54.5         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 75.6          |
| Policy-TimeAlgoOpt      | 0.716         |
| Policy-TimeSampleProc   | 0.556         |
| Policy-TimeSampling     | 1.85          |
| Policy-TimeStep         | 3.18          |
| Time                    | 657           |
| n_timesteps             | 25000         |
-------------------------------------------

 ---------------- Iteration 25 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 250 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 251 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 252 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 253 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 254 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 255 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 256 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 257 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 258 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 259 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.405         |
| Data-EnvSampler-Poli... | 0.962         |
| Data-EnvTrajs-Averag... | 149           |
| Data-EnvTrajs-MaxReturn | 249           |
| Data-EnvTrajs-MinReturn | 92.2          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 62.7          |
| Data-TimeEnvSampleProc  | 0.00068       |
| Data-TimeEnvSampling    | 1.4           |
| Iteration               | 25            |
| ItrTime                 | 36            |
| LossAfter               | -0.017382665  |
| LossBefore              | -8.693303e-06 |
| Model-TimeModelFit      | 31.5          |
| ModelSampler-n_times... | 1040000       |
| Policy-AverageAbsPol... | 0.8734039     |
| Policy-AverageDiscou... | -14           |
| Policy-AveragePolicyStd | 0.57698756    |
| Policy-AverageReturn    | -19.8         |
| Policy-MaxReturn        | 108           |
| Policy-MinReturn        | -169          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 74.6          |
| Policy-TimeAlgoOpt      | 0.693         |
| Policy-TimeSampleProc   | 0.5           |
| Policy-TimeSampling     | 1.82          |
| Policy-TimeStep         | 3.07          |
| Time                    | 693           |
| n_timesteps             | 26000         |
-------------------------------------------

 ---------------- Iteration 26 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 260 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 261 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 262 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 263 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 264 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 265 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 266 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 267 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 268 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 269 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.361         |
| Data-EnvSampler-Poli... | 0.902         |
| Data-EnvTrajs-Averag... | 131           |
| Data-EnvTrajs-MaxReturn | 201           |
| Data-EnvTrajs-MinReturn | 60.1          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 56            |
| Data-TimeEnvSampleProc  | 0.00111       |
| Data-TimeEnvSampling    | 1.3           |
| Iteration               | 26            |
| ItrTime                 | 36.5          |
| LossAfter               | -0.016428262  |
| LossBefore              | -8.348322e-06 |
| Model-TimeModelFit      | 32.2          |
| ModelSampler-n_times... | 1080000       |
| Policy-AverageAbsPol... | 0.9351042     |
| Policy-AverageDiscou... | 94.3          |
| Policy-AveragePolicyStd | 0.55765134    |
| Policy-AverageReturn    | 260           |
| Policy-MaxReturn        | 369           |
| Policy-MinReturn        | 107           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 66.5          |
| Policy-TimeAlgoOpt      | 0.654         |
| Policy-TimeSampleProc   | 0.497         |
| Policy-TimeSampling     | 1.82          |
| Policy-TimeStep         | 3.02          |
| Time                    | 729           |
| n_timesteps             | 27000         |
-------------------------------------------

 ---------------- Iteration 27 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 270 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 271 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 272 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 273 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 274 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 275 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 276 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 277 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 278 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 279 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.381         |
| Data-EnvSampler-Poli... | 0.954         |
| Data-EnvTrajs-Averag... | 188           |
| Data-EnvTrajs-MaxReturn | 310           |
| Data-EnvTrajs-MinReturn | 62            |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 94.4          |
| Data-TimeEnvSampleProc  | 0.00103       |
| Data-TimeEnvSampling    | 1.38          |
| Iteration               | 27            |
| ItrTime                 | 36.1          |
| LossAfter               | -0.014358102  |
| LossBefore              | -8.050136e-06 |
| Model-TimeModelFit      | 31.8          |
| ModelSampler-n_times... | 1120000       |
| Policy-AverageAbsPol... | 0.9629165     |
| Policy-AverageDiscou... | 50.6          |
| Policy-AveragePolicyStd | 0.5416822     |
| Policy-AverageReturn    | 162           |
| Policy-MaxReturn        | 253           |
| Policy-MinReturn        | -60.6         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 75.2          |
| Policy-TimeAlgoOpt      | 0.686         |
| Policy-TimeSampleProc   | 0.454         |
| Policy-TimeSampling     | 1.71          |
| Policy-TimeStep         | 2.92          |
| Time                    | 766           |
| n_timesteps             | 28000         |
-------------------------------------------

 ---------------- Iteration 28 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 280 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 281 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 282 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 283 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 284 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 285 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 286 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 287 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 288 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 289 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.378         |
| Data-EnvSampler-Poli... | 0.922         |
| Data-EnvTrajs-Averag... | 181           |
| Data-EnvTrajs-MaxReturn | 238           |
| Data-EnvTrajs-MinReturn | 64.9          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 68.1          |
| Data-TimeEnvSampleProc  | 0.000878      |
| Data-TimeEnvSampling    | 1.33          |
| Iteration               | 28            |
| ItrTime                 | 35.7          |
| LossAfter               | -0.016903121  |
| LossBefore              | -7.915784e-06 |
| Model-TimeModelFit      | 31.7          |
| ModelSampler-n_times... | 1160000       |
| Policy-AverageAbsPol... | 0.957168      |
| Policy-AverageDiscou... | 42.1          |
| Policy-AveragePolicyStd | 0.5335784     |
| Policy-AverageReturn    | 113           |
| Policy-MaxReturn        | 300           |
| Policy-MinReturn        | -235          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 109           |
| Policy-TimeAlgoOpt      | 0.637         |
| Policy-TimeSampleProc   | 0.443         |
| Policy-TimeSampling     | 1.55          |
| Policy-TimeStep         | 2.68          |
| Time                    | 801           |
| n_timesteps             | 29000         |
-------------------------------------------

 ---------------- Iteration 29 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 290 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 291 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 292 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 293 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 294 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 295 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 296 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 297 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 298 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 299 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.355         |
| Data-EnvSampler-Poli... | 0.868         |
| Data-EnvTrajs-Averag... | 183           |
| Data-EnvTrajs-MaxReturn | 237           |
| Data-EnvTrajs-MinReturn | 107           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 46.2          |
| Data-TimeEnvSampleProc  | 0.000868      |
| Data-TimeEnvSampling    | 1.26          |
| Iteration               | 29            |
| ItrTime                 | 36.7          |
| LossAfter               | -0.017597284  |
| LossBefore              | -7.805986e-06 |
| Model-TimeModelFit      | 32.6          |
| ModelSampler-n_times... | 1200000       |
| Policy-AverageAbsPol... | 0.9843913     |
| Policy-AverageDiscou... | 105           |
| Policy-AveragePolicyStd | 0.5279212     |
| Policy-AverageReturn    | 284           |
| Policy-MaxReturn        | 420           |
| Policy-MinReturn        | 117           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 77.1          |
| Policy-TimeAlgoOpt      | 0.655         |
| Policy-TimeSampleProc   | 0.472         |
| Policy-TimeSampling     | 1.64          |
| Policy-TimeStep         | 2.79          |
| Time                    | 838           |
| n_timesteps             | 30000         |
-------------------------------------------

 ---------------- Iteration 30 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 300 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 301 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 302 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 303 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 304 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 305 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 306 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 307 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 308 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 309 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.352         |
| Data-EnvSampler-Poli... | 0.909         |
| Data-EnvTrajs-Averag... | 192           |
| Data-EnvTrajs-MaxReturn | 264           |
| Data-EnvTrajs-MinReturn | 139           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 45.2          |
| Data-TimeEnvSampleProc  | 0.00101       |
| Data-TimeEnvSampling    | 1.29          |
| Iteration               | 30            |
| ItrTime                 | 36.6          |
| LossAfter               | -0.018755594  |
| LossBefore              | -7.638432e-06 |
| Model-TimeModelFit      | 32.8          |
| ModelSampler-n_times... | 1240000       |
| Policy-AverageAbsPol... | 0.95271987    |
| Policy-AverageDiscou... | 9.61          |
| Policy-AveragePolicyStd | 0.5192449     |
| Policy-AverageReturn    | 39.4          |
| Policy-MaxReturn        | 131           |
| Policy-MinReturn        | -65           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 57.6          |
| Policy-TimeAlgoOpt      | 0.594         |
| Policy-TimeSampleProc   | 0.38          |
| Policy-TimeSampling     | 1.54          |
| Policy-TimeStep         | 2.57          |
| Time                    | 875           |
| n_timesteps             | 31000         |
-------------------------------------------

 ---------------- Iteration 31 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 310 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 311 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 312 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 313 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 314 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 315 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 316 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 317 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 318 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 319 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.339          |
| Data-EnvSampler-Poli... | 0.865          |
| Data-EnvTrajs-Averag... | 177            |
| Data-EnvTrajs-MaxReturn | 268            |
| Data-EnvTrajs-MinReturn | 105            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 74             |
| Data-TimeEnvSampleProc  | 0.000876       |
| Data-TimeEnvSampling    | 1.24           |
| Iteration               | 31             |
| ItrTime                 | 36.2           |
| LossAfter               | -0.016251884   |
| LossBefore              | -7.4620557e-06 |
| Model-TimeModelFit      | 32.3           |
| ModelSampler-n_times... | 1280000        |
| Policy-AverageAbsPol... | 0.9617552      |
| Policy-AverageDiscou... | 53.5           |
| Policy-AveragePolicyStd | 0.51102036     |
| Policy-AverageReturn    | 143            |
| Policy-MaxReturn        | 283            |
| Policy-MinReturn        | -42.3          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 70.7           |
| Policy-TimeAlgoOpt      | 0.669          |
| Policy-TimeSampleProc   | 0.28           |
| Policy-TimeSampling     | 1.71           |
| Policy-TimeStep         | 2.69           |
| Time                    | 911            |
| n_timesteps             | 32000          |
--------------------------------------------

 ---------------- Iteration 32 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 320 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 321 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 322 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 323 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 324 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 325 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 326 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 327 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 328 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 329 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.371          |
| Data-EnvSampler-Poli... | 0.956          |
| Data-EnvTrajs-Averag... | 204            |
| Data-EnvTrajs-MaxReturn | 289            |
| Data-EnvTrajs-MinReturn | 106            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 60.2           |
| Data-TimeEnvSampleProc  | 0.00108        |
| Data-TimeEnvSampling    | 1.37           |
| Iteration               | 32             |
| ItrTime                 | 36.7           |
| LossAfter               | -0.017221015   |
| LossBefore              | -7.3417405e-06 |
| Model-TimeModelFit      | 32.6           |
| ModelSampler-n_times... | 1320000        |
| Policy-AverageAbsPol... | 0.9275947      |
| Policy-AverageDiscou... | 13.8           |
| Policy-AveragePolicyStd | 0.5063889      |
| Policy-AverageReturn    | 57.4           |
| Policy-MaxReturn        | 160            |
| Policy-MinReturn        | -54.5          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 53.7           |
| Policy-TimeAlgoOpt      | 0.633          |
| Policy-TimeSampleProc   | 0.499          |
| Policy-TimeSampling     | 1.6            |
| Policy-TimeStep         | 2.78           |
| Time                    | 947            |
| n_timesteps             | 33000          |
--------------------------------------------

 ---------------- Iteration 33 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 330 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 331 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 332 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 333 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 334 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 335 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 336 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 337 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 338 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 339 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.381         |
| Data-EnvSampler-Poli... | 0.978         |
| Data-EnvTrajs-Averag... | 139           |
| Data-EnvTrajs-MaxReturn | 309           |
| Data-EnvTrajs-MinReturn | 81            |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 86.8          |
| Data-TimeEnvSampleProc  | 0.00121       |
| Data-TimeEnvSampling    | 1.4           |
| Iteration               | 33            |
| ItrTime                 | 36.9          |
| LossAfter               | -0.018015742  |
| LossBefore              | -7.295692e-06 |
| Model-TimeModelFit      | 32.7          |
| ModelSampler-n_times... | 1360000       |
| Policy-AverageAbsPol... | 0.9249313     |
| Policy-AverageDiscou... | 45.7          |
| Policy-AveragePolicyStd | 0.5012506     |
| Policy-AverageReturn    | 135           |
| Policy-MaxReturn        | 232           |
| Policy-MinReturn        | 43.5          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 39.4          |
| Policy-TimeAlgoOpt      | 0.64          |
| Policy-TimeSampleProc   | 0.527         |
| Policy-TimeSampling     | 1.59          |
| Policy-TimeStep         | 2.8           |
| Time                    | 984           |
| n_timesteps             | 34000         |
-------------------------------------------

 ---------------- Iteration 34 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 340 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 341 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 342 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 343 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 344 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 345 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 346 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 347 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 348 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 349 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.355          |
| Data-EnvSampler-Poli... | 0.909          |
| Data-EnvTrajs-Averag... | 213            |
| Data-EnvTrajs-MaxReturn | 290            |
| Data-EnvTrajs-MinReturn | 112            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 57.1           |
| Data-TimeEnvSampleProc  | 0.000688       |
| Data-TimeEnvSampling    | 1.3            |
| Iteration               | 34             |
| ItrTime                 | 37.6           |
| LossAfter               | -0.017182788   |
| LossBefore              | -7.0295973e-06 |
| Model-TimeModelFit      | 33.4           |
| ModelSampler-n_times... | 1400000        |
| Policy-AverageAbsPol... | 0.90622324     |
| Policy-AverageDiscou... | 26.9           |
| Policy-AveragePolicyStd | 0.48930314     |
| Policy-AverageReturn    | 83             |
| Policy-MaxReturn        | 177            |
| Policy-MinReturn        | -27.6          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 43.8           |
| Policy-TimeAlgoOpt      | 0.6            |
| Policy-TimeSampleProc   | 0.578          |
| Policy-TimeSampling     | 1.69           |
| Policy-TimeStep         | 2.91           |
| Time                    | 1.02e+03       |
| n_timesteps             | 35000          |
--------------------------------------------

 ---------------- Iteration 35 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 350 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 351 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 352 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 353 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 354 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 355 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 356 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 357 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 358 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 359 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.333          |
| Data-EnvSampler-Poli... | 0.868          |
| Data-EnvTrajs-Averag... | 255            |
| Data-EnvTrajs-MaxReturn | 307            |
| Data-EnvTrajs-MinReturn | 212            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 34.9           |
| Data-TimeEnvSampleProc  | 0.000922       |
| Data-TimeEnvSampling    | 1.23           |
| Iteration               | 35             |
| ItrTime                 | 35.8           |
| LossAfter               | -0.01787063    |
| LossBefore              | -6.8682566e-06 |
| Model-TimeModelFit      | 31.9           |
| ModelSampler-n_times... | 1440000        |
| Policy-AverageAbsPol... | 0.92058396     |
| Policy-AverageDiscou... | 20.4           |
| Policy-AveragePolicyStd | 0.48073772     |
| Policy-AverageReturn    | 69.3           |
| Policy-MaxReturn        | 179            |
| Policy-MinReturn        | -25.2          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 65.9           |
| Policy-TimeAlgoOpt      | 0.587          |
| Policy-TimeSampleProc   | 0.45           |
| Policy-TimeSampling     | 1.58           |
| Policy-TimeStep         | 2.68           |
| Time                    | 1.06e+03       |
| n_timesteps             | 36000          |
--------------------------------------------

 ---------------- Iteration 36 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 360 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 361 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 362 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 363 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 364 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 365 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 366 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 367 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 368 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 369 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.342          |
| Data-EnvSampler-Poli... | 0.91           |
| Data-EnvTrajs-Averag... | 123            |
| Data-EnvTrajs-MaxReturn | 254            |
| Data-EnvTrajs-MinReturn | 6.27           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 84.7           |
| Data-TimeEnvSampleProc  | 0.000756       |
| Data-TimeEnvSampling    | 1.29           |
| Iteration               | 36             |
| ItrTime                 | 35.9           |
| LossAfter               | -0.015172255   |
| LossBefore              | -6.6085195e-06 |
| Model-TimeModelFit      | 32             |
| ModelSampler-n_times... | 1480000        |
| Policy-AverageAbsPol... | 0.95502067     |
| Policy-AverageDiscou... | 211            |
| Policy-AveragePolicyStd | 0.46981356     |
| Policy-AverageReturn    | 752            |
| Policy-MaxReturn        | 8.79e+03       |
| Policy-MinReturn        | 137            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.85e+03       |
| Policy-TimeAlgoOpt      | 0.619          |
| Policy-TimeSampleProc   | 0.386          |
| Policy-TimeSampling     | 1.61           |
| Policy-TimeStep         | 2.65           |
| Time                    | 1.09e+03       |
| n_timesteps             | 37000          |
--------------------------------------------

 ---------------- Iteration 37 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 370 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 371 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 372 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 373 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 374 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 375 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 376 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 377 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 378 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 379 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.338          |
| Data-EnvSampler-Poli... | 0.806          |
| Data-EnvTrajs-Averag... | 228            |
| Data-EnvTrajs-MaxReturn | 318            |
| Data-EnvTrajs-MinReturn | 157            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 64.9           |
| Data-TimeEnvSampleProc  | 0.000888       |
| Data-TimeEnvSampling    | 1.18           |
| Iteration               | 37             |
| ItrTime                 | 35.7           |
| LossAfter               | -0.018917274   |
| LossBefore              | -6.4671412e-06 |
| Model-TimeModelFit      | 31.8           |
| ModelSampler-n_times... | 1520000        |
| Policy-AverageAbsPol... | 0.9456457      |
| Policy-AverageDiscou... | 85             |
| Policy-AveragePolicyStd | 0.46242964     |
| Policy-AverageReturn    | 230            |
| Policy-MaxReturn        | 338            |
| Policy-MinReturn        | 109            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 64.5           |
| Policy-TimeAlgoOpt      | 0.645          |
| Policy-TimeSampleProc   | 0.487          |
| Policy-TimeSampling     | 1.55           |
| Policy-TimeStep         | 2.71           |
| Time                    | 1.13e+03       |
| n_timesteps             | 38000          |
--------------------------------------------

 ---------------- Iteration 38 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 380 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 381 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 382 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 383 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 384 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 385 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 386 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 387 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 388 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 389 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.351         |
| Data-EnvSampler-Poli... | 0.918         |
| Data-EnvTrajs-Averag... | 247           |
| Data-EnvTrajs-MaxReturn | 347           |
| Data-EnvTrajs-MinReturn | 196           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 53.9          |
| Data-TimeEnvSampleProc  | 0.000911      |
| Data-TimeEnvSampling    | 1.3           |
| Iteration               | 38            |
| ItrTime                 | 36.9          |
| LossAfter               | -0.018864758  |
| LossBefore              | -6.221184e-06 |
| Model-TimeModelFit      | 32.9          |
| ModelSampler-n_times... | 1560000       |
| Policy-AverageAbsPol... | 0.9507129     |
| Policy-AverageDiscou... | 55.3          |
| Policy-AveragePolicyStd | 0.45181775    |
| Policy-AverageReturn    | 165           |
| Policy-MaxReturn        | 277           |
| Policy-MinReturn        | 59            |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 68.6          |
| Policy-TimeAlgoOpt      | 0.611         |
| Policy-TimeSampleProc   | 0.475         |
| Policy-TimeSampling     | 1.56          |
| Policy-TimeStep         | 2.67          |
| Time                    | 1.17e+03      |
| n_timesteps             | 39000         |
-------------------------------------------

 ---------------- Iteration 39 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 390 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 391 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 392 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 393 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 394 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 395 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 396 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 397 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 398 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 399 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.341         |
| Data-EnvSampler-Poli... | 0.893         |
| Data-EnvTrajs-Averag... | 265           |
| Data-EnvTrajs-MaxReturn | 388           |
| Data-EnvTrajs-MinReturn | 188           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 67.3          |
| Data-TimeEnvSampleProc  | 0.00103       |
| Data-TimeEnvSampling    | 1.27          |
| Iteration               | 39            |
| ItrTime                 | 36.2          |
| LossAfter               | -0.021501679  |
| LossBefore              | -6.081727e-06 |
| Model-TimeModelFit      | 32.4          |
| ModelSampler-n_times... | 1600000       |
| Policy-AverageAbsPol... | 0.93970704    |
| Policy-AverageDiscou... | 64.2          |
| Policy-AveragePolicyStd | 0.44522852    |
| Policy-AverageReturn    | 190           |
| Policy-MaxReturn        | 296           |
| Policy-MinReturn        | 111           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 51.6          |
| Policy-TimeAlgoOpt      | 0.617         |
| Policy-TimeSampleProc   | 0.348         |
| Policy-TimeSampling     | 1.55          |
| Policy-TimeStep         | 2.57          |
| Time                    | 1.2e+03       |
| n_timesteps             | 40000         |
-------------------------------------------

 ---------------- Iteration 40 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 400 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 401 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 402 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 403 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 404 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 405 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 406 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 407 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 408 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 409 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.371         |
| Data-EnvSampler-Poli... | 0.913         |
| Data-EnvTrajs-Averag... | 264           |
| Data-EnvTrajs-MaxReturn | 290           |
| Data-EnvTrajs-MinReturn | 228           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 27.9          |
| Data-TimeEnvSampleProc  | 0.000987      |
| Data-TimeEnvSampling    | 1.33          |
| Iteration               | 40            |
| ItrTime                 | 35.6          |
| LossAfter               | -0.015527318  |
| LossBefore              | -5.868561e-06 |
| Model-TimeModelFit      | 31.6          |
| ModelSampler-n_times... | 1640000       |
| Policy-AverageAbsPol... | 0.9069751     |
| Policy-AverageDiscou... | 33.4          |
| Policy-AveragePolicyStd | 0.43559733    |
| Policy-AverageReturn    | 107           |
| Policy-MaxReturn        | 199           |
| Policy-MinReturn        | 5.37          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 56.1          |
| Policy-TimeAlgoOpt      | 0.572         |
| Policy-TimeSampleProc   | 0.487         |
| Policy-TimeSampling     | 1.56          |
| Policy-TimeStep         | 2.69          |
| Time                    | 1.24e+03      |
| n_timesteps             | 41000         |
-------------------------------------------

 ---------------- Iteration 41 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 410 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 411 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 412 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 413 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 414 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 415 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 416 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 417 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 418 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 419 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.33           |
| Data-EnvSampler-Poli... | 0.871          |
| Data-EnvTrajs-Averag... | 242            |
| Data-EnvTrajs-MaxReturn | 349            |
| Data-EnvTrajs-MinReturn | 158            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 75.2           |
| Data-TimeEnvSampleProc  | 0.00101        |
| Data-TimeEnvSampling    | 1.24           |
| Iteration               | 41             |
| ItrTime                 | 35.8           |
| LossAfter               | -0.014694592   |
| LossBefore              | -5.6425024e-06 |
| Model-TimeModelFit      | 31.9           |
| ModelSampler-n_times... | 1680000        |
| Policy-AverageAbsPol... | 0.90918994     |
| Policy-AverageDiscou... | 76.6           |
| Policy-AveragePolicyStd | 0.4262242      |
| Policy-AverageReturn    | 219            |
| Policy-MaxReturn        | 313            |
| Policy-MinReturn        | 156            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 44.3           |
| Policy-TimeAlgoOpt      | 0.556          |
| Policy-TimeSampleProc   | 0.48           |
| Policy-TimeSampling     | 1.58           |
| Policy-TimeStep         | 2.68           |
| Time                    | 1.27e+03       |
| n_timesteps             | 42000          |
--------------------------------------------

 ---------------- Iteration 42 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 420 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 421 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 422 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 423 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 424 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 425 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 426 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 427 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 428 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 429 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.348          |
| Data-EnvSampler-Poli... | 0.869          |
| Data-EnvTrajs-Averag... | 270            |
| Data-EnvTrajs-MaxReturn | 338            |
| Data-EnvTrajs-MinReturn | 177            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 56.7           |
| Data-TimeEnvSampleProc  | 0.000837       |
| Data-TimeEnvSampling    | 1.26           |
| Iteration               | 42             |
| ItrTime                 | 34.3           |
| LossAfter               | -0.02074494    |
| LossBefore              | -5.4297925e-06 |
| Model-TimeModelFit      | 30.1           |
| ModelSampler-n_times... | 1720000        |
| Policy-AverageAbsPol... | 0.9431379      |
| Policy-AverageDiscou... | 102            |
| Policy-AveragePolicyStd | 0.41700244     |
| Policy-AverageReturn    | 287            |
| Policy-MaxReturn        | 385            |
| Policy-MinReturn        | 192            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 44.6           |
| Policy-TimeAlgoOpt      | 0.569          |
| Policy-TimeSampleProc   | 0.55           |
| Policy-TimeSampling     | 1.7            |
| Policy-TimeStep         | 2.88           |
| Time                    | 1.31e+03       |
| n_timesteps             | 43000          |
--------------------------------------------

 ---------------- Iteration 43 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 430 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 431 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 432 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 433 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 434 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 435 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 436 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 437 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 438 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 439 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.34           |
| Data-EnvSampler-Poli... | 0.823          |
| Data-EnvTrajs-Averag... | 255            |
| Data-EnvTrajs-MaxReturn | 395            |
| Data-EnvTrajs-MinReturn | 89.2           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 130            |
| Data-TimeEnvSampleProc  | 0.000796       |
| Data-TimeEnvSampling    | 1.19           |
| Iteration               | 43             |
| ItrTime                 | 34.8           |
| LossAfter               | -0.01315875    |
| LossBefore              | -5.3209033e-06 |
| Model-TimeModelFit      | 31             |
| ModelSampler-n_times... | 1760000        |
| Policy-AverageAbsPol... | 0.92908967     |
| Policy-AverageDiscou... | 85.1           |
| Policy-AveragePolicyStd | 0.41407478     |
| Policy-AverageReturn    | 246            |
| Policy-MaxReturn        | 324            |
| Policy-MinReturn        | 122            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 47.5           |
| Policy-TimeAlgoOpt      | 0.594          |
| Policy-TimeSampleProc   | 0.445          |
| Policy-TimeSampling     | 1.55           |
| Policy-TimeStep         | 2.63           |
| Time                    | 1.34e+03       |
| n_timesteps             | 44000          |
--------------------------------------------

 ---------------- Iteration 44 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 440 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 441 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 442 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 443 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 444 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 445 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 446 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 447 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 448 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 449 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.342          |
| Data-EnvSampler-Poli... | 0.807          |
| Data-EnvTrajs-Averag... | 341            |
| Data-EnvTrajs-MaxReturn | 433            |
| Data-EnvTrajs-MinReturn | 267            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 56.7           |
| Data-TimeEnvSampleProc  | 0.00102        |
| Data-TimeEnvSampling    | 1.18           |
| Iteration               | 44             |
| ItrTime                 | 34.3           |
| LossAfter               | -0.01879557    |
| LossBefore              | -5.2415567e-06 |
| Model-TimeModelFit      | 30.6           |
| ModelSampler-n_times... | 1800000        |
| Policy-AverageAbsPol... | 0.91241604     |
| Policy-AverageDiscou... | 62.3           |
| Policy-AveragePolicyStd | 0.4083597      |
| Policy-AverageReturn    | 174            |
| Policy-MaxReturn        | 309            |
| Policy-MinReturn        | 34.4           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 82.7           |
| Policy-TimeAlgoOpt      | 0.625          |
| Policy-TimeSampleProc   | 0.308          |
| Policy-TimeSampling     | 1.52           |
| Policy-TimeStep         | 2.48           |
| Time                    | 1.38e+03       |
| n_timesteps             | 45000          |
--------------------------------------------

 ---------------- Iteration 45 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 450 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 451 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 452 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 453 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 454 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 455 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 456 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 457 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 458 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 459 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.332         |
| Data-EnvSampler-Poli... | 0.795         |
| Data-EnvTrajs-Averag... | 242           |
| Data-EnvTrajs-MaxReturn | 367           |
| Data-EnvTrajs-MinReturn | 30.6          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 114           |
| Data-TimeEnvSampleProc  | 0.0009        |
| Data-TimeEnvSampling    | 1.16          |
| Iteration               | 45            |
| ItrTime                 | 34.6          |
| LossAfter               | -0.018048173  |
| LossBefore              | -5.206264e-06 |
| Model-TimeModelFit      | 30.9          |
| ModelSampler-n_times... | 1840000       |
| Policy-AverageAbsPol... | 0.93108237    |
| Policy-AverageDiscou... | 135           |
| Policy-AveragePolicyStd | 0.4067501     |
| Policy-AverageReturn    | 376           |
| Policy-MaxReturn        | 501           |
| Policy-MinReturn        | 321           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 46.3          |
| Policy-TimeAlgoOpt      | 0.561         |
| Policy-TimeSampleProc   | 0.423         |
| Policy-TimeSampling     | 1.5           |
| Policy-TimeStep         | 2.51          |
| Time                    | 1.41e+03      |
| n_timesteps             | 46000         |
-------------------------------------------

 ---------------- Iteration 46 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 460 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 461 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 462 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 463 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 464 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 465 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 466 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 467 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 468 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 469 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.333         |
| Data-EnvSampler-Poli... | 0.861         |
| Data-EnvTrajs-Averag... | 260           |
| Data-EnvTrajs-MaxReturn | 327           |
| Data-EnvTrajs-MinReturn | 198           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 41.3          |
| Data-TimeEnvSampleProc  | 0.000863      |
| Data-TimeEnvSampling    | 1.23          |
| Iteration               | 46            |
| ItrTime                 | 34.8          |
| LossAfter               | -0.018327028  |
| LossBefore              | -5.045045e-06 |
| Model-TimeModelFit      | 31            |
| ModelSampler-n_times... | 1880000       |
| Policy-AverageAbsPol... | 0.92172414    |
| Policy-AverageDiscou... | 64.1          |
| Policy-AveragePolicyStd | 0.401606      |
| Policy-AverageReturn    | 192           |
| Policy-MaxReturn        | 370           |
| Policy-MinReturn        | 74.2          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 71.2          |
| Policy-TimeAlgoOpt      | 0.577         |
| Policy-TimeSampleProc   | 0.447         |
| Policy-TimeSampling     | 1.56          |
| Policy-TimeStep         | 2.62          |
| Time                    | 1.45e+03      |
| n_timesteps             | 47000         |
-------------------------------------------

 ---------------- Iteration 47 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 470 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 471 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 472 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 473 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 474 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 475 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 476 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 477 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 478 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 479 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.332          |
| Data-EnvSampler-Poli... | 0.833          |
| Data-EnvTrajs-Averag... | 311            |
| Data-EnvTrajs-MaxReturn | 440            |
| Data-EnvTrajs-MinReturn | 204            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 87.7           |
| Data-TimeEnvSampleProc  | 0.000947       |
| Data-TimeEnvSampling    | 1.21           |
| Iteration               | 47             |
| ItrTime                 | 34.7           |
| LossAfter               | -0.017622279   |
| LossBefore              | -4.8695088e-06 |
| Model-TimeModelFit      | 30.8           |
| ModelSampler-n_times... | 1920000        |
| Policy-AverageAbsPol... | 0.9444914      |
| Policy-AverageDiscou... | 78.3           |
| Policy-AveragePolicyStd | 0.3955451      |
| Policy-AverageReturn    | 230            |
| Policy-MaxReturn        | 340            |
| Policy-MinReturn        | -16.1          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 88.5           |
| Policy-TimeAlgoOpt      | 0.697          |
| Policy-TimeSampleProc   | 0.355          |
| Policy-TimeSampling     | 1.63           |
| Policy-TimeStep         | 2.72           |
| Time                    | 1.48e+03       |
| n_timesteps             | 48000          |
--------------------------------------------

 ---------------- Iteration 48 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 480 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 481 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 482 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 483 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 484 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 485 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 486 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 487 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 488 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 489 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.366         |
| Data-EnvSampler-Poli... | 0.919         |
| Data-EnvTrajs-Averag... | 256           |
| Data-EnvTrajs-MaxReturn | 402           |
| Data-EnvTrajs-MinReturn | 162           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 89.2          |
| Data-TimeEnvSampleProc  | 0.000887      |
| Data-TimeEnvSampling    | 1.32          |
| Iteration               | 48            |
| ItrTime                 | 35.7          |
| LossAfter               | -0.017967403  |
| LossBefore              | -4.783564e-06 |
| Model-TimeModelFit      | 31.6          |
| ModelSampler-n_times... | 1960000       |
| Policy-AverageAbsPol... | 0.95716447    |
| Policy-AverageDiscou... | 117           |
| Policy-AveragePolicyStd | 0.39119595    |
| Policy-AverageReturn    | 321           |
| Policy-MaxReturn        | 457           |
| Policy-MinReturn        | 80.2          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 75.6          |
| Policy-TimeAlgoOpt      | 0.67          |
| Policy-TimeSampleProc   | 0.461         |
| Policy-TimeSampling     | 1.58          |
| Policy-TimeStep         | 2.75          |
| Time                    | 1.52e+03      |
| n_timesteps             | 49000         |
-------------------------------------------

 ---------------- Iteration 49 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 490 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 491 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 492 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 493 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 494 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 495 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 496 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 497 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 498 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 499 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.34           |
| Data-EnvSampler-Poli... | 0.887          |
| Data-EnvTrajs-Averag... | 274            |
| Data-EnvTrajs-MaxReturn | 329            |
| Data-EnvTrajs-MinReturn | 206            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 47.3           |
| Data-TimeEnvSampleProc  | 0.000902       |
| Data-TimeEnvSampling    | 1.27           |
| Iteration               | 49             |
| ItrTime                 | 34.8           |
| LossAfter               | -0.018406855   |
| LossBefore              | -4.6917744e-06 |
| Model-TimeModelFit      | 31.1           |
| ModelSampler-n_times... | 2000000        |
| Policy-AverageAbsPol... | 0.9581551      |
| Policy-AverageDiscou... | 90.2           |
| Policy-AveragePolicyStd | 0.38787898     |
| Policy-AverageReturn    | 259            |
| Policy-MaxReturn        | 366            |
| Policy-MinReturn        | 103            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 61.2           |
| Policy-TimeAlgoOpt      | 0.611          |
| Policy-TimeSampleProc   | 0.315          |
| Policy-TimeSampling     | 1.56           |
| Policy-TimeStep         | 2.52           |
| Time                    | 1.55e+03       |
| n_timesteps             | 50000          |
--------------------------------------------

 ---------------- Iteration 50 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 500 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 501 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 502 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 503 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 504 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 505 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 506 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 507 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 508 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 509 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.327         |
| Data-EnvSampler-Poli... | 0.843         |
| Data-EnvTrajs-Averag... | 316           |
| Data-EnvTrajs-MaxReturn | 416           |
| Data-EnvTrajs-MinReturn | 256           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 58.8          |
| Data-TimeEnvSampleProc  | 0.000957      |
| Data-TimeEnvSampling    | 1.2           |
| Iteration               | 50            |
| ItrTime                 | 35.8          |
| LossAfter               | -0.020721879  |
| LossBefore              | -4.620088e-06 |
| Model-TimeModelFit      | 31.7          |
| ModelSampler-n_times... | 2040000       |
| Policy-AverageAbsPol... | 0.9671244     |
| Policy-AverageDiscou... | 83.1          |
| Policy-AveragePolicyStd | 0.38488916    |
| Policy-AverageReturn    | 267           |
| Policy-MaxReturn        | 395           |
| Policy-MinReturn        | 92.7          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 76.1          |
| Policy-TimeAlgoOpt      | 0.535         |
| Policy-TimeSampleProc   | 0.602         |
| Policy-TimeSampling     | 1.68          |
| Policy-TimeStep         | 2.9           |
| Time                    | 1.59e+03      |
| n_timesteps             | 51000         |
-------------------------------------------
Training finished
