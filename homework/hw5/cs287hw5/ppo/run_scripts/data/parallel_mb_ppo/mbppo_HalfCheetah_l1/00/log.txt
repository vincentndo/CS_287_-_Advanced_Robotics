Logging to /home/vincent/workplace/CS_287_-_Advanced_Robotics/homework/hw5/cs287hw5/ppo/run_scripts/data/parallel_mb_ppo/mbppo_HalfCheetah_l1//00

 ---------------- Iteration 0 ----------------
Obtaining random samples from the environment...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 0 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 1 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 2 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 3 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 4 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 5 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 6 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 7 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 8 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 9 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.116          |
| Data-EnvSampler-Poli... | 0.0352         |
| Data-EnvTrajs-Averag... | -55.5          |
| Data-EnvTrajs-MaxReturn | -26.7          |
| Data-EnvTrajs-MinReturn | -88.8          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 20.8           |
| Data-TimeEnvSampleProc  | 0.00051        |
| Data-TimeEnvSampling    | 0.161          |
| Iteration               | 0              |
| ItrTime                 | 8              |
| LossAfter               | -0.017477706   |
| LossBefore              | -1.4278356e-05 |
| Model-TimeModelFit      | 2.62           |
| ModelSampler-n_times... | 40000          |
| Policy-AverageAbsPol... | 0.9487342      |
| Policy-AverageDiscou... | 5.99e+03       |
| Policy-AveragePolicyStd | 1.0086474      |
| Policy-AverageReturn    | 1.68e+04       |
| Policy-MaxReturn        | 1.73e+04       |
| Policy-MinReturn        | 1.65e+04       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 220            |
| Policy-TimeAlgoOpt      | 0.95           |
| Policy-TimeSampleProc   | 0.418          |
| Policy-TimeSampling     | 3.75           |
| Policy-TimeStep         | 5.21           |
| Time                    | 8              |
| n_timesteps             | 1000           |
--------------------------------------------

 ---------------- Iteration 1 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 10 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 11 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 12 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 13 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 14 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 15 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 16 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 17 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 18 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 19 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.206          |
| Data-EnvSampler-Poli... | 0.477          |
| Data-EnvTrajs-Averag... | -73.8          |
| Data-EnvTrajs-MaxReturn | -48.3          |
| Data-EnvTrajs-MinReturn | -119           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 24             |
| Data-TimeEnvSampleProc  | 0.00059        |
| Data-TimeEnvSampling    | 0.706          |
| Iteration               | 1              |
| ItrTime                 | 7.03           |
| LossAfter               | -0.015450381   |
| LossBefore              | -1.4137309e-05 |
| Model-TimeModelFit      | 3.94           |
| ModelSampler-n_times... | 80000          |
| Policy-AverageAbsPol... | 0.74809885     |
| Policy-AverageDiscou... | -95.2          |
| Policy-AveragePolicyStd | 0.99399674     |
| Policy-AverageReturn    | -250           |
| Policy-MaxReturn        | -135           |
| Policy-MinReturn        | -1.25e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 238            |
| Policy-TimeAlgoOpt      | 0.596          |
| Policy-TimeSampleProc   | 0.331          |
| Policy-TimeSampling     | 1.43           |
| Policy-TimeStep         | 2.38           |
| Time                    | 15.2           |
| n_timesteps             | 2000           |
--------------------------------------------

 ---------------- Iteration 2 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 20 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 21 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 22 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 23 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 24 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 25 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 26 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 27 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 28 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 29 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.238           |
| Data-EnvSampler-Poli... | 0.444           |
| Data-EnvTrajs-Averag... | -52.8           |
| Data-EnvTrajs-MaxReturn | -1.85           |
| Data-EnvTrajs-MinReturn | -107            |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 37.4            |
| Data-TimeEnvSampleProc  | 0.000565        |
| Data-TimeEnvSampling    | 0.705           |
| Iteration               | 2               |
| ItrTime                 | 9.43            |
| LossAfter               | -0.016666664    |
| LossBefore              | -1.37138595e-05 |
| Model-TimeModelFit      | 6.25            |
| ModelSampler-n_times... | 120000          |
| Policy-AverageAbsPol... | 0.6489353       |
| Policy-AverageDiscou... | -57.1           |
| Policy-AveragePolicyStd | 0.9556748       |
| Policy-AverageReturn    | -130            |
| Policy-MaxReturn        | -104            |
| Policy-MinReturn        | -156            |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 15.8            |
| Policy-TimeAlgoOpt      | 0.502           |
| Policy-TimeSampleProc   | 0.574           |
| Policy-TimeSampling     | 1.35            |
| Policy-TimeStep         | 2.48            |
| Time                    | 24.6            |
| n_timesteps             | 3000            |
---------------------------------------------

 ---------------- Iteration 3 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 30 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 31 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 32 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 33 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 34 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 35 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 36 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 37 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 38 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 39 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.229         |
| Data-EnvSampler-Poli... | 0.454         |
| Data-EnvTrajs-Averag... | -34.6         |
| Data-EnvTrajs-MaxReturn | -8.01         |
| Data-EnvTrajs-MinReturn | -77.1         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 23.6          |
| Data-TimeEnvSampleProc  | 0.000959      |
| Data-TimeEnvSampling    | 0.707         |
| Iteration               | 3             |
| ItrTime                 | 11.5          |
| LossAfter               | -0.016732324  |
| LossBefore              | -1.352784e-05 |
| Model-TimeModelFit      | 8.22          |
| ModelSampler-n_times... | 160000        |
| Policy-AverageAbsPol... | 0.6347626     |
| Policy-AverageDiscou... | -543          |
| Policy-AveragePolicyStd | 0.9362218     |
| Policy-AverageReturn    | -1.84e+03     |
| Policy-MaxReturn        | -332          |
| Policy-MinReturn        | -8.08e+03     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 2.66e+03      |
| Policy-TimeAlgoOpt      | 0.624         |
| Policy-TimeSampleProc   | 0.332         |
| Policy-TimeSampling     | 1.6           |
| Policy-TimeStep         | 2.6           |
| Time                    | 36.1          |
| n_timesteps             | 4000          |
-------------------------------------------

 ---------------- Iteration 4 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 40 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 41 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 42 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 43 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 44 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 45 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 46 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 47 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 48 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 49 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.265          |
| Data-EnvSampler-Poli... | 0.509          |
| Data-EnvTrajs-Averag... | -32.8          |
| Data-EnvTrajs-MaxReturn | 6.87           |
| Data-EnvTrajs-MinReturn | -59.4          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 22.9           |
| Data-TimeEnvSampleProc  | 0.000961       |
| Data-TimeEnvSampling    | 0.799          |
| Iteration               | 4              |
| ItrTime                 | 13.4           |
| LossAfter               | -0.014551972   |
| LossBefore              | -1.3113853e-05 |
| Model-TimeModelFit      | 10.2           |
| ModelSampler-n_times... | 200000         |
| Policy-AverageAbsPol... | 0.5248047      |
| Policy-AverageDiscou... | -89.5          |
| Policy-AveragePolicyStd | 0.8990748      |
| Policy-AverageReturn    | -207           |
| Policy-MaxReturn        | -182           |
| Policy-MinReturn        | -244           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 14.2           |
| Policy-TimeAlgoOpt      | 0.534          |
| Policy-TimeSampleProc   | 0.336          |
| Policy-TimeSampling     | 1.46           |
| Policy-TimeStep         | 2.38           |
| Time                    | 49.5           |
| n_timesteps             | 5000           |
--------------------------------------------

 ---------------- Iteration 5 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 50 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 51 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 52 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 53 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 54 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 55 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 56 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 57 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 58 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 59 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.259          |
| Data-EnvSampler-Poli... | 0.579          |
| Data-EnvTrajs-Averag... | -45.1          |
| Data-EnvTrajs-MaxReturn | -7.39          |
| Data-EnvTrajs-MinReturn | -72.5          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 23.2           |
| Data-TimeEnvSampleProc  | 0.000688       |
| Data-TimeEnvSampling    | 0.866          |
| Iteration               | 5              |
| ItrTime                 | 16.2           |
| LossAfter               | -0.013092275   |
| LossBefore              | -1.2746964e-05 |
| Model-TimeModelFit      | 12.7           |
| ModelSampler-n_times... | 240000         |
| Policy-AverageAbsPol... | 0.5114252      |
| Policy-AverageDiscou... | -169           |
| Policy-AveragePolicyStd | 0.8669175      |
| Policy-AverageReturn    | -401           |
| Policy-MaxReturn        | -369           |
| Policy-MinReturn        | -440           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 17             |
| Policy-TimeAlgoOpt      | 0.503          |
| Policy-TimeSampleProc   | 0.589          |
| Policy-TimeSampling     | 1.43           |
| Policy-TimeStep         | 2.58           |
| Time                    | 65.7           |
| n_timesteps             | 6000           |
--------------------------------------------

 ---------------- Iteration 6 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 60 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 61 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 62 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 63 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 64 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 65 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 66 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 67 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 68 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 69 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.265          |
| Data-EnvSampler-Poli... | 0.537          |
| Data-EnvTrajs-Averag... | -34.1          |
| Data-EnvTrajs-MaxReturn | -17.4          |
| Data-EnvTrajs-MinReturn | -49.4          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 13.8           |
| Data-TimeEnvSampleProc  | 0.000959       |
| Data-TimeEnvSampling    | 0.83           |
| Iteration               | 6              |
| ItrTime                 | 18.4           |
| LossAfter               | -0.015078256   |
| LossBefore              | -1.2332913e-05 |
| Model-TimeModelFit      | 14.9           |
| ModelSampler-n_times... | 280000         |
| Policy-AverageAbsPol... | 0.4872151      |
| Policy-AverageDiscou... | -88.3          |
| Policy-AveragePolicyStd | 0.83242214     |
| Policy-AverageReturn    | -206           |
| Policy-MaxReturn        | -161           |
| Policy-MinReturn        | -246           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 24.2           |
| Policy-TimeAlgoOpt      | 0.601          |
| Policy-TimeSampleProc   | 0.402          |
| Policy-TimeSampling     | 1.59           |
| Policy-TimeStep         | 2.64           |
| Time                    | 84.1           |
| n_timesteps             | 7000           |
--------------------------------------------

 ---------------- Iteration 7 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 70 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 71 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 72 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 73 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 74 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 75 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 76 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 77 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 78 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 79 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.294         |
| Data-EnvSampler-Poli... | 0.571         |
| Data-EnvTrajs-Averag... | -55           |
| Data-EnvTrajs-MaxReturn | -4.04         |
| Data-EnvTrajs-MinReturn | -114          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 37.8          |
| Data-TimeEnvSampleProc  | 0.000966      |
| Data-TimeEnvSampling    | 0.894         |
| Iteration               | 7             |
| ItrTime                 | 20.8          |
| LossAfter               | -0.016619127  |
| LossBefore              | -1.188383e-05 |
| Model-TimeModelFit      | 17            |
| ModelSampler-n_times... | 320000        |
| Policy-AverageAbsPol... | 0.45806843    |
| Policy-AverageDiscou... | 24.9          |
| Policy-AveragePolicyStd | 0.79475504    |
| Policy-AverageReturn    | 54.1          |
| Policy-MaxReturn        | 124           |
| Policy-MinReturn        | 4.58          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 35.5          |
| Policy-TimeAlgoOpt      | 0.638         |
| Policy-TimeSampleProc   | 0.415         |
| Policy-TimeSampling     | 1.8           |
| Policy-TimeStep         | 2.91          |
| Time                    | 105           |
| n_timesteps             | 8000          |
-------------------------------------------

 ---------------- Iteration 8 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 80 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 81 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 82 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 83 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 84 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 85 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 86 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 87 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 88 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 89 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.327          |
| Data-EnvSampler-Poli... | 0.713          |
| Data-EnvTrajs-Averag... | -60            |
| Data-EnvTrajs-MaxReturn | -34            |
| Data-EnvTrajs-MinReturn | -99.8          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 22.8           |
| Data-TimeEnvSampleProc  | 0.000912       |
| Data-TimeEnvSampling    | 1.08           |
| Iteration               | 8              |
| ItrTime                 | 23.4           |
| LossAfter               | -0.01634158    |
| LossBefore              | -1.1600931e-05 |
| Model-TimeModelFit      | 19.7           |
| ModelSampler-n_times... | 360000         |
| Policy-AverageAbsPol... | 0.46825862     |
| Policy-AverageDiscou... | -7.49          |
| Policy-AveragePolicyStd | 0.7739186      |
| Policy-AverageReturn    | 11.1           |
| Policy-MaxReturn        | 66.2           |
| Policy-MinReturn        | -53.1          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 31             |
| Policy-TimeAlgoOpt      | 0.554          |
| Policy-TimeSampleProc   | 0.435          |
| Policy-TimeSampling     | 1.56           |
| Policy-TimeStep         | 2.59           |
| Time                    | 128            |
| n_timesteps             | 9000           |
--------------------------------------------

 ---------------- Iteration 9 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 90 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 91 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 92 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 93 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 94 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 95 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 96 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 97 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 98 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 99 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.285          |
| Data-EnvSampler-Poli... | 0.596          |
| Data-EnvTrajs-Averag... | -20.5          |
| Data-EnvTrajs-MaxReturn | 27.5           |
| Data-EnvTrajs-MinReturn | -68.9          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 37             |
| Data-TimeEnvSampleProc  | 0.00102        |
| Data-TimeEnvSampling    | 0.911          |
| Iteration               | 9              |
| ItrTime                 | 24.9           |
| LossAfter               | -0.016682865   |
| LossBefore              | -1.1448568e-05 |
| Model-TimeModelFit      | 21.4           |
| ModelSampler-n_times... | 400000         |
| Policy-AverageAbsPol... | 0.4716928      |
| Policy-AverageDiscou... | -99.6          |
| Policy-AveragePolicyStd | 0.7600711      |
| Policy-AverageReturn    | -243           |
| Policy-MaxReturn        | -180           |
| Policy-MinReturn        | -292           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 27.8           |
| Policy-TimeAlgoOpt      | 0.649          |
| Policy-TimeSampleProc   | 0.413          |
| Policy-TimeSampling     | 1.54           |
| Policy-TimeStep         | 2.64           |
| Time                    | 153            |
| n_timesteps             | 10000          |
--------------------------------------------

 ---------------- Iteration 10 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 100 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 101 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 102 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 103 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 104 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 105 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 106 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 107 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 108 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 109 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.31           |
| Data-EnvSampler-Poli... | 0.675          |
| Data-EnvTrajs-Averag... | -55.2          |
| Data-EnvTrajs-MaxReturn | 14.2           |
| Data-EnvTrajs-MinReturn | -97            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 37.2           |
| Data-TimeEnvSampleProc  | 0.000828       |
| Data-TimeEnvSampling    | 1.02           |
| Iteration               | 10             |
| ItrTime                 | 28             |
| LossAfter               | -0.015346611   |
| LossBefore              | -1.1255904e-05 |
| Model-TimeModelFit      | 24.3           |
| ModelSampler-n_times... | 440000         |
| Policy-AverageAbsPol... | 0.45783886     |
| Policy-AverageDiscou... | -42.2          |
| Policy-AveragePolicyStd | 0.7460348      |
| Policy-AverageReturn    | -97.4          |
| Policy-MaxReturn        | -37.5          |
| Policy-MinReturn        | -149           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 33.3           |
| Policy-TimeAlgoOpt      | 0.67           |
| Policy-TimeSampleProc   | 0.349          |
| Policy-TimeSampling     | 1.6            |
| Policy-TimeStep         | 2.66           |
| Time                    | 181            |
| n_timesteps             | 11000          |
--------------------------------------------

 ---------------- Iteration 11 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 110 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 111 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 112 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 113 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 114 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 115 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 116 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 117 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 118 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 119 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Data-EnvSampler-EnvE... | 0.305        |
| Data-EnvSampler-Poli... | 0.643        |
| Data-EnvTrajs-Averag... | -12.1        |
| Data-EnvTrajs-MaxReturn | 17.3         |
| Data-EnvTrajs-MinReturn | -51.5        |
| Data-EnvTrajs-NumTrajs  | 5            |
| Data-EnvTrajs-StdReturn | 27           |
| Data-TimeEnvSampleProc  | 0.000957     |
| Data-TimeEnvSampling    | 0.98         |
| Iteration               | 11           |
| ItrTime                 | 31.2         |
| LossAfter               | -0.015574747 |
| LossBefore              | -1.11087e-05 |
| Model-TimeModelFit      | 27.3         |
| ModelSampler-n_times... | 480000       |
| Policy-AverageAbsPol... | 0.53927696   |
| Policy-AverageDiscou... | 224          |
| Policy-AveragePolicyStd | 0.7349653    |
| Policy-AverageReturn    | 1.3e+03      |
| Policy-MaxReturn        | 3.9e+03      |
| Policy-MinReturn        | -161         |
| Policy-NumTrajs         | 20           |
| Policy-StdReturn        | 1.34e+03     |
| Policy-TimeAlgoOpt      | 0.664        |
| Policy-TimeSampleProc   | 0.423        |
| Policy-TimeSampling     | 1.86         |
| Policy-TimeStep         | 2.99         |
| Time                    | 212          |
| n_timesteps             | 12000        |
------------------------------------------

 ---------------- Iteration 12 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 120 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 121 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 122 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 123 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 124 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 125 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 126 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 127 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 128 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 129 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.311          |
| Data-EnvSampler-Poli... | 0.696          |
| Data-EnvTrajs-Averag... | -22.6          |
| Data-EnvTrajs-MaxReturn | 27.6           |
| Data-EnvTrajs-MinReturn | -70.7          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 38.6           |
| Data-TimeEnvSampleProc  | 0.00105        |
| Data-TimeEnvSampling    | 1.05           |
| Iteration               | 12             |
| ItrTime                 | 32.9           |
| LossAfter               | -0.015034972   |
| LossBefore              | -1.0897016e-05 |
| Model-TimeModelFit      | 28.8           |
| ModelSampler-n_times... | 520000         |
| Policy-AverageAbsPol... | 0.5651441      |
| Policy-AverageDiscou... | -16.5          |
| Policy-AveragePolicyStd | 0.7206151      |
| Policy-AverageReturn    | -33.3          |
| Policy-MaxReturn        | 95.5           |
| Policy-MinReturn        | -117           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 56.4           |
| Policy-TimeAlgoOpt      | 0.675          |
| Policy-TimeSampleProc   | 0.555          |
| Policy-TimeSampling     | 1.81           |
| Policy-TimeStep         | 3.06           |
| Time                    | 245            |
| n_timesteps             | 13000          |
--------------------------------------------

 ---------------- Iteration 13 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 130 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 131 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 132 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 133 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 134 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 135 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 136 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 137 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 138 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 139 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.32           |
| Data-EnvSampler-Poli... | 0.663          |
| Data-EnvTrajs-Averag... | -29.5          |
| Data-EnvTrajs-MaxReturn | 16             |
| Data-EnvTrajs-MinReturn | -61.6          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 33.5           |
| Data-TimeEnvSampleProc  | 0.000906       |
| Data-TimeEnvSampling    | 1.02           |
| Iteration               | 13             |
| ItrTime                 | 33.4           |
| LossAfter               | -0.013315554   |
| LossBefore              | -1.0572095e-05 |
| Model-TimeModelFit      | 29.3           |
| ModelSampler-n_times... | 560000         |
| Policy-AverageAbsPol... | 0.4992882      |
| Policy-AverageDiscou... | -39.7          |
| Policy-AveragePolicyStd | 0.69939554     |
| Policy-AverageReturn    | -101           |
| Policy-MaxReturn        | -71.2          |
| Policy-MinReturn        | -138           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 19             |
| Policy-TimeAlgoOpt      | 0.681          |
| Policy-TimeSampleProc   | 0.592          |
| Policy-TimeSampling     | 1.68           |
| Policy-TimeStep         | 2.99           |
| Time                    | 279            |
| n_timesteps             | 14000          |
--------------------------------------------

 ---------------- Iteration 14 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 140 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 141 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 142 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 143 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 144 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 145 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 146 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 147 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 148 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 149 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.283          |
| Data-EnvSampler-Poli... | 0.598          |
| Data-EnvTrajs-Averag... | -36.7          |
| Data-EnvTrajs-MaxReturn | -13.6          |
| Data-EnvTrajs-MinReturn | -69.2          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 21.1           |
| Data-TimeEnvSampleProc  | 0.00077        |
| Data-TimeEnvSampling    | 0.91           |
| Iteration               | 14             |
| ItrTime                 | 32.8           |
| LossAfter               | -0.018014116   |
| LossBefore              | -1.0443104e-05 |
| Model-TimeModelFit      | 29             |
| ModelSampler-n_times... | 600000         |
| Policy-AverageAbsPol... | 0.50194615     |
| Policy-AverageDiscou... | -34.1          |
| Policy-AveragePolicyStd | 0.6887035      |
| Policy-AverageReturn    | -116           |
| Policy-MaxReturn        | -8.54          |
| Policy-MinReturn        | -1.16e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 252            |
| Policy-TimeAlgoOpt      | 0.668          |
| Policy-TimeSampleProc   | 0.348          |
| Policy-TimeSampling     | 1.87           |
| Policy-TimeStep         | 2.91           |
| Time                    | 311            |
| n_timesteps             | 15000          |
--------------------------------------------

 ---------------- Iteration 15 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 150 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 151 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 152 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 153 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 154 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 155 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 156 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 157 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 158 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 159 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.279          |
| Data-EnvSampler-Poli... | 0.585          |
| Data-EnvTrajs-Averag... | -17.5          |
| Data-EnvTrajs-MaxReturn | 15.5           |
| Data-EnvTrajs-MinReturn | -62            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 25.9           |
| Data-TimeEnvSampleProc  | 0.0011         |
| Data-TimeEnvSampling    | 0.893          |
| Iteration               | 15             |
| ItrTime                 | 34.4           |
| LossAfter               | -0.016580792   |
| LossBefore              | -1.0333621e-05 |
| Model-TimeModelFit      | 30.5           |
| ModelSampler-n_times... | 640000         |
| Policy-AverageAbsPol... | 0.45031282     |
| Policy-AverageDiscou... | -50.8          |
| Policy-AveragePolicyStd | 0.67919785     |
| Policy-AverageReturn    | -119           |
| Policy-MaxReturn        | -73.7          |
| Policy-MinReturn        | -177           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 23.1           |
| Policy-TimeAlgoOpt      | 0.651          |
| Policy-TimeSampleProc   | 0.545          |
| Policy-TimeSampling     | 1.79           |
| Policy-TimeStep         | 3.02           |
| Time                    | 346            |
| n_timesteps             | 16000          |
--------------------------------------------

 ---------------- Iteration 16 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 160 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 161 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 162 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 163 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 164 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 165 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 166 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 167 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 168 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 169 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.314          |
| Data-EnvSampler-Poli... | 0.629          |
| Data-EnvTrajs-Averag... | -16.5          |
| Data-EnvTrajs-MaxReturn | 43.4           |
| Data-EnvTrajs-MinReturn | -72.4          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 38.5           |
| Data-TimeEnvSampleProc  | 0.000845       |
| Data-TimeEnvSampling    | 0.975          |
| Iteration               | 16             |
| ItrTime                 | 34.5           |
| LossAfter               | -0.01650944    |
| LossBefore              | -1.0040169e-05 |
| Model-TimeModelFit      | 30.4           |
| ModelSampler-n_times... | 680000         |
| Policy-AverageAbsPol... | 0.45443878     |
| Policy-AverageDiscou... | -14.9          |
| Policy-AveragePolicyStd | 0.66020185     |
| Policy-AverageReturn    | -36.6          |
| Policy-MaxReturn        | 21.8           |
| Policy-MinReturn        | -81.9          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 31.4           |
| Policy-TimeAlgoOpt      | 0.656          |
| Policy-TimeSampleProc   | 0.537          |
| Policy-TimeSampling     | 1.85           |
| Policy-TimeStep         | 3.08           |
| Time                    | 380            |
| n_timesteps             | 17000          |
--------------------------------------------

 ---------------- Iteration 17 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 170 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 171 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 172 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 173 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 174 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 175 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 176 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 177 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 178 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 179 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.324         |
| Data-EnvSampler-Poli... | 0.711         |
| Data-EnvTrajs-Averag... | 6.63          |
| Data-EnvTrajs-MaxReturn | 36.1          |
| Data-EnvTrajs-MinReturn | -34.2         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 23            |
| Data-TimeEnvSampleProc  | 0.00101       |
| Data-TimeEnvSampling    | 1.07          |
| Iteration               | 17            |
| ItrTime                 | 34.5          |
| LossAfter               | -0.0181074    |
| LossBefore              | -9.797277e-06 |
| Model-TimeModelFit      | 30.4          |
| ModelSampler-n_times... | 720000        |
| Policy-AverageAbsPol... | 0.48380485    |
| Policy-AverageDiscou... | 3.15          |
| Policy-AveragePolicyStd | 0.64448494    |
| Policy-AverageReturn    | 42.2          |
| Policy-MaxReturn        | 909           |
| Policy-MinReturn        | -58.1         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 208           |
| Policy-TimeAlgoOpt      | 0.675         |
| Policy-TimeSampleProc   | 0.444         |
| Policy-TimeSampling     | 1.83          |
| Policy-TimeStep         | 3             |
| Time                    | 415           |
| n_timesteps             | 18000         |
-------------------------------------------

 ---------------- Iteration 18 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 180 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 181 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 182 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 183 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 184 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 185 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 186 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 187 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 188 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 189 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.313         |
| Data-EnvSampler-Poli... | 0.719         |
| Data-EnvTrajs-Averag... | -28.7         |
| Data-EnvTrajs-MaxReturn | 95.8          |
| Data-EnvTrajs-MinReturn | -142          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 86.9          |
| Data-TimeEnvSampleProc  | 0.00111       |
| Data-TimeEnvSampling    | 1.06          |
| Iteration               | 18            |
| ItrTime                 | 34.9          |
| LossAfter               | -0.016786125  |
| LossBefore              | -9.600129e-06 |
| Model-TimeModelFit      | 30.9          |
| ModelSampler-n_times... | 760000        |
| Policy-AverageAbsPol... | 0.5291279     |
| Policy-AverageDiscou... | -31.2         |
| Policy-AveragePolicyStd | 0.63216805    |
| Policy-AverageReturn    | -68.3         |
| Policy-MaxReturn        | -2.26         |
| Policy-MinReturn        | -141          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 41.7          |
| Policy-TimeAlgoOpt      | 0.659         |
| Policy-TimeSampleProc   | 0.42          |
| Policy-TimeSampling     | 1.88          |
| Policy-TimeStep         | 3             |
| Time                    | 450           |
| n_timesteps             | 19000         |
-------------------------------------------

 ---------------- Iteration 19 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 190 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 191 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 192 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 193 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 194 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 195 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 196 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 197 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 198 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 199 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.34           |
| Data-EnvSampler-Poli... | 0.777          |
| Data-EnvTrajs-Averag... | 44.5           |
| Data-EnvTrajs-MaxReturn | 86.4           |
| Data-EnvTrajs-MinReturn | -0.643         |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 35.7           |
| Data-TimeEnvSampleProc  | 0.000941       |
| Data-TimeEnvSampling    | 1.15           |
| Iteration               | 19             |
| ItrTime                 | 35.2           |
| LossAfter               | -0.01940938    |
| LossBefore              | -9.4332345e-06 |
| Model-TimeModelFit      | 31.2           |
| ModelSampler-n_times... | 800000         |
| Policy-AverageAbsPol... | 0.5439187      |
| Policy-AverageDiscou... | 24             |
| Policy-AveragePolicyStd | 0.62404186     |
| Policy-AverageReturn    | 72.5           |
| Policy-MaxReturn        | 238            |
| Policy-MinReturn        | -5.28          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 48.7           |
| Policy-TimeAlgoOpt      | 0.63           |
| Policy-TimeSampleProc   | 0.469          |
| Policy-TimeSampling     | 1.72           |
| Policy-TimeStep         | 2.87           |
| Time                    | 485            |
| n_timesteps             | 20000          |
--------------------------------------------

 ---------------- Iteration 20 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 200 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 201 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 202 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 203 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 204 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 205 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 206 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 207 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 208 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 209 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.35          |
| Data-EnvSampler-Poli... | 0.788         |
| Data-EnvTrajs-Averag... | -0.568        |
| Data-EnvTrajs-MaxReturn | 60.8          |
| Data-EnvTrajs-MinReturn | -46           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 41            |
| Data-TimeEnvSampleProc  | 0.0011        |
| Data-TimeEnvSampling    | 1.18          |
| Iteration               | 20            |
| ItrTime                 | 35.7          |
| LossAfter               | -0.017338717  |
| LossBefore              | -9.364336e-06 |
| Model-TimeModelFit      | 31.9          |
| ModelSampler-n_times... | 840000        |
| Policy-AverageAbsPol... | 0.57247305    |
| Policy-AverageDiscou... | 14.8          |
| Policy-AveragePolicyStd | 0.61863446    |
| Policy-AverageReturn    | 112           |
| Policy-MaxReturn        | 1.44e+03      |
| Policy-MinReturn        | -140          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 336           |
| Policy-TimeAlgoOpt      | 0.599         |
| Policy-TimeSampleProc   | 0.38          |
| Policy-TimeSampling     | 1.62          |
| Policy-TimeStep         | 2.64          |
| Time                    | 521           |
| n_timesteps             | 21000         |
-------------------------------------------

 ---------------- Iteration 21 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 210 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 211 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 212 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 213 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 214 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 215 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 216 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 217 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 218 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 219 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.333         |
| Data-EnvSampler-Poli... | 0.749         |
| Data-EnvTrajs-Averag... | 38.7          |
| Data-EnvTrajs-MaxReturn | 88.4          |
| Data-EnvTrajs-MinReturn | -3.1          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 36.7          |
| Data-TimeEnvSampleProc  | 0.00108       |
| Data-TimeEnvSampling    | 1.12          |
| Iteration               | 21            |
| ItrTime                 | 36.2          |
| LossAfter               | -0.018357491  |
| LossBefore              | -9.316651e-06 |
| Model-TimeModelFit      | 32.1          |
| ModelSampler-n_times... | 880000        |
| Policy-AverageAbsPol... | 0.64190626    |
| Policy-AverageDiscou... | 709           |
| Policy-AveragePolicyStd | 0.6160387     |
| Policy-AverageReturn    | 2.37e+03      |
| Policy-MaxReturn        | 4.2e+03       |
| Policy-MinReturn        | 122           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.05e+03      |
| Policy-TimeAlgoOpt      | 0.699         |
| Policy-TimeSampleProc   | 0.404         |
| Policy-TimeSampling     | 1.82          |
| Policy-TimeStep         | 2.96          |
| Time                    | 557           |
| n_timesteps             | 22000         |
-------------------------------------------

 ---------------- Iteration 22 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 220 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 221 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 222 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 223 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 224 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 225 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 226 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 227 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 228 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 229 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.354         |
| Data-EnvSampler-Poli... | 0.792         |
| Data-EnvTrajs-Averag... | 53            |
| Data-EnvTrajs-MaxReturn | 167           |
| Data-EnvTrajs-MinReturn | -149          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 106           |
| Data-TimeEnvSampleProc  | 0.00114       |
| Data-TimeEnvSampling    | 1.18          |
| Iteration               | 22            |
| ItrTime                 | 35.1          |
| LossAfter               | -0.017518952  |
| LossBefore              | -9.224991e-06 |
| Model-TimeModelFit      | 31            |
| ModelSampler-n_times... | 920000        |
| Policy-AverageAbsPol... | 0.60629845    |
| Policy-AverageDiscou... | -55.6         |
| Policy-AveragePolicyStd | 0.61019737    |
| Policy-AverageReturn    | -139          |
| Policy-MaxReturn        | -0.204        |
| Policy-MinReturn        | -454          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 95            |
| Policy-TimeAlgoOpt      | 0.548         |
| Policy-TimeSampleProc   | 0.546         |
| Policy-TimeSampling     | 1.73          |
| Policy-TimeStep         | 2.88          |
| Time                    | 592           |
| n_timesteps             | 23000         |
-------------------------------------------

 ---------------- Iteration 23 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 230 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 231 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 232 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 233 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 234 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 235 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 236 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 237 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 238 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 239 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.323         |
| Data-EnvSampler-Poli... | 0.718         |
| Data-EnvTrajs-Averag... | 15            |
| Data-EnvTrajs-MaxReturn | 89.6          |
| Data-EnvTrajs-MinReturn | -70.2         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 59.8          |
| Data-TimeEnvSampleProc  | 0.00101       |
| Data-TimeEnvSampling    | 1.07          |
| Iteration               | 23            |
| ItrTime                 | 36.4          |
| LossAfter               | -0.01989266   |
| LossBefore              | -9.088224e-06 |
| Model-TimeModelFit      | 32.6          |
| ModelSampler-n_times... | 960000        |
| Policy-AverageAbsPol... | 0.5995093     |
| Policy-AverageDiscou... | -32.2         |
| Policy-AveragePolicyStd | 0.6020624     |
| Policy-AverageReturn    | -36.1         |
| Policy-MaxReturn        | 236           |
| Policy-MinReturn        | -152          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 109           |
| Policy-TimeAlgoOpt      | 0.633         |
| Policy-TimeSampleProc   | 0.424         |
| Policy-TimeSampling     | 1.65          |
| Policy-TimeStep         | 2.74          |
| Time                    | 629           |
| n_timesteps             | 24000         |
-------------------------------------------

 ---------------- Iteration 24 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 240 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 241 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 242 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 243 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 244 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 245 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 246 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 247 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 248 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 249 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.321         |
| Data-EnvSampler-Poli... | 0.717         |
| Data-EnvTrajs-Averag... | 5.3           |
| Data-EnvTrajs-MaxReturn | 103           |
| Data-EnvTrajs-MinReturn | -85.1         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 70            |
| Data-TimeEnvSampleProc  | 0.000786      |
| Data-TimeEnvSampling    | 1.07          |
| Iteration               | 24            |
| ItrTime                 | 36.4          |
| LossAfter               | -0.015587274  |
| LossBefore              | -8.949326e-06 |
| Model-TimeModelFit      | 32.4          |
| ModelSampler-n_times... | 1000000       |
| Policy-AverageAbsPol... | 0.6249874     |
| Policy-AverageDiscou... | 39.4          |
| Policy-AveragePolicyStd | 0.5947324     |
| Policy-AverageReturn    | 126           |
| Policy-MaxReturn        | 342           |
| Policy-MinReturn        | 13.6          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 77.3          |
| Policy-TimeAlgoOpt      | 0.67          |
| Policy-TimeSampleProc   | 0.538         |
| Policy-TimeSampling     | 1.7           |
| Policy-TimeStep         | 2.95          |
| Time                    | 665           |
| n_timesteps             | 25000         |
-------------------------------------------

 ---------------- Iteration 25 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 250 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 251 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 252 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 253 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 254 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 255 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 256 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 257 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 258 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 259 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.335         |
| Data-EnvSampler-Poli... | 0.707         |
| Data-EnvTrajs-Averag... | 34.7          |
| Data-EnvTrajs-MaxReturn | 81            |
| Data-EnvTrajs-MinReturn | -17.2         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 41.5          |
| Data-TimeEnvSampleProc  | 0.00623       |
| Data-TimeEnvSampling    | 1.08          |
| Iteration               | 25            |
| ItrTime                 | 36.6          |
| LossAfter               | -0.016521307  |
| LossBefore              | -8.778667e-06 |
| Model-TimeModelFit      | 32.7          |
| ModelSampler-n_times... | 1040000       |
| Policy-AverageAbsPol... | 0.6496615     |
| Policy-AverageDiscou... | -41.4         |
| Policy-AveragePolicyStd | 0.5835212     |
| Policy-AverageReturn    | -89.4         |
| Policy-MaxReturn        | 63.7          |
| Policy-MinReturn        | -188          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 60.4          |
| Policy-TimeAlgoOpt      | 0.633         |
| Policy-TimeSampleProc   | 0.478         |
| Policy-TimeSampling     | 1.73          |
| Policy-TimeStep         | 2.88          |
| Time                    | 702           |
| n_timesteps             | 26000         |
-------------------------------------------

 ---------------- Iteration 26 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 260 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 261 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 262 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 263 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 264 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 265 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 266 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 267 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 268 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 269 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.323         |
| Data-EnvSampler-Poli... | 0.683         |
| Data-EnvTrajs-Averag... | 43.2          |
| Data-EnvTrajs-MaxReturn | 110           |
| Data-EnvTrajs-MinReturn | -94.6         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 71.9          |
| Data-TimeEnvSampleProc  | 0.00112       |
| Data-TimeEnvSampling    | 1.04          |
| Iteration               | 26            |
| ItrTime                 | 36.5          |
| LossAfter               | -0.01648503   |
| LossBefore              | -8.575435e-06 |
| Model-TimeModelFit      | 32.4          |
| ModelSampler-n_times... | 1080000       |
| Policy-AverageAbsPol... | 0.6727784     |
| Policy-AverageDiscou... | -33.3         |
| Policy-AveragePolicyStd | 0.57180333    |
| Policy-AverageReturn    | -73.5         |
| Policy-MaxReturn        | 43.1          |
| Policy-MinReturn        | -144          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 45.6          |
| Policy-TimeAlgoOpt      | 0.68          |
| Policy-TimeSampleProc   | 0.403         |
| Policy-TimeSampling     | 1.94          |
| Policy-TimeStep         | 3.07          |
| Time                    | 738           |
| n_timesteps             | 27000         |
-------------------------------------------

 ---------------- Iteration 27 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 270 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 271 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 272 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 273 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 274 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 275 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 276 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 277 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 278 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 279 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.348         |
| Data-EnvSampler-Poli... | 0.753         |
| Data-EnvTrajs-Averag... | 49.1          |
| Data-EnvTrajs-MaxReturn | 180           |
| Data-EnvTrajs-MinReturn | -88.2         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 113           |
| Data-TimeEnvSampleProc  | 0.00118       |
| Data-TimeEnvSampling    | 1.15          |
| Iteration               | 27            |
| ItrTime                 | 36.7          |
| LossAfter               | -0.0192789    |
| LossBefore              | -8.416532e-06 |
| Model-TimeModelFit      | 32.6          |
| ModelSampler-n_times... | 1120000       |
| Policy-AverageAbsPol... | 0.69495517    |
| Policy-AverageDiscou... | -34.4         |
| Policy-AveragePolicyStd | 0.561841      |
| Policy-AverageReturn    | -84.1         |
| Policy-MaxReturn        | 29.7          |
| Policy-MinReturn        | -164          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 47.2          |
| Policy-TimeAlgoOpt      | 0.547         |
| Policy-TimeSampleProc   | 0.662         |
| Policy-TimeSampling     | 1.66          |
| Policy-TimeStep         | 2.91          |
| Time                    | 775           |
| n_timesteps             | 28000         |
-------------------------------------------

 ---------------- Iteration 28 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 280 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 281 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 282 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 283 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 284 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 285 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 286 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 287 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 288 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 289 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.341         |
| Data-EnvSampler-Poli... | 0.756         |
| Data-EnvTrajs-Averag... | 118           |
| Data-EnvTrajs-MaxReturn | 161           |
| Data-EnvTrajs-MinReturn | 47.2          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 40.9          |
| Data-TimeEnvSampleProc  | 0.00113       |
| Data-TimeEnvSampling    | 1.13          |
| Iteration               | 28            |
| ItrTime                 | 36.7          |
| LossAfter               | -0.017945403  |
| LossBefore              | -8.213343e-06 |
| Model-TimeModelFit      | 32.3          |
| ModelSampler-n_times... | 1160000       |
| Policy-AverageAbsPol... | 0.67376065    |
| Policy-AverageDiscou... | 53.5          |
| Policy-AveragePolicyStd | 0.55165684    |
| Policy-AverageReturn    | 134           |
| Policy-MaxReturn        | 218           |
| Policy-MinReturn        | 13.5          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 56.7          |
| Policy-TimeAlgoOpt      | 0.726         |
| Policy-TimeSampleProc   | 0.574         |
| Policy-TimeSampling     | 1.97          |
| Policy-TimeStep         | 3.33          |
| Time                    | 812           |
| n_timesteps             | 29000         |
-------------------------------------------

 ---------------- Iteration 29 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 290 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 291 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 292 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 293 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 294 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 295 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 296 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 297 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 298 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 299 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.357          |
| Data-EnvSampler-Poli... | 0.796          |
| Data-EnvTrajs-Averag... | 21.2           |
| Data-EnvTrajs-MaxReturn | 94             |
| Data-EnvTrajs-MinReturn | -108           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 75.3           |
| Data-TimeEnvSampleProc  | 0.00107        |
| Data-TimeEnvSampling    | 1.19           |
| Iteration               | 29             |
| ItrTime                 | 36.7           |
| LossAfter               | -0.019561313   |
| LossBefore              | -8.0002355e-06 |
| Model-TimeModelFit      | 32.6           |
| ModelSampler-n_times... | 1200000        |
| Policy-AverageAbsPol... | 0.69550633     |
| Policy-AverageDiscou... | 27.1           |
| Policy-AveragePolicyStd | 0.53991574     |
| Policy-AverageReturn    | 88.4           |
| Policy-MaxReturn        | 204            |
| Policy-MinReturn        | -33.5          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 60.1           |
| Policy-TimeAlgoOpt      | 0.627          |
| Policy-TimeSampleProc   | 0.517          |
| Policy-TimeSampling     | 1.72           |
| Policy-TimeStep         | 2.9            |
| Time                    | 848            |
| n_timesteps             | 30000          |
--------------------------------------------

 ---------------- Iteration 30 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 300 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 301 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 302 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 303 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 304 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 305 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 306 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 307 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 308 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 309 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.36          |
| Data-EnvSampler-Poli... | 0.822         |
| Data-EnvTrajs-Averag... | -15.3         |
| Data-EnvTrajs-MaxReturn | 138           |
| Data-EnvTrajs-MinReturn | -138          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 116           |
| Data-TimeEnvSampleProc  | 0.00111       |
| Data-TimeEnvSampling    | 1.22          |
| Iteration               | 30            |
| ItrTime                 | 37.1          |
| LossAfter               | -0.017651686  |
| LossBefore              | -7.872068e-06 |
| Model-TimeModelFit      | 33            |
| ModelSampler-n_times... | 1240000       |
| Policy-AverageAbsPol... | 0.6752299     |
| Policy-AverageDiscou... | -3.56         |
| Policy-AveragePolicyStd | 0.5326565     |
| Policy-AverageReturn    | -3.92         |
| Policy-MaxReturn        | 103           |
| Policy-MinReturn        | -78.9         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 46.4          |
| Policy-TimeAlgoOpt      | 0.62          |
| Policy-TimeSampleProc   | 0.451         |
| Policy-TimeSampling     | 1.76          |
| Policy-TimeStep         | 2.87          |
| Time                    | 885           |
| n_timesteps             | 31000         |
-------------------------------------------

 ---------------- Iteration 31 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 310 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 311 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 312 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 313 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 314 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 315 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 316 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 317 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 318 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 319 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.365         |
| Data-EnvSampler-Poli... | 0.884         |
| Data-EnvTrajs-Averag... | 106           |
| Data-EnvTrajs-MaxReturn | 225           |
| Data-EnvTrajs-MinReturn | -78.4         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 100           |
| Data-TimeEnvSampleProc  | 0.00128       |
| Data-TimeEnvSampling    | 1.29          |
| Iteration               | 31            |
| ItrTime                 | 37            |
| LossAfter               | -0.017145127  |
| LossBefore              | -7.642957e-06 |
| Model-TimeModelFit      | 33.1          |
| ModelSampler-n_times... | 1280000       |
| Policy-AverageAbsPol... | 0.68928367    |
| Policy-AverageDiscou... | 2.44          |
| Policy-AveragePolicyStd | 0.5218383     |
| Policy-AverageReturn    | 4.08          |
| Policy-MaxReturn        | 88.7          |
| Policy-MinReturn        | -82.8         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 51.1          |
| Policy-TimeAlgoOpt      | 0.598         |
| Policy-TimeSampleProc   | 0.418         |
| Policy-TimeSampling     | 1.55          |
| Policy-TimeStep         | 2.61          |
| Time                    | 922           |
| n_timesteps             | 32000         |
-------------------------------------------

 ---------------- Iteration 32 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 320 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 321 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 322 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 323 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 324 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 325 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 326 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 327 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 328 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 329 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.372          |
| Data-EnvSampler-Poli... | 0.944          |
| Data-EnvTrajs-Averag... | 83.7           |
| Data-EnvTrajs-MaxReturn | 169            |
| Data-EnvTrajs-MinReturn | -87.1          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 89.8           |
| Data-TimeEnvSampleProc  | 0.00124        |
| Data-TimeEnvSampling    | 1.36           |
| Iteration               | 32             |
| ItrTime                 | 37.3           |
| LossAfter               | -0.021492474   |
| LossBefore              | -7.6011015e-06 |
| Model-TimeModelFit      | 33             |
| ModelSampler-n_times... | 1320000        |
| Policy-AverageAbsPol... | 0.70778346     |
| Policy-AverageDiscou... | -27.8          |
| Policy-AveragePolicyStd | 0.52021027     |
| Policy-AverageReturn    | -80.4          |
| Policy-MaxReturn        | 87.2           |
| Policy-MinReturn        | -297           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 96             |
| Policy-TimeAlgoOpt      | 0.719          |
| Policy-TimeSampleProc   | 0.396          |
| Policy-TimeSampling     | 1.75           |
| Policy-TimeStep         | 2.89           |
| Time                    | 960            |
| n_timesteps             | 33000          |
--------------------------------------------

 ---------------- Iteration 33 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 330 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 331 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 332 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 333 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 334 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 335 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 336 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 337 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 338 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 339 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.34          |
| Data-EnvSampler-Poli... | 0.785         |
| Data-EnvTrajs-Averag... | 112           |
| Data-EnvTrajs-MaxReturn | 220           |
| Data-EnvTrajs-MinReturn | 25.8          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 69.6          |
| Data-TimeEnvSampleProc  | 0.00108       |
| Data-TimeEnvSampling    | 1.16          |
| Iteration               | 33            |
| ItrTime                 | 37.1          |
| LossAfter               | -0.0153096635 |
| LossBefore              | -7.484025e-06 |
| Model-TimeModelFit      | 33.2          |
| ModelSampler-n_times... | 1360000       |
| Policy-AverageAbsPol... | 0.7173939     |
| Policy-AverageDiscou... | 12.4          |
| Policy-AveragePolicyStd | 0.51266927    |
| Policy-AverageReturn    | 21.1          |
| Policy-MaxReturn        | 125           |
| Policy-MinReturn        | -186          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 76.1          |
| Policy-TimeAlgoOpt      | 0.613         |
| Policy-TimeSampleProc   | 0.405         |
| Policy-TimeSampling     | 1.73          |
| Policy-TimeStep         | 2.78          |
| Time                    | 997           |
| n_timesteps             | 34000         |
-------------------------------------------

 ---------------- Iteration 34 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 340 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 341 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 342 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 343 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 344 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 345 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 346 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 347 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 348 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 349 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Data-EnvSampler-EnvE... | 0.325        |
| Data-EnvSampler-Poli... | 0.831        |
| Data-EnvTrajs-Averag... | 60.7         |
| Data-EnvTrajs-MaxReturn | 194          |
| Data-EnvTrajs-MinReturn | -91.2        |
| Data-EnvTrajs-NumTrajs  | 5            |
| Data-EnvTrajs-StdReturn | 99.2         |
| Data-TimeEnvSampleProc  | 0.00107      |
| Data-TimeEnvSampling    | 1.19         |
| Iteration               | 34           |
| ItrTime                 | 36.1         |
| LossAfter               | -0.016342295 |
| LossBefore              | -7.2186e-06  |
| Model-TimeModelFit      | 32           |
| ModelSampler-n_times... | 1400000      |
| Policy-AverageAbsPol... | 0.71097094   |
| Policy-AverageDiscou... | 9.71         |
| Policy-AveragePolicyStd | 0.5004005    |
| Policy-AverageReturn    | 28.5         |
| Policy-MaxReturn        | 114          |
| Policy-MinReturn        | -29.1        |
| Policy-NumTrajs         | 20           |
| Policy-StdReturn        | 47.3         |
| Policy-TimeAlgoOpt      | 0.664        |
| Policy-TimeSampleProc   | 0.4          |
| Policy-TimeSampling     | 1.79         |
| Policy-TimeStep         | 2.87         |
| Time                    | 1.03e+03     |
| n_timesteps             | 35000        |
------------------------------------------

 ---------------- Iteration 35 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 350 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 351 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 352 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 353 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 354 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 355 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 356 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 357 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 358 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 359 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.32           |
| Data-EnvSampler-Poli... | 0.744          |
| Data-EnvTrajs-Averag... | 148            |
| Data-EnvTrajs-MaxReturn | 268            |
| Data-EnvTrajs-MinReturn | 13.4           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 89.9           |
| Data-TimeEnvSampleProc  | 0.00111        |
| Data-TimeEnvSampling    | 1.1            |
| Iteration               | 35             |
| ItrTime                 | 37.6           |
| LossAfter               | -0.018988933   |
| LossBefore              | -7.0717983e-06 |
| Model-TimeModelFit      | 33.5           |
| ModelSampler-n_times... | 1440000        |
| Policy-AverageAbsPol... | 0.7107306      |
| Policy-AverageDiscou... | -8.84          |
| Policy-AveragePolicyStd | 0.49258512     |
| Policy-AverageReturn    | -9.34          |
| Policy-MaxReturn        | 102            |
| Policy-MinReturn        | -236           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 95.5           |
| Policy-TimeAlgoOpt      | 0.637          |
| Policy-TimeSampleProc   | 0.556          |
| Policy-TimeSampling     | 1.81           |
| Policy-TimeStep         | 3.06           |
| Time                    | 1.07e+03       |
| n_timesteps             | 36000          |
--------------------------------------------

 ---------------- Iteration 36 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 360 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 361 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 362 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 363 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 364 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 365 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 366 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 367 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 368 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 369 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.35           |
| Data-EnvSampler-Poli... | 0.768          |
| Data-EnvTrajs-Averag... | 91.5           |
| Data-EnvTrajs-MaxReturn | 152            |
| Data-EnvTrajs-MinReturn | 42.3           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 35.8           |
| Data-TimeEnvSampleProc  | 0.00126        |
| Data-TimeEnvSampling    | 1.15           |
| Iteration               | 36             |
| ItrTime                 | 36.7           |
| LossAfter               | -0.019306723   |
| LossBefore              | -6.8698446e-06 |
| Model-TimeModelFit      | 32.5           |
| ModelSampler-n_times... | 1480000        |
| Policy-AverageAbsPol... | 0.75951385     |
| Policy-AverageDiscou... | 3.34           |
| Policy-AveragePolicyStd | 0.48301122     |
| Policy-AverageReturn    | 29.9           |
| Policy-MaxReturn        | 108            |
| Policy-MinReturn        | -69.3          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 44.9           |
| Policy-TimeAlgoOpt      | 0.612          |
| Policy-TimeSampleProc   | 0.597          |
| Policy-TimeSampling     | 1.77           |
| Policy-TimeStep         | 3.03           |
| Time                    | 1.11e+03       |
| n_timesteps             | 37000          |
--------------------------------------------

 ---------------- Iteration 37 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 370 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 371 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 372 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 373 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 374 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 375 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 376 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 377 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 378 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 379 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.335         |
| Data-EnvSampler-Poli... | 0.741         |
| Data-EnvTrajs-Averag... | 116           |
| Data-EnvTrajs-MaxReturn | 204           |
| Data-EnvTrajs-MinReturn | -35.1         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 93            |
| Data-TimeEnvSampleProc  | 0.00107       |
| Data-TimeEnvSampling    | 1.11          |
| Iteration               | 37            |
| ItrTime                 | 37            |
| LossAfter               | -0.019509146  |
| LossBefore              | -6.679852e-06 |
| Model-TimeModelFit      | 32.8          |
| ModelSampler-n_times... | 1520000       |
| Policy-AverageAbsPol... | 0.7404271     |
| Policy-AverageDiscou... | 71.9          |
| Policy-AveragePolicyStd | 0.47405106    |
| Policy-AverageReturn    | 159           |
| Policy-MaxReturn        | 319           |
| Policy-MinReturn        | -87.3         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 113           |
| Policy-TimeAlgoOpt      | 0.648         |
| Policy-TimeSampleProc   | 0.463         |
| Policy-TimeSampling     | 1.94          |
| Policy-TimeStep         | 3.09          |
| Time                    | 1.14e+03      |
| n_timesteps             | 38000         |
-------------------------------------------

 ---------------- Iteration 38 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 380 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 381 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 382 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 383 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 384 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 385 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 386 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 387 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 388 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 389 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.312          |
| Data-EnvSampler-Poli... | 0.758          |
| Data-EnvTrajs-Averag... | 110            |
| Data-EnvTrajs-MaxReturn | 219            |
| Data-EnvTrajs-MinReturn | 18.1           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 78.6           |
| Data-TimeEnvSampleProc  | 0.00112        |
| Data-TimeEnvSampling    | 1.1            |
| Iteration               | 38             |
| ItrTime                 | 36.3           |
| LossAfter               | -0.018825075   |
| LossBefore              | -6.5306663e-06 |
| Model-TimeModelFit      | 32.2           |
| ModelSampler-n_times... | 1560000        |
| Policy-AverageAbsPol... | 0.76597804     |
| Policy-AverageDiscou... | 22             |
| Policy-AveragePolicyStd | 0.46698835     |
| Policy-AverageReturn    | 73.1           |
| Policy-MaxReturn        | 193            |
| Policy-MinReturn        | -122           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 89.1           |
| Policy-TimeAlgoOpt      | 0.661          |
| Policy-TimeSampleProc   | 0.604          |
| Policy-TimeSampling     | 1.68           |
| Policy-TimeStep         | 2.98           |
| Time                    | 1.18e+03       |
| n_timesteps             | 39000          |
--------------------------------------------

 ---------------- Iteration 39 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 390 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 391 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 392 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 393 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 394 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 395 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 396 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 397 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 398 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 399 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.381          |
| Data-EnvSampler-Poli... | 0.919          |
| Data-EnvTrajs-Averag... | 164            |
| Data-EnvTrajs-MaxReturn | 264            |
| Data-EnvTrajs-MinReturn | 74.8           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 72.4           |
| Data-TimeEnvSampleProc  | 0.00127        |
| Data-TimeEnvSampling    | 1.35           |
| Iteration               | 39             |
| ItrTime                 | 37             |
| LossAfter               | -0.018615544   |
| LossBefore              | -6.3562334e-06 |
| Model-TimeModelFit      | 33             |
| ModelSampler-n_times... | 1600000        |
| Policy-AverageAbsPol... | 0.80846965     |
| Policy-AverageDiscou... | 94.6           |
| Policy-AveragePolicyStd | 0.4581817      |
| Policy-AverageReturn    | 225            |
| Policy-MaxReturn        | 388            |
| Policy-MinReturn        | -22.2          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 81.5           |
| Policy-TimeAlgoOpt      | 0.549          |
| Policy-TimeSampleProc   | 0.561          |
| Policy-TimeSampling     | 1.55           |
| Policy-TimeStep         | 2.71           |
| Time                    | 1.22e+03       |
| n_timesteps             | 40000          |
--------------------------------------------

 ---------------- Iteration 40 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 400 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 401 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 402 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 403 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 404 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 405 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 406 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 407 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 408 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 409 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.303          |
| Data-EnvSampler-Poli... | 0.723          |
| Data-EnvTrajs-Averag... | -8.2           |
| Data-EnvTrajs-MaxReturn | 185            |
| Data-EnvTrajs-MinReturn | -123           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 109            |
| Data-TimeEnvSampleProc  | 0.001          |
| Data-TimeEnvSampling    | 1.06           |
| Iteration               | 40             |
| ItrTime                 | 35.8           |
| LossAfter               | -0.017758114   |
| LossBefore              | -6.2279155e-06 |
| Model-TimeModelFit      | 32             |
| ModelSampler-n_times... | 1640000        |
| Policy-AverageAbsPol... | 0.82065135     |
| Policy-AverageDiscou... | 69.5           |
| Policy-AveragePolicyStd | 0.45299628     |
| Policy-AverageReturn    | 172            |
| Policy-MaxReturn        | 308            |
| Policy-MinReturn        | 5.63           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 74.3           |
| Policy-TimeAlgoOpt      | 0.619          |
| Policy-TimeSampleProc   | 0.434          |
| Policy-TimeSampling     | 1.6            |
| Policy-TimeStep         | 2.7            |
| Time                    | 1.25e+03       |
| n_timesteps             | 41000          |
--------------------------------------------

 ---------------- Iteration 41 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 410 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 411 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 412 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 413 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 414 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 415 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 416 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 417 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 418 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 419 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.317         |
| Data-EnvSampler-Poli... | 0.713         |
| Data-EnvTrajs-Averag... | 89.6          |
| Data-EnvTrajs-MaxReturn | 223           |
| Data-EnvTrajs-MinReturn | -67.4         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 104           |
| Data-TimeEnvSampleProc  | 0.00116       |
| Data-TimeEnvSampling    | 1.06          |
| Iteration               | 41            |
| ItrTime                 | 34.7          |
| LossAfter               | -0.021890342  |
| LossBefore              | -6.005603e-06 |
| Model-TimeModelFit      | 31.1          |
| ModelSampler-n_times... | 1680000       |
| Policy-AverageAbsPol... | 0.823994      |
| Policy-AverageDiscou... | 73.7          |
| Policy-AveragePolicyStd | 0.44408137    |
| Policy-AverageReturn    | 163           |
| Policy-MaxReturn        | 1.29e+03      |
| Policy-MinReturn        | -97.2         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 269           |
| Policy-TimeAlgoOpt      | 0.597         |
| Policy-TimeSampleProc   | 0.365         |
| Policy-TimeSampling     | 1.59          |
| Policy-TimeStep         | 2.58          |
| Time                    | 1.29e+03      |
| n_timesteps             | 42000         |
-------------------------------------------

 ---------------- Iteration 42 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 420 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 421 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 422 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 423 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 424 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 425 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 426 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 427 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 428 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 429 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.295          |
| Data-EnvSampler-Poli... | 0.624          |
| Data-EnvTrajs-Averag... | -20.5          |
| Data-EnvTrajs-MaxReturn | 183            |
| Data-EnvTrajs-MinReturn | -133           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 118            |
| Data-TimeEnvSampleProc  | 0.000816       |
| Data-TimeEnvSampling    | 0.948          |
| Iteration               | 42             |
| ItrTime                 | 34.8           |
| LossAfter               | -0.021627372   |
| LossBefore              | -5.9296112e-06 |
| Model-TimeModelFit      | 30.9           |
| ModelSampler-n_times... | 1720000        |
| Policy-AverageAbsPol... | 0.7966582      |
| Policy-AverageDiscou... | 25.8           |
| Policy-AveragePolicyStd | 0.44003877     |
| Policy-AverageReturn    | 54.5           |
| Policy-MaxReturn        | 243            |
| Policy-MinReturn        | -131           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 96.4           |
| Policy-TimeAlgoOpt      | 0.569          |
| Policy-TimeSampleProc   | 0.603          |
| Policy-TimeSampling     | 1.75           |
| Policy-TimeStep         | 3              |
| Time                    | 1.32e+03       |
| n_timesteps             | 43000          |
--------------------------------------------

 ---------------- Iteration 43 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 430 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 431 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 432 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 433 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 434 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 435 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 436 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 437 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 438 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 439 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.282          |
| Data-EnvSampler-Poli... | 0.576          |
| Data-EnvTrajs-Averag... | 35.2           |
| Data-EnvTrajs-MaxReturn | 208            |
| Data-EnvTrajs-MinReturn | -55.6          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 100            |
| Data-TimeEnvSampleProc  | 0.000724       |
| Data-TimeEnvSampling    | 0.887          |
| Iteration               | 43             |
| ItrTime                 | 35.7           |
| LossAfter               | -0.018079095   |
| LossBefore              | -5.7538023e-06 |
| Model-TimeModelFit      | 31.9           |
| ModelSampler-n_times... | 1760000        |
| Policy-AverageAbsPol... | 0.80050373     |
| Policy-AverageDiscou... | 69             |
| Policy-AveragePolicyStd | 0.4326044      |
| Policy-AverageReturn    | 180            |
| Policy-MaxReturn        | 256            |
| Policy-MinReturn        | 61.2           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 50.7           |
| Policy-TimeAlgoOpt      | 0.658          |
| Policy-TimeSampleProc   | 0.459          |
| Policy-TimeSampling     | 1.73           |
| Policy-TimeStep         | 2.89           |
| Time                    | 1.36e+03       |
| n_timesteps             | 44000          |
--------------------------------------------

 ---------------- Iteration 44 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 440 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 441 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 442 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 443 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 444 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 445 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 446 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 447 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 448 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 449 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.283          |
| Data-EnvSampler-Poli... | 0.627          |
| Data-EnvTrajs-Averag... | 136            |
| Data-EnvTrajs-MaxReturn | 283            |
| Data-EnvTrajs-MinReturn | -75.2          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 127            |
| Data-TimeEnvSampleProc  | 0.000638       |
| Data-TimeEnvSampling    | 0.939          |
| Iteration               | 44             |
| ItrTime                 | 35.3           |
| LossAfter               | -0.020151773   |
| LossBefore              | -5.6631675e-06 |
| Model-TimeModelFit      | 31.7           |
| ModelSampler-n_times... | 1800000        |
| Policy-AverageAbsPol... | 0.74518895     |
| Policy-AverageDiscou... | 30.1           |
| Policy-AveragePolicyStd | 0.42851692     |
| Policy-AverageReturn    | 46.5           |
| Policy-MaxReturn        | 310            |
| Policy-MinReturn        | -224           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 170            |
| Policy-TimeAlgoOpt      | 0.592          |
| Policy-TimeSampleProc   | 0.493          |
| Policy-TimeSampling     | 1.55           |
| Policy-TimeStep         | 2.7            |
| Time                    | 1.39e+03       |
| n_timesteps             | 45000          |
--------------------------------------------

 ---------------- Iteration 45 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 450 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 451 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 452 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 453 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 454 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 455 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 456 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 457 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 458 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 459 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.289          |
| Data-EnvSampler-Poli... | 0.622          |
| Data-EnvTrajs-Averag... | 113            |
| Data-EnvTrajs-MaxReturn | 221            |
| Data-EnvTrajs-MinReturn | -111           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 122            |
| Data-TimeEnvSampleProc  | 0.000587       |
| Data-TimeEnvSampling    | 0.942          |
| Iteration               | 45             |
| ItrTime                 | 35.1           |
| LossAfter               | -0.020487117   |
| LossBefore              | -5.5217893e-06 |
| Model-TimeModelFit      | 31.5           |
| ModelSampler-n_times... | 1840000        |
| Policy-AverageAbsPol... | 0.77321583     |
| Policy-AverageDiscou... | 4.13           |
| Policy-AveragePolicyStd | 0.42191964     |
| Policy-AverageReturn    | -1.14          |
| Policy-MaxReturn        | 217            |
| Policy-MinReturn        | -265           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 142            |
| Policy-TimeAlgoOpt      | 0.619          |
| Policy-TimeSampleProc   | 0.552          |
| Policy-TimeSampling     | 1.48           |
| Policy-TimeStep         | 2.7            |
| Time                    | 1.43e+03       |
| n_timesteps             | 46000          |
--------------------------------------------

 ---------------- Iteration 46 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 460 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 461 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 462 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 463 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 464 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 465 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 466 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 467 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 468 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 469 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.285         |
| Data-EnvSampler-Poli... | 0.586         |
| Data-EnvTrajs-Averag... | 107           |
| Data-EnvTrajs-MaxReturn | 235           |
| Data-EnvTrajs-MinReturn | -11.6         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 80.4          |
| Data-TimeEnvSampleProc  | 0.000983      |
| Data-TimeEnvSampling    | 0.902         |
| Iteration               | 46            |
| ItrTime                 | 35.4          |
| LossAfter               | -0.020131335  |
| LossBefore              | -5.394867e-06 |
| Model-TimeModelFit      | 31.6          |
| ModelSampler-n_times... | 1880000       |
| Policy-AverageAbsPol... | 0.7783317     |
| Policy-AverageDiscou... | 40.6          |
| Policy-AveragePolicyStd | 0.41701415    |
| Policy-AverageReturn    | 119           |
| Policy-MaxReturn        | 316           |
| Policy-MinReturn        | -327          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 131           |
| Policy-TimeAlgoOpt      | 0.611         |
| Policy-TimeSampleProc   | 0.613         |
| Policy-TimeSampling     | 1.55          |
| Policy-TimeStep         | 2.85          |
| Time                    | 1.46e+03      |
| n_timesteps             | 47000         |
-------------------------------------------

 ---------------- Iteration 47 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 470 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 471 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 472 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 473 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 474 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 475 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 476 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 477 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 478 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 479 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.278          |
| Data-EnvSampler-Poli... | 0.564          |
| Data-EnvTrajs-Averag... | 132            |
| Data-EnvTrajs-MaxReturn | 249            |
| Data-EnvTrajs-MinReturn | -55.4          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 108            |
| Data-TimeEnvSampleProc  | 0.00101        |
| Data-TimeEnvSampling    | 0.873          |
| Iteration               | 47             |
| ItrTime                 | 36.4           |
| LossAfter               | -0.025234153   |
| LossBefore              | -5.3601457e-06 |
| Model-TimeModelFit      | 32.6           |
| ModelSampler-n_times... | 1920000        |
| Policy-AverageAbsPol... | 0.7317917      |
| Policy-AverageDiscou... | 48.5           |
| Policy-AveragePolicyStd | 0.41559273     |
| Policy-AverageReturn    | 234            |
| Policy-MaxReturn        | 1.7e+03        |
| Policy-MinReturn        | -231           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 464            |
| Policy-TimeAlgoOpt      | 0.555          |
| Policy-TimeSampleProc   | 0.638          |
| Policy-TimeSampling     | 1.65           |
| Policy-TimeStep         | 2.89           |
| Time                    | 1.5e+03        |
| n_timesteps             | 48000          |
--------------------------------------------

 ---------------- Iteration 48 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 480 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 481 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 482 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 483 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 484 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 485 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 486 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 487 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 488 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 489 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.273          |
| Data-EnvSampler-Poli... | 0.571          |
| Data-EnvTrajs-Averag... | 71.5           |
| Data-EnvTrajs-MaxReturn | 228            |
| Data-EnvTrajs-MinReturn | -119           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 138            |
| Data-TimeEnvSampleProc  | 0.000942       |
| Data-TimeEnvSampling    | 0.872          |
| Iteration               | 48             |
| ItrTime                 | 35.5           |
| LossAfter               | -0.020030906   |
| LossBefore              | -5.2212813e-06 |
| Model-TimeModelFit      | 31.8           |
| ModelSampler-n_times... | 1960000        |
| Policy-AverageAbsPol... | 0.7405876      |
| Policy-AverageDiscou... | -47.7          |
| Policy-AveragePolicyStd | 0.410111       |
| Policy-AverageReturn    | -122           |
| Policy-MaxReturn        | 3.92           |
| Policy-MinReturn        | -287           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 72.7           |
| Policy-TimeAlgoOpt      | 0.571          |
| Policy-TimeSampleProc   | 0.515          |
| Policy-TimeSampling     | 1.7            |
| Policy-TimeStep         | 2.84           |
| Time                    | 1.54e+03       |
| n_timesteps             | 49000          |
--------------------------------------------

 ---------------- Iteration 49 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 490 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 491 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 492 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 493 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 494 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 495 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 496 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 497 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 498 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 499 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.274          |
| Data-EnvSampler-Poli... | 0.605          |
| Data-EnvTrajs-Averag... | 115            |
| Data-EnvTrajs-MaxReturn | 243            |
| Data-EnvTrajs-MinReturn | -147           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 138            |
| Data-TimeEnvSampleProc  | 0.000749       |
| Data-TimeEnvSampling    | 0.909          |
| Iteration               | 49             |
| ItrTime                 | 35.3           |
| LossAfter               | -0.025199078   |
| LossBefore              | -5.1192765e-06 |
| Model-TimeModelFit      | 31.7           |
| ModelSampler-n_times... | 2000000        |
| Policy-AverageAbsPol... | 0.76088023     |
| Policy-AverageDiscou... | -24.9          |
| Policy-AveragePolicyStd | 0.4055501      |
| Policy-AverageReturn    | -12.8          |
| Policy-MaxReturn        | 498            |
| Policy-MinReturn        | -443           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 219            |
| Policy-TimeAlgoOpt      | 0.618          |
| Policy-TimeSampleProc   | 0.403          |
| Policy-TimeSampling     | 1.64           |
| Policy-TimeStep         | 2.73           |
| Time                    | 1.57e+03       |
| n_timesteps             | 50000          |
--------------------------------------------

 ---------------- Iteration 50 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 500 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 501 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 502 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 503 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 504 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 505 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 506 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 507 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 508 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 509 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.274          |
| Data-EnvSampler-Poli... | 0.576          |
| Data-EnvTrajs-Averag... | 116            |
| Data-EnvTrajs-MaxReturn | 288            |
| Data-EnvTrajs-MinReturn | -69.5          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 115            |
| Data-TimeEnvSampleProc  | 0.000999       |
| Data-TimeEnvSampling    | 0.879          |
| Iteration               | 50             |
| ItrTime                 | 30.3           |
| LossAfter               | -0.020992756   |
| LossBefore              | -4.9264845e-06 |
| Model-TimeModelFit      | 27.3           |
| ModelSampler-n_times... | 2040000        |
| Policy-AverageAbsPol... | 0.82029        |
| Policy-AverageDiscou... | 93.4           |
| Policy-AveragePolicyStd | 0.39726135     |
| Policy-AverageReturn    | 222            |
| Policy-MaxReturn        | 370            |
| Policy-MinReturn        | -96.3          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 103            |
| Policy-TimeAlgoOpt      | 0.507          |
| Policy-TimeSampleProc   | 0.361          |
| Policy-TimeSampling     | 1.28           |
| Policy-TimeStep         | 2.19           |
| Time                    | 1.6e+03        |
| n_timesteps             | 51000          |
--------------------------------------------
Training finished
