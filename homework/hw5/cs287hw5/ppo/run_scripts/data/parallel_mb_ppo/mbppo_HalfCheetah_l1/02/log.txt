Logging to /home/vincent/workplace/CS_287_-_Advanced_Robotics/homework/hw5/cs287hw5/ppo/run_scripts/data/parallel_mb_ppo/mbppo_HalfCheetah_l1//02

 ---------------- Iteration 0 ----------------
Obtaining random samples from the environment...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 0 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 1 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 2 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 3 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 4 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 5 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 6 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 7 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 8 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 9 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.113          |
| Data-EnvSampler-Poli... | 0.0358         |
| Data-EnvTrajs-Averag... | -56.2          |
| Data-EnvTrajs-MaxReturn | -20.4          |
| Data-EnvTrajs-MinReturn | -110           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 31             |
| Data-TimeEnvSampleProc  | 0.000465       |
| Data-TimeEnvSampling    | 0.158          |
| Iteration               | 0              |
| ItrTime                 | 7.98           |
| LossAfter               | -0.017832678   |
| LossBefore              | -1.3993712e-05 |
| Model-TimeModelFit      | 2.6            |
| ModelSampler-n_times... | 40000          |
| Policy-AverageAbsPol... | 0.8157834      |
| Policy-AverageDiscou... | 194            |
| Policy-AveragePolicyStd | 0.98128355     |
| Policy-AverageReturn    | 663            |
| Policy-MaxReturn        | 695            |
| Policy-MinReturn        | 628            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 19             |
| Policy-TimeAlgoOpt      | 0.978          |
| Policy-TimeSampleProc   | 0.438          |
| Policy-TimeSampling     | 3.78           |
| Policy-TimeStep         | 5.23           |
| Time                    | 7.98           |
| n_timesteps             | 1000           |
--------------------------------------------

 ---------------- Iteration 1 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 10 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 11 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 12 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 13 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 14 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 15 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 16 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 17 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 18 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 19 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.213          |
| Data-EnvSampler-Poli... | 0.498          |
| Data-EnvTrajs-Averag... | -74.7          |
| Data-EnvTrajs-MaxReturn | -14.4          |
| Data-EnvTrajs-MinReturn | -122           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 39.8           |
| Data-TimeEnvSampleProc  | 0.000923       |
| Data-TimeEnvSampling    | 0.732          |
| Iteration               | 1              |
| ItrTime                 | 7.07           |
| LossAfter               | -0.011716609   |
| LossBefore              | -1.3657494e-05 |
| Model-TimeModelFit      | 3.84           |
| ModelSampler-n_times... | 80000          |
| Policy-AverageAbsPol... | 0.7055254      |
| Policy-AverageDiscou... | -12.7          |
| Policy-AveragePolicyStd | 0.945996       |
| Policy-AverageReturn    | -29.6          |
| Policy-MaxReturn        | -6.24          |
| Policy-MinReturn        | -62.4          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 15             |
| Policy-TimeAlgoOpt      | 0.597          |
| Policy-TimeSampleProc   | 0.361          |
| Policy-TimeSampling     | 1.49           |
| Policy-TimeStep         | 2.49           |
| Time                    | 15.2           |
| n_timesteps             | 2000           |
--------------------------------------------

 ---------------- Iteration 2 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 20 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 21 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 22 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 23 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 24 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 25 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 26 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 27 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 28 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 29 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.225          |
| Data-EnvSampler-Poli... | 0.42           |
| Data-EnvTrajs-Averag... | -62.2          |
| Data-EnvTrajs-MaxReturn | -45.1          |
| Data-EnvTrajs-MinReturn | -119           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 28.6           |
| Data-TimeEnvSampleProc  | 0.000642       |
| Data-TimeEnvSampling    | 0.667          |
| Iteration               | 2              |
| ItrTime                 | 9.3            |
| LossAfter               | -0.016222816   |
| LossBefore              | -1.3581816e-05 |
| Model-TimeModelFit      | 6.19           |
| ModelSampler-n_times... | 120000         |
| Policy-AverageAbsPol... | 0.68285775     |
| Policy-AverageDiscou... | 186            |
| Policy-AveragePolicyStd | 0.9400789      |
| Policy-AverageReturn    | 961            |
| Policy-MaxReturn        | 1.75e+03       |
| Policy-MinReturn        | -299           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 633            |
| Policy-TimeAlgoOpt      | 0.615          |
| Policy-TimeSampleProc   | 0.28           |
| Policy-TimeSampling     | 1.51           |
| Policy-TimeStep         | 2.44           |
| Time                    | 24.5           |
| n_timesteps             | 3000           |
--------------------------------------------

 ---------------- Iteration 3 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 30 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 31 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 32 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 33 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 34 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 35 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 36 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 37 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 38 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 39 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.227           |
| Data-EnvSampler-Poli... | 0.477           |
| Data-EnvTrajs-Averag... | -57.9           |
| Data-EnvTrajs-MaxReturn | 5.99            |
| Data-EnvTrajs-MinReturn | -168            |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 60.8            |
| Data-TimeEnvSampleProc  | 0.000682        |
| Data-TimeEnvSampling    | 0.727           |
| Iteration               | 3               |
| ItrTime                 | 11.6            |
| LossAfter               | -0.014003563    |
| LossBefore              | -1.33318945e-05 |
| Model-TimeModelFit      | 8.21            |
| ModelSampler-n_times... | 160000          |
| Policy-AverageAbsPol... | 0.6935812       |
| Policy-AverageDiscou... | 472             |
| Policy-AveragePolicyStd | 0.9185401       |
| Policy-AverageReturn    | 1.4e+03         |
| Policy-MaxReturn        | 1.6e+03         |
| Policy-MinReturn        | 1.13e+03        |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 121             |
| Policy-TimeAlgoOpt      | 0.541           |
| Policy-TimeSampleProc   | 0.571           |
| Policy-TimeSampling     | 1.53            |
| Policy-TimeStep         | 2.68            |
| Time                    | 36.1            |
| n_timesteps             | 4000            |
---------------------------------------------

 ---------------- Iteration 4 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 40 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 41 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 42 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 43 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 44 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 45 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 46 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 47 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 48 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 49 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.241          |
| Data-EnvSampler-Poli... | 0.471          |
| Data-EnvTrajs-Averag... | -103           |
| Data-EnvTrajs-MaxReturn | -49.1          |
| Data-EnvTrajs-MinReturn | -164           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 45.5           |
| Data-TimeEnvSampleProc  | 0.000777       |
| Data-TimeEnvSampling    | 0.737          |
| Iteration               | 4              |
| ItrTime                 | 13.5           |
| LossAfter               | -0.013146854   |
| LossBefore              | -1.3014687e-05 |
| Model-TimeModelFit      | 10.3           |
| ModelSampler-n_times... | 200000         |
| Policy-AverageAbsPol... | 0.66883856     |
| Policy-AverageDiscou... | 74.6           |
| Policy-AveragePolicyStd | 0.8896317      |
| Policy-AverageReturn    | 245            |
| Policy-MaxReturn        | 549            |
| Policy-MinReturn        | 47.7           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 132            |
| Policy-TimeAlgoOpt      | 0.539          |
| Policy-TimeSampleProc   | 0.343          |
| Policy-TimeSampling     | 1.55           |
| Policy-TimeStep         | 2.49           |
| Time                    | 49.6           |
| n_timesteps             | 5000           |
--------------------------------------------

 ---------------- Iteration 5 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 50 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 51 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 52 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 53 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 54 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 55 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 56 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 57 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 58 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 59 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.255          |
| Data-EnvSampler-Poli... | 0.538          |
| Data-EnvTrajs-Averag... | -85            |
| Data-EnvTrajs-MaxReturn | -18.4          |
| Data-EnvTrajs-MinReturn | -173           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 58             |
| Data-TimeEnvSampleProc  | 0.0009         |
| Data-TimeEnvSampling    | 0.82           |
| Iteration               | 5              |
| ItrTime                 | 16             |
| LossAfter               | -0.014340861   |
| LossBefore              | -1.2675303e-05 |
| Model-TimeModelFit      | 12.8           |
| ModelSampler-n_times... | 240000         |
| Policy-AverageAbsPol... | 0.61838275     |
| Policy-AverageDiscou... | -78.2          |
| Policy-AveragePolicyStd | 0.8593658      |
| Policy-AverageReturn    | -188           |
| Policy-MaxReturn        | -138           |
| Policy-MinReturn        | -271           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 35.6           |
| Policy-TimeAlgoOpt      | 0.55           |
| Policy-TimeSampleProc   | 0.267          |
| Policy-TimeSampling     | 1.51           |
| Policy-TimeStep         | 2.35           |
| Time                    | 65.6           |
| n_timesteps             | 6000           |
--------------------------------------------

 ---------------- Iteration 6 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 60 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 61 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 62 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 63 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 64 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 65 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 66 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 67 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 68 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 69 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.252          |
| Data-EnvSampler-Poli... | 0.524          |
| Data-EnvTrajs-Averag... | -53.6          |
| Data-EnvTrajs-MaxReturn | -23            |
| Data-EnvTrajs-MinReturn | -103           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 27.2           |
| Data-TimeEnvSampleProc  | 0.000934       |
| Data-TimeEnvSampling    | 0.81           |
| Iteration               | 6              |
| ItrTime                 | 18.4           |
| LossAfter               | -0.013176355   |
| LossBefore              | -1.2483783e-05 |
| Model-TimeModelFit      | 14.9           |
| ModelSampler-n_times... | 280000         |
| Policy-AverageAbsPol... | 0.58402497     |
| Policy-AverageDiscou... | -88.4          |
| Policy-AveragePolicyStd | 0.84035224     |
| Policy-AverageReturn    | -207           |
| Policy-MaxReturn        | -94.4          |
| Policy-MinReturn        | -298           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 51.4           |
| Policy-TimeAlgoOpt      | 0.611          |
| Policy-TimeSampleProc   | 0.537          |
| Policy-TimeSampling     | 1.54           |
| Policy-TimeStep         | 2.73           |
| Time                    | 84             |
| n_timesteps             | 7000           |
--------------------------------------------

 ---------------- Iteration 7 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 70 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 71 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 72 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 73 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 74 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 75 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 76 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 77 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 78 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 79 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.283          |
| Data-EnvSampler-Poli... | 0.593          |
| Data-EnvTrajs-Averag... | -108           |
| Data-EnvTrajs-MaxReturn | -73.1          |
| Data-EnvTrajs-MinReturn | -167           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 32.2           |
| Data-TimeEnvSampleProc  | 0.000588       |
| Data-TimeEnvSampling    | 0.903          |
| Iteration               | 7              |
| ItrTime                 | 21             |
| LossAfter               | -0.013334985   |
| LossBefore              | -1.2271179e-05 |
| Model-TimeModelFit      | 17.3           |
| ModelSampler-n_times... | 320000         |
| Policy-AverageAbsPol... | 0.54352593     |
| Policy-AverageDiscou... | -177           |
| Policy-AveragePolicyStd | 0.82514536     |
| Policy-AverageReturn    | -419           |
| Policy-MaxReturn        | -334           |
| Policy-MinReturn        | -491           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 45.1           |
| Policy-TimeAlgoOpt      | 0.603          |
| Policy-TimeSampleProc   | 0.523          |
| Policy-TimeSampling     | 1.58           |
| Policy-TimeStep         | 2.73           |
| Time                    | 105            |
| n_timesteps             | 8000           |
--------------------------------------------

 ---------------- Iteration 8 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 80 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 81 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 82 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 83 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 84 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 85 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 86 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 87 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 88 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 89 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.318          |
| Data-EnvSampler-Poli... | 0.684          |
| Data-EnvTrajs-Averag... | -88.7          |
| Data-EnvTrajs-MaxReturn | -52.9          |
| Data-EnvTrajs-MinReturn | -173           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 42.9           |
| Data-TimeEnvSampleProc  | 0.00111        |
| Data-TimeEnvSampling    | 1.03           |
| Iteration               | 8              |
| ItrTime                 | 23.1           |
| LossAfter               | -0.014934903   |
| LossBefore              | -1.2021179e-05 |
| Model-TimeModelFit      | 19.5           |
| ModelSampler-n_times... | 360000         |
| Policy-AverageAbsPol... | 0.53618586     |
| Policy-AverageDiscou... | -2.61          |
| Policy-AveragePolicyStd | 0.8061759      |
| Policy-AverageReturn    | 16.9           |
| Policy-MaxReturn        | 86.3           |
| Policy-MinReturn        | -75.4          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 39.6           |
| Policy-TimeAlgoOpt      | 0.652          |
| Policy-TimeSampleProc   | 0.297          |
| Policy-TimeSampling     | 1.58           |
| Policy-TimeStep         | 2.55           |
| Time                    | 128            |
| n_timesteps             | 9000           |
--------------------------------------------

 ---------------- Iteration 9 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 90 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 91 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 92 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 93 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 94 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 95 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 96 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 97 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 98 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 99 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.28            |
| Data-EnvSampler-Poli... | 0.581           |
| Data-EnvTrajs-Averag... | -67.4           |
| Data-EnvTrajs-MaxReturn | -6.44           |
| Data-EnvTrajs-MinReturn | -118            |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 38.9            |
| Data-TimeEnvSampleProc  | 0.000572        |
| Data-TimeEnvSampling    | 0.89            |
| Iteration               | 9               |
| ItrTime                 | 25.2            |
| LossAfter               | -0.01519794     |
| LossBefore              | -1.17189375e-05 |
| Model-TimeModelFit      | 21.6            |
| ModelSampler-n_times... | 400000          |
| Policy-AverageAbsPol... | 0.53800344      |
| Policy-AverageDiscou... | -74.9           |
| Policy-AveragePolicyStd | 0.78208286      |
| Policy-AverageReturn    | -171            |
| Policy-MaxReturn        | -105            |
| Policy-MinReturn        | -233            |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 36.7            |
| Policy-TimeAlgoOpt      | 0.602           |
| Policy-TimeSampleProc   | 0.434           |
| Policy-TimeSampling     | 1.64            |
| Policy-TimeStep         | 2.72            |
| Time                    | 153             |
| n_timesteps             | 10000           |
---------------------------------------------

 ---------------- Iteration 10 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 100 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 101 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 102 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 103 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 104 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 105 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 106 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 107 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 108 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 109 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.294          |
| Data-EnvSampler-Poli... | 0.607          |
| Data-EnvTrajs-Averag... | -43.3          |
| Data-EnvTrajs-MaxReturn | -2.5           |
| Data-EnvTrajs-MinReturn | -74.9          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 29.1           |
| Data-TimeEnvSampleProc  | 0.000984       |
| Data-TimeEnvSampling    | 0.932          |
| Iteration               | 10             |
| ItrTime                 | 27.9           |
| LossAfter               | -0.015841905   |
| LossBefore              | -1.1460392e-05 |
| Model-TimeModelFit      | 24.3           |
| ModelSampler-n_times... | 440000         |
| Policy-AverageAbsPol... | 0.54860187     |
| Policy-AverageDiscou... | 67.4           |
| Policy-AveragePolicyStd | 0.76078        |
| Policy-AverageReturn    | 165            |
| Policy-MaxReturn        | 222            |
| Policy-MinReturn        | 18.9           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 51             |
| Policy-TimeAlgoOpt      | 0.64           |
| Policy-TimeSampleProc   | 0.339          |
| Policy-TimeSampling     | 1.61           |
| Policy-TimeStep         | 2.64           |
| Time                    | 181            |
| n_timesteps             | 11000          |
--------------------------------------------

 ---------------- Iteration 11 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 110 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 111 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 112 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 113 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 114 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 115 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 116 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 117 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 118 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 119 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.28          |
| Data-EnvSampler-Poli... | 0.575         |
| Data-EnvTrajs-Averag... | -40.8         |
| Data-EnvTrajs-MaxReturn | 2.19          |
| Data-EnvTrajs-MinReturn | -78           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 28.4          |
| Data-TimeEnvSampleProc  | 0.00102       |
| Data-TimeEnvSampling    | 0.885         |
| Iteration               | 11            |
| ItrTime                 | 31.1          |
| LossAfter               | -0.015124919  |
| LossBefore              | -1.118362e-05 |
| Model-TimeModelFit      | 27.3          |
| ModelSampler-n_times... | 480000        |
| Policy-AverageAbsPol... | 0.5704816     |
| Policy-AverageDiscou... | 17.2          |
| Policy-AveragePolicyStd | 0.7408728     |
| Policy-AverageReturn    | 62.9          |
| Policy-MaxReturn        | 151           |
| Policy-MinReturn        | -16.5         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 49.6          |
| Policy-TimeAlgoOpt      | 0.629         |
| Policy-TimeSampleProc   | 0.482         |
| Policy-TimeSampling     | 1.81          |
| Policy-TimeStep         | 2.94          |
| Time                    | 212           |
| n_timesteps             | 12000         |
-------------------------------------------

 ---------------- Iteration 12 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 120 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 121 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 122 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 123 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 124 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 125 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 126 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 127 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 128 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 129 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.305          |
| Data-EnvSampler-Poli... | 0.644          |
| Data-EnvTrajs-Averag... | -42.2          |
| Data-EnvTrajs-MaxReturn | 0.656          |
| Data-EnvTrajs-MinReturn | -117           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 39.8           |
| Data-TimeEnvSampleProc  | 0.00108        |
| Data-TimeEnvSampling    | 0.979          |
| Iteration               | 12             |
| ItrTime                 | 32.7           |
| LossAfter               | -0.01620017    |
| LossBefore              | -1.0937544e-05 |
| Model-TimeModelFit      | 28.7           |
| ModelSampler-n_times... | 520000         |
| Policy-AverageAbsPol... | 0.5999923      |
| Policy-AverageDiscou... | -26.2          |
| Policy-AveragePolicyStd | 0.71999526     |
| Policy-AverageReturn    | -56.3          |
| Policy-MaxReturn        | 38.9           |
| Policy-MinReturn        | -151           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 58.7           |
| Policy-TimeAlgoOpt      | 0.737          |
| Policy-TimeSampleProc   | 0.431          |
| Policy-TimeSampling     | 1.87           |
| Policy-TimeStep         | 3.07           |
| Time                    | 245            |
| n_timesteps             | 13000          |
--------------------------------------------

 ---------------- Iteration 13 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 130 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 131 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 132 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 133 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 134 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 135 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 136 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 137 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 138 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 139 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.32           |
| Data-EnvSampler-Poli... | 0.636          |
| Data-EnvTrajs-Averag... | -28.9          |
| Data-EnvTrajs-MaxReturn | 6.41           |
| Data-EnvTrajs-MinReturn | -77.4          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 31.1           |
| Data-TimeEnvSampleProc  | 0.000962       |
| Data-TimeEnvSampling    | 0.986          |
| Iteration               | 13             |
| ItrTime                 | 33.4           |
| LossAfter               | -0.014692481   |
| LossBefore              | -1.0759326e-05 |
| Model-TimeModelFit      | 29.4           |
| ModelSampler-n_times... | 560000         |
| Policy-AverageAbsPol... | 0.6151547      |
| Policy-AverageDiscou... | -84.9          |
| Policy-AveragePolicyStd | 0.7104815      |
| Policy-AverageReturn    | -203           |
| Policy-MaxReturn        | -105           |
| Policy-MinReturn        | -286           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 50.6           |
| Policy-TimeAlgoOpt      | 0.625          |
| Policy-TimeSampleProc   | 0.581          |
| Policy-TimeSampling     | 1.68           |
| Policy-TimeStep         | 3.01           |
| Time                    | 279            |
| n_timesteps             | 14000          |
--------------------------------------------

 ---------------- Iteration 14 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 140 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 141 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 142 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 143 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 144 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 145 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 146 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 147 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 148 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 149 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.292          |
| Data-EnvSampler-Poli... | 0.576          |
| Data-EnvTrajs-Averag... | -15            |
| Data-EnvTrajs-MaxReturn | 23.9           |
| Data-EnvTrajs-MinReturn | -56.2          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 34.2           |
| Data-TimeEnvSampleProc  | 0.000988       |
| Data-TimeEnvSampling    | 0.897          |
| Iteration               | 14             |
| ItrTime                 | 32.8           |
| LossAfter               | -0.01612273    |
| LossBefore              | -1.0531875e-05 |
| Model-TimeModelFit      | 29             |
| ModelSampler-n_times... | 600000         |
| Policy-AverageAbsPol... | 0.6247509      |
| Policy-AverageDiscou... | 20.4           |
| Policy-AveragePolicyStd | 0.6947981      |
| Policy-AverageReturn    | 57.6           |
| Policy-MaxReturn        | 135            |
| Policy-MinReturn        | -1.83          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 36.8           |
| Policy-TimeAlgoOpt      | 0.639          |
| Policy-TimeSampleProc   | 0.58           |
| Policy-TimeSampling     | 1.67           |
| Policy-TimeStep         | 2.94           |
| Time                    | 311            |
| n_timesteps             | 15000          |
--------------------------------------------

 ---------------- Iteration 15 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 150 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 151 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 152 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 153 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 154 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 155 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 156 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 157 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 158 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 159 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.283         |
| Data-EnvSampler-Poli... | 0.555         |
| Data-EnvTrajs-Averag... | -19.7         |
| Data-EnvTrajs-MaxReturn | 11.8          |
| Data-EnvTrajs-MinReturn | -61.4         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 27.3          |
| Data-TimeEnvSampleProc  | 0.00105       |
| Data-TimeEnvSampling    | 0.866         |
| Iteration               | 15            |
| ItrTime                 | 34.4          |
| LossAfter               | -0.017418435  |
| LossBefore              | -1.020937e-05 |
| Model-TimeModelFit      | 30.5          |
| ModelSampler-n_times... | 640000        |
| Policy-AverageAbsPol... | 0.58848476    |
| Policy-AverageDiscou... | -37.3         |
| Policy-AveragePolicyStd | 0.67167705    |
| Policy-AverageReturn    | -95           |
| Policy-MaxReturn        | -65.8         |
| Policy-MinReturn        | -120          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 15.2          |
| Policy-TimeAlgoOpt      | 0.602         |
| Policy-TimeSampleProc   | 0.65          |
| Policy-TimeSampling     | 1.68          |
| Policy-TimeStep         | 3.02          |
| Time                    | 346           |
| n_timesteps             | 16000         |
-------------------------------------------

 ---------------- Iteration 16 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 160 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 161 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 162 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 163 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 164 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 165 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 166 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 167 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 168 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 169 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Data-EnvSampler-EnvE... | 0.303        |
| Data-EnvSampler-Poli... | 0.645        |
| Data-EnvTrajs-Averag... | -57.6        |
| Data-EnvTrajs-MaxReturn | -5.86        |
| Data-EnvTrajs-MinReturn | -121         |
| Data-EnvTrajs-NumTrajs  | 5            |
| Data-EnvTrajs-StdReturn | 40.7         |
| Data-TimeEnvSampleProc  | 0.00109      |
| Data-TimeEnvSampling    | 0.98         |
| Iteration               | 16           |
| ItrTime                 | 34.3         |
| LossAfter               | -0.01803355  |
| LossBefore              | -9.94525e-06 |
| Model-TimeModelFit      | 30           |
| ModelSampler-n_times... | 680000       |
| Policy-AverageAbsPol... | 0.603342     |
| Policy-AverageDiscou... | -12.6        |
| Policy-AveragePolicyStd | 0.6535829    |
| Policy-AverageReturn    | -26.3        |
| Policy-MaxReturn        | 90.7         |
| Policy-MinReturn        | -105         |
| Policy-NumTrajs         | 20           |
| Policy-StdReturn        | 37.9         |
| Policy-TimeAlgoOpt      | 0.7          |
| Policy-TimeSampleProc   | 0.58         |
| Policy-TimeSampling     | 1.9          |
| Policy-TimeStep         | 3.26         |
| Time                    | 380          |
| n_timesteps             | 17000        |
------------------------------------------

 ---------------- Iteration 17 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 170 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 171 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 172 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 173 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 174 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 175 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 176 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 177 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 178 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 179 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.333         |
| Data-EnvSampler-Poli... | 0.765         |
| Data-EnvTrajs-Averag... | -58           |
| Data-EnvTrajs-MaxReturn | -6.34         |
| Data-EnvTrajs-MinReturn | -106          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 32.8          |
| Data-TimeEnvSampleProc  | 0.00122       |
| Data-TimeEnvSampling    | 1.13          |
| Iteration               | 17            |
| ItrTime                 | 34.3          |
| LossAfter               | -0.016477184  |
| LossBefore              | -9.679211e-06 |
| Model-TimeModelFit      | 29.9          |
| ModelSampler-n_times... | 720000        |
| Policy-AverageAbsPol... | 0.59663606    |
| Policy-AverageDiscou... | -8.64         |
| Policy-AveragePolicyStd | 0.63747686    |
| Policy-AverageReturn    | -10.6         |
| Policy-MaxReturn        | 126           |
| Policy-MinReturn        | -74.1         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 40.8          |
| Policy-TimeAlgoOpt      | 0.648         |
| Policy-TimeSampleProc   | 0.592         |
| Policy-TimeSampling     | 1.94          |
| Policy-TimeStep         | 3.24          |
| Time                    | 414           |
| n_timesteps             | 18000         |
-------------------------------------------

 ---------------- Iteration 18 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 180 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 181 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 182 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 183 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 184 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 185 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 186 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 187 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 188 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 189 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.352         |
| Data-EnvSampler-Poli... | 0.742         |
| Data-EnvTrajs-Averag... | 5.84          |
| Data-EnvTrajs-MaxReturn | 32.4          |
| Data-EnvTrajs-MinReturn | -9.43         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 14.3          |
| Data-TimeEnvSampleProc  | 0.000829      |
| Data-TimeEnvSampling    | 1.13          |
| Iteration               | 18            |
| ItrTime                 | 34.7          |
| LossAfter               | -0.014186133  |
| LossBefore              | -9.510696e-06 |
| Model-TimeModelFit      | 30.5          |
| ModelSampler-n_times... | 760000        |
| Policy-AverageAbsPol... | 0.5664664     |
| Policy-AverageDiscou... | -29.4         |
| Policy-AveragePolicyStd | 0.6244899     |
| Policy-AverageReturn    | -59.5         |
| Policy-MaxReturn        | 243           |
| Policy-MinReturn        | -136          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 76.8          |
| Policy-TimeAlgoOpt      | 0.676         |
| Policy-TimeSampleProc   | 0.467         |
| Policy-TimeSampling     | 1.9           |
| Policy-TimeStep         | 3.09          |
| Time                    | 449           |
| n_timesteps             | 19000         |
-------------------------------------------

 ---------------- Iteration 19 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 190 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 191 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 192 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 193 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 194 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 195 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 196 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 197 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 198 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 199 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.384         |
| Data-EnvSampler-Poli... | 0.788         |
| Data-EnvTrajs-Averag... | -14.9         |
| Data-EnvTrajs-MaxReturn | 5.53          |
| Data-EnvTrajs-MinReturn | -50.1         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 19.2          |
| Data-TimeEnvSampleProc  | 0.000675      |
| Data-TimeEnvSampling    | 1.21          |
| Iteration               | 19            |
| ItrTime                 | 34.9          |
| LossAfter               | -0.017092029  |
| LossBefore              | -9.208805e-06 |
| Model-TimeModelFit      | 30.8          |
| ModelSampler-n_times... | 800000        |
| Policy-AverageAbsPol... | 0.597145      |
| Policy-AverageDiscou... | 6.66          |
| Policy-AveragePolicyStd | 0.60809416    |
| Policy-AverageReturn    | 7.03          |
| Policy-MaxReturn        | 77.5          |
| Policy-MinReturn        | -39.5         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 29.1          |
| Policy-TimeAlgoOpt      | 0.616         |
| Policy-TimeSampleProc   | 0.563         |
| Policy-TimeSampling     | 1.71          |
| Policy-TimeStep         | 2.95          |
| Time                    | 484           |
| n_timesteps             | 20000         |
-------------------------------------------

 ---------------- Iteration 20 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 200 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 201 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 202 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 203 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 204 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 205 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 206 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 207 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 208 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 209 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.355         |
| Data-EnvSampler-Poli... | 0.813         |
| Data-EnvTrajs-Averag... | 3.77          |
| Data-EnvTrajs-MaxReturn | 44.5          |
| Data-EnvTrajs-MinReturn | -26.6         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 32.8          |
| Data-TimeEnvSampleProc  | 0.000824      |
| Data-TimeEnvSampling    | 1.21          |
| Iteration               | 20            |
| ItrTime                 | 35.7          |
| LossAfter               | -0.016523063  |
| LossBefore              | -8.986948e-06 |
| Model-TimeModelFit      | 31.6          |
| ModelSampler-n_times... | 840000        |
| Policy-AverageAbsPol... | 0.6175975     |
| Policy-AverageDiscou... | 20.5          |
| Policy-AveragePolicyStd | 0.5951345     |
| Policy-AverageReturn    | 51.1          |
| Policy-MaxReturn        | 135           |
| Policy-MinReturn        | -313          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 93.3          |
| Policy-TimeAlgoOpt      | 0.658         |
| Policy-TimeSampleProc   | 0.438         |
| Policy-TimeSampling     | 1.71          |
| Policy-TimeStep         | 2.85          |
| Time                    | 520           |
| n_timesteps             | 21000         |
-------------------------------------------

 ---------------- Iteration 21 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 210 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 211 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 212 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 213 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 214 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 215 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 216 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 217 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 218 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 219 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Data-EnvSampler-EnvE... | 0.394        |
| Data-EnvSampler-Poli... | 0.871        |
| Data-EnvTrajs-Averag... | 20.6         |
| Data-EnvTrajs-MaxReturn | 50.2         |
| Data-EnvTrajs-MinReturn | -9.7         |
| Data-EnvTrajs-NumTrajs  | 5            |
| Data-EnvTrajs-StdReturn | 25.7         |
| Data-TimeEnvSampleProc  | 0.000967     |
| Data-TimeEnvSampling    | 1.31         |
| Iteration               | 21           |
| ItrTime                 | 36.4         |
| LossAfter               | -0.015108099 |
| LossBefore              | -8.85725e-06 |
| Model-TimeModelFit      | 32.2         |
| ModelSampler-n_times... | 880000       |
| Policy-AverageAbsPol... | 0.62220097   |
| Policy-AverageDiscou... | -25.9        |
| Policy-AveragePolicyStd | 0.5871779    |
| Policy-AverageReturn    | -57.4        |
| Policy-MaxReturn        | 64.6         |
| Policy-MinReturn        | -164         |
| Policy-NumTrajs         | 20           |
| Policy-StdReturn        | 51.2         |
| Policy-TimeAlgoOpt      | 0.681        |
| Policy-TimeSampleProc   | 0.41         |
| Policy-TimeSampling     | 1.73         |
| Policy-TimeStep         | 2.86         |
| Time                    | 556          |
| n_timesteps             | 22000        |
------------------------------------------

 ---------------- Iteration 22 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 220 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 221 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 222 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 223 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 224 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 225 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 226 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 227 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 228 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 229 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.414         |
| Data-EnvSampler-Poli... | 0.805         |
| Data-EnvTrajs-Averag... | 10            |
| Data-EnvTrajs-MaxReturn | 30.2          |
| Data-EnvTrajs-MinReturn | -15.6         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 16.4          |
| Data-TimeEnvSampleProc  | 0.000958      |
| Data-TimeEnvSampling    | 1.26          |
| Iteration               | 22            |
| ItrTime                 | 35.3          |
| LossAfter               | -0.015542285  |
| LossBefore              | -8.592038e-06 |
| Model-TimeModelFit      | 31.1          |
| ModelSampler-n_times... | 920000        |
| Policy-AverageAbsPol... | 0.63157415    |
| Policy-AverageDiscou... | -29.2         |
| Policy-AveragePolicyStd | 0.5714837     |
| Policy-AverageReturn    | -64.6         |
| Policy-MaxReturn        | -28.4         |
| Policy-MinReturn        | -117          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 21.2          |
| Policy-TimeAlgoOpt      | 0.688         |
| Policy-TimeSampleProc   | 0.37          |
| Policy-TimeSampling     | 1.75          |
| Policy-TimeStep         | 2.88          |
| Time                    | 591           |
| n_timesteps             | 23000         |
-------------------------------------------

 ---------------- Iteration 23 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 230 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 231 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 232 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 233 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 234 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 235 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 236 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 237 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 238 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 239 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.357         |
| Data-EnvSampler-Poli... | 0.756         |
| Data-EnvTrajs-Averag... | 48.1          |
| Data-EnvTrajs-MaxReturn | 117           |
| Data-EnvTrajs-MinReturn | -10.9         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 53.6          |
| Data-TimeEnvSampleProc  | 0.000983      |
| Data-TimeEnvSampling    | 1.15          |
| Iteration               | 23            |
| ItrTime                 | 36.4          |
| LossAfter               | -0.017728198  |
| LossBefore              | -8.374923e-06 |
| Model-TimeModelFit      | 32.5          |
| ModelSampler-n_times... | 960000        |
| Policy-AverageAbsPol... | 0.65336347    |
| Policy-AverageDiscou... | 5.71          |
| Policy-AveragePolicyStd | 0.55962735    |
| Policy-AverageReturn    | 18.8          |
| Policy-MaxReturn        | 79            |
| Policy-MinReturn        | -29.7         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 25.1          |
| Policy-TimeAlgoOpt      | 0.556         |
| Policy-TimeSampleProc   | 0.468         |
| Policy-TimeSampling     | 1.64          |
| Policy-TimeStep         | 2.7           |
| Time                    | 628           |
| n_timesteps             | 24000         |
-------------------------------------------

 ---------------- Iteration 24 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 240 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 241 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 242 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 243 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 244 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 245 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 246 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 247 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 248 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 249 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Data-EnvSampler-EnvE... | 0.354        |
| Data-EnvSampler-Poli... | 0.83         |
| Data-EnvTrajs-Averag... | 62.5         |
| Data-EnvTrajs-MaxReturn | 91.2         |
| Data-EnvTrajs-MinReturn | 37.1         |
| Data-EnvTrajs-NumTrajs  | 5            |
| Data-EnvTrajs-StdReturn | 22.2         |
| Data-TimeEnvSampleProc  | 0.000977     |
| Data-TimeEnvSampling    | 1.22         |
| Iteration               | 24           |
| ItrTime                 | 36.6         |
| LossAfter               | -0.016548416 |
| LossBefore              | -8.08562e-06 |
| Model-TimeModelFit      | 32.3         |
| ModelSampler-n_times... | 1000000      |
| Policy-AverageAbsPol... | 0.67092323   |
| Policy-AverageDiscou... | -8.64        |
| Policy-AveragePolicyStd | 0.5437496    |
| Policy-AverageReturn    | -12.9        |
| Policy-MaxReturn        | 53.9         |
| Policy-MinReturn        | -71.9        |
| Policy-NumTrajs         | 20           |
| Policy-StdReturn        | 32.4         |
| Policy-TimeAlgoOpt      | 0.729        |
| Policy-TimeSampleProc   | 0.48         |
| Policy-TimeSampling     | 1.81         |
| Policy-TimeStep         | 3.04         |
| Time                    | 664          |
| n_timesteps             | 25000        |
------------------------------------------

 ---------------- Iteration 25 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 250 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 251 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 252 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 253 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 254 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 255 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 256 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 257 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 258 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 259 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.365         |
| Data-EnvSampler-Poli... | 0.808         |
| Data-EnvTrajs-Averag... | 65.6          |
| Data-EnvTrajs-MaxReturn | 100           |
| Data-EnvTrajs-MinReturn | 22.3          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 26.5          |
| Data-TimeEnvSampleProc  | 0.000853      |
| Data-TimeEnvSampling    | 1.21          |
| Iteration               | 25            |
| ItrTime                 | 36.7          |
| LossAfter               | -0.015465534  |
| LossBefore              | -7.806051e-06 |
| Model-TimeModelFit      | 32.4          |
| ModelSampler-n_times... | 1040000       |
| Policy-AverageAbsPol... | 0.70232487    |
| Policy-AverageDiscou... | 32.6          |
| Policy-AveragePolicyStd | 0.5295916     |
| Policy-AverageReturn    | 98            |
| Policy-MaxReturn        | 152           |
| Policy-MinReturn        | 51.3          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 27.2          |
| Policy-TimeAlgoOpt      | 0.626         |
| Policy-TimeSampleProc   | 0.595         |
| Policy-TimeSampling     | 1.78          |
| Policy-TimeStep         | 3.04          |
| Time                    | 701           |
| n_timesteps             | 26000         |
-------------------------------------------

 ---------------- Iteration 26 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 260 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 261 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 262 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 263 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 264 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 265 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 266 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 267 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 268 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 269 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.336          |
| Data-EnvSampler-Poli... | 0.743          |
| Data-EnvTrajs-Averag... | 124            |
| Data-EnvTrajs-MaxReturn | 189            |
| Data-EnvTrajs-MinReturn | 41.5           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 52.4           |
| Data-TimeEnvSampleProc  | 0.000808       |
| Data-TimeEnvSampling    | 1.11           |
| Iteration               | 26             |
| ItrTime                 | 36.4           |
| LossAfter               | -0.017319286   |
| LossBefore              | -7.4764107e-06 |
| Model-TimeModelFit      | 32.1           |
| ModelSampler-n_times... | 1080000        |
| Policy-AverageAbsPol... | 0.7015887      |
| Policy-AverageDiscou... | 16.3           |
| Policy-AveragePolicyStd | 0.51240355     |
| Policy-AverageReturn    | 49.4           |
| Policy-MaxReturn        | 97.5           |
| Policy-MinReturn        | 6.31           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 25.9           |
| Policy-TimeAlgoOpt      | 0.668          |
| Policy-TimeSampleProc   | 0.518          |
| Policy-TimeSampling     | 1.87           |
| Policy-TimeStep         | 3.12           |
| Time                    | 737            |
| n_timesteps             | 27000          |
--------------------------------------------

 ---------------- Iteration 27 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 270 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 271 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 272 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 273 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 274 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 275 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 276 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 277 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 278 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 279 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.363         |
| Data-EnvSampler-Poli... | 0.838         |
| Data-EnvTrajs-Averag... | 111           |
| Data-EnvTrajs-MaxReturn | 123           |
| Data-EnvTrajs-MinReturn | 84            |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 14            |
| Data-TimeEnvSampleProc  | 0.00113       |
| Data-TimeEnvSampling    | 1.24          |
| Iteration               | 27            |
| ItrTime                 | 36.7          |
| LossAfter               | -0.015291927  |
| LossBefore              | -7.236627e-06 |
| Model-TimeModelFit      | 32.5          |
| ModelSampler-n_times... | 1120000       |
| Policy-AverageAbsPol... | 0.73271596    |
| Policy-AverageDiscou... | 38.3          |
| Policy-AveragePolicyStd | 0.49983826    |
| Policy-AverageReturn    | 112           |
| Policy-MaxReturn        | 210           |
| Policy-MinReturn        | 17            |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 43.7          |
| Policy-TimeAlgoOpt      | 0.657         |
| Policy-TimeSampleProc   | 0.427         |
| Policy-TimeSampling     | 1.84          |
| Policy-TimeStep         | 2.95          |
| Time                    | 774           |
| n_timesteps             | 28000         |
-------------------------------------------

 ---------------- Iteration 28 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 280 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 281 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 282 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 283 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 284 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 285 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 286 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 287 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 288 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 289 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.354          |
| Data-EnvSampler-Poli... | 0.781          |
| Data-EnvTrajs-Averag... | 140            |
| Data-EnvTrajs-MaxReturn | 163            |
| Data-EnvTrajs-MinReturn | 113            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 18.4           |
| Data-TimeEnvSampleProc  | 0.000956       |
| Data-TimeEnvSampling    | 1.17           |
| Iteration               | 28             |
| ItrTime                 | 36.5           |
| LossAfter               | -0.019179272   |
| LossBefore              | -7.0434953e-06 |
| Model-TimeModelFit      | 32             |
| ModelSampler-n_times... | 1160000        |
| Policy-AverageAbsPol... | 0.733212       |
| Policy-AverageDiscou... | 106            |
| Policy-AveragePolicyStd | 0.49114603     |
| Policy-AverageReturn    | 276            |
| Policy-MaxReturn        | 349            |
| Policy-MinReturn        | 198            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 38.8           |
| Policy-TimeAlgoOpt      | 0.68           |
| Policy-TimeSampleProc   | 0.543          |
| Policy-TimeSampling     | 1.97           |
| Policy-TimeStep         | 3.23           |
| Time                    | 811            |
| n_timesteps             | 29000          |
--------------------------------------------

 ---------------- Iteration 29 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 290 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 291 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 292 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 293 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 294 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 295 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 296 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 297 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 298 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 299 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.414          |
| Data-EnvSampler-Poli... | 0.872          |
| Data-EnvTrajs-Averag... | 148            |
| Data-EnvTrajs-MaxReturn | 219            |
| Data-EnvTrajs-MinReturn | 111            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 39.1           |
| Data-TimeEnvSampleProc  | 0.00108        |
| Data-TimeEnvSampling    | 1.32           |
| Iteration               | 29             |
| ItrTime                 | 36.8           |
| LossAfter               | -0.016338175   |
| LossBefore              | -6.8578265e-06 |
| Model-TimeModelFit      | 32.7           |
| ModelSampler-n_times... | 1200000        |
| Policy-AverageAbsPol... | 0.76161957     |
| Policy-AverageDiscou... | 61             |
| Policy-AveragePolicyStd | 0.47966626     |
| Policy-AverageReturn    | 177            |
| Policy-MaxReturn        | 257            |
| Policy-MinReturn        | 86.2           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 51.1           |
| Policy-TimeAlgoOpt      | 0.618          |
| Policy-TimeSampleProc   | 0.389          |
| Policy-TimeSampling     | 1.79           |
| Policy-TimeStep         | 2.84           |
| Time                    | 848            |
| n_timesteps             | 30000          |
--------------------------------------------

 ---------------- Iteration 30 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 300 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 301 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 302 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 303 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 304 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 305 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 306 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 307 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 308 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 309 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.372          |
| Data-EnvSampler-Poli... | 0.851          |
| Data-EnvTrajs-Averag... | 220            |
| Data-EnvTrajs-MaxReturn | 275            |
| Data-EnvTrajs-MinReturn | 169            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 36.8           |
| Data-TimeEnvSampleProc  | 0.0011         |
| Data-TimeEnvSampling    | 1.26           |
| Iteration               | 30             |
| ItrTime                 | 36.7           |
| LossAfter               | -0.017797742   |
| LossBefore              | -6.6353355e-06 |
| Model-TimeModelFit      | 32.2           |
| ModelSampler-n_times... | 1240000        |
| Policy-AverageAbsPol... | 0.7482558      |
| Policy-AverageDiscou... | 51.5           |
| Policy-AveragePolicyStd | 0.47103256     |
| Policy-AverageReturn    | 148            |
| Policy-MaxReturn        | 245            |
| Policy-MinReturn        | 58.6           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 49.9           |
| Policy-TimeAlgoOpt      | 0.65           |
| Policy-TimeSampleProc   | 0.639          |
| Policy-TimeSampling     | 1.91           |
| Policy-TimeStep         | 3.24           |
| Time                    | 884            |
| n_timesteps             | 31000          |
--------------------------------------------

 ---------------- Iteration 31 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 310 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 311 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 312 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 313 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 314 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 315 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 316 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 317 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 318 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 319 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.452         |
| Data-EnvSampler-Poli... | 0.917         |
| Data-EnvTrajs-Averag... | 215           |
| Data-EnvTrajs-MaxReturn | 247           |
| Data-EnvTrajs-MinReturn | 168           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 27.5          |
| Data-TimeEnvSampleProc  | 0.00106       |
| Data-TimeEnvSampling    | 1.41          |
| Iteration               | 31            |
| ItrTime                 | 36.9          |
| LossAfter               | -0.017829442  |
| LossBefore              | -6.378035e-06 |
| Model-TimeModelFit      | 32.7          |
| ModelSampler-n_times... | 1280000       |
| Policy-AverageAbsPol... | 0.794195      |
| Policy-AverageDiscou... | 35            |
| Policy-AveragePolicyStd | 0.4595007     |
| Policy-AverageReturn    | 109           |
| Policy-MaxReturn        | 170           |
| Policy-MinReturn        | 10.2          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 41.5          |
| Policy-TimeAlgoOpt      | 0.674         |
| Policy-TimeSampleProc   | 0.35          |
| Policy-TimeSampling     | 1.72          |
| Policy-TimeStep         | 2.78          |
| Time                    | 921           |
| n_timesteps             | 32000         |
-------------------------------------------

 ---------------- Iteration 32 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 320 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 321 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 322 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 323 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 324 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 325 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 326 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 327 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 328 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 329 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.416         |
| Data-EnvSampler-Poli... | 0.937         |
| Data-EnvTrajs-Averag... | 201           |
| Data-EnvTrajs-MaxReturn | 249           |
| Data-EnvTrajs-MinReturn | 146           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 36.7          |
| Data-TimeEnvSampleProc  | 0.000951      |
| Data-TimeEnvSampling    | 1.39          |
| Iteration               | 32            |
| ItrTime                 | 37.3          |
| LossAfter               | -0.018309843  |
| LossBefore              | -6.179591e-06 |
| Model-TimeModelFit      | 32.8          |
| ModelSampler-n_times... | 1320000       |
| Policy-AverageAbsPol... | 0.7688724     |
| Policy-AverageDiscou... | 35.3          |
| Policy-AveragePolicyStd | 0.44970235    |
| Policy-AverageReturn    | 113           |
| Policy-MaxReturn        | 189           |
| Policy-MinReturn        | 24            |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 38.9          |
| Policy-TimeAlgoOpt      | 0.653         |
| Policy-TimeSampleProc   | 0.581         |
| Policy-TimeSampling     | 1.77          |
| Policy-TimeStep         | 3.07          |
| Time                    | 958           |
| n_timesteps             | 33000         |
-------------------------------------------

 ---------------- Iteration 33 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 330 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 331 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 332 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 333 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 334 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 335 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 336 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 337 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 338 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 339 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.418          |
| Data-EnvSampler-Poli... | 0.98           |
| Data-EnvTrajs-Averag... | 197            |
| Data-EnvTrajs-MaxReturn | 259            |
| Data-EnvTrajs-MinReturn | 126            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 48.8           |
| Data-TimeEnvSampleProc  | 0.000642       |
| Data-TimeEnvSampling    | 1.44           |
| Iteration               | 33             |
| ItrTime                 | 37.3           |
| LossAfter               | -0.01821548    |
| LossBefore              | -6.0517864e-06 |
| Model-TimeModelFit      | 32.7           |
| ModelSampler-n_times... | 1360000        |
| Policy-AverageAbsPol... | 0.7937696      |
| Policy-AverageDiscou... | 117            |
| Policy-AveragePolicyStd | 0.44446492     |
| Policy-AverageReturn    | 317            |
| Policy-MaxReturn        | 406            |
| Policy-MinReturn        | 254            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 39             |
| Policy-TimeAlgoOpt      | 0.635          |
| Policy-TimeSampleProc   | 0.545          |
| Policy-TimeSampling     | 1.91           |
| Policy-TimeStep         | 3.17           |
| Time                    | 996            |
| n_timesteps             | 34000          |
--------------------------------------------

 ---------------- Iteration 34 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 340 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 341 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 342 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 343 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 344 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 345 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 346 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 347 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 348 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 349 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.393          |
| Data-EnvSampler-Poli... | 0.867          |
| Data-EnvTrajs-Averag... | 242            |
| Data-EnvTrajs-MaxReturn | 289            |
| Data-EnvTrajs-MinReturn | 199            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 37.1           |
| Data-TimeEnvSampleProc  | 0.000682       |
| Data-TimeEnvSampling    | 1.3            |
| Iteration               | 34             |
| ItrTime                 | 36.6           |
| LossAfter               | -0.015611059   |
| LossBefore              | -5.8435007e-06 |
| Model-TimeModelFit      | 32.3           |
| ModelSampler-n_times... | 1400000        |
| Policy-AverageAbsPol... | 0.7985075      |
| Policy-AverageDiscou... | 52.2           |
| Policy-AveragePolicyStd | 0.43505517     |
| Policy-AverageReturn    | 158            |
| Policy-MaxReturn        | 229            |
| Policy-MinReturn        | 82.8           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 39             |
| Policy-TimeAlgoOpt      | 0.644          |
| Policy-TimeSampleProc   | 0.454          |
| Policy-TimeSampling     | 1.86           |
| Policy-TimeStep         | 3              |
| Time                    | 1.03e+03       |
| n_timesteps             | 35000          |
--------------------------------------------

 ---------------- Iteration 35 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 350 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 351 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 352 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 353 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 354 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 355 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 356 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 357 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 358 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 359 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.361          |
| Data-EnvSampler-Poli... | 0.743          |
| Data-EnvTrajs-Averag... | 243            |
| Data-EnvTrajs-MaxReturn | 266            |
| Data-EnvTrajs-MinReturn | 209            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 19.2           |
| Data-TimeEnvSampleProc  | 0.000988       |
| Data-TimeEnvSampling    | 1.14           |
| Iteration               | 35             |
| ItrTime                 | 37.6           |
| LossAfter               | -0.016309898   |
| LossBefore              | -5.5836294e-06 |
| Model-TimeModelFit      | 33.1           |
| ModelSampler-n_times... | 1440000        |
| Policy-AverageAbsPol... | 0.82742935     |
| Policy-AverageDiscou... | 62             |
| Policy-AveragePolicyStd | 0.42418253     |
| Policy-AverageReturn    | 185            |
| Policy-MaxReturn        | 240            |
| Policy-MinReturn        | 102            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 36             |
| Policy-TimeAlgoOpt      | 0.697          |
| Policy-TimeSampleProc   | 0.462          |
| Policy-TimeSampling     | 2.06           |
| Policy-TimeStep         | 3.32           |
| Time                    | 1.07e+03       |
| n_timesteps             | 36000          |
--------------------------------------------

 ---------------- Iteration 36 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 360 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 361 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 362 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 363 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 364 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 365 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 366 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 367 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 368 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 369 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.361          |
| Data-EnvSampler-Poli... | 0.788          |
| Data-EnvTrajs-Averag... | 252            |
| Data-EnvTrajs-MaxReturn | 290            |
| Data-EnvTrajs-MinReturn | 211            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 26.8           |
| Data-TimeEnvSampleProc  | 0.000815       |
| Data-TimeEnvSampling    | 1.19           |
| Iteration               | 36             |
| ItrTime                 | 36.7           |
| LossAfter               | -0.017083986   |
| LossBefore              | -5.4209954e-06 |
| Model-TimeModelFit      | 32.3           |
| ModelSampler-n_times... | 1480000        |
| Policy-AverageAbsPol... | 0.7858893      |
| Policy-AverageDiscou... | 91.3           |
| Policy-AveragePolicyStd | 0.41809627     |
| Policy-AverageReturn    | 245            |
| Policy-MaxReturn        | 333            |
| Policy-MinReturn        | 143            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 47.5           |
| Policy-TimeAlgoOpt      | 0.659          |
| Policy-TimeSampleProc   | 0.676          |
| Policy-TimeSampling     | 1.83           |
| Policy-TimeStep         | 3.24           |
| Time                    | 1.11e+03       |
| n_timesteps             | 37000          |
--------------------------------------------

 ---------------- Iteration 37 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 370 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 371 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 372 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 373 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 374 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 375 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 376 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 377 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 378 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 379 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.36           |
| Data-EnvSampler-Poli... | 0.762          |
| Data-EnvTrajs-Averag... | 206            |
| Data-EnvTrajs-MaxReturn | 276            |
| Data-EnvTrajs-MinReturn | 132            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 48.3           |
| Data-TimeEnvSampleProc  | 0.000832       |
| Data-TimeEnvSampling    | 1.16           |
| Iteration               | 37             |
| ItrTime                 | 36.8           |
| LossAfter               | -0.015788205   |
| LossBefore              | -5.1738484e-06 |
| Model-TimeModelFit      | 32.5           |
| ModelSampler-n_times... | 1520000        |
| Policy-AverageAbsPol... | 0.79481244     |
| Policy-AverageDiscou... | 41.8           |
| Policy-AveragePolicyStd | 0.40737548     |
| Policy-AverageReturn    | 123            |
| Policy-MaxReturn        | 201            |
| Policy-MinReturn        | 55.3           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 45.9           |
| Policy-TimeAlgoOpt      | 0.709          |
| Policy-TimeSampleProc   | 0.54           |
| Policy-TimeSampling     | 1.89           |
| Policy-TimeStep         | 3.16           |
| Time                    | 1.14e+03       |
| n_timesteps             | 38000          |
--------------------------------------------

 ---------------- Iteration 38 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 380 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 381 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 382 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 383 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 384 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 385 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 386 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 387 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 388 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 389 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.347          |
| Data-EnvSampler-Poli... | 0.85           |
| Data-EnvTrajs-Averag... | 277            |
| Data-EnvTrajs-MaxReturn | 327            |
| Data-EnvTrajs-MinReturn | 227            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 38.3           |
| Data-TimeEnvSampleProc  | 0.000907       |
| Data-TimeEnvSampling    | 1.23           |
| Iteration               | 38             |
| ItrTime                 | 36.4           |
| LossAfter               | -0.011346238   |
| LossBefore              | -4.9666164e-06 |
| Model-TimeModelFit      | 32             |
| ModelSampler-n_times... | 1560000        |
| Policy-AverageAbsPol... | 0.77026325     |
| Policy-AverageDiscou... | -91.4          |
| Policy-AveragePolicyStd | 0.39993545     |
| Policy-AverageReturn    | -389           |
| Policy-MaxReturn        | 453            |
| Policy-MinReturn        | -1.44e+04      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 3.22e+03       |
| Policy-TimeAlgoOpt      | 0.68           |
| Policy-TimeSampleProc   | 0.604          |
| Policy-TimeSampling     | 1.76           |
| Policy-TimeStep         | 3.12           |
| Time                    | 1.18e+03       |
| n_timesteps             | 39000          |
--------------------------------------------

 ---------------- Iteration 39 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 390 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 391 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 392 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 393 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 394 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 395 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 396 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 397 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 398 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 399 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.401         |
| Data-EnvSampler-Poli... | 0.873         |
| Data-EnvTrajs-Averag... | 294           |
| Data-EnvTrajs-MaxReturn | 342           |
| Data-EnvTrajs-MinReturn | 235           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 40.9          |
| Data-TimeEnvSampleProc  | 0.00109       |
| Data-TimeEnvSampling    | 1.31          |
| Iteration               | 39            |
| ItrTime                 | 36.9          |
| LossAfter               | -0.017798308  |
| LossBefore              | -4.856309e-06 |
| Model-TimeModelFit      | 32.9          |
| ModelSampler-n_times... | 1600000       |
| Policy-AverageAbsPol... | 0.808396      |
| Policy-AverageDiscou... | 92.3          |
| Policy-AveragePolicyStd | 0.39568356    |
| Policy-AverageReturn    | 250           |
| Policy-MaxReturn        | 353           |
| Policy-MinReturn        | 130           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 54.5          |
| Policy-TimeAlgoOpt      | 0.606         |
| Policy-TimeSampleProc   | 0.422         |
| Policy-TimeSampling     | 1.61          |
| Policy-TimeStep         | 2.67          |
| Time                    | 1.22e+03      |
| n_timesteps             | 40000         |
-------------------------------------------

 ---------------- Iteration 40 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 400 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 401 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 402 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 403 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 404 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 405 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 406 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 407 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 408 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 409 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.33          |
| Data-EnvSampler-Poli... | 0.751         |
| Data-EnvTrajs-Averag... | 269           |
| Data-EnvTrajs-MaxReturn | 362           |
| Data-EnvTrajs-MinReturn | 166           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 78.1          |
| Data-TimeEnvSampleProc  | 0.00078       |
| Data-TimeEnvSampling    | 1.12          |
| Iteration               | 40            |
| ItrTime                 | 36            |
| LossAfter               | -0.016915672  |
| LossBefore              | -4.839637e-06 |
| Model-TimeModelFit      | 32            |
| ModelSampler-n_times... | 1640000       |
| Policy-AverageAbsPol... | 0.80757314    |
| Policy-AverageDiscou... | 104           |
| Policy-AveragePolicyStd | 0.39370984    |
| Policy-AverageReturn    | 279           |
| Policy-MaxReturn        | 416           |
| Policy-MinReturn        | 152           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 58.9          |
| Policy-TimeAlgoOpt      | 0.59          |
| Policy-TimeSampleProc   | 0.497         |
| Policy-TimeSampling     | 1.79          |
| Policy-TimeStep         | 2.92          |
| Time                    | 1.25e+03      |
| n_timesteps             | 41000         |
-------------------------------------------

 ---------------- Iteration 41 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 410 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 411 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 412 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 413 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 414 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 415 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 416 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 417 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 418 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 419 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.339          |
| Data-EnvSampler-Poli... | 0.764          |
| Data-EnvTrajs-Averag... | 250            |
| Data-EnvTrajs-MaxReturn | 341            |
| Data-EnvTrajs-MinReturn | 109            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 89.3           |
| Data-TimeEnvSampleProc  | 0.000686       |
| Data-TimeEnvSampling    | 1.14           |
| Iteration               | 41             |
| ItrTime                 | 35.4           |
| LossAfter               | -0.015538818   |
| LossBefore              | -4.6446976e-06 |
| Model-TimeModelFit      | 31.5           |
| ModelSampler-n_times... | 1680000        |
| Policy-AverageAbsPol... | 0.83760905     |
| Policy-AverageDiscou... | 81.3           |
| Policy-AveragePolicyStd | 0.38803938     |
| Policy-AverageReturn    | 235            |
| Policy-MaxReturn        | 336            |
| Policy-MinReturn        | 155            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 54             |
| Policy-TimeAlgoOpt      | 0.585          |
| Policy-TimeSampleProc   | 0.473          |
| Policy-TimeSampling     | 1.55           |
| Policy-TimeStep         | 2.69           |
| Time                    | 1.29e+03       |
| n_timesteps             | 42000          |
--------------------------------------------

 ---------------- Iteration 42 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 420 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 421 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 422 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 423 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 424 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 425 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 426 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 427 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 428 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 429 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.283         |
| Data-EnvSampler-Poli... | 0.56          |
| Data-EnvTrajs-Averag... | 278           |
| Data-EnvTrajs-MaxReturn | 397           |
| Data-EnvTrajs-MinReturn | 221           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 61.8          |
| Data-TimeEnvSampleProc  | 0.00101       |
| Data-TimeEnvSampling    | 0.873         |
| Iteration               | 42            |
| ItrTime                 | 34.6          |
| LossAfter               | -0.020240959  |
| LossBefore              | -4.538737e-06 |
| Model-TimeModelFit      | 30.8          |
| ModelSampler-n_times... | 1720000       |
| Policy-AverageAbsPol... | 0.8070841     |
| Policy-AverageDiscou... | 116           |
| Policy-AveragePolicyStd | 0.38310277    |
| Policy-AverageReturn    | 307           |
| Policy-MaxReturn        | 439           |
| Policy-MinReturn        | 148           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 80.8          |
| Policy-TimeAlgoOpt      | 0.652         |
| Policy-TimeSampleProc   | 0.403         |
| Policy-TimeSampling     | 1.73          |
| Policy-TimeStep         | 2.86          |
| Time                    | 1.32e+03      |
| n_timesteps             | 43000         |
-------------------------------------------

 ---------------- Iteration 43 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 430 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 431 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 432 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 433 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 434 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 435 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 436 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 437 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 438 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 439 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.297         |
| Data-EnvSampler-Poli... | 0.656         |
| Data-EnvTrajs-Averag... | 307           |
| Data-EnvTrajs-MaxReturn | 336           |
| Data-EnvTrajs-MinReturn | 269           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 28.1          |
| Data-TimeEnvSampleProc  | 0.000844      |
| Data-TimeEnvSampling    | 0.984         |
| Iteration               | 43            |
| ItrTime                 | 35.7          |
| LossAfter               | -0.021044387  |
| LossBefore              | -4.281829e-06 |
| Model-TimeModelFit      | 31.9          |
| ModelSampler-n_times... | 1760000       |
| Policy-AverageAbsPol... | 0.79170746    |
| Policy-AverageDiscou... | 79.3          |
| Policy-AveragePolicyStd | 0.3743708     |
| Policy-AverageReturn    | 224           |
| Policy-MaxReturn        | 356           |
| Policy-MinReturn        | 128           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 56.9          |
| Policy-TimeAlgoOpt      | 0.582         |
| Policy-TimeSampleProc   | 0.57          |
| Policy-TimeSampling     | 1.64          |
| Policy-TimeStep         | 2.86          |
| Time                    | 1.36e+03      |
| n_timesteps             | 44000         |
-------------------------------------------

 ---------------- Iteration 44 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 440 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 441 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 442 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 443 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 444 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 445 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 446 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 447 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 448 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 449 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.284          |
| Data-EnvSampler-Poli... | 0.602          |
| Data-EnvTrajs-Averag... | 269            |
| Data-EnvTrajs-MaxReturn | 344            |
| Data-EnvTrajs-MinReturn | 215            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 49.2           |
| Data-TimeEnvSampleProc  | 0.000644       |
| Data-TimeEnvSampling    | 0.914          |
| Iteration               | 44             |
| ItrTime                 | 35.4           |
| LossAfter               | -0.020114541   |
| LossBefore              | -4.1190024e-06 |
| Model-TimeModelFit      | 31.7           |
| ModelSampler-n_times... | 1800000        |
| Policy-AverageAbsPol... | 0.7964988      |
| Policy-AverageDiscou... | 101            |
| Policy-AveragePolicyStd | 0.36804003     |
| Policy-AverageReturn    | 274            |
| Policy-MaxReturn        | 364            |
| Policy-MinReturn        | 185            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 53.5           |
| Policy-TimeAlgoOpt      | 0.595          |
| Policy-TimeSampleProc   | 0.532          |
| Policy-TimeSampling     | 1.58           |
| Policy-TimeStep         | 2.78           |
| Time                    | 1.39e+03       |
| n_timesteps             | 45000          |
--------------------------------------------

 ---------------- Iteration 45 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 450 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 451 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 452 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 453 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 454 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 455 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 456 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 457 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 458 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 459 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.266          |
| Data-EnvSampler-Poli... | 0.545          |
| Data-EnvTrajs-Averag... | 290            |
| Data-EnvTrajs-MaxReturn | 372            |
| Data-EnvTrajs-MinReturn | 242            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 44.7           |
| Data-TimeEnvSampleProc  | 0.000859       |
| Data-TimeEnvSampling    | 0.837          |
| Iteration               | 45             |
| ItrTime                 | 35             |
| LossAfter               | -0.015632192   |
| LossBefore              | -3.9457495e-06 |
| Model-TimeModelFit      | 31.5           |
| ModelSampler-n_times... | 1840000        |
| Policy-AverageAbsPol... | 0.8360192      |
| Policy-AverageDiscou... | 113            |
| Policy-AveragePolicyStd | 0.36278072     |
| Policy-AverageReturn    | 309            |
| Policy-MaxReturn        | 403            |
| Policy-MinReturn        | 208            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 54.8           |
| Policy-TimeAlgoOpt      | 0.602          |
| Policy-TimeSampleProc   | 0.382          |
| Policy-TimeSampling     | 1.66           |
| Policy-TimeStep         | 2.7            |
| Time                    | 1.43e+03       |
| n_timesteps             | 46000          |
--------------------------------------------

 ---------------- Iteration 46 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 460 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 461 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 462 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 463 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 464 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 465 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 466 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 467 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 468 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 469 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Data-EnvSampler-EnvE... | 0.278        |
| Data-EnvSampler-Poli... | 0.625        |
| Data-EnvTrajs-Averag... | 338          |
| Data-EnvTrajs-MaxReturn | 422          |
| Data-EnvTrajs-MinReturn | 254          |
| Data-EnvTrajs-NumTrajs  | 5            |
| Data-EnvTrajs-StdReturn | 65.2         |
| Data-TimeEnvSampleProc  | 0.000686     |
| Data-TimeEnvSampling    | 0.931        |
| Iteration               | 46           |
| ItrTime                 | 35.3         |
| LossAfter               | -0.017850738 |
| LossBefore              | -3.88745e-06 |
| Model-TimeModelFit      | 31.6         |
| ModelSampler-n_times... | 1880000      |
| Policy-AverageAbsPol... | 0.83062255   |
| Policy-AverageDiscou... | 110          |
| Policy-AveragePolicyStd | 0.36080244   |
| Policy-AverageReturn    | 289          |
| Policy-MaxReturn        | 352          |
| Policy-MinReturn        | 189          |
| Policy-NumTrajs         | 20           |
| Policy-StdReturn        | 51.5         |
| Policy-TimeAlgoOpt      | 0.621        |
| Policy-TimeSampleProc   | 0.551        |
| Policy-TimeSampling     | 1.58         |
| Policy-TimeStep         | 2.8          |
| Time                    | 1.46e+03     |
| n_timesteps             | 47000        |
------------------------------------------

 ---------------- Iteration 47 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 470 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 471 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 472 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 473 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 474 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 475 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 476 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 477 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 478 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 479 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.277          |
| Data-EnvSampler-Poli... | 0.579          |
| Data-EnvTrajs-Averag... | 321            |
| Data-EnvTrajs-MaxReturn | 389            |
| Data-EnvTrajs-MinReturn | 243            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 50.1           |
| Data-TimeEnvSampleProc  | 0.000947       |
| Data-TimeEnvSampling    | 0.885          |
| Iteration               | 47             |
| ItrTime                 | 36.4           |
| LossAfter               | -0.017055616   |
| LossBefore              | -3.7033963e-06 |
| Model-TimeModelFit      | 32.6           |
| ModelSampler-n_times... | 1920000        |
| Policy-AverageAbsPol... | 0.82780206     |
| Policy-AverageDiscou... | 151            |
| Policy-AveragePolicyStd | 0.35429212     |
| Policy-AverageReturn    | 395            |
| Policy-MaxReturn        | 543            |
| Policy-MinReturn        | 280            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 69.7           |
| Policy-TimeAlgoOpt      | 0.632          |
| Policy-TimeSampleProc   | 0.476          |
| Policy-TimeSampling     | 1.68           |
| Policy-TimeStep         | 2.89           |
| Time                    | 1.5e+03        |
| n_timesteps             | 48000          |
--------------------------------------------

 ---------------- Iteration 48 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 480 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 481 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 482 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 483 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 484 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 485 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 486 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 487 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 488 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 489 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.273          |
| Data-EnvSampler-Poli... | 0.591          |
| Data-EnvTrajs-Averag... | 349            |
| Data-EnvTrajs-MaxReturn | 417            |
| Data-EnvTrajs-MinReturn | 255            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 59.9           |
| Data-TimeEnvSampleProc  | 0.000952       |
| Data-TimeEnvSampling    | 0.894          |
| Iteration               | 48             |
| ItrTime                 | 35.6           |
| LossAfter               | -0.016049359   |
| LossBefore              | -3.4643494e-06 |
| Model-TimeModelFit      | 31.8           |
| ModelSampler-n_times... | 1960000        |
| Policy-AverageAbsPol... | 0.84284943     |
| Policy-AverageDiscou... | 117            |
| Policy-AveragePolicyStd | 0.3454544      |
| Policy-AverageReturn    | 321            |
| Policy-MaxReturn        | 413            |
| Policy-MinReturn        | 238            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 46.4           |
| Policy-TimeAlgoOpt      | 0.612          |
| Policy-TimeSampleProc   | 0.536          |
| Policy-TimeSampling     | 1.71           |
| Policy-TimeStep         | 2.89           |
| Time                    | 1.54e+03       |
| n_timesteps             | 49000          |
--------------------------------------------

 ---------------- Iteration 49 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 490 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 491 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 492 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 493 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 494 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 495 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 496 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 497 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 498 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 499 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.27           |
| Data-EnvSampler-Poli... | 0.551          |
| Data-EnvTrajs-Averag... | 375            |
| Data-EnvTrajs-MaxReturn | 402            |
| Data-EnvTrajs-MinReturn | 351            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 16.5           |
| Data-TimeEnvSampleProc  | 0.000958       |
| Data-TimeEnvSampling    | 0.848          |
| Iteration               | 49             |
| ItrTime                 | 35.3           |
| LossAfter               | -0.017579984   |
| LossBefore              | -3.3423482e-06 |
| Model-TimeModelFit      | 31.7           |
| ModelSampler-n_times... | 2000000        |
| Policy-AverageAbsPol... | 0.83961093     |
| Policy-AverageDiscou... | 133            |
| Policy-AveragePolicyStd | 0.34190503     |
| Policy-AverageReturn    | 352            |
| Policy-MaxReturn        | 427            |
| Policy-MinReturn        | 271            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 44.9           |
| Policy-TimeAlgoOpt      | 0.61           |
| Policy-TimeSampleProc   | 0.504          |
| Policy-TimeSampling     | 1.57           |
| Policy-TimeStep         | 2.72           |
| Time                    | 1.57e+03       |
| n_timesteps             | 50000          |
--------------------------------------------

 ---------------- Iteration 50 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 500 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 501 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 502 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 503 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 504 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 505 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 506 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 507 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 508 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 509 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.278          |
| Data-EnvSampler-Poli... | 0.568          |
| Data-EnvTrajs-Averag... | 370            |
| Data-EnvTrajs-MaxReturn | 379            |
| Data-EnvTrajs-MinReturn | 348            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 11.6           |
| Data-TimeEnvSampleProc  | 0.000989       |
| Data-TimeEnvSampling    | 0.875          |
| Iteration               | 50             |
| ItrTime                 | 30.3           |
| LossAfter               | -0.01565344    |
| LossBefore              | -3.1242903e-06 |
| Model-TimeModelFit      | 27.3           |
| ModelSampler-n_times... | 2040000        |
| Policy-AverageAbsPol... | 0.8551344      |
| Policy-AverageDiscou... | 79             |
| Policy-AveragePolicyStd | 0.33436948     |
| Policy-AverageReturn    | 217            |
| Policy-MaxReturn        | 313            |
| Policy-MinReturn        | 135            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 48             |
| Policy-TimeAlgoOpt      | 0.54           |
| Policy-TimeSampleProc   | 0.271          |
| Policy-TimeSampling     | 1.3            |
| Policy-TimeStep         | 2.12           |
| Time                    | 1.6e+03        |
| n_timesteps             | 51000          |
--------------------------------------------
Training finished
