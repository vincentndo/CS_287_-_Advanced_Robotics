Logging to /home/vincent/workplace/CS_287_-_Advanced_Robotics/homework/hw5/cs287hw5/ppo/run_scripts/data/parallel_mb_ppo/mbppo_HalfCheetah_l2_no_square//00

 ---------------- Iteration 0 ----------------
Obtaining random samples from the environment...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 0 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 1 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 2 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 3 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 4 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 5 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 6 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 7 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 8 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 9 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.139           |
| Data-EnvSampler-Poli... | 0.0439          |
| Data-EnvTrajs-Averag... | -67.5           |
| Data-EnvTrajs-MaxReturn | -17             |
| Data-EnvTrajs-MinReturn | -117            |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 37.1            |
| Data-TimeEnvSampleProc  | 0.000798        |
| Data-TimeEnvSampling    | 0.195           |
| Iteration               | 0               |
| ItrTime                 | 8.8             |
| LossAfter               | -0.011911431    |
| LossBefore              | -1.41102755e-05 |
| Model-TimeModelFit      | 3.22            |
| ModelSampler-n_times... | 40000           |
| Policy-AverageAbsPol... | 1.0870384       |
| Policy-AverageDiscou... | 3.96e+03        |
| Policy-AveragePolicyStd | 0.99212223      |
| Policy-AverageReturn    | 1.3e+04         |
| Policy-MaxReturn        | 1.38e+04        |
| Policy-MinReturn        | 1.23e+04        |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 415             |
| Policy-TimeAlgoOpt      | 0.979           |
| Policy-TimeSampleProc   | 0.575           |
| Policy-TimeSampling     | 3.78            |
| Policy-TimeStep         | 5.38            |
| Time                    | 8.8             |
| n_timesteps             | 1000            |
---------------------------------------------

 ---------------- Iteration 1 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 10 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 11 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 12 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 13 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 14 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 15 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 16 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 17 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 18 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 19 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.213          |
| Data-EnvSampler-Poli... | 0.521          |
| Data-EnvTrajs-Averag... | -40.3          |
| Data-EnvTrajs-MaxReturn | -8.16          |
| Data-EnvTrajs-MinReturn | -60.8          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 17.7           |
| Data-TimeEnvSampleProc  | 0.000955       |
| Data-TimeEnvSampling    | 0.756          |
| Iteration               | 1              |
| ItrTime                 | 7.37           |
| LossAfter               | -0.013708557   |
| LossBefore              | -1.3777607e-05 |
| Model-TimeModelFit      | 3.95           |
| ModelSampler-n_times... | 80000          |
| Policy-AverageAbsPol... | 0.565489       |
| Policy-AverageDiscou... | -80.9          |
| Policy-AveragePolicyStd | 0.9598452      |
| Policy-AverageReturn    | -188           |
| Policy-MaxReturn        | -149           |
| Policy-MinReturn        | -235           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 21.1           |
| Policy-TimeAlgoOpt      | 0.538          |
| Policy-TimeSampleProc   | 0.438          |
| Policy-TimeSampling     | 1.63           |
| Policy-TimeStep         | 2.66           |
| Time                    | 16.3           |
| n_timesteps             | 2000           |
--------------------------------------------

 ---------------- Iteration 2 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 20 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 21 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 22 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 23 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 24 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 25 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 26 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 27 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 28 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 29 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.279          |
| Data-EnvSampler-Poli... | 0.601          |
| Data-EnvTrajs-Averag... | -79.8          |
| Data-EnvTrajs-MaxReturn | -29.1          |
| Data-EnvTrajs-MinReturn | -127           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 34.4           |
| Data-TimeEnvSampleProc  | 0.000634       |
| Data-TimeEnvSampling    | 0.914          |
| Iteration               | 2              |
| ItrTime                 | 9.35           |
| LossAfter               | -0.013588701   |
| LossBefore              | -1.3409375e-05 |
| Model-TimeModelFit      | 5.83           |
| ModelSampler-n_times... | 120000         |
| Policy-AverageAbsPol... | 0.59801716     |
| Policy-AverageDiscou... | -56            |
| Policy-AveragePolicyStd | 0.92528474     |
| Policy-AverageReturn    | -129           |
| Policy-MaxReturn        | -100           |
| Policy-MinReturn        | -187           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 20.6           |
| Policy-TimeAlgoOpt      | 0.608          |
| Policy-TimeSampleProc   | 0.472          |
| Policy-TimeSampling     | 1.48           |
| Policy-TimeStep         | 2.6            |
| Time                    | 25.7           |
| n_timesteps             | 3000           |
--------------------------------------------

 ---------------- Iteration 3 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 30 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 31 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 32 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 33 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 34 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 35 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 36 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 37 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 38 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 39 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.28           |
| Data-EnvSampler-Poli... | 0.738          |
| Data-EnvTrajs-Averag... | -67.1          |
| Data-EnvTrajs-MaxReturn | -8.22          |
| Data-EnvTrajs-MinReturn | -158           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 50.9           |
| Data-TimeEnvSampleProc  | 0.00116        |
| Data-TimeEnvSampling    | 1.05           |
| Iteration               | 3              |
| ItrTime                 | 14.5           |
| LossAfter               | -0.016258841   |
| LossBefore              | -1.3211326e-05 |
| Model-TimeModelFit      | 9.5            |
| ModelSampler-n_times... | 160000         |
| Policy-AverageAbsPol... | 0.56089485     |
| Policy-AverageDiscou... | 30.8           |
| Policy-AveragePolicyStd | 0.9049886      |
| Policy-AverageReturn    | 57.4           |
| Policy-MaxReturn        | 148            |
| Policy-MinReturn        | -134           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 70.9           |
| Policy-TimeAlgoOpt      | 0.786          |
| Policy-TimeSampleProc   | 0.592          |
| Policy-TimeSampling     | 2.51           |
| Policy-TimeStep         | 3.93           |
| Time                    | 40.2           |
| n_timesteps             | 4000           |
--------------------------------------------

 ---------------- Iteration 4 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 40 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 41 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 42 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 43 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 44 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 45 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 46 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 47 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 48 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 49 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.249          |
| Data-EnvSampler-Poli... | 0.557          |
| Data-EnvTrajs-Averag... | -31.3          |
| Data-EnvTrajs-MaxReturn | -19.7          |
| Data-EnvTrajs-MinReturn | -52.3          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 11.5           |
| Data-TimeEnvSampleProc  | 0.000754       |
| Data-TimeEnvSampling    | 0.831          |
| Iteration               | 4              |
| ItrTime                 | 13.8           |
| LossAfter               | -0.0154582     |
| LossBefore              | -1.2861894e-05 |
| Model-TimeModelFit      | 10.4           |
| ModelSampler-n_times... | 200000         |
| Policy-AverageAbsPol... | 0.5619915      |
| Policy-AverageDiscou... | -52.9          |
| Policy-AveragePolicyStd | 0.87303734     |
| Policy-AverageReturn    | -124           |
| Policy-MaxReturn        | -86.4          |
| Policy-MinReturn        | -155           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 18             |
| Policy-TimeAlgoOpt      | 0.562          |
| Policy-TimeSampleProc   | 0.452          |
| Policy-TimeSampling     | 1.54           |
| Policy-TimeStep         | 2.59           |
| Time                    | 54             |
| n_timesteps             | 5000           |
--------------------------------------------

 ---------------- Iteration 5 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 50 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 51 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 52 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 53 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 54 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 55 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 56 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 57 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 58 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 59 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.306          |
| Data-EnvSampler-Poli... | 0.723          |
| Data-EnvTrajs-Averag... | -37.7          |
| Data-EnvTrajs-MaxReturn | -18.5          |
| Data-EnvTrajs-MinReturn | -66.7          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 15.9           |
| Data-TimeEnvSampleProc  | 0.000875       |
| Data-TimeEnvSampling    | 1.06           |
| Iteration               | 5              |
| ItrTime                 | 17.1           |
| LossAfter               | -0.013102083   |
| LossBefore              | -1.2478248e-05 |
| Model-TimeModelFit      | 13.2           |
| ModelSampler-n_times... | 240000         |
| Policy-AverageAbsPol... | 0.50491464     |
| Policy-AverageDiscou... | -23.8          |
| Policy-AveragePolicyStd | 0.84310377     |
| Policy-AverageReturn    | -52.4          |
| Policy-MaxReturn        | -18.2          |
| Policy-MinReturn        | -81            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 16.7           |
| Policy-TimeAlgoOpt      | 0.592          |
| Policy-TimeSampleProc   | 0.452          |
| Policy-TimeSampling     | 1.68           |
| Policy-TimeStep         | 2.77           |
| Time                    | 71             |
| n_timesteps             | 6000           |
--------------------------------------------

 ---------------- Iteration 6 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 60 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 61 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 62 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 63 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 64 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 65 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 66 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 67 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 68 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 69 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.351          |
| Data-EnvSampler-Poli... | 0.792          |
| Data-EnvTrajs-Averag... | -37.5          |
| Data-EnvTrajs-MaxReturn | -16            |
| Data-EnvTrajs-MinReturn | -56.6          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 13.9           |
| Data-TimeEnvSampleProc  | 0.000788       |
| Data-TimeEnvSampling    | 1.19           |
| Iteration               | 6              |
| ItrTime                 | 19.9           |
| LossAfter               | -0.014057194   |
| LossBefore              | -1.2104521e-05 |
| Model-TimeModelFit      | 14.8           |
| ModelSampler-n_times... | 280000         |
| Policy-AverageAbsPol... | 0.47693324     |
| Policy-AverageDiscou... | -5.99          |
| Policy-AveragePolicyStd | 0.81131154     |
| Policy-AverageReturn    | -11.3          |
| Policy-MaxReturn        | 22.2           |
| Policy-MinReturn        | -36.4          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 16             |
| Policy-TimeAlgoOpt      | 0.823          |
| Policy-TimeSampleProc   | 0.754          |
| Policy-TimeSampling     | 2.32           |
| Policy-TimeStep         | 3.93           |
| Time                    | 91             |
| n_timesteps             | 7000           |
--------------------------------------------

 ---------------- Iteration 7 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 70 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 71 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 72 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 73 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 74 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 75 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 76 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 77 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 78 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 79 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.418          |
| Data-EnvSampler-Poli... | 0.902          |
| Data-EnvTrajs-Averag... | -32.2          |
| Data-EnvTrajs-MaxReturn | -9.82          |
| Data-EnvTrajs-MinReturn | -52.5          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 15.8           |
| Data-TimeEnvSampleProc  | 0.000657       |
| Data-TimeEnvSampling    | 1.37           |
| Iteration               | 7              |
| ItrTime                 | 20             |
| LossAfter               | -0.013695296   |
| LossBefore              | -1.1771057e-05 |
| Model-TimeModelFit      | 15.9           |
| ModelSampler-n_times... | 320000         |
| Policy-AverageAbsPol... | 0.42255786     |
| Policy-AverageDiscou... | -43.2          |
| Policy-AveragePolicyStd | 0.78599584     |
| Policy-AverageReturn    | -95.5          |
| Policy-MaxReturn        | -71            |
| Policy-MinReturn        | -149           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 16.9           |
| Policy-TimeAlgoOpt      | 0.582          |
| Policy-TimeSampleProc   | 0.53           |
| Policy-TimeSampling     | 1.61           |
| Policy-TimeStep         | 2.75           |
| Time                    | 111            |
| n_timesteps             | 8000           |
--------------------------------------------

 ---------------- Iteration 8 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 80 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 81 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 82 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 83 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 84 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 85 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 86 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 87 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 88 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 89 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.356          |
| Data-EnvSampler-Poli... | 0.786          |
| Data-EnvTrajs-Averag... | -29.9          |
| Data-EnvTrajs-MaxReturn | 16.4           |
| Data-EnvTrajs-MinReturn | -80.8          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 36.7           |
| Data-TimeEnvSampleProc  | 0.000899       |
| Data-TimeEnvSampling    | 1.18           |
| Iteration               | 8              |
| ItrTime                 | 24.9           |
| LossAfter               | -0.016545272   |
| LossBefore              | -1.1491828e-05 |
| Model-TimeModelFit      | 20.7           |
| ModelSampler-n_times... | 360000         |
| Policy-AverageAbsPol... | 0.43167084     |
| Policy-AverageDiscou... | -15.2          |
| Policy-AveragePolicyStd | 0.76273876     |
| Policy-AverageReturn    | -31.8          |
| Policy-MaxReturn        | 92.5           |
| Policy-MinReturn        | -98.8          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 43.7           |
| Policy-TimeAlgoOpt      | 0.538          |
| Policy-TimeSampleProc   | 0.781          |
| Policy-TimeSampling     | 1.7            |
| Policy-TimeStep         | 3.1            |
| Time                    | 136            |
| n_timesteps             | 9000           |
--------------------------------------------

 ---------------- Iteration 9 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 90 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 91 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 92 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 93 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 94 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 95 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 96 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 97 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 98 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 99 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.385          |
| Data-EnvSampler-Poli... | 1.07           |
| Data-EnvTrajs-Averag... | 1.03           |
| Data-EnvTrajs-MaxReturn | 27.4           |
| Data-EnvTrajs-MinReturn | -24.1          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 18.1           |
| Data-TimeEnvSampleProc  | 0.000952       |
| Data-TimeEnvSampling    | 1.5            |
| Iteration               | 9              |
| ItrTime                 | 27.6           |
| LossAfter               | -0.016887711   |
| LossBefore              | -1.1163297e-05 |
| Model-TimeModelFit      | 23.5           |
| ModelSampler-n_times... | 400000         |
| Policy-AverageAbsPol... | 0.44979692     |
| Policy-AverageDiscou... | 24.6           |
| Policy-AveragePolicyStd | 0.7396104      |
| Policy-AverageReturn    | 60.4           |
| Policy-MaxReturn        | 139            |
| Policy-MinReturn        | 6.63           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 31.9           |
| Policy-TimeAlgoOpt      | 0.528          |
| Policy-TimeSampleProc   | 0.508          |
| Policy-TimeSampling     | 1.46           |
| Policy-TimeStep         | 2.55           |
| Time                    | 164            |
| n_timesteps             | 10000          |
--------------------------------------------

 ---------------- Iteration 10 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 100 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 101 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 102 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 103 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 104 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 105 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 106 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 107 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 108 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 109 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.425          |
| Data-EnvSampler-Poli... | 0.909          |
| Data-EnvTrajs-Averag... | 14.9           |
| Data-EnvTrajs-MaxReturn | 49.6           |
| Data-EnvTrajs-MinReturn | -4.53          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 18.9           |
| Data-TimeEnvSampleProc  | 0.00449        |
| Data-TimeEnvSampling    | 1.37           |
| Iteration               | 10             |
| ItrTime                 | 29.6           |
| LossAfter               | -0.016776336   |
| LossBefore              | -1.0785063e-05 |
| Model-TimeModelFit      | 25.2           |
| ModelSampler-n_times... | 440000         |
| Policy-AverageAbsPol... | 0.44981194     |
| Policy-AverageDiscou... | -0.0645        |
| Policy-AveragePolicyStd | 0.7120018      |
| Policy-AverageReturn    | -17.6          |
| Policy-MaxReturn        | 56.6           |
| Policy-MinReturn        | -75            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 28.5           |
| Policy-TimeAlgoOpt      | 0.568          |
| Policy-TimeSampleProc   | 0.697          |
| Policy-TimeSampling     | 1.72           |
| Policy-TimeStep         | 3.03           |
| Time                    | 193            |
| n_timesteps             | 11000          |
--------------------------------------------

 ---------------- Iteration 11 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 110 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 111 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 112 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 113 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 114 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 115 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 116 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 117 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 118 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 119 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.4            |
| Data-EnvSampler-Poli... | 0.933          |
| Data-EnvTrajs-Averag... | 4.71           |
| Data-EnvTrajs-MaxReturn | 30.8           |
| Data-EnvTrajs-MinReturn | -10.6          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 17.3           |
| Data-TimeEnvSampleProc  | 0.000566       |
| Data-TimeEnvSampling    | 1.39           |
| Iteration               | 11             |
| ItrTime                 | 32.4           |
| LossAfter               | -0.014705163   |
| LossBefore              | -1.0478914e-05 |
| Model-TimeModelFit      | 28.5           |
| ModelSampler-n_times... | 480000         |
| Policy-AverageAbsPol... | 0.53100735     |
| Policy-AverageDiscou... | -0.472         |
| Policy-AveragePolicyStd | 0.6911476      |
| Policy-AverageReturn    | 4.7            |
| Policy-MaxReturn        | 102            |
| Policy-MinReturn        | -81.7          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 40.6           |
| Policy-TimeAlgoOpt      | 0.557          |
| Policy-TimeSampleProc   | 0.485          |
| Policy-TimeSampling     | 1.52           |
| Policy-TimeStep         | 2.6            |
| Time                    | 226            |
| n_timesteps             | 12000          |
--------------------------------------------

 ---------------- Iteration 12 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 120 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 121 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 122 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 123 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 124 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 125 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 126 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 127 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 128 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 129 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.333          |
| Data-EnvSampler-Poli... | 0.749          |
| Data-EnvTrajs-Averag... | -20.8          |
| Data-EnvTrajs-MaxReturn | 74.8           |
| Data-EnvTrajs-MinReturn | -86.6          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 61.4           |
| Data-TimeEnvSampleProc  | 0.000758       |
| Data-TimeEnvSampling    | 1.12           |
| Iteration               | 12             |
| ItrTime                 | 32.2           |
| LossAfter               | -0.017129978   |
| LossBefore              | -1.0260375e-05 |
| Model-TimeModelFit      | 28.6           |
| ModelSampler-n_times... | 520000         |
| Policy-AverageAbsPol... | 0.5339998      |
| Policy-AverageDiscou... | -42            |
| Policy-AveragePolicyStd | 0.67666715     |
| Policy-AverageReturn    | -88            |
| Policy-MaxReturn        | 0.477          |
| Policy-MinReturn        | -190           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 51.8           |
| Policy-TimeAlgoOpt      | 0.551          |
| Policy-TimeSampleProc   | 0.424          |
| Policy-TimeSampling     | 1.47           |
| Policy-TimeStep         | 2.46           |
| Time                    | 258            |
| n_timesteps             | 13000          |
--------------------------------------------

 ---------------- Iteration 13 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 130 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 131 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 132 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 133 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 134 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 135 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 136 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 137 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 138 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 139 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.463          |
| Data-EnvSampler-Poli... | 1.07           |
| Data-EnvTrajs-Averag... | 44.2           |
| Data-EnvTrajs-MaxReturn | 84.7           |
| Data-EnvTrajs-MinReturn | 19.4           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 24.1           |
| Data-TimeEnvSampleProc  | 0.00129        |
| Data-TimeEnvSampling    | 1.6            |
| Iteration               | 13             |
| ItrTime                 | 38.5           |
| LossAfter               | -0.0168958     |
| LossBefore              | -9.9945955e-06 |
| Model-TimeModelFit      | 34.1           |
| ModelSampler-n_times... | 560000         |
| Policy-AverageAbsPol... | 0.56339777     |
| Policy-AverageDiscou... | 39.6           |
| Policy-AveragePolicyStd | 0.65757054     |
| Policy-AverageReturn    | 72.6           |
| Policy-MaxReturn        | 137            |
| Policy-MinReturn        | 16.2           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 35.2           |
| Policy-TimeAlgoOpt      | 0.577          |
| Policy-TimeSampleProc   | 0.646          |
| Policy-TimeSampling     | 1.6            |
| Policy-TimeStep         | 2.87           |
| Time                    | 296            |
| n_timesteps             | 14000          |
--------------------------------------------

 ---------------- Iteration 14 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 140 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 141 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 142 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 143 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 144 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 145 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 146 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 147 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 148 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 149 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Data-EnvSampler-EnvE... | 0.622        |
| Data-EnvSampler-Poli... | 1.45         |
| Data-EnvTrajs-Averag... | 37.9         |
| Data-EnvTrajs-MaxReturn | 82.8         |
| Data-EnvTrajs-MinReturn | -17.1        |
| Data-EnvTrajs-NumTrajs  | 5            |
| Data-EnvTrajs-StdReturn | 37.6         |
| Data-TimeEnvSampleProc  | 0.00173      |
| Data-TimeEnvSampling    | 2.17         |
| Iteration               | 14           |
| ItrTime                 | 40.9         |
| LossAfter               | -0.01623603  |
| LossBefore              | -9.70095e-06 |
| Model-TimeModelFit      | 34.3         |
| ModelSampler-n_times... | 600000       |
| Policy-AverageAbsPol... | 0.55443615   |
| Policy-AverageDiscou... | -1.14        |
| Policy-AveragePolicyStd | 0.63920665   |
| Policy-AverageReturn    | 3.83         |
| Policy-MaxReturn        | 41.5         |
| Policy-MinReturn        | -107         |
| Policy-NumTrajs         | 20           |
| Policy-StdReturn        | 30.3         |
| Policy-TimeAlgoOpt      | 0.869        |
| Policy-TimeSampleProc   | 0.896        |
| Policy-TimeSampling     | 2.69         |
| Policy-TimeStep         | 4.51         |
| Time                    | 337          |
| n_timesteps             | 15000        |
------------------------------------------

 ---------------- Iteration 15 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 150 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 151 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 152 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 153 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 154 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 155 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 156 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 157 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 158 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 159 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.697         |
| Data-EnvSampler-Poli... | 1.52          |
| Data-EnvTrajs-Averag... | 2.87          |
| Data-EnvTrajs-MaxReturn | 92.4          |
| Data-EnvTrajs-MinReturn | -70.2         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 58            |
| Data-TimeEnvSampleProc  | 0.00164       |
| Data-TimeEnvSampling    | 2.28          |
| Iteration               | 15            |
| ItrTime                 | 36.2          |
| LossAfter               | -0.014575086  |
| LossBefore              | -9.397036e-06 |
| Model-TimeModelFit      | 29.7          |
| ModelSampler-n_times... | 640000        |
| Policy-AverageAbsPol... | 0.58114636    |
| Policy-AverageDiscou... | 37.1          |
| Policy-AveragePolicyStd | 0.6206081     |
| Policy-AverageReturn    | 88.4          |
| Policy-MaxReturn        | 179           |
| Policy-MinReturn        | -36.8         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 55.6          |
| Policy-TimeAlgoOpt      | 0.877         |
| Policy-TimeSampleProc   | 0.72          |
| Policy-TimeSampling     | 2.55          |
| Policy-TimeStep         | 4.17          |
| Time                    | 374           |
| n_timesteps             | 16000         |
-------------------------------------------

 ---------------- Iteration 16 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 160 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 161 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 162 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 163 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 164 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 165 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 166 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 167 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 168 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 169 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Data-EnvSampler-EnvE... | 0.676        |
| Data-EnvSampler-Poli... | 1.41         |
| Data-EnvTrajs-Averag... | -47.9        |
| Data-EnvTrajs-MaxReturn | -1.93        |
| Data-EnvTrajs-MinReturn | -113         |
| Data-EnvTrajs-NumTrajs  | 5            |
| Data-EnvTrajs-StdReturn | 40.4         |
| Data-TimeEnvSampleProc  | 0.00238      |
| Data-TimeEnvSampling    | 2.15         |
| Iteration               | 16           |
| ItrTime                 | 40.3         |
| LossAfter               | -0.016722042 |
| LossBefore              | -9.18305e-06 |
| Model-TimeModelFit      | 35.3         |
| ModelSampler-n_times... | 680000       |
| Policy-AverageAbsPol... | 0.5684121    |
| Policy-AverageDiscou... | 4.66         |
| Policy-AveragePolicyStd | 0.60641277   |
| Policy-AverageReturn    | 19.3         |
| Policy-MaxReturn        | 74.6         |
| Policy-MinReturn        | -61.7        |
| Policy-NumTrajs         | 20           |
| Policy-StdReturn        | 32.8         |
| Policy-TimeAlgoOpt      | 0.561        |
| Policy-TimeSampleProc   | 0.622        |
| Policy-TimeSampling     | 1.6          |
| Policy-TimeStep         | 2.8          |
| Time                    | 414          |
| n_timesteps             | 17000        |
------------------------------------------

 ---------------- Iteration 17 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 170 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 171 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 172 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 173 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 174 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 175 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 176 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 177 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 178 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 179 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.451          |
| Data-EnvSampler-Poli... | 1.08           |
| Data-EnvTrajs-Averag... | -48.7          |
| Data-EnvTrajs-MaxReturn | 68.5           |
| Data-EnvTrajs-MinReturn | -131           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 69.1           |
| Data-TimeEnvSampleProc  | 0.00117        |
| Data-TimeEnvSampling    | 1.59           |
| Iteration               | 17             |
| ItrTime                 | 42.8           |
| LossAfter               | -0.017409151   |
| LossBefore              | -9.0027115e-06 |
| Model-TimeModelFit      | 38.2           |
| ModelSampler-n_times... | 720000         |
| Policy-AverageAbsPol... | 0.5736902      |
| Policy-AverageDiscou... | -37.4          |
| Policy-AveragePolicyStd | 0.59449416     |
| Policy-AverageReturn    | -78.3          |
| Policy-MaxReturn        | -2.42          |
| Policy-MinReturn        | -164           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 44.1           |
| Policy-TimeAlgoOpt      | 0.6            |
| Policy-TimeSampleProc   | 0.572          |
| Policy-TimeSampling     | 1.73           |
| Policy-TimeStep         | 2.97           |
| Time                    | 457            |
| n_timesteps             | 18000          |
--------------------------------------------

 ---------------- Iteration 18 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 180 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 181 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 182 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 183 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 184 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 185 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 186 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 187 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 188 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 189 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.477         |
| Data-EnvSampler-Poli... | 1.41          |
| Data-EnvTrajs-Averag... | 38.7          |
| Data-EnvTrajs-MaxReturn | 66.3          |
| Data-EnvTrajs-MinReturn | 6.35          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 26.6          |
| Data-TimeEnvSampleProc  | 0.00121       |
| Data-TimeEnvSampling    | 1.94          |
| Iteration               | 18            |
| ItrTime                 | 39.9          |
| LossAfter               | -0.0141208945 |
| LossBefore              | -8.717403e-06 |
| Model-TimeModelFit      | 35.4          |
| ModelSampler-n_times... | 760000        |
| Policy-AverageAbsPol... | 0.5674679     |
| Policy-AverageDiscou... | -32.6         |
| Policy-AveragePolicyStd | 0.5791613     |
| Policy-AverageReturn    | -68.4         |
| Policy-MaxReturn        | -18.1         |
| Policy-MinReturn        | -123          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 29.5          |
| Policy-TimeAlgoOpt      | 0.593         |
| Policy-TimeSampleProc   | 0.51          |
| Policy-TimeSampling     | 1.42          |
| Policy-TimeStep         | 2.56          |
| Time                    | 497           |
| n_timesteps             | 19000         |
-------------------------------------------

 ---------------- Iteration 19 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 190 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 191 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 192 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 193 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 194 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 195 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 196 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 197 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 198 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 199 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.384         |
| Data-EnvSampler-Poli... | 0.861         |
| Data-EnvTrajs-Averag... | 21.8          |
| Data-EnvTrajs-MaxReturn | 132           |
| Data-EnvTrajs-MinReturn | -39.2         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 64.8          |
| Data-TimeEnvSampleProc  | 0.00119       |
| Data-TimeEnvSampling    | 1.29          |
| Iteration               | 19            |
| ItrTime                 | 39.2          |
| LossAfter               | -0.014978411  |
| LossBefore              | -8.458504e-06 |
| Model-TimeModelFit      | 34.8          |
| ModelSampler-n_times... | 800000        |
| Policy-AverageAbsPol... | 0.5441739     |
| Policy-AverageDiscou... | -17           |
| Policy-AveragePolicyStd | 0.5646006     |
| Policy-AverageReturn    | -42.3         |
| Policy-MaxReturn        | 3.08          |
| Policy-MinReturn        | -102          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 26.6          |
| Policy-TimeAlgoOpt      | 0.565         |
| Policy-TimeSampleProc   | 0.68          |
| Policy-TimeSampling     | 1.86          |
| Policy-TimeStep         | 3.17          |
| Time                    | 536           |
| n_timesteps             | 20000         |
-------------------------------------------

 ---------------- Iteration 20 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 200 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 201 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 202 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 203 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 204 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 205 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 206 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 207 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 208 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 209 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.465         |
| Data-EnvSampler-Poli... | 1.29          |
| Data-EnvTrajs-Averag... | 52.7          |
| Data-EnvTrajs-MaxReturn | 80.9          |
| Data-EnvTrajs-MinReturn | 25.8          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 21.3          |
| Data-TimeEnvSampleProc  | 0.00142       |
| Data-TimeEnvSampling    | 1.79          |
| Iteration               | 20            |
| ItrTime                 | 39            |
| LossAfter               | -0.017221486  |
| LossBefore              | -8.262775e-06 |
| Model-TimeModelFit      | 34.5          |
| ModelSampler-n_times... | 840000        |
| Policy-AverageAbsPol... | 0.54779613    |
| Policy-AverageDiscou... | 8.1           |
| Policy-AveragePolicyStd | 0.553789      |
| Policy-AverageReturn    | 14.3          |
| Policy-MaxReturn        | 88.6          |
| Policy-MinReturn        | -19.4         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 25.5          |
| Policy-TimeAlgoOpt      | 0.607         |
| Policy-TimeSampleProc   | 0.465         |
| Policy-TimeSampling     | 1.58          |
| Policy-TimeStep         | 2.69          |
| Time                    | 575           |
| n_timesteps             | 21000         |
-------------------------------------------

 ---------------- Iteration 21 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 210 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 211 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 212 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 213 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 214 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 215 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 216 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 217 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 218 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 219 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.411         |
| Data-EnvSampler-Poli... | 1.04          |
| Data-EnvTrajs-Averag... | 4.27          |
| Data-EnvTrajs-MaxReturn | 74.4          |
| Data-EnvTrajs-MinReturn | -61.8         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 45            |
| Data-TimeEnvSampleProc  | 0.00264       |
| Data-TimeEnvSampling    | 1.54          |
| Iteration               | 21            |
| ItrTime                 | 41.8          |
| LossAfter               | -0.01691776   |
| LossBefore              | -8.033658e-06 |
| Model-TimeModelFit      | 37.6          |
| ModelSampler-n_times... | 880000        |
| Policy-AverageAbsPol... | 0.56806237    |
| Policy-AverageDiscou... | 28.3          |
| Policy-AveragePolicyStd | 0.5406291     |
| Policy-AverageReturn    | 75.7          |
| Policy-MaxReturn        | 150           |
| Policy-MinReturn        | -157          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 64.5          |
| Policy-TimeAlgoOpt      | 0.565         |
| Policy-TimeSampleProc   | 0.557         |
| Policy-TimeSampling     | 1.44          |
| Policy-TimeStep         | 2.62          |
| Time                    | 617           |
| n_timesteps             | 22000         |
-------------------------------------------

 ---------------- Iteration 22 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 220 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 221 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 222 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 223 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 224 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 225 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 226 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 227 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 228 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 229 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.443         |
| Data-EnvSampler-Poli... | 1.06          |
| Data-EnvTrajs-Averag... | 62.1          |
| Data-EnvTrajs-MaxReturn | 94.6          |
| Data-EnvTrajs-MinReturn | 42.3          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 19            |
| Data-TimeEnvSampleProc  | 0.00113       |
| Data-TimeEnvSampling    | 1.55          |
| Iteration               | 22            |
| ItrTime                 | 39.4          |
| LossAfter               | -0.018748438  |
| LossBefore              | -7.843068e-06 |
| Model-TimeModelFit      | 33.9          |
| ModelSampler-n_times... | 920000        |
| Policy-AverageAbsPol... | 0.6212404     |
| Policy-AverageDiscou... | 55            |
| Policy-AveragePolicyStd | 0.5298484     |
| Policy-AverageReturn    | 127           |
| Policy-MaxReturn        | 211           |
| Policy-MinReturn        | -36.9         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 53.5          |
| Policy-TimeAlgoOpt      | 0.725         |
| Policy-TimeSampleProc   | 0.982         |
| Policy-TimeSampling     | 2.19          |
| Policy-TimeStep         | 3.95          |
| Time                    | 656           |
| n_timesteps             | 23000         |
-------------------------------------------

 ---------------- Iteration 23 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 230 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 231 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 232 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 233 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 234 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 235 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 236 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 237 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 238 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 239 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.644         |
| Data-EnvSampler-Poli... | 1.35          |
| Data-EnvTrajs-Averag... | -30           |
| Data-EnvTrajs-MaxReturn | 24.7          |
| Data-EnvTrajs-MinReturn | -77.9         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 41            |
| Data-TimeEnvSampleProc  | 0.0014        |
| Data-TimeEnvSampling    | 2.06          |
| Iteration               | 23            |
| ItrTime                 | 49.5          |
| LossAfter               | -0.024517642  |
| LossBefore              | -7.758152e-06 |
| Model-TimeModelFit      | 41.6          |
| ModelSampler-n_times... | 960000        |
| Policy-AverageAbsPol... | 0.59454036    |
| Policy-AverageDiscou... | 182           |
| Policy-AveragePolicyStd | 0.52549154    |
| Policy-AverageReturn    | 529           |
| Policy-MaxReturn        | 2.45e+03      |
| Policy-MinReturn        | -657          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 841           |
| Policy-TimeAlgoOpt      | 1.03          |
| Policy-TimeSampleProc   | 1.36          |
| Policy-TimeSampling     | 3.41          |
| Policy-TimeStep         | 5.84          |
| Time                    | 705           |
| n_timesteps             | 24000         |
-------------------------------------------

 ---------------- Iteration 24 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 240 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 241 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 242 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 243 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 244 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 245 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 246 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 247 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 248 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 249 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.799         |
| Data-EnvSampler-Poli... | 1.97          |
| Data-EnvTrajs-Averag... | -0.945        |
| Data-EnvTrajs-MaxReturn | 36.2          |
| Data-EnvTrajs-MinReturn | -51.3         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 29.6          |
| Data-TimeEnvSampleProc  | 0.00208       |
| Data-TimeEnvSampling    | 2.85          |
| Iteration               | 24            |
| ItrTime                 | 49.5          |
| LossAfter               | -0.018155435  |
| LossBefore              | -7.670726e-06 |
| Model-TimeModelFit      | 42.9          |
| ModelSampler-n_times... | 1000000       |
| Policy-AverageAbsPol... | 0.6518275     |
| Policy-AverageDiscou... | 36.2          |
| Policy-AveragePolicyStd | 0.52194417    |
| Policy-AverageReturn    | 98.3          |
| Policy-MaxReturn        | 283           |
| Policy-MinReturn        | 24.5          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 55.8          |
| Policy-TimeAlgoOpt      | 0.655         |
| Policy-TimeSampleProc   | 0.789         |
| Policy-TimeSampling     | 2.2           |
| Policy-TimeStep         | 3.7           |
| Time                    | 755           |
| n_timesteps             | 25000         |
-------------------------------------------

 ---------------- Iteration 25 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 250 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 251 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 252 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 253 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 254 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 255 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 256 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 257 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 258 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 259 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.428          |
| Data-EnvSampler-Poli... | 1.27           |
| Data-EnvTrajs-Averag... | 27.4           |
| Data-EnvTrajs-MaxReturn | 125            |
| Data-EnvTrajs-MinReturn | -93.5          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 75.9           |
| Data-TimeEnvSampleProc  | 0.00204        |
| Data-TimeEnvSampling    | 1.75           |
| Iteration               | 25             |
| ItrTime                 | 47.4           |
| LossAfter               | -0.017911281   |
| LossBefore              | -7.5988405e-06 |
| Model-TimeModelFit      | 42.7           |
| ModelSampler-n_times... | 1040000        |
| Policy-AverageAbsPol... | 0.6145585      |
| Policy-AverageDiscou... | -15.2          |
| Policy-AveragePolicyStd | 0.5177735      |
| Policy-AverageReturn    | -25.4          |
| Policy-MaxReturn        | 69.1           |
| Policy-MinReturn        | -125           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 55             |
| Policy-TimeAlgoOpt      | 0.656          |
| Policy-TimeSampleProc   | 0.506          |
| Policy-TimeSampling     | 1.74           |
| Policy-TimeStep         | 2.92           |
| Time                    | 802            |
| n_timesteps             | 26000          |
--------------------------------------------

 ---------------- Iteration 26 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 260 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 261 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 262 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 263 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 264 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 265 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 266 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 267 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 268 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 269 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.53           |
| Data-EnvSampler-Poli... | 1.59           |
| Data-EnvTrajs-Averag... | 57             |
| Data-EnvTrajs-MaxReturn | 90.6           |
| Data-EnvTrajs-MinReturn | -17.3          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 38.6           |
| Data-TimeEnvSampleProc  | 0.00444        |
| Data-TimeEnvSampling    | 2.2            |
| Iteration               | 26             |
| ItrTime                 | 46.7           |
| LossAfter               | -0.017702673   |
| LossBefore              | -7.3847086e-06 |
| Model-TimeModelFit      | 41.2           |
| ModelSampler-n_times... | 1080000        |
| Policy-AverageAbsPol... | 0.6467319      |
| Policy-AverageDiscou... | 63.4           |
| Policy-AveragePolicyStd | 0.50671834     |
| Policy-AverageReturn    | 164            |
| Policy-MaxReturn        | 235            |
| Policy-MinReturn        | 57.9           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 46.3           |
| Policy-TimeAlgoOpt      | 0.647          |
| Policy-TimeSampleProc   | 0.751          |
| Policy-TimeSampling     | 1.88           |
| Policy-TimeStep         | 3.31           |
| Time                    | 849            |
| n_timesteps             | 27000          |
--------------------------------------------

 ---------------- Iteration 27 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 270 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 271 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 272 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 273 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 274 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 275 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 276 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 277 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 278 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 279 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.417          |
| Data-EnvSampler-Poli... | 0.946          |
| Data-EnvTrajs-Averag... | 93.6           |
| Data-EnvTrajs-MaxReturn | 136            |
| Data-EnvTrajs-MinReturn | 56.8           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 32.2           |
| Data-TimeEnvSampleProc  | 0.00094        |
| Data-TimeEnvSampling    | 1.4            |
| Iteration               | 27             |
| ItrTime                 | 44.7           |
| LossAfter               | -0.018434018   |
| LossBefore              | -7.3281453e-06 |
| Model-TimeModelFit      | 40.3           |
| ModelSampler-n_times... | 1120000        |
| Policy-AverageAbsPol... | 0.58551866     |
| Policy-AverageDiscou... | -28.7          |
| Policy-AveragePolicyStd | 0.50424        |
| Policy-AverageReturn    | -79.3          |
| Policy-MaxReturn        | 43.6           |
| Policy-MinReturn        | -539           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 124            |
| Policy-TimeAlgoOpt      | 0.623          |
| Policy-TimeSampleProc   | 0.593          |
| Policy-TimeSampling     | 1.74           |
| Policy-TimeStep         | 3              |
| Time                    | 894            |
| n_timesteps             | 28000          |
--------------------------------------------

 ---------------- Iteration 28 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 280 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 281 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 282 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 283 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 284 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 285 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 286 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 287 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 288 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 289 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.441          |
| Data-EnvSampler-Poli... | 0.993          |
| Data-EnvTrajs-Averag... | 28.9           |
| Data-EnvTrajs-MaxReturn | 89.2           |
| Data-EnvTrajs-MinReturn | -73.7          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 63.7           |
| Data-TimeEnvSampleProc  | 0.00103        |
| Data-TimeEnvSampling    | 1.48           |
| Iteration               | 28             |
| ItrTime                 | 44             |
| LossAfter               | -0.014403227   |
| LossBefore              | -7.1814607e-06 |
| Model-TimeModelFit      | 39.5           |
| ModelSampler-n_times... | 1160000        |
| Policy-AverageAbsPol... | 0.61938584     |
| Policy-AverageDiscou... | 4.25           |
| Policy-AveragePolicyStd | 0.49611905     |
| Policy-AverageReturn    | 12.4           |
| Policy-MaxReturn        | 127            |
| Policy-MinReturn        | -547           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 137            |
| Policy-TimeAlgoOpt      | 0.621          |
| Policy-TimeSampleProc   | 0.645          |
| Policy-TimeSampling     | 1.79           |
| Policy-TimeStep         | 3.1            |
| Time                    | 938            |
| n_timesteps             | 29000          |
--------------------------------------------

 ---------------- Iteration 29 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 290 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 291 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 292 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 293 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 294 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 295 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 296 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 297 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 298 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 299 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.479          |
| Data-EnvSampler-Poli... | 1.25           |
| Data-EnvTrajs-Averag... | 78             |
| Data-EnvTrajs-MaxReturn | 118            |
| Data-EnvTrajs-MinReturn | 37             |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 29.5           |
| Data-TimeEnvSampleProc  | 0.00117        |
| Data-TimeEnvSampling    | 1.78           |
| Iteration               | 29             |
| ItrTime                 | 44.3           |
| LossAfter               | -0.016800532   |
| LossBefore              | -6.9930074e-06 |
| Model-TimeModelFit      | 39.4           |
| ModelSampler-n_times... | 1200000        |
| Policy-AverageAbsPol... | 0.640122       |
| Policy-AverageDiscou... | 79.8           |
| Policy-AveragePolicyStd | 0.4876722      |
| Policy-AverageReturn    | 285            |
| Policy-MaxReturn        | 3.7e+03        |
| Policy-MinReturn        | 14.4           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 804            |
| Policy-TimeAlgoOpt      | 0.683          |
| Policy-TimeSampleProc   | 0.565          |
| Policy-TimeSampling     | 1.82           |
| Policy-TimeStep         | 3.1            |
| Time                    | 982            |
| n_timesteps             | 30000          |
--------------------------------------------

 ---------------- Iteration 30 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 300 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 301 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 302 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 303 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 304 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 305 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 306 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 307 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 308 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 309 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Data-EnvSampler-EnvE... | 0.595        |
| Data-EnvSampler-Poli... | 1.45         |
| Data-EnvTrajs-Averag... | 123          |
| Data-EnvTrajs-MaxReturn | 152          |
| Data-EnvTrajs-MinReturn | 67.9         |
| Data-EnvTrajs-NumTrajs  | 5            |
| Data-EnvTrajs-StdReturn | 30.5         |
| Data-TimeEnvSampleProc  | 0.00156      |
| Data-TimeEnvSampling    | 2.11         |
| Iteration               | 30           |
| ItrTime                 | 46.6         |
| LossAfter               | -0.01528291  |
| LossBefore              | -6.73023e-06 |
| Model-TimeModelFit      | 39.1         |
| ModelSampler-n_times... | 1240000      |
| Policy-AverageAbsPol... | 0.6065164    |
| Policy-AverageDiscou... | -23.1        |
| Policy-AveragePolicyStd | 0.47740003   |
| Policy-AverageReturn    | -51.7        |
| Policy-MaxReturn        | 34.7         |
| Policy-MinReturn        | -123         |
| Policy-NumTrajs         | 20           |
| Policy-StdReturn        | 43.6         |
| Policy-TimeAlgoOpt      | 0.947        |
| Policy-TimeSampleProc   | 1.1          |
| Policy-TimeSampling     | 3.29         |
| Policy-TimeStep         | 5.38         |
| Time                    | 1.03e+03     |
| n_timesteps             | 31000        |
------------------------------------------

 ---------------- Iteration 31 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 310 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 311 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 312 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 313 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 314 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 315 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 316 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 317 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 318 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 319 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.421         |
| Data-EnvSampler-Poli... | 0.993         |
| Data-EnvTrajs-Averag... | 131           |
| Data-EnvTrajs-MaxReturn | 146           |
| Data-EnvTrajs-MinReturn | 102           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 15.9          |
| Data-TimeEnvSampleProc  | 0.00118       |
| Data-TimeEnvSampling    | 1.45          |
| Iteration               | 31            |
| ItrTime                 | 44.3          |
| LossAfter               | -0.020877253  |
| LossBefore              | -6.667826e-06 |
| Model-TimeModelFit      | 40            |
| ModelSampler-n_times... | 1280000       |
| Policy-AverageAbsPol... | 0.6160072     |
| Policy-AverageDiscou... | -54.7         |
| Policy-AveragePolicyStd | 0.4724181     |
| Policy-AverageReturn    | -290          |
| Policy-MaxReturn        | 161           |
| Policy-MinReturn        | -1.21e+03     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 439           |
| Policy-TimeAlgoOpt      | 0.58          |
| Policy-TimeSampleProc   | 0.612         |
| Policy-TimeSampling     | 1.63          |
| Policy-TimeStep         | 2.88          |
| Time                    | 1.07e+03      |
| n_timesteps             | 32000         |
-------------------------------------------

 ---------------- Iteration 32 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 320 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 321 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 322 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 323 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 324 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 325 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 326 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 327 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 328 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 329 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.472         |
| Data-EnvSampler-Poli... | 1.25          |
| Data-EnvTrajs-Averag... | 99.7          |
| Data-EnvTrajs-MaxReturn | 127           |
| Data-EnvTrajs-MinReturn | 75.9          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 18.2          |
| Data-TimeEnvSampleProc  | 0.00311       |
| Data-TimeEnvSampling    | 1.78          |
| Iteration               | 32            |
| ItrTime                 | 45.2          |
| LossAfter               | -0.019944614  |
| LossBefore              | -6.608503e-06 |
| Model-TimeModelFit      | 40.9          |
| ModelSampler-n_times... | 1320000       |
| Policy-AverageAbsPol... | 0.62342423    |
| Policy-AverageDiscou... | -28.4         |
| Policy-AveragePolicyStd | 0.470593      |
| Policy-AverageReturn    | -112          |
| Policy-MaxReturn        | 109           |
| Policy-MinReturn        | -687          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 243           |
| Policy-TimeAlgoOpt      | 0.611         |
| Policy-TimeSampleProc   | 0.365         |
| Policy-TimeSampling     | 1.53          |
| Policy-TimeStep         | 2.53          |
| Time                    | 1.12e+03      |
| n_timesteps             | 33000         |
-------------------------------------------

 ---------------- Iteration 33 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 330 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 331 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 332 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 333 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 334 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 335 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 336 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 337 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 338 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 339 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.43          |
| Data-EnvSampler-Poli... | 0.966         |
| Data-EnvTrajs-Averag... | 87.9          |
| Data-EnvTrajs-MaxReturn | 140           |
| Data-EnvTrajs-MinReturn | 41.4          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 34.7          |
| Data-TimeEnvSampleProc  | 0.00135       |
| Data-TimeEnvSampling    | 1.44          |
| Iteration               | 33            |
| ItrTime                 | 46.4          |
| LossAfter               | -0.016473178  |
| LossBefore              | -6.541366e-06 |
| Model-TimeModelFit      | 41.2          |
| ModelSampler-n_times... | 1360000       |
| Policy-AverageAbsPol... | 0.61778337    |
| Policy-AverageDiscou... | -50.3         |
| Policy-AveragePolicyStd | 0.46627393    |
| Policy-AverageReturn    | -118          |
| Policy-MaxReturn        | -62.3         |
| Policy-MinReturn        | -205          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 35.5          |
| Policy-TimeAlgoOpt      | 0.812         |
| Policy-TimeSampleProc   | 0.619         |
| Policy-TimeSampling     | 2.27          |
| Policy-TimeStep         | 3.75          |
| Time                    | 1.16e+03      |
| n_timesteps             | 34000         |
-------------------------------------------

 ---------------- Iteration 34 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 340 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 341 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 342 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 343 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 344 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 345 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 346 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 347 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 348 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 349 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.523         |
| Data-EnvSampler-Poli... | 1.23          |
| Data-EnvTrajs-Averag... | 98.6          |
| Data-EnvTrajs-MaxReturn | 118           |
| Data-EnvTrajs-MinReturn | 81            |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 12.6          |
| Data-TimeEnvSampleProc  | 0.00133       |
| Data-TimeEnvSampling    | 1.8           |
| Iteration               | 34            |
| ItrTime                 | 33.5          |
| LossAfter               | -0.022088028  |
| LossBefore              | -6.339721e-06 |
| Model-TimeModelFit      | 27.7          |
| ModelSampler-n_times... | 1400000       |
| Policy-AverageAbsPol... | 0.6319709     |
| Policy-AverageDiscou... | 8.2           |
| Policy-AveragePolicyStd | 0.45722213    |
| Policy-AverageReturn    | 26.8          |
| Policy-MaxReturn        | 111           |
| Policy-MinReturn        | -489          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 128           |
| Policy-TimeAlgoOpt      | 0.856         |
| Policy-TimeSampleProc   | 0.677         |
| Policy-TimeSampling     | 2.4           |
| Policy-TimeStep         | 3.97          |
| Time                    | 1.2e+03       |
| n_timesteps             | 35000         |
-------------------------------------------

 ---------------- Iteration 35 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 350 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 351 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 352 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 353 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 354 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 355 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 356 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 357 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 358 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 359 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.628          |
| Data-EnvSampler-Poli... | 1.23           |
| Data-EnvTrajs-Averag... | 94.1           |
| Data-EnvTrajs-MaxReturn | 107            |
| Data-EnvTrajs-MinReturn | 74.8           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 12.8           |
| Data-TimeEnvSampleProc  | 0.00141        |
| Data-TimeEnvSampling    | 1.93           |
| Iteration               | 35             |
| ItrTime                 | 35.1           |
| LossAfter               | -0.015703384   |
| LossBefore              | -6.1492938e-06 |
| Model-TimeModelFit      | 30.7           |
| ModelSampler-n_times... | 1440000        |
| Policy-AverageAbsPol... | 0.6505666      |
| Policy-AverageDiscou... | -39.9          |
| Policy-AveragePolicyStd | 0.44915047     |
| Policy-AverageReturn    | -86            |
| Policy-MaxReturn        | -14.6          |
| Policy-MinReturn        | -147           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 37.9           |
| Policy-TimeAlgoOpt      | 0.573          |
| Policy-TimeSampleProc   | 0.309          |
| Policy-TimeSampling     | 1.54           |
| Policy-TimeStep         | 2.47           |
| Time                    | 1.23e+03       |
| n_timesteps             | 36000          |
--------------------------------------------

 ---------------- Iteration 36 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 360 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 361 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 362 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 363 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 364 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 365 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 366 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 367 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 368 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 369 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.376         |
| Data-EnvSampler-Poli... | 0.904         |
| Data-EnvTrajs-Averag... | 63.3          |
| Data-EnvTrajs-MaxReturn | 85.4          |
| Data-EnvTrajs-MinReturn | 44            |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 16.5          |
| Data-TimeEnvSampleProc  | 0.000964      |
| Data-TimeEnvSampling    | 1.32          |
| Iteration               | 36            |
| ItrTime                 | 36.5          |
| LossAfter               | -0.018602407  |
| LossBefore              | -6.024418e-06 |
| Model-TimeModelFit      | 32.7          |
| ModelSampler-n_times... | 1480000       |
| Policy-AverageAbsPol... | 0.654034      |
| Policy-AverageDiscou... | 14.7          |
| Policy-AveragePolicyStd | 0.4431843     |
| Policy-AverageReturn    | 40.4          |
| Policy-MaxReturn        | 103           |
| Policy-MinReturn        | -18.7         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 33.9          |
| Policy-TimeAlgoOpt      | 0.547         |
| Policy-TimeSampleProc   | 0.365         |
| Policy-TimeSampling     | 1.47          |
| Policy-TimeStep         | 2.42          |
| Time                    | 1.27e+03      |
| n_timesteps             | 37000         |
-------------------------------------------

 ---------------- Iteration 37 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 370 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 371 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 372 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 373 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 374 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 375 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 376 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 377 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 378 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 379 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.333          |
| Data-EnvSampler-Poli... | 0.905          |
| Data-EnvTrajs-Averag... | 110            |
| Data-EnvTrajs-MaxReturn | 137            |
| Data-EnvTrajs-MinReturn | 67.6           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 26.3           |
| Data-TimeEnvSampleProc  | 0.000762       |
| Data-TimeEnvSampling    | 1.27           |
| Iteration               | 37             |
| ItrTime                 | 36.9           |
| LossAfter               | -0.014780741   |
| LossBefore              | -5.8297123e-06 |
| Model-TimeModelFit      | 33.2           |
| ModelSampler-n_times... | 1520000        |
| Policy-AverageAbsPol... | 0.68955564     |
| Policy-AverageDiscou... | 39.5           |
| Policy-AveragePolicyStd | 0.43396452     |
| Policy-AverageReturn    | 96.1           |
| Policy-MaxReturn        | 155            |
| Policy-MinReturn        | 51.9           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 27             |
| Policy-TimeAlgoOpt      | 0.593          |
| Policy-TimeSampleProc   | 0.403          |
| Policy-TimeSampling     | 1.38           |
| Policy-TimeStep         | 2.41           |
| Time                    | 1.31e+03       |
| n_timesteps             | 38000          |
--------------------------------------------

 ---------------- Iteration 38 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 380 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 381 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 382 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 383 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 384 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 385 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 386 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 387 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 388 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 389 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.368          |
| Data-EnvSampler-Poli... | 0.823          |
| Data-EnvTrajs-Averag... | 107            |
| Data-EnvTrajs-MaxReturn | 147            |
| Data-EnvTrajs-MinReturn | 77.8           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 22.5           |
| Data-TimeEnvSampleProc  | 0.000911       |
| Data-TimeEnvSampling    | 1.22           |
| Iteration               | 38             |
| ItrTime                 | 37.7           |
| LossAfter               | -0.017183956   |
| LossBefore              | -5.6011154e-06 |
| Model-TimeModelFit      | 34.2           |
| ModelSampler-n_times... | 1560000        |
| Policy-AverageAbsPol... | 0.6859084      |
| Policy-AverageDiscou... | 39.4           |
| Policy-AveragePolicyStd | 0.42505506     |
| Policy-AverageReturn    | 106            |
| Policy-MaxReturn        | 149            |
| Policy-MinReturn        | 49.9           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 26.7           |
| Policy-TimeAlgoOpt      | 0.573          |
| Policy-TimeSampleProc   | 0.312          |
| Policy-TimeSampling     | 1.4            |
| Policy-TimeStep         | 2.3            |
| Time                    | 1.34e+03       |
| n_timesteps             | 39000          |
--------------------------------------------

 ---------------- Iteration 39 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 390 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 391 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 392 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 393 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 394 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 395 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 396 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 397 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 398 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 399 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.321         |
| Data-EnvSampler-Poli... | 0.822         |
| Data-EnvTrajs-Averag... | 136           |
| Data-EnvTrajs-MaxReturn | 193           |
| Data-EnvTrajs-MinReturn | 96.5          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 35.3          |
| Data-TimeEnvSampleProc  | 0.00111       |
| Data-TimeEnvSampling    | 1.18          |
| Iteration               | 39            |
| ItrTime                 | 35.4          |
| LossAfter               | -0.017847683  |
| LossBefore              | -5.324488e-06 |
| Model-TimeModelFit      | 31.8          |
| ModelSampler-n_times... | 1600000       |
| Policy-AverageAbsPol... | 0.6741545     |
| Policy-AverageDiscou... | 10.6          |
| Policy-AveragePolicyStd | 0.41409165    |
| Policy-AverageReturn    | 33.8          |
| Policy-MaxReturn        | 102           |
| Policy-MinReturn        | -65.3         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 40.4          |
| Policy-TimeAlgoOpt      | 0.556         |
| Policy-TimeSampleProc   | 0.395         |
| Policy-TimeSampling     | 1.48          |
| Policy-TimeStep         | 2.46          |
| Time                    | 1.38e+03      |
| n_timesteps             | 40000         |
-------------------------------------------

 ---------------- Iteration 40 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 400 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 401 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 402 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 403 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 404 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 405 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 406 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 407 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 408 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 409 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.336         |
| Data-EnvSampler-Poli... | 0.771         |
| Data-EnvTrajs-Averag... | 141           |
| Data-EnvTrajs-MaxReturn | 170           |
| Data-EnvTrajs-MinReturn | 121           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 16.8          |
| Data-TimeEnvSampleProc  | 0.000995      |
| Data-TimeEnvSampling    | 1.14          |
| Iteration               | 40            |
| ItrTime                 | 39.3          |
| LossAfter               | -0.016815664  |
| LossBefore              | -5.081705e-06 |
| Model-TimeModelFit      | 35.8          |
| ModelSampler-n_times... | 1640000       |
| Policy-AverageAbsPol... | 0.679777      |
| Policy-AverageDiscou... | 47            |
| Policy-AveragePolicyStd | 0.40343037    |
| Policy-AverageReturn    | 123           |
| Policy-MaxReturn        | 219           |
| Policy-MinReturn        | 62.1          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 34.9          |
| Policy-TimeAlgoOpt      | 0.546         |
| Policy-TimeSampleProc   | 0.413         |
| Policy-TimeSampling     | 1.34          |
| Policy-TimeStep         | 2.33          |
| Time                    | 1.42e+03      |
| n_timesteps             | 41000         |
-------------------------------------------

 ---------------- Iteration 41 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 410 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 411 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 412 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 413 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 414 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 415 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 416 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 417 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 418 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 419 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.301         |
| Data-EnvSampler-Poli... | 0.75          |
| Data-EnvTrajs-Averag... | 195           |
| Data-EnvTrajs-MaxReturn | 236           |
| Data-EnvTrajs-MinReturn | 151           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 28.7          |
| Data-TimeEnvSampleProc  | 0.000772      |
| Data-TimeEnvSampling    | 1.08          |
| Iteration               | 41            |
| ItrTime                 | 34.9          |
| LossAfter               | -0.017839465  |
| LossBefore              | -4.852278e-06 |
| Model-TimeModelFit      | 31.6          |
| ModelSampler-n_times... | 1680000       |
| Policy-AverageAbsPol... | 0.7221206     |
| Policy-AverageDiscou... | 69.3          |
| Policy-AveragePolicyStd | 0.39473292    |
| Policy-AverageReturn    | 190           |
| Policy-MaxReturn        | 267           |
| Policy-MinReturn        | 83.8          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 52.1          |
| Policy-TimeAlgoOpt      | 0.536         |
| Policy-TimeSampleProc   | 0.271         |
| Policy-TimeSampling     | 1.35          |
| Policy-TimeStep         | 2.21          |
| Time                    | 1.45e+03      |
| n_timesteps             | 42000         |
-------------------------------------------

 ---------------- Iteration 42 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 420 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 421 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 422 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 423 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 424 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 425 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 426 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 427 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 428 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 429 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.295          |
| Data-EnvSampler-Poli... | 0.767          |
| Data-EnvTrajs-Averag... | 160            |
| Data-EnvTrajs-MaxReturn | 184            |
| Data-EnvTrajs-MinReturn | 129            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 19.4           |
| Data-TimeEnvSampleProc  | 0.000945       |
| Data-TimeEnvSampling    | 1.09           |
| Iteration               | 42             |
| ItrTime                 | 37.4           |
| LossAfter               | -0.019877132   |
| LossBefore              | -4.6886453e-06 |
| Model-TimeModelFit      | 33.4           |
| ModelSampler-n_times... | 1720000        |
| Policy-AverageAbsPol... | 0.75831664     |
| Policy-AverageDiscou... | 109            |
| Policy-AveragePolicyStd | 0.38844645     |
| Policy-AverageReturn    | 287            |
| Policy-MaxReturn        | 380            |
| Policy-MinReturn        | 140            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 54.4           |
| Policy-TimeAlgoOpt      | 0.623          |
| Policy-TimeSampleProc   | 0.504          |
| Policy-TimeSampling     | 1.69           |
| Policy-TimeStep         | 2.87           |
| Time                    | 1.49e+03       |
| n_timesteps             | 43000          |
--------------------------------------------

 ---------------- Iteration 43 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 430 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 431 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 432 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 433 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 434 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 435 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 436 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 437 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 438 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 439 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.307          |
| Data-EnvSampler-Poli... | 0.807          |
| Data-EnvTrajs-Averag... | 159            |
| Data-EnvTrajs-MaxReturn | 203            |
| Data-EnvTrajs-MinReturn | 120            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 31.3           |
| Data-TimeEnvSampleProc  | 0.000561       |
| Data-TimeEnvSampling    | 1.14           |
| Iteration               | 43             |
| ItrTime                 | 36.6           |
| LossAfter               | -0.018676225   |
| LossBefore              | -4.4437907e-06 |
| Model-TimeModelFit      | 31.6           |
| ModelSampler-n_times... | 1760000        |
| Policy-AverageAbsPol... | 0.77252984     |
| Policy-AverageDiscou... | 88.3           |
| Policy-AveragePolicyStd | 0.37952304     |
| Policy-AverageReturn    | 256            |
| Policy-MaxReturn        | 344            |
| Policy-MinReturn        | 84.4           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 63.5           |
| Policy-TimeAlgoOpt      | 0.876          |
| Policy-TimeSampleProc   | 0.617          |
| Policy-TimeSampling     | 2.36           |
| Policy-TimeStep         | 3.9            |
| Time                    | 1.53e+03       |
| n_timesteps             | 44000          |
--------------------------------------------

 ---------------- Iteration 44 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 440 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 441 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 442 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 443 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 444 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 445 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 446 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 447 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 448 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 449 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.506         |
| Data-EnvSampler-Poli... | 1.29          |
| Data-EnvTrajs-Averag... | 191           |
| Data-EnvTrajs-MaxReturn | 230           |
| Data-EnvTrajs-MinReturn | 135           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 34.2          |
| Data-TimeEnvSampleProc  | 0.00151       |
| Data-TimeEnvSampling    | 1.85          |
| Iteration               | 44            |
| ItrTime                 | 35.6          |
| LossAfter               | -0.018979754  |
| LossBefore              | -4.334552e-06 |
| Model-TimeModelFit      | 29.8          |
| ModelSampler-n_times... | 1800000       |
| Policy-AverageAbsPol... | 0.7625218     |
| Policy-AverageDiscou... | 2.33          |
| Policy-AveragePolicyStd | 0.37453702    |
| Policy-AverageReturn    | 18.1          |
| Policy-MaxReturn        | 93.5          |
| Policy-MinReturn        | -68.3         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 44.6          |
| Policy-TimeAlgoOpt      | 0.781         |
| Policy-TimeSampleProc   | 0.855         |
| Policy-TimeSampling     | 2.31          |
| Policy-TimeStep         | 4.01          |
| Time                    | 1.56e+03      |
| n_timesteps             | 45000         |
-------------------------------------------

 ---------------- Iteration 45 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 450 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 451 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 452 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 453 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 454 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 455 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 456 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 457 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 458 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 459 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.519         |
| Data-EnvSampler-Poli... | 1.32          |
| Data-EnvTrajs-Averag... | 246           |
| Data-EnvTrajs-MaxReturn | 273           |
| Data-EnvTrajs-MinReturn | 222           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 18.5          |
| Data-TimeEnvSampleProc  | 0.00165       |
| Data-TimeEnvSampling    | 1.89          |
| Iteration               | 45            |
| ItrTime                 | 37.3          |
| LossAfter               | -0.017549947  |
| LossBefore              | -4.137327e-06 |
| Model-TimeModelFit      | 33            |
| ModelSampler-n_times... | 1840000       |
| Policy-AverageAbsPol... | 0.8110637     |
| Policy-AverageDiscou... | 85.9          |
| Policy-AveragePolicyStd | 0.3679638     |
| Policy-AverageReturn    | 226           |
| Policy-MaxReturn        | 316           |
| Policy-MinReturn        | 141           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 43.1          |
| Policy-TimeAlgoOpt      | 0.601         |
| Policy-TimeSampleProc   | 0.347         |
| Policy-TimeSampling     | 1.46          |
| Policy-TimeStep         | 2.44          |
| Time                    | 1.6e+03       |
| n_timesteps             | 46000         |
-------------------------------------------

 ---------------- Iteration 46 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 460 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 461 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 462 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 463 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 464 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 465 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 466 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 467 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 468 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 469 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.326         |
| Data-EnvSampler-Poli... | 0.807         |
| Data-EnvTrajs-Averag... | 222           |
| Data-EnvTrajs-MaxReturn | 251           |
| Data-EnvTrajs-MinReturn | 199           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 17.8          |
| Data-TimeEnvSampleProc  | 0.001         |
| Data-TimeEnvSampling    | 1.17          |
| Iteration               | 46            |
| ItrTime                 | 41.5          |
| LossAfter               | -0.01930713   |
| LossBefore              | -3.936201e-06 |
| Model-TimeModelFit      | 37.9          |
| ModelSampler-n_times... | 1880000       |
| Policy-AverageAbsPol... | 0.84799737    |
| Policy-AverageDiscou... | 115           |
| Policy-AveragePolicyStd | 0.36096102    |
| Policy-AverageReturn    | 307           |
| Policy-MaxReturn        | 378           |
| Policy-MinReturn        | 249           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 32            |
| Policy-TimeAlgoOpt      | 0.557         |
| Policy-TimeSampleProc   | 0.381         |
| Policy-TimeSampling     | 1.49          |
| Policy-TimeStep         | 2.47          |
| Time                    | 1.64e+03      |
| n_timesteps             | 47000         |
-------------------------------------------

 ---------------- Iteration 47 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 470 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 471 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 472 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 473 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 474 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 475 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 476 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 477 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 478 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 479 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.319          |
| Data-EnvSampler-Poli... | 0.794          |
| Data-EnvTrajs-Averag... | 222            |
| Data-EnvTrajs-MaxReturn | 286            |
| Data-EnvTrajs-MinReturn | 141            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 56.2           |
| Data-TimeEnvSampleProc  | 0.000769       |
| Data-TimeEnvSampling    | 1.14           |
| Iteration               | 47             |
| ItrTime                 | 40.9           |
| LossAfter               | -0.01766936    |
| LossBefore              | -3.7207449e-06 |
| Model-TimeModelFit      | 37.4           |
| ModelSampler-n_times... | 1920000        |
| Policy-AverageAbsPol... | 0.835002       |
| Policy-AverageDiscou... | 60.5           |
| Policy-AveragePolicyStd | 0.3528743      |
| Policy-AverageReturn    | 168            |
| Policy-MaxReturn        | 248            |
| Policy-MinReturn        | 71.4           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 49.3           |
| Policy-TimeAlgoOpt      | 0.581          |
| Policy-TimeSampleProc   | 0.331          |
| Policy-TimeSampling     | 1.4            |
| Policy-TimeStep         | 2.37           |
| Time                    | 1.68e+03       |
| n_timesteps             | 48000          |
--------------------------------------------

 ---------------- Iteration 48 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 480 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 481 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 482 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 483 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 484 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 485 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 486 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 487 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 488 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 489 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.304          |
| Data-EnvSampler-Poli... | 0.754          |
| Data-EnvTrajs-Averag... | 263            |
| Data-EnvTrajs-MaxReturn | 308            |
| Data-EnvTrajs-MinReturn | 218            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 36.1           |
| Data-TimeEnvSampleProc  | 0.000985       |
| Data-TimeEnvSampling    | 1.09           |
| Iteration               | 48             |
| ItrTime                 | 41.1           |
| LossAfter               | -0.018514518   |
| LossBefore              | -3.5004193e-06 |
| Model-TimeModelFit      | 37.5           |
| ModelSampler-n_times... | 1960000        |
| Policy-AverageAbsPol... | 0.8901147      |
| Policy-AverageDiscou... | 126            |
| Policy-AveragePolicyStd | 0.34465137     |
| Policy-AverageReturn    | 351            |
| Policy-MaxReturn        | 414            |
| Policy-MinReturn        | 206            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 51.6           |
| Policy-TimeAlgoOpt      | 0.58           |
| Policy-TimeSampleProc   | 0.439          |
| Policy-TimeSampling     | 1.44           |
| Policy-TimeStep         | 2.49           |
| Time                    | 1.72e+03       |
| n_timesteps             | 49000          |
--------------------------------------------

 ---------------- Iteration 49 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 490 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 491 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 492 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 493 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 494 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 495 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 496 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 497 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 498 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 499 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.304          |
| Data-EnvSampler-Poli... | 0.766          |
| Data-EnvTrajs-Averag... | 232            |
| Data-EnvTrajs-MaxReturn | 253            |
| Data-EnvTrajs-MinReturn | 213            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 14.6           |
| Data-TimeEnvSampleProc  | 0.000811       |
| Data-TimeEnvSampling    | 1.1            |
| Iteration               | 49             |
| ItrTime                 | 37.3           |
| LossAfter               | -0.01625281    |
| LossBefore              | -3.1847155e-06 |
| Model-TimeModelFit      | 31.9           |
| ModelSampler-n_times... | 2000000        |
| Policy-AverageAbsPol... | 0.89276385     |
| Policy-AverageDiscou... | 82.8           |
| Policy-AveragePolicyStd | 0.33414596     |
| Policy-AverageReturn    | 228            |
| Policy-MaxReturn        | 292            |
| Policy-MinReturn        | 128            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 36.7           |
| Policy-TimeAlgoOpt      | 0.799          |
| Policy-TimeSampleProc   | 0.848          |
| Policy-TimeSampling     | 2.55           |
| Policy-TimeStep         | 4.25           |
| Time                    | 1.76e+03       |
| n_timesteps             | 50000          |
--------------------------------------------

 ---------------- Iteration 50 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 500 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 501 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 502 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 503 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 504 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 505 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 506 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 507 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 508 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 509 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.55           |
| Data-EnvSampler-Poli... | 1.36           |
| Data-EnvTrajs-Averag... | 232            |
| Data-EnvTrajs-MaxReturn | 272            |
| Data-EnvTrajs-MinReturn | 125            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 53.9           |
| Data-TimeEnvSampleProc  | 0.00162        |
| Data-TimeEnvSampling    | 1.96           |
| Iteration               | 50             |
| ItrTime                 | 37.4           |
| LossAfter               | -0.015436828   |
| LossBefore              | -2.9333482e-06 |
| Model-TimeModelFit      | 33.4           |
| ModelSampler-n_times... | 2040000        |
| Policy-AverageAbsPol... | 0.87562746     |
| Policy-AverageDiscou... | 69.3           |
| Policy-AveragePolicyStd | 0.32672137     |
| Policy-AverageReturn    | 195            |
| Policy-MaxReturn        | 269            |
| Policy-MinReturn        | 109            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 42.4           |
| Policy-TimeAlgoOpt      | 0.501          |
| Policy-TimeSampleProc   | 0.242          |
| Policy-TimeSampling     | 1.25           |
| Policy-TimeStep         | 2.01           |
| Time                    | 1.8e+03        |
| n_timesteps             | 51000          |
--------------------------------------------
Training finished
