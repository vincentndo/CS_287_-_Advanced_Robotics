Logging to /home/vincent/workplace/CS_287_-_Advanced_Robotics/homework/hw5/cs287hw5/ppo/run_scripts/data/parallel_mb_ppo/mbppo_HalfCheetah_l2_no_square//02

 ---------------- Iteration 0 ----------------
Obtaining random samples from the environment...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 0 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 1 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 2 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 3 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 4 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 5 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 6 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 7 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 8 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 9 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.127          |
| Data-EnvSampler-Poli... | 0.0394         |
| Data-EnvTrajs-Averag... | -85.3          |
| Data-EnvTrajs-MaxReturn | -56.3          |
| Data-EnvTrajs-MinReturn | -122           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 24.2           |
| Data-TimeEnvSampleProc  | 0.000469       |
| Data-TimeEnvSampling    | 0.177          |
| Iteration               | 0              |
| ItrTime                 | 8.55           |
| LossAfter               | -0.016972858   |
| LossBefore              | -1.4031762e-05 |
| Model-TimeModelFit      | 3.11           |
| ModelSampler-n_times... | 40000          |
| Policy-AverageAbsPol... | 0.68772477     |
| Policy-AverageDiscou... | -260           |
| Policy-AveragePolicyStd | 0.984708       |
| Policy-AverageReturn    | -678           |
| Policy-MaxReturn        | -454           |
| Policy-MinReturn        | -1.68e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 274            |
| Policy-TimeAlgoOpt      | 0.943          |
| Policy-TimeSampleProc   | 0.363          |
| Policy-TimeSampling     | 3.86           |
| Policy-TimeStep         | 5.27           |
| Time                    | 8.55           |
| n_timesteps             | 1000           |
--------------------------------------------

 ---------------- Iteration 1 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 10 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 11 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 12 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 13 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 14 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 15 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 16 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 17 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 18 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 19 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.225          |
| Data-EnvSampler-Poli... | 0.6            |
| Data-EnvTrajs-Averag... | -71.8          |
| Data-EnvTrajs-MaxReturn | -2.04          |
| Data-EnvTrajs-MinReturn | -121           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 49.9           |
| Data-TimeEnvSampleProc  | 0.000781       |
| Data-TimeEnvSampling    | 0.845          |
| Iteration               | 1              |
| ItrTime                 | 7.19           |
| LossAfter               | -0.017221546   |
| LossBefore              | -1.3656345e-05 |
| Model-TimeModelFit      | 3.77           |
| ModelSampler-n_times... | 80000          |
| Policy-AverageAbsPol... | 0.6737797      |
| Policy-AverageDiscou... | 62.2           |
| Policy-AveragePolicyStd | 0.945682       |
| Policy-AverageReturn    | 195            |
| Policy-MaxReturn        | 318            |
| Policy-MinReturn        | 82.6           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 67.2           |
| Policy-TimeAlgoOpt      | 0.587          |
| Policy-TimeSampleProc   | 0.445          |
| Policy-TimeSampling     | 1.52           |
| Policy-TimeStep         | 2.58           |
| Time                    | 15.9           |
| n_timesteps             | 2000           |
--------------------------------------------

 ---------------- Iteration 2 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 20 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 21 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 22 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 23 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 24 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 25 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 26 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 27 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 28 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 29 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.328         |
| Data-EnvSampler-Poli... | 0.754         |
| Data-EnvTrajs-Averag... | -68.7         |
| Data-EnvTrajs-MaxReturn | 28.4          |
| Data-EnvTrajs-MinReturn | -169          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 62.5          |
| Data-TimeEnvSampleProc  | 0.000869      |
| Data-TimeEnvSampling    | 1.11          |
| Iteration               | 2             |
| ItrTime                 | 8.97          |
| LossAfter               | -0.017178098  |
| LossBefore              | -1.315038e-05 |
| Model-TimeModelFit      | 5.4           |
| ModelSampler-n_times... | 120000        |
| Policy-AverageAbsPol... | 0.6286408     |
| Policy-AverageDiscou... | 70.1          |
| Policy-AveragePolicyStd | 0.90272623    |
| Policy-AverageReturn    | 182           |
| Policy-MaxReturn        | 276           |
| Policy-MinReturn        | 86.5          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 53.7          |
| Policy-TimeAlgoOpt      | 0.561         |
| Policy-TimeSampleProc   | 0.463         |
| Policy-TimeSampling     | 1.4           |
| Policy-TimeStep         | 2.46          |
| Time                    | 24.9          |
| n_timesteps             | 3000          |
-------------------------------------------

 ---------------- Iteration 3 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 30 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 31 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 32 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 33 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 34 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 35 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 36 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 37 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 38 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 39 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.345          |
| Data-EnvSampler-Poli... | 0.978          |
| Data-EnvTrajs-Averag... | -33.2          |
| Data-EnvTrajs-MaxReturn | 7.48           |
| Data-EnvTrajs-MinReturn | -55.7          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 21.6           |
| Data-TimeEnvSampleProc  | 0.00064        |
| Data-TimeEnvSampling    | 1.36           |
| Iteration               | 3              |
| ItrTime                 | 14.4           |
| LossAfter               | -0.015029509   |
| LossBefore              | -1.2790633e-05 |
| Model-TimeModelFit      | 8.99           |
| ModelSampler-n_times... | 160000         |
| Policy-AverageAbsPol... | 0.56905127     |
| Policy-AverageDiscou... | -60.8          |
| Policy-AveragePolicyStd | 0.86942554     |
| Policy-AverageReturn    | -140           |
| Policy-MaxReturn        | -79.8          |
| Policy-MinReturn        | -223           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 37.1           |
| Policy-TimeAlgoOpt      | 0.847          |
| Policy-TimeSampleProc   | 0.79           |
| Policy-TimeSampling     | 2.39           |
| Policy-TimeStep         | 4.06           |
| Time                    | 39.3           |
| n_timesteps             | 4000           |
--------------------------------------------

 ---------------- Iteration 4 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 40 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 41 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 42 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 43 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 44 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 45 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 46 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 47 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 48 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 49 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.43           |
| Data-EnvSampler-Poli... | 0.878          |
| Data-EnvTrajs-Averag... | -55            |
| Data-EnvTrajs-MaxReturn | -15.6          |
| Data-EnvTrajs-MinReturn | -113           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 35.5           |
| Data-TimeEnvSampleProc  | 0.000504       |
| Data-TimeEnvSampling    | 1.36           |
| Iteration               | 4              |
| ItrTime                 | 13.6           |
| LossAfter               | -0.012681856   |
| LossBefore              | -1.2427257e-05 |
| Model-TimeModelFit      | 9.46           |
| ModelSampler-n_times... | 200000         |
| Policy-AverageAbsPol... | 0.5569769      |
| Policy-AverageDiscou... | -68.6          |
| Policy-AveragePolicyStd | 0.84019375     |
| Policy-AverageReturn    | -160           |
| Policy-MaxReturn        | -102           |
| Policy-MinReturn        | -236           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 32.5           |
| Policy-TimeAlgoOpt      | 0.628          |
| Policy-TimeSampleProc   | 0.472          |
| Policy-TimeSampling     | 1.65           |
| Policy-TimeStep         | 2.81           |
| Time                    | 52.9           |
| n_timesteps             | 5000           |
--------------------------------------------

 ---------------- Iteration 5 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 50 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 51 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 52 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 53 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 54 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 55 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 56 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 57 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 58 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 59 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.409          |
| Data-EnvSampler-Poli... | 0.919          |
| Data-EnvTrajs-Averag... | 2.41           |
| Data-EnvTrajs-MaxReturn | 24.5           |
| Data-EnvTrajs-MinReturn | -26.3          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 19.7           |
| Data-TimeEnvSampleProc  | 0.000987       |
| Data-TimeEnvSampling    | 1.36           |
| Iteration               | 5              |
| ItrTime                 | 17.2           |
| LossAfter               | -0.015105865   |
| LossBefore              | -1.2144852e-05 |
| Model-TimeModelFit      | 12.9           |
| ModelSampler-n_times... | 240000         |
| Policy-AverageAbsPol... | 0.6185583      |
| Policy-AverageDiscou... | -27.3          |
| Policy-AveragePolicyStd | 0.81623155     |
| Policy-AverageReturn    | -56.1          |
| Policy-MaxReturn        | -3.05          |
| Policy-MinReturn        | -132           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 32.4           |
| Policy-TimeAlgoOpt      | 0.575          |
| Policy-TimeSampleProc   | 0.749          |
| Policy-TimeSampling     | 1.56           |
| Policy-TimeStep         | 2.93           |
| Time                    | 70.1           |
| n_timesteps             | 6000           |
--------------------------------------------

 ---------------- Iteration 6 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 60 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 61 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 62 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 63 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 64 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 65 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 66 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 67 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 68 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 69 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.385         |
| Data-EnvSampler-Poli... | 1.01          |
| Data-EnvTrajs-Averag... | -23.4         |
| Data-EnvTrajs-MaxReturn | 29.6          |
| Data-EnvTrajs-MinReturn | -54.3         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 31.8          |
| Data-TimeEnvSampleProc  | 0.000902      |
| Data-TimeEnvSampling    | 1.43          |
| Iteration               | 6             |
| ItrTime                 | 19.7          |
| LossAfter               | -0.016250707  |
| LossBefore              | -1.183411e-05 |
| Model-TimeModelFit      | 14.5          |
| ModelSampler-n_times... | 280000        |
| Policy-AverageAbsPol... | 0.69175535    |
| Policy-AverageDiscou... | 13.4          |
| Policy-AveragePolicyStd | 0.79145616    |
| Policy-AverageReturn    | 41.8          |
| Policy-MaxReturn        | 111           |
| Policy-MinReturn        | -12           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 36.1          |
| Policy-TimeAlgoOpt      | 0.766         |
| Policy-TimeSampleProc   | 0.794         |
| Policy-TimeSampling     | 2.13          |
| Policy-TimeStep         | 3.75          |
| Time                    | 89.8          |
| n_timesteps             | 7000          |
-------------------------------------------

 ---------------- Iteration 7 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 70 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 71 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 72 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 73 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 74 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 75 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 76 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 77 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 78 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 79 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.555          |
| Data-EnvSampler-Poli... | 1.07           |
| Data-EnvTrajs-Averag... | 76             |
| Data-EnvTrajs-MaxReturn | 110            |
| Data-EnvTrajs-MinReturn | 50.1           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 19.5           |
| Data-TimeEnvSampleProc  | 0.00117        |
| Data-TimeEnvSampling    | 1.67           |
| Iteration               | 7              |
| ItrTime                 | 20.2           |
| LossAfter               | -0.016744135   |
| LossBefore              | -1.1691494e-05 |
| Model-TimeModelFit      | 15.8           |
| ModelSampler-n_times... | 320000         |
| Policy-AverageAbsPol... | 0.72036946     |
| Policy-AverageDiscou... | -123           |
| Policy-AveragePolicyStd | 0.7804503      |
| Policy-AverageReturn    | -292           |
| Policy-MaxReturn        | -217           |
| Policy-MinReturn        | -377           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 40.8           |
| Policy-TimeAlgoOpt      | 0.557          |
| Policy-TimeSampleProc   | 0.512          |
| Policy-TimeSampling     | 1.58           |
| Policy-TimeStep         | 2.7            |
| Time                    | 110            |
| n_timesteps             | 8000           |
--------------------------------------------

 ---------------- Iteration 8 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 80 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 81 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 82 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 83 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 84 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 85 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 86 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 87 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 88 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 89 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.357          |
| Data-EnvSampler-Poli... | 0.844          |
| Data-EnvTrajs-Averag... | -20.4          |
| Data-EnvTrajs-MaxReturn | 19.2           |
| Data-EnvTrajs-MinReturn | -48.1          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 22.6           |
| Data-TimeEnvSampleProc  | 0.000809       |
| Data-TimeEnvSampling    | 1.24           |
| Iteration               | 8              |
| ItrTime                 | 24.1           |
| LossAfter               | -0.01660148    |
| LossBefore              | -1.1353759e-05 |
| Model-TimeModelFit      | 20.3           |
| ModelSampler-n_times... | 360000         |
| Policy-AverageAbsPol... | 0.71850616     |
| Policy-AverageDiscou... | 9.32           |
| Policy-AveragePolicyStd | 0.7541431      |
| Policy-AverageReturn    | 27.9           |
| Policy-MaxReturn        | 74.2           |
| Policy-MinReturn        | -68            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 38.1           |
| Policy-TimeAlgoOpt      | 0.567          |
| Policy-TimeSampleProc   | 0.396          |
| Policy-TimeSampling     | 1.59           |
| Policy-TimeStep         | 2.57           |
| Time                    | 134            |
| n_timesteps             | 9000           |
--------------------------------------------

 ---------------- Iteration 9 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 90 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 91 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 92 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 93 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 94 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 95 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 96 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 97 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 98 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 99 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.408          |
| Data-EnvSampler-Poli... | 1.27           |
| Data-EnvTrajs-Averag... | 57.8           |
| Data-EnvTrajs-MaxReturn | 115            |
| Data-EnvTrajs-MinReturn | -38.5          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 55.8           |
| Data-TimeEnvSampleProc  | 0.000943       |
| Data-TimeEnvSampling    | 1.72           |
| Iteration               | 9              |
| ItrTime                 | 27.6           |
| LossAfter               | -0.015907094   |
| LossBefore              | -1.1068684e-05 |
| Model-TimeModelFit      | 23.2           |
| ModelSampler-n_times... | 400000         |
| Policy-AverageAbsPol... | 0.6985971      |
| Policy-AverageDiscou... | -51.7          |
| Policy-AveragePolicyStd | 0.7316551      |
| Policy-AverageReturn    | -119           |
| Policy-MaxReturn        | -42.9          |
| Policy-MinReturn        | -180           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 32.8           |
| Policy-TimeAlgoOpt      | 0.605          |
| Policy-TimeSampleProc   | 0.446          |
| Policy-TimeSampling     | 1.6            |
| Policy-TimeStep         | 2.68           |
| Time                    | 162            |
| n_timesteps             | 10000          |
--------------------------------------------

 ---------------- Iteration 10 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 100 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 101 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 102 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 103 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 104 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 105 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 106 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 107 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 108 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 109 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.368           |
| Data-EnvSampler-Poli... | 0.961           |
| Data-EnvTrajs-Averag... | 52.7            |
| Data-EnvTrajs-MaxReturn | 141             |
| Data-EnvTrajs-MinReturn | 14.6            |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 45.3            |
| Data-TimeEnvSampleProc  | 0.000736        |
| Data-TimeEnvSampling    | 1.37            |
| Iteration               | 10              |
| ItrTime                 | 29.1            |
| LossAfter               | -0.014986219    |
| LossBefore              | -1.09379325e-05 |
| Model-TimeModelFit      | 24.7            |
| ModelSampler-n_times... | 440000          |
| Policy-AverageAbsPol... | 0.73467624      |
| Policy-AverageDiscou... | -8.75           |
| Policy-AveragePolicyStd | 0.72403616      |
| Policy-AverageReturn    | -204            |
| Policy-MaxReturn        | 329             |
| Policy-MinReturn        | -8.39e+03       |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 1.88e+03        |
| Policy-TimeAlgoOpt      | 0.608           |
| Policy-TimeSampleProc   | 0.661           |
| Policy-TimeSampling     | 1.8             |
| Policy-TimeStep         | 3.12            |
| Time                    | 191             |
| n_timesteps             | 11000           |
---------------------------------------------

 ---------------- Iteration 11 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 110 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 111 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 112 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 113 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 114 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 115 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 116 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 117 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 118 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 119 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.417          |
| Data-EnvSampler-Poli... | 1              |
| Data-EnvTrajs-Averag... | 80.1           |
| Data-EnvTrajs-MaxReturn | 164            |
| Data-EnvTrajs-MinReturn | -18            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 65.9           |
| Data-TimeEnvSampleProc  | 0.00892        |
| Data-TimeEnvSampling    | 1.46           |
| Iteration               | 11             |
| ItrTime                 | 32.5           |
| LossAfter               | -0.01481352    |
| LossBefore              | -1.0734105e-05 |
| Model-TimeModelFit      | 28.3           |
| ModelSampler-n_times... | 480000         |
| Policy-AverageAbsPol... | 0.7103452      |
| Policy-AverageDiscou... | -34.9          |
| Policy-AveragePolicyStd | 0.7074095      |
| Policy-AverageReturn    | -73.7          |
| Policy-MaxReturn        | -5.24          |
| Policy-MinReturn        | -139           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 38.4           |
| Policy-TimeAlgoOpt      | 0.554          |
| Policy-TimeSampleProc   | 0.557          |
| Policy-TimeSampling     | 1.57           |
| Policy-TimeStep         | 2.72           |
| Time                    | 223            |
| n_timesteps             | 12000          |
--------------------------------------------

 ---------------- Iteration 12 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 120 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 121 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 122 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 123 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 124 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 125 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 126 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 127 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 128 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 129 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.353           |
| Data-EnvSampler-Poli... | 0.815           |
| Data-EnvTrajs-Averag... | 62.8            |
| Data-EnvTrajs-MaxReturn | 172             |
| Data-EnvTrajs-MinReturn | -45.4           |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 75.8            |
| Data-TimeEnvSampleProc  | 0.00115         |
| Data-TimeEnvSampling    | 1.2             |
| Iteration               | 12              |
| ItrTime                 | 32.3            |
| LossAfter               | -0.015612293    |
| LossBefore              | -1.04146775e-05 |
| Model-TimeModelFit      | 28.6            |
| ModelSampler-n_times... | 520000          |
| Policy-AverageAbsPol... | 0.75816095      |
| Policy-AverageDiscou... | 10.9            |
| Policy-AveragePolicyStd | 0.68603915      |
| Policy-AverageReturn    | 38.5            |
| Policy-MaxReturn        | 122             |
| Policy-MinReturn        | -16.8           |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 29.3            |
| Policy-TimeAlgoOpt      | 0.572           |
| Policy-TimeSampleProc   | 0.391           |
| Policy-TimeSampling     | 1.47            |
| Policy-TimeStep         | 2.49            |
| Time                    | 256             |
| n_timesteps             | 13000           |
---------------------------------------------

 ---------------- Iteration 13 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 130 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 131 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 132 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 133 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 134 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 135 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 136 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 137 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 138 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 139 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.367         |
| Data-EnvSampler-Poli... | 0.838         |
| Data-EnvTrajs-Averag... | 88.7          |
| Data-EnvTrajs-MaxReturn | 142           |
| Data-EnvTrajs-MinReturn | 47.8          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 33.9          |
| Data-TimeEnvSampleProc  | 0.000548      |
| Data-TimeEnvSampling    | 1.24          |
| Iteration               | 13            |
| ItrTime                 | 37.7          |
| LossAfter               | -0.018138599  |
| LossBefore              | -1.020429e-05 |
| Model-TimeModelFit      | 33.3          |
| ModelSampler-n_times... | 560000        |
| Policy-AverageAbsPol... | 0.8047065     |
| Policy-AverageDiscou... | 91.9          |
| Policy-AveragePolicyStd | 0.6714478     |
| Policy-AverageReturn    | 237           |
| Policy-MaxReturn        | 287           |
| Policy-MinReturn        | 192           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 30            |
| Policy-TimeAlgoOpt      | 0.541         |
| Policy-TimeSampleProc   | 0.82          |
| Policy-TimeSampling     | 1.79          |
| Policy-TimeStep         | 3.18          |
| Time                    | 293           |
| n_timesteps             | 14000         |
-------------------------------------------

 ---------------- Iteration 14 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 140 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 141 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 142 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 143 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 144 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 145 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 146 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 147 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 148 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 149 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.464         |
| Data-EnvSampler-Poli... | 1.08          |
| Data-EnvTrajs-Averag... | 5.91          |
| Data-EnvTrajs-MaxReturn | 71.7          |
| Data-EnvTrajs-MinReturn | -126          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 73            |
| Data-TimeEnvSampleProc  | 0.000805      |
| Data-TimeEnvSampling    | 1.6           |
| Iteration               | 14            |
| ItrTime                 | 39.1          |
| LossAfter               | -0.018807068  |
| LossBefore              | -9.981298e-06 |
| Model-TimeModelFit      | 34.7          |
| ModelSampler-n_times... | 600000        |
| Policy-AverageAbsPol... | 0.80853164    |
| Policy-AverageDiscou... | 119           |
| Policy-AveragePolicyStd | 0.65664387    |
| Policy-AverageReturn    | 319           |
| Policy-MaxReturn        | 371           |
| Policy-MinReturn        | 203           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 44.3          |
| Policy-TimeAlgoOpt      | 0.623         |
| Policy-TimeSampleProc   | 0.497         |
| Policy-TimeSampling     | 1.68          |
| Policy-TimeStep         | 2.83          |
| Time                    | 333           |
| n_timesteps             | 15000         |
-------------------------------------------

 ---------------- Iteration 15 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 150 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 151 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 152 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 153 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 154 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 155 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 156 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 157 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 158 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 159 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.657         |
| Data-EnvSampler-Poli... | 1.36          |
| Data-EnvTrajs-Averag... | 70            |
| Data-EnvTrajs-MaxReturn | 155           |
| Data-EnvTrajs-MinReturn | -1.59         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 55.4          |
| Data-TimeEnvSampleProc  | 0.00123       |
| Data-TimeEnvSampling    | 2.07          |
| Iteration               | 15            |
| ItrTime                 | 36.6          |
| LossAfter               | -0.017061595  |
| LossBefore              | -9.899491e-06 |
| Model-TimeModelFit      | 31.3          |
| ModelSampler-n_times... | 640000        |
| Policy-AverageAbsPol... | 0.7714479     |
| Policy-AverageDiscou... | 2.6           |
| Policy-AveragePolicyStd | 0.6512242     |
| Policy-AverageReturn    | 16.9          |
| Policy-MaxReturn        | 113           |
| Policy-MinReturn        | -114          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 54.1          |
| Policy-TimeAlgoOpt      | 0.661         |
| Policy-TimeSampleProc   | 0.67          |
| Policy-TimeSampling     | 1.79          |
| Policy-TimeStep         | 3.17          |
| Time                    | 369           |
| n_timesteps             | 16000         |
-------------------------------------------

 ---------------- Iteration 16 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 160 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 161 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 162 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 163 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 164 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 165 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 166 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 167 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 168 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 169 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.569          |
| Data-EnvSampler-Poli... | 1.23           |
| Data-EnvTrajs-Averag... | 33             |
| Data-EnvTrajs-MaxReturn | 68.1           |
| Data-EnvTrajs-MinReturn | -7.01          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 27.2           |
| Data-TimeEnvSampleProc  | 0.00149        |
| Data-TimeEnvSampling    | 1.84           |
| Iteration               | 16             |
| ItrTime                 | 41.8           |
| LossAfter               | -0.015076704   |
| LossBefore              | -9.7035345e-06 |
| Model-TimeModelFit      | 36             |
| ModelSampler-n_times... | 680000         |
| Policy-AverageAbsPol... | 0.79081655     |
| Policy-AverageDiscou... | -23.8          |
| Policy-AveragePolicyStd | 0.63930655     |
| Policy-AverageReturn    | -52            |
| Policy-MaxReturn        | 20.4           |
| Policy-MinReturn        | -158           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 49.7           |
| Policy-TimeAlgoOpt      | 0.655          |
| Policy-TimeSampleProc   | 0.828          |
| Policy-TimeSampling     | 2.39           |
| Policy-TimeStep         | 3.96           |
| Time                    | 411            |
| n_timesteps             | 17000          |
--------------------------------------------

 ---------------- Iteration 17 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 170 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 171 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 172 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 173 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 174 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 175 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 176 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 177 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 178 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 179 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.441         |
| Data-EnvSampler-Poli... | 1.04          |
| Data-EnvTrajs-Averag... | 46.9          |
| Data-EnvTrajs-MaxReturn | 110           |
| Data-EnvTrajs-MinReturn | -8.16         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 46.5          |
| Data-TimeEnvSampleProc  | 0.00107       |
| Data-TimeEnvSampling    | 1.52          |
| Iteration               | 17            |
| ItrTime                 | 42.1          |
| LossAfter               | -0.016675498  |
| LossBefore              | -9.617544e-06 |
| Model-TimeModelFit      | 37.4          |
| ModelSampler-n_times... | 720000        |
| Policy-AverageAbsPol... | 0.85991585    |
| Policy-AverageDiscou... | -36.4         |
| Policy-AveragePolicyStd | 0.633403      |
| Policy-AverageReturn    | -81.6         |
| Policy-MaxReturn        | 9.94          |
| Policy-MinReturn        | -206          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 49.3          |
| Policy-TimeAlgoOpt      | 0.617         |
| Policy-TimeSampleProc   | 0.669         |
| Policy-TimeSampling     | 1.93          |
| Policy-TimeStep         | 3.26          |
| Time                    | 453           |
| n_timesteps             | 18000         |
-------------------------------------------

 ---------------- Iteration 18 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 180 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 181 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 182 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 183 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 184 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 185 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 186 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 187 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 188 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 189 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.48          |
| Data-EnvSampler-Poli... | 1.08          |
| Data-EnvTrajs-Averag... | 123           |
| Data-EnvTrajs-MaxReturn | 149           |
| Data-EnvTrajs-MinReturn | 95.1          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 21            |
| Data-TimeEnvSampleProc  | 0.000551      |
| Data-TimeEnvSampling    | 1.6           |
| Iteration               | 18            |
| ItrTime                 | 41            |
| LossAfter               | -0.01534613   |
| LossBefore              | -9.389388e-06 |
| Model-TimeModelFit      | 36.7          |
| ModelSampler-n_times... | 760000        |
| Policy-AverageAbsPol... | 0.89203566    |
| Policy-AverageDiscou... | 293           |
| Policy-AveragePolicyStd | 0.6195639     |
| Policy-AverageReturn    | 752           |
| Policy-MaxReturn        | 871           |
| Policy-MinReturn        | 626           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 61.3          |
| Policy-TimeAlgoOpt      | 0.561         |
| Policy-TimeSampleProc   | 0.468         |
| Policy-TimeSampling     | 1.59          |
| Policy-TimeStep         | 2.66          |
| Time                    | 494           |
| n_timesteps             | 19000         |
-------------------------------------------

 ---------------- Iteration 19 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 190 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 191 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 192 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 193 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 194 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 195 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 196 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 197 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 198 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 199 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.422         |
| Data-EnvSampler-Poli... | 1.12          |
| Data-EnvTrajs-Averag... | 158           |
| Data-EnvTrajs-MaxReturn | 251           |
| Data-EnvTrajs-MinReturn | 57.8          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 67.1          |
| Data-TimeEnvSampleProc  | 0.00089       |
| Data-TimeEnvSampling    | 1.58          |
| Iteration               | 19            |
| ItrTime                 | 38.3          |
| LossAfter               | -0.014808618  |
| LossBefore              | -9.251134e-06 |
| Model-TimeModelFit      | 34.2          |
| ModelSampler-n_times... | 800000        |
| Policy-AverageAbsPol... | 0.8727424     |
| Policy-AverageDiscou... | 2.95          |
| Policy-AveragePolicyStd | 0.6110961     |
| Policy-AverageReturn    | 19.9          |
| Policy-MaxReturn        | 115           |
| Policy-MinReturn        | -95.9         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 44.7          |
| Policy-TimeAlgoOpt      | 0.551         |
| Policy-TimeSampleProc   | 0.549         |
| Policy-TimeSampling     | 1.42          |
| Policy-TimeStep         | 2.58          |
| Time                    | 532           |
| n_timesteps             | 20000         |
-------------------------------------------

 ---------------- Iteration 20 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 200 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 201 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 202 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 203 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 204 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 205 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 206 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 207 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 208 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 209 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.428          |
| Data-EnvSampler-Poli... | 0.993          |
| Data-EnvTrajs-Averag... | 138            |
| Data-EnvTrajs-MaxReturn | 209            |
| Data-EnvTrajs-MinReturn | -10.2          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 77.3           |
| Data-TimeEnvSampleProc  | 0.00157        |
| Data-TimeEnvSampling    | 1.48           |
| Iteration               | 20             |
| ItrTime                 | 39.1           |
| LossAfter               | -0.0146308625  |
| LossBefore              | -8.9480845e-06 |
| Model-TimeModelFit      | 34.2           |
| ModelSampler-n_times... | 840000         |
| Policy-AverageAbsPol... | 0.90140706     |
| Policy-AverageDiscou... | 42.5           |
| Policy-AveragePolicyStd | 0.59460086     |
| Policy-AverageReturn    | 124            |
| Policy-MaxReturn        | 185            |
| Policy-MinReturn        | 71             |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 32.6           |
| Policy-TimeAlgoOpt      | 0.647          |
| Policy-TimeSampleProc   | 0.708          |
| Policy-TimeSampling     | 2.04           |
| Policy-TimeStep         | 3.43           |
| Time                    | 572            |
| n_timesteps             | 21000          |
--------------------------------------------

 ---------------- Iteration 21 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 210 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 211 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 212 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 213 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 214 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 215 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 216 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 217 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 218 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 219 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.431         |
| Data-EnvSampler-Poli... | 0.976         |
| Data-EnvTrajs-Averag... | 130           |
| Data-EnvTrajs-MaxReturn | 249           |
| Data-EnvTrajs-MinReturn | 57.8          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 71.4          |
| Data-TimeEnvSampleProc  | 0.00122       |
| Data-TimeEnvSampling    | 1.45          |
| Iteration               | 21            |
| ItrTime                 | 41.9          |
| LossAfter               | -0.015120302  |
| LossBefore              | -8.747962e-06 |
| Model-TimeModelFit      | 37.8          |
| ModelSampler-n_times... | 880000        |
| Policy-AverageAbsPol... | 0.93430406    |
| Policy-AverageDiscou... | 107           |
| Policy-AveragePolicyStd | 0.58236957    |
| Policy-AverageReturn    | 285           |
| Policy-MaxReturn        | 346           |
| Policy-MinReturn        | 29.1          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 70.9          |
| Policy-TimeAlgoOpt      | 0.619         |
| Policy-TimeSampleProc   | 0.42          |
| Policy-TimeSampling     | 1.57          |
| Policy-TimeStep         | 2.64          |
| Time                    | 613           |
| n_timesteps             | 22000         |
-------------------------------------------

 ---------------- Iteration 22 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 220 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 221 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 222 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 223 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 224 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 225 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 226 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 227 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 228 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 229 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.35          |
| Data-EnvSampler-Poli... | 0.861         |
| Data-EnvTrajs-Averag... | 115           |
| Data-EnvTrajs-MaxReturn | 222           |
| Data-EnvTrajs-MinReturn | -43.9         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 111           |
| Data-TimeEnvSampleProc  | 0.000846      |
| Data-TimeEnvSampling    | 1.25          |
| Iteration               | 22            |
| ItrTime                 | 37.9          |
| LossAfter               | -0.0156543    |
| LossBefore              | -8.602019e-06 |
| Model-TimeModelFit      | 33.7          |
| ModelSampler-n_times... | 920000        |
| Policy-AverageAbsPol... | 0.9170906     |
| Policy-AverageDiscou... | 56.5          |
| Policy-AveragePolicyStd | 0.5747251     |
| Policy-AverageReturn    | 161           |
| Policy-MaxReturn        | 227           |
| Policy-MinReturn        | 90.6          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 35.3          |
| Policy-TimeAlgoOpt      | 0.605         |
| Policy-TimeSampleProc   | 0.568         |
| Policy-TimeSampling     | 1.69          |
| Policy-TimeStep         | 2.9           |
| Time                    | 651           |
| n_timesteps             | 23000         |
-------------------------------------------

 ---------------- Iteration 23 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 230 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 231 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 232 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 233 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 234 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 235 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 236 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 237 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 238 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 239 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Data-EnvSampler-EnvE... | 0.435        |
| Data-EnvSampler-Poli... | 1.41         |
| Data-EnvTrajs-Averag... | 208          |
| Data-EnvTrajs-MaxReturn | 263          |
| Data-EnvTrajs-MinReturn | 156          |
| Data-EnvTrajs-NumTrajs  | 5            |
| Data-EnvTrajs-StdReturn | 34           |
| Data-TimeEnvSampleProc  | 0.00873      |
| Data-TimeEnvSampling    | 1.9          |
| Iteration               | 23           |
| ItrTime                 | 46.9         |
| LossAfter               | -0.014485996 |
| LossBefore              | -8.37299e-06 |
| Model-TimeModelFit      | 41.6         |
| ModelSampler-n_times... | 960000       |
| Policy-AverageAbsPol... | 0.9457736    |
| Policy-AverageDiscou... | 120          |
| Policy-AveragePolicyStd | 0.56029856   |
| Policy-AverageReturn    | 319          |
| Policy-MaxReturn        | 399          |
| Policy-MinReturn        | 91.2         |
| Policy-NumTrajs         | 20           |
| Policy-StdReturn        | 74.9         |
| Policy-TimeAlgoOpt      | 0.692        |
| Policy-TimeSampleProc   | 0.712        |
| Policy-TimeSampling     | 2            |
| Policy-TimeStep         | 3.42         |
| Time                    | 698          |
| n_timesteps             | 24000        |
------------------------------------------

 ---------------- Iteration 24 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 240 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 241 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 242 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 243 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 244 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 245 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 246 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 247 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 248 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 249 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.823         |
| Data-EnvSampler-Poli... | 1.96          |
| Data-EnvTrajs-Averag... | 267           |
| Data-EnvTrajs-MaxReturn | 331           |
| Data-EnvTrajs-MinReturn | 216           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 42            |
| Data-TimeEnvSampleProc  | 0.00105       |
| Data-TimeEnvSampling    | 2.85          |
| Iteration               | 24            |
| ItrTime                 | 51.4          |
| LossAfter               | -0.0163677    |
| LossBefore              | -8.040419e-06 |
| Model-TimeModelFit      | 42.8          |
| ModelSampler-n_times... | 1000000       |
| Policy-AverageAbsPol... | 0.95566803    |
| Policy-AverageDiscou... | 102           |
| Policy-AveragePolicyStd | 0.5426997     |
| Policy-AverageReturn    | 271           |
| Policy-MaxReturn        | 357           |
| Policy-MinReturn        | 185           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 37.6          |
| Policy-TimeAlgoOpt      | 1             |
| Policy-TimeSampleProc   | 1.23          |
| Policy-TimeSampling     | 3.45          |
| Policy-TimeStep         | 5.73          |
| Time                    | 750           |
| n_timesteps             | 25000         |
-------------------------------------------

 ---------------- Iteration 25 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 250 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 251 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 252 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 253 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 254 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 255 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 256 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 257 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 258 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 259 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Data-EnvSampler-EnvE... | 0.803        |
| Data-EnvSampler-Poli... | 2.16         |
| Data-EnvTrajs-Averag... | 256          |
| Data-EnvTrajs-MaxReturn | 304          |
| Data-EnvTrajs-MinReturn | 168          |
| Data-EnvTrajs-NumTrajs  | 5            |
| Data-EnvTrajs-StdReturn | 48.5         |
| Data-TimeEnvSampleProc  | 0.00439      |
| Data-TimeEnvSampling    | 3.1          |
| Iteration               | 25           |
| ItrTime                 | 49.2         |
| LossAfter               | -0.00547041  |
| LossBefore              | -7.81955e-06 |
| Model-TimeModelFit      | 42.7         |
| ModelSampler-n_times... | 1040000      |
| Policy-AverageAbsPol... | 0.9580991    |
| Policy-AverageDiscou... | -241         |
| Policy-AveragePolicyStd | 0.5304379    |
| Policy-AverageReturn    | -706         |
| Policy-MaxReturn        | 186          |
| Policy-MinReturn        | -1.66e+04    |
| Policy-NumTrajs         | 20           |
| Policy-StdReturn        | 3.64e+03     |
| Policy-TimeAlgoOpt      | 0.61         |
| Policy-TimeSampleProc   | 0.675        |
| Policy-TimeSampling     | 2.1          |
| Policy-TimeStep         | 3.43         |
| Time                    | 799          |
| n_timesteps             | 26000        |
------------------------------------------

 ---------------- Iteration 26 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 260 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 261 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 262 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 263 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 264 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 265 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 266 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 267 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 268 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 269 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.386          |
| Data-EnvSampler-Poli... | 0.955          |
| Data-EnvTrajs-Averag... | 286            |
| Data-EnvTrajs-MaxReturn | 354            |
| Data-EnvTrajs-MinReturn | 221            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 47.4           |
| Data-TimeEnvSampleProc  | 0.000918       |
| Data-TimeEnvSampling    | 1.38           |
| Iteration               | 26             |
| ItrTime                 | 45.7           |
| LossAfter               | -0.014912092   |
| LossBefore              | -7.5627936e-06 |
| Model-TimeModelFit      | 41.2           |
| ModelSampler-n_times... | 1080000        |
| Policy-AverageAbsPol... | 0.97167903     |
| Policy-AverageDiscou... | 96.1           |
| Policy-AveragePolicyStd | 0.51728076     |
| Policy-AverageReturn    | 259            |
| Policy-MaxReturn        | 306            |
| Policy-MinReturn        | 159            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 36.6           |
| Policy-TimeAlgoOpt      | 0.565          |
| Policy-TimeSampleProc   | 0.738          |
| Policy-TimeSampling     | 1.85           |
| Policy-TimeStep         | 3.2            |
| Time                    | 845            |
| n_timesteps             | 27000          |
--------------------------------------------

 ---------------- Iteration 27 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 270 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 271 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 272 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 273 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 274 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 275 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 276 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 277 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 278 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 279 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.401          |
| Data-EnvSampler-Poli... | 1.05           |
| Data-EnvTrajs-Averag... | 216            |
| Data-EnvTrajs-MaxReturn | 305            |
| Data-EnvTrajs-MinReturn | 48.5           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 95.8           |
| Data-TimeEnvSampleProc  | 0.000938       |
| Data-TimeEnvSampling    | 1.49           |
| Iteration               | 27             |
| ItrTime                 | 44.9           |
| LossAfter               | -0.016628027   |
| LossBefore              | -7.4416675e-06 |
| Model-TimeModelFit      | 40.3           |
| ModelSampler-n_times... | 1120000        |
| Policy-AverageAbsPol... | 1.0098685      |
| Policy-AverageDiscou... | 55.7           |
| Policy-AveragePolicyStd | 0.5115566      |
| Policy-AverageReturn    | 160            |
| Policy-MaxReturn        | 226            |
| Policy-MinReturn        | 80.4           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 39.3           |
| Policy-TimeAlgoOpt      | 0.633          |
| Policy-TimeSampleProc   | 0.609          |
| Policy-TimeSampling     | 1.82           |
| Policy-TimeStep         | 3.1            |
| Time                    | 890            |
| n_timesteps             | 28000          |
--------------------------------------------

 ---------------- Iteration 28 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 280 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 281 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 282 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 283 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 284 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 285 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 286 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 287 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 288 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 289 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.417         |
| Data-EnvSampler-Poli... | 1.02          |
| Data-EnvTrajs-Averag... | 168           |
| Data-EnvTrajs-MaxReturn | 365           |
| Data-EnvTrajs-MinReturn | -34.5         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 155           |
| Data-TimeEnvSampleProc  | 0.00098       |
| Data-TimeEnvSampling    | 1.47          |
| Iteration               | 28            |
| ItrTime                 | 43.5          |
| LossAfter               | -0.014192713  |
| LossBefore              | -7.284546e-06 |
| Model-TimeModelFit      | 38.4          |
| ModelSampler-n_times... | 1160000       |
| Policy-AverageAbsPol... | 0.97117496    |
| Policy-AverageDiscou... | 93.4          |
| Policy-AveragePolicyStd | 0.5032385     |
| Policy-AverageReturn    | 241           |
| Policy-MaxReturn        | 352           |
| Policy-MinReturn        | 63.8          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 80.9          |
| Policy-TimeAlgoOpt      | 0.607         |
| Policy-TimeSampleProc   | 0.874         |
| Policy-TimeSampling     | 2.12          |
| Policy-TimeStep         | 3.68          |
| Time                    | 933           |
| n_timesteps             | 29000         |
-------------------------------------------

 ---------------- Iteration 29 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 290 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 291 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 292 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 293 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 294 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 295 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 296 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 297 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 298 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 299 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.419          |
| Data-EnvSampler-Poli... | 1.04           |
| Data-EnvTrajs-Averag... | 197            |
| Data-EnvTrajs-MaxReturn | 299            |
| Data-EnvTrajs-MinReturn | 29.2           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 112            |
| Data-TimeEnvSampleProc  | 0.000985       |
| Data-TimeEnvSampling    | 1.51           |
| Iteration               | 29             |
| ItrTime                 | 44             |
| LossAfter               | -0.012440307   |
| LossBefore              | -7.1468417e-06 |
| Model-TimeModelFit      | 39.3           |
| ModelSampler-n_times... | 1200000        |
| Policy-AverageAbsPol... | 1.0023125      |
| Policy-AverageDiscou... | 66.4           |
| Policy-AveragePolicyStd | 0.49636954     |
| Policy-AverageReturn    | 189            |
| Policy-MaxReturn        | 235            |
| Policy-MinReturn        | 110            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 37.3           |
| Policy-TimeAlgoOpt      | 0.608          |
| Policy-TimeSampleProc   | 0.61           |
| Policy-TimeSampling     | 1.84           |
| Policy-TimeStep         | 3.14           |
| Time                    | 977            |
| n_timesteps             | 30000          |
--------------------------------------------

 ---------------- Iteration 30 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 300 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 301 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 302 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 303 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 304 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 305 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 306 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 307 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 308 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 309 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.472          |
| Data-EnvSampler-Poli... | 1.14           |
| Data-EnvTrajs-Averag... | 235            |
| Data-EnvTrajs-MaxReturn | 308            |
| Data-EnvTrajs-MinReturn | 79.2           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 85.7           |
| Data-TimeEnvSampleProc  | 0.000859       |
| Data-TimeEnvSampling    | 1.65           |
| Iteration               | 30             |
| ItrTime                 | 42.7           |
| LossAfter               | -0.015977232   |
| LossBefore              | -7.0498445e-06 |
| Model-TimeModelFit      | 37.7           |
| ModelSampler-n_times... | 1240000        |
| Policy-AverageAbsPol... | 1.0083255      |
| Policy-AverageDiscou... | 105            |
| Policy-AveragePolicyStd | 0.49162036     |
| Policy-AverageReturn    | 288            |
| Policy-MaxReturn        | 366            |
| Policy-MinReturn        | 6.1            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 88.3           |
| Policy-TimeAlgoOpt      | 0.689          |
| Policy-TimeSampleProc   | 0.768          |
| Policy-TimeSampling     | 1.86           |
| Policy-TimeStep         | 3.37           |
| Time                    | 1.02e+03       |
| n_timesteps             | 31000          |
--------------------------------------------

 ---------------- Iteration 31 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 310 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 311 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 312 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 313 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 314 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 315 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 316 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 317 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 318 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 319 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.725          |
| Data-EnvSampler-Poli... | 1.62           |
| Data-EnvTrajs-Averag... | 284            |
| Data-EnvTrajs-MaxReturn | 376            |
| Data-EnvTrajs-MinReturn | 64.6           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 114            |
| Data-TimeEnvSampleProc  | 0.00156        |
| Data-TimeEnvSampling    | 2.41           |
| Iteration               | 31             |
| ItrTime                 | 46.7           |
| LossAfter               | -0.013821096   |
| LossBefore              | -6.7782753e-06 |
| Model-TimeModelFit      | 39.1           |
| ModelSampler-n_times... | 1280000        |
| Policy-AverageAbsPol... | 1.0506837      |
| Policy-AverageDiscou... | 53.9           |
| Policy-AveragePolicyStd | 0.4782246      |
| Policy-AverageReturn    | 166            |
| Policy-MaxReturn        | 235            |
| Policy-MinReturn        | 78.3           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 38             |
| Policy-TimeAlgoOpt      | 1              |
| Policy-TimeSampleProc   | 0.994          |
| Policy-TimeSampling     | 3.21           |
| Policy-TimeStep         | 5.25           |
| Time                    | 1.07e+03       |
| n_timesteps             | 32000          |
--------------------------------------------

 ---------------- Iteration 32 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 320 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 321 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 322 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 323 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 324 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 325 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 326 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 327 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 328 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 329 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.72          |
| Data-EnvSampler-Poli... | 1.84          |
| Data-EnvTrajs-Averag... | 251           |
| Data-EnvTrajs-MaxReturn | 356           |
| Data-EnvTrajs-MinReturn | 91.5          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 104           |
| Data-TimeEnvSampleProc  | 0.00111       |
| Data-TimeEnvSampling    | 2.64          |
| Iteration               | 32            |
| ItrTime                 | 47            |
| LossAfter               | -0.01407937   |
| LossBefore              | -6.534881e-06 |
| Model-TimeModelFit      | 39.3          |
| ModelSampler-n_times... | 1320000       |
| Policy-AverageAbsPol... | 1.0299655     |
| Policy-AverageDiscou... | 75.6          |
| Policy-AveragePolicyStd | 0.467275      |
| Policy-AverageReturn    | 208           |
| Policy-MaxReturn        | 287           |
| Policy-MinReturn        | 67.8          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 61.8          |
| Policy-TimeAlgoOpt      | 0.828         |
| Policy-TimeSampleProc   | 1.12          |
| Policy-TimeSampling     | 3.06          |
| Policy-TimeStep         | 5.04          |
| Time                    | 1.11e+03      |
| n_timesteps             | 33000         |
-------------------------------------------

 ---------------- Iteration 33 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 330 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 331 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 332 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 333 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 334 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 335 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 336 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 337 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 338 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 339 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.402          |
| Data-EnvSampler-Poli... | 1.04           |
| Data-EnvTrajs-Averag... | 284            |
| Data-EnvTrajs-MaxReturn | 389            |
| Data-EnvTrajs-MinReturn | 182            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 87.6           |
| Data-TimeEnvSampleProc  | 0.000957       |
| Data-TimeEnvSampling    | 1.49           |
| Iteration               | 33             |
| ItrTime                 | 44.8           |
| LossAfter               | -0.014841508   |
| LossBefore              | -6.3637785e-06 |
| Model-TimeModelFit      | 38.8           |
| ModelSampler-n_times... | 1360000        |
| Policy-AverageAbsPol... | 0.9939248      |
| Policy-AverageDiscou... | 88.2           |
| Policy-AveragePolicyStd | 0.45861262     |
| Policy-AverageReturn    | 246            |
| Policy-MaxReturn        | 358            |
| Policy-MinReturn        | 101            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 65             |
| Policy-TimeAlgoOpt      | 0.862          |
| Policy-TimeSampleProc   | 0.926          |
| Policy-TimeSampling     | 2.64           |
| Policy-TimeStep         | 4.49           |
| Time                    | 1.16e+03       |
| n_timesteps             | 34000          |
--------------------------------------------

 ---------------- Iteration 34 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 340 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 341 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 342 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 343 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 344 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 345 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 346 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 347 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 348 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 349 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.509         |
| Data-EnvSampler-Poli... | 1.28          |
| Data-EnvTrajs-Averag... | 315           |
| Data-EnvTrajs-MaxReturn | 365           |
| Data-EnvTrajs-MinReturn | 249           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 39.3          |
| Data-TimeEnvSampleProc  | 0.00135       |
| Data-TimeEnvSampling    | 1.83          |
| Iteration               | 34            |
| ItrTime                 | 33.9          |
| LossAfter               | -0.013857989  |
| LossBefore              | -6.221729e-06 |
| Model-TimeModelFit      | 29.5          |
| ModelSampler-n_times... | 1400000       |
| Policy-AverageAbsPol... | 1.0025475     |
| Policy-AverageDiscou... | 122           |
| Policy-AveragePolicyStd | 0.4518499     |
| Policy-AverageReturn    | 303           |
| Policy-MaxReturn        | 397           |
| Policy-MinReturn        | 105           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 76            |
| Policy-TimeAlgoOpt      | 0.581         |
| Policy-TimeSampleProc   | 0.345         |
| Policy-TimeSampling     | 1.58          |
| Policy-TimeStep         | 2.53          |
| Time                    | 1.19e+03      |
| n_timesteps             | 35000         |
-------------------------------------------

 ---------------- Iteration 35 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 350 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 351 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 352 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 353 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 354 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 355 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 356 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 357 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 358 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 359 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.349         |
| Data-EnvSampler-Poli... | 0.863         |
| Data-EnvTrajs-Averag... | 331           |
| Data-EnvTrajs-MaxReturn | 380           |
| Data-EnvTrajs-MinReturn | 269           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 45.9          |
| Data-TimeEnvSampleProc  | 0.00126       |
| Data-TimeEnvSampling    | 1.25          |
| Iteration               | 35            |
| ItrTime                 | 36.6          |
| LossAfter               | -0.013666748  |
| LossBefore              | -6.086192e-06 |
| Model-TimeModelFit      | 32.9          |
| ModelSampler-n_times... | 1440000       |
| Policy-AverageAbsPol... | 1.0358028     |
| Policy-AverageDiscou... | 91.7          |
| Policy-AveragePolicyStd | 0.44604358    |
| Policy-AverageReturn    | 243           |
| Policy-MaxReturn        | 308           |
| Policy-MinReturn        | 80.3          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 50.1          |
| Policy-TimeAlgoOpt      | 0.565         |
| Policy-TimeSampleProc   | 0.341         |
| Policy-TimeSampling     | 1.43          |
| Policy-TimeStep         | 2.39          |
| Time                    | 1.23e+03      |
| n_timesteps             | 36000         |
-------------------------------------------

 ---------------- Iteration 36 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 360 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 361 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 362 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 363 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 364 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 365 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 366 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 367 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 368 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 369 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.343          |
| Data-EnvSampler-Poli... | 0.798          |
| Data-EnvTrajs-Averag... | 273            |
| Data-EnvTrajs-MaxReturn | 397            |
| Data-EnvTrajs-MinReturn | 5.26           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 139            |
| Data-TimeEnvSampleProc  | 0.00089        |
| Data-TimeEnvSampling    | 1.17           |
| Iteration               | 36             |
| ItrTime                 | 35.9           |
| LossAfter               | -0.014414759   |
| LossBefore              | -5.8272753e-06 |
| Model-TimeModelFit      | 32.4           |
| ModelSampler-n_times... | 1480000        |
| Policy-AverageAbsPol... | 1.0011493      |
| Policy-AverageDiscou... | 123            |
| Policy-AveragePolicyStd | 0.43467882     |
| Policy-AverageReturn    | 330            |
| Policy-MaxReturn        | 459            |
| Policy-MinReturn        | 141            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 67.2           |
| Policy-TimeAlgoOpt      | 0.608          |
| Policy-TimeSampleProc   | 0.314          |
| Policy-TimeSampling     | 1.42           |
| Policy-TimeStep         | 2.36           |
| Time                    | 1.26e+03       |
| n_timesteps             | 37000          |
--------------------------------------------

 ---------------- Iteration 37 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 370 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 371 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 372 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 373 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 374 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 375 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 376 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 377 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 378 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 379 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.32           |
| Data-EnvSampler-Poli... | 0.787          |
| Data-EnvTrajs-Averag... | 357            |
| Data-EnvTrajs-MaxReturn | 385            |
| Data-EnvTrajs-MinReturn | 316            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 27.3           |
| Data-TimeEnvSampleProc  | 0.0011         |
| Data-TimeEnvSampling    | 1.14           |
| Iteration               | 37             |
| ItrTime                 | 36.8           |
| LossAfter               | -0.01645799    |
| LossBefore              | -5.6361755e-06 |
| Model-TimeModelFit      | 33.3           |
| ModelSampler-n_times... | 1520000        |
| Policy-AverageAbsPol... | 0.9908379      |
| Policy-AverageDiscou... | 138            |
| Policy-AveragePolicyStd | 0.42731726     |
| Policy-AverageReturn    | 364            |
| Policy-MaxReturn        | 474            |
| Policy-MinReturn        | -26.3          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 130            |
| Policy-TimeAlgoOpt      | 0.554          |
| Policy-TimeSampleProc   | 0.387          |
| Policy-TimeSampling     | 1.43           |
| Policy-TimeStep         | 2.42           |
| Time                    | 1.3e+03        |
| n_timesteps             | 38000          |
--------------------------------------------

 ---------------- Iteration 38 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 380 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 381 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 382 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 383 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 384 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 385 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 386 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 387 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 388 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 389 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.347          |
| Data-EnvSampler-Poli... | 0.877          |
| Data-EnvTrajs-Averag... | 282            |
| Data-EnvTrajs-MaxReturn | 385            |
| Data-EnvTrajs-MinReturn | 42.9           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 124            |
| Data-TimeEnvSampleProc  | 0.000953       |
| Data-TimeEnvSampling    | 1.27           |
| Iteration               | 38             |
| ItrTime                 | 38.4           |
| LossAfter               | -0.015709642   |
| LossBefore              | -5.4620455e-06 |
| Model-TimeModelFit      | 34.8           |
| ModelSampler-n_times... | 1560000        |
| Policy-AverageAbsPol... | 0.9763339      |
| Policy-AverageDiscou... | 127            |
| Policy-AveragePolicyStd | 0.41932097     |
| Policy-AverageReturn    | 347            |
| Policy-MaxReturn        | 404            |
| Policy-MinReturn        | 228            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 45.8           |
| Policy-TimeAlgoOpt      | 0.567          |
| Policy-TimeSampleProc   | 0.353          |
| Policy-TimeSampling     | 1.36           |
| Policy-TimeStep         | 2.32           |
| Time                    | 1.34e+03       |
| n_timesteps             | 39000          |
--------------------------------------------

 ---------------- Iteration 39 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 390 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 391 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 392 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 393 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 394 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 395 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 396 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 397 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 398 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 399 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.289          |
| Data-EnvSampler-Poli... | 0.711          |
| Data-EnvTrajs-Averag... | 253            |
| Data-EnvTrajs-MaxReturn | 400            |
| Data-EnvTrajs-MinReturn | 46.6           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 145            |
| Data-TimeEnvSampleProc  | 0.000932       |
| Data-TimeEnvSampling    | 1.03           |
| Iteration               | 39             |
| ItrTime                 | 35.3           |
| LossAfter               | -0.016642539   |
| LossBefore              | -5.3344734e-06 |
| Model-TimeModelFit      | 31.9           |
| ModelSampler-n_times... | 1600000        |
| Policy-AverageAbsPol... | 0.95651674     |
| Policy-AverageDiscou... | 113            |
| Policy-AveragePolicyStd | 0.4138256      |
| Policy-AverageReturn    | 293            |
| Policy-MaxReturn        | 422            |
| Policy-MinReturn        | -12.4          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 117            |
| Policy-TimeAlgoOpt      | 0.547          |
| Policy-TimeSampleProc   | 0.376          |
| Policy-TimeSampling     | 1.37           |
| Policy-TimeStep         | 2.34           |
| Time                    | 1.38e+03       |
| n_timesteps             | 40000          |
--------------------------------------------

 ---------------- Iteration 40 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 400 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 401 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 402 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 403 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 404 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 405 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 406 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 407 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 408 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 409 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.318         |
| Data-EnvSampler-Poli... | 0.805         |
| Data-EnvTrajs-Averag... | 353           |
| Data-EnvTrajs-MaxReturn | 426           |
| Data-EnvTrajs-MinReturn | 240           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 62.5          |
| Data-TimeEnvSampleProc  | 0.00114       |
| Data-TimeEnvSampling    | 1.16          |
| Iteration               | 40            |
| ItrTime                 | 39.2          |
| LossAfter               | -0.014019237  |
| LossBefore              | -5.150077e-06 |
| Model-TimeModelFit      | 34.8          |
| ModelSampler-n_times... | 1640000       |
| Policy-AverageAbsPol... | 0.99071044    |
| Policy-AverageDiscou... | 122           |
| Policy-AveragePolicyStd | 0.40722623    |
| Policy-AverageReturn    | 334           |
| Policy-MaxReturn        | 404           |
| Policy-MinReturn        | 113           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 71.2          |
| Policy-TimeAlgoOpt      | 0.693         |
| Policy-TimeSampleProc   | 0.559         |
| Policy-TimeSampling     | 1.91          |
| Policy-TimeStep         | 3.22          |
| Time                    | 1.41e+03      |
| n_timesteps             | 41000         |
-------------------------------------------

 ---------------- Iteration 41 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 410 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 411 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 412 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 413 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 414 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 415 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 416 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 417 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 418 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 419 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.309          |
| Data-EnvSampler-Poli... | 0.795          |
| Data-EnvTrajs-Averag... | 411            |
| Data-EnvTrajs-MaxReturn | 454            |
| Data-EnvTrajs-MinReturn | 364            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 35.5           |
| Data-TimeEnvSampleProc  | 0.000687       |
| Data-TimeEnvSampling    | 1.14           |
| Iteration               | 41             |
| ItrTime                 | 35.5           |
| LossAfter               | -0.014186383   |
| LossBefore              | -4.9750083e-06 |
| Model-TimeModelFit      | 30.9           |
| ModelSampler-n_times... | 1680000        |
| Policy-AverageAbsPol... | 0.96500945     |
| Policy-AverageDiscou... | 158            |
| Policy-AveragePolicyStd | 0.39971793     |
| Policy-AverageReturn    | 412            |
| Policy-MaxReturn        | 489            |
| Policy-MinReturn        | 193            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 64.4           |
| Policy-TimeAlgoOpt      | 0.676          |
| Policy-TimeSampleProc   | 0.603          |
| Policy-TimeSampling     | 2.09           |
| Policy-TimeStep         | 3.44           |
| Time                    | 1.45e+03       |
| n_timesteps             | 42000          |
--------------------------------------------

 ---------------- Iteration 42 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 420 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 421 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 422 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 423 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 424 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 425 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 426 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 427 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 428 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 429 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.302         |
| Data-EnvSampler-Poli... | 0.804         |
| Data-EnvTrajs-Averag... | 227           |
| Data-EnvTrajs-MaxReturn | 368           |
| Data-EnvTrajs-MinReturn | 14.3          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 132           |
| Data-TimeEnvSampleProc  | 0.000878      |
| Data-TimeEnvSampling    | 1.14          |
| Iteration               | 42            |
| ItrTime                 | 36.5          |
| LossAfter               | -0.015176983  |
| LossBefore              | -4.685128e-06 |
| Model-TimeModelFit      | 31            |
| ModelSampler-n_times... | 1720000       |
| Policy-AverageAbsPol... | 0.9679331     |
| Policy-AverageDiscou... | 198           |
| Policy-AveragePolicyStd | 0.38889712    |
| Policy-AverageReturn    | 523           |
| Policy-MaxReturn        | 596           |
| Policy-MinReturn        | 437           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 48.6          |
| Policy-TimeAlgoOpt      | 0.769         |
| Policy-TimeSampleProc   | 0.828         |
| Policy-TimeSampling     | 2.71          |
| Policy-TimeStep         | 4.38          |
| Time                    | 1.49e+03      |
| n_timesteps             | 43000         |
-------------------------------------------

 ---------------- Iteration 43 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 430 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 431 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 432 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 433 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 434 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 435 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 436 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 437 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 438 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 439 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.525          |
| Data-EnvSampler-Poli... | 1.25           |
| Data-EnvTrajs-Averag... | 249            |
| Data-EnvTrajs-MaxReturn | 551            |
| Data-EnvTrajs-MinReturn | -11.1          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 208            |
| Data-TimeEnvSampleProc  | 0.00159        |
| Data-TimeEnvSampling    | 1.83           |
| Iteration               | 43             |
| ItrTime                 | 35.4           |
| LossAfter               | -0.013385112   |
| LossBefore              | -4.4135572e-06 |
| Model-TimeModelFit      | 29.5           |
| ModelSampler-n_times... | 1760000        |
| Policy-AverageAbsPol... | 0.98513967     |
| Policy-AverageDiscou... | 222            |
| Policy-AveragePolicyStd | 0.37787142     |
| Policy-AverageReturn    | 594            |
| Policy-MaxReturn        | 658            |
| Policy-MinReturn        | 515            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 39.5           |
| Policy-TimeAlgoOpt      | 0.833          |
| Policy-TimeSampleProc   | 0.748          |
| Policy-TimeSampling     | 2.43           |
| Policy-TimeStep         | 4.06           |
| Time                    | 1.52e+03       |
| n_timesteps             | 44000          |
--------------------------------------------

 ---------------- Iteration 44 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 440 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 441 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 442 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 443 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 444 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 445 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 446 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 447 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 448 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 449 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.545          |
| Data-EnvSampler-Poli... | 1.34           |
| Data-EnvTrajs-Averag... | 232            |
| Data-EnvTrajs-MaxReturn | 510            |
| Data-EnvTrajs-MinReturn | 23.6           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 197            |
| Data-TimeEnvSampleProc  | 0.00163        |
| Data-TimeEnvSampling    | 1.95           |
| Iteration               | 44             |
| ItrTime                 | 36             |
| LossAfter               | -0.0115069775  |
| LossBefore              | -4.1317485e-06 |
| Model-TimeModelFit      | 31.7           |
| ModelSampler-n_times... | 1800000        |
| Policy-AverageAbsPol... | 1.024682       |
| Policy-AverageDiscou... | 182            |
| Policy-AveragePolicyStd | 0.36850277     |
| Policy-AverageReturn    | 491            |
| Policy-MaxReturn        | 546            |
| Policy-MinReturn        | 418            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 36.2           |
| Policy-TimeAlgoOpt      | 0.588          |
| Policy-TimeSampleProc   | 0.329          |
| Policy-TimeSampling     | 1.46           |
| Policy-TimeStep         | 2.42           |
| Time                    | 1.56e+03       |
| n_timesteps             | 45000          |
--------------------------------------------

 ---------------- Iteration 45 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 450 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 451 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 452 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 453 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 454 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 455 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 456 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 457 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 458 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 459 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.334         |
| Data-EnvSampler-Poli... | 0.799         |
| Data-EnvTrajs-Averag... | 254           |
| Data-EnvTrajs-MaxReturn | 446           |
| Data-EnvTrajs-MinReturn | -12.8         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 161           |
| Data-TimeEnvSampleProc  | 0.000979      |
| Data-TimeEnvSampling    | 1.17          |
| Iteration               | 45            |
| ItrTime                 | 38.3          |
| LossAfter               | -0.015804134  |
| LossBefore              | -3.979604e-06 |
| Model-TimeModelFit      | 34.7          |
| ModelSampler-n_times... | 1840000       |
| Policy-AverageAbsPol... | 1.0086429     |
| Policy-AverageDiscou... | 106           |
| Policy-AveragePolicyStd | 0.3622865     |
| Policy-AverageReturn    | 280           |
| Policy-MaxReturn        | 380           |
| Policy-MinReturn        | 158           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 56.1          |
| Policy-TimeAlgoOpt      | 0.539         |
| Policy-TimeSampleProc   | 0.442         |
| Policy-TimeSampling     | 1.36          |
| Policy-TimeStep         | 2.4           |
| Time                    | 1.6e+03       |
| n_timesteps             | 46000         |
-------------------------------------------

 ---------------- Iteration 46 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 460 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 461 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 462 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 463 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 464 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 465 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 466 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 467 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 468 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 469 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.309          |
| Data-EnvSampler-Poli... | 0.826          |
| Data-EnvTrajs-Averag... | 326            |
| Data-EnvTrajs-MaxReturn | 509            |
| Data-EnvTrajs-MinReturn | 124            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 163            |
| Data-TimeEnvSampleProc  | 0.000763       |
| Data-TimeEnvSampling    | 1.17           |
| Iteration               | 46             |
| ItrTime                 | 41.7           |
| LossAfter               | -0.012671296   |
| LossBefore              | -3.7441073e-06 |
| Model-TimeModelFit      | 38             |
| ModelSampler-n_times... | 1880000        |
| Policy-AverageAbsPol... | 1.025176       |
| Policy-AverageDiscou... | 167            |
| Policy-AveragePolicyStd | 0.3541715      |
| Policy-AverageReturn    | 468            |
| Policy-MaxReturn        | 614            |
| Policy-MinReturn        | 192            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 81             |
| Policy-TimeAlgoOpt      | 0.59           |
| Policy-TimeSampleProc   | 0.5            |
| Policy-TimeSampling     | 1.36           |
| Policy-TimeStep         | 2.47           |
| Time                    | 1.64e+03       |
| n_timesteps             | 47000          |
--------------------------------------------

 ---------------- Iteration 47 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 470 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 471 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 472 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 473 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 474 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 475 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 476 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 477 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 478 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 479 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.323          |
| Data-EnvSampler-Poli... | 0.82           |
| Data-EnvTrajs-Averag... | 372            |
| Data-EnvTrajs-MaxReturn | 502            |
| Data-EnvTrajs-MinReturn | 180            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 137            |
| Data-TimeEnvSampleProc  | 0.000925       |
| Data-TimeEnvSampling    | 1.18           |
| Iteration               | 47             |
| ItrTime                 | 40.2           |
| LossAfter               | -0.011704894   |
| LossBefore              | -3.4392792e-06 |
| Model-TimeModelFit      | 36.7           |
| ModelSampler-n_times... | 1920000        |
| Policy-AverageAbsPol... | 1.0153182      |
| Policy-AverageDiscou... | 174            |
| Policy-AveragePolicyStd | 0.34483415     |
| Policy-AverageReturn    | 467            |
| Policy-MaxReturn        | 539            |
| Policy-MinReturn        | 301            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 51.7           |
| Policy-TimeAlgoOpt      | 0.563          |
| Policy-TimeSampleProc   | 0.267          |
| Policy-TimeSampling     | 1.39           |
| Policy-TimeStep         | 2.26           |
| Time                    | 1.68e+03       |
| n_timesteps             | 48000          |
--------------------------------------------

 ---------------- Iteration 48 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 480 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 481 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 482 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 483 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 484 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 485 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 486 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 487 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 488 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 489 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.313          |
| Data-EnvSampler-Poli... | 0.715          |
| Data-EnvTrajs-Averag... | 416            |
| Data-EnvTrajs-MaxReturn | 566            |
| Data-EnvTrajs-MinReturn | 236            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 142            |
| Data-TimeEnvSampleProc  | 0.000879       |
| Data-TimeEnvSampling    | 1.06           |
| Iteration               | 48             |
| ItrTime                 | 38.5           |
| LossAfter               | -0.013714586   |
| LossBefore              | -3.2105922e-06 |
| Model-TimeModelFit      | 33.2           |
| ModelSampler-n_times... | 1960000        |
| Policy-AverageAbsPol... | 1.0364718      |
| Policy-AverageDiscou... | 155            |
| Policy-AveragePolicyStd | 0.33580855     |
| Policy-AverageReturn    | 428            |
| Policy-MaxReturn        | 520            |
| Policy-MinReturn        | 332            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 52.4           |
| Policy-TimeAlgoOpt      | 0.833          |
| Policy-TimeSampleProc   | 0.761          |
| Policy-TimeSampling     | 2.52           |
| Policy-TimeStep         | 4.18           |
| Time                    | 1.72e+03       |
| n_timesteps             | 49000          |
--------------------------------------------

 ---------------- Iteration 49 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 490 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 491 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 492 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 493 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 494 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 495 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 496 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 497 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 498 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 499 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.528          |
| Data-EnvSampler-Poli... | 1.27           |
| Data-EnvTrajs-Averag... | 405            |
| Data-EnvTrajs-MaxReturn | 509            |
| Data-EnvTrajs-MinReturn | 304            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 77             |
| Data-TimeEnvSampleProc  | 0.000979       |
| Data-TimeEnvSampling    | 1.84           |
| Iteration               | 49             |
| ItrTime                 | 35.8           |
| LossAfter               | -0.013605069   |
| LossBefore              | -2.9478742e-06 |
| Model-TimeModelFit      | 30.4           |
| ModelSampler-n_times... | 2000000        |
| Policy-AverageAbsPol... | 1.0516644      |
| Policy-AverageDiscou... | 191            |
| Policy-AveragePolicyStd | 0.32782236     |
| Policy-AverageReturn    | 504            |
| Policy-MaxReturn        | 576            |
| Policy-MinReturn        | 421            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 46.3           |
| Policy-TimeAlgoOpt      | 0.736          |
| Policy-TimeSampleProc   | 0.604          |
| Policy-TimeSampling     | 2.18           |
| Policy-TimeStep         | 3.58           |
| Time                    | 1.75e+03       |
| n_timesteps             | 50000          |
--------------------------------------------

 ---------------- Iteration 50 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 500 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 501 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 502 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 503 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 504 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 505 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 506 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 507 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 508 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 509 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.528          |
| Data-EnvSampler-Poli... | 1.32           |
| Data-EnvTrajs-Averag... | 296            |
| Data-EnvTrajs-MaxReturn | 507            |
| Data-EnvTrajs-MinReturn | 34.6           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 166            |
| Data-TimeEnvSampleProc  | 0.00173        |
| Data-TimeEnvSampling    | 1.91           |
| Iteration               | 50             |
| ItrTime                 | 42.2           |
| LossAfter               | -0.009814846   |
| LossBefore              | -2.6833632e-06 |
| Model-TimeModelFit      | 37.6           |
| ModelSampler-n_times... | 2040000        |
| Policy-AverageAbsPol... | 1.030728       |
| Policy-AverageDiscou... | 209            |
| Policy-AveragePolicyStd | 0.32031006     |
| Policy-AverageReturn    | 553            |
| Policy-MaxReturn        | 648            |
| Policy-MinReturn        | 435            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 65.8           |
| Policy-TimeAlgoOpt      | 0.608          |
| Policy-TimeSampleProc   | 0.396          |
| Policy-TimeSampling     | 1.61           |
| Policy-TimeStep         | 2.65           |
| Time                    | 1.79e+03       |
| n_timesteps             | 51000          |
--------------------------------------------
Training finished
