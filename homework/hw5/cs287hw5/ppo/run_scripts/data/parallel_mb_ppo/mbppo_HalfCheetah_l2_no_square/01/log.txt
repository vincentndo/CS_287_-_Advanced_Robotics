Logging to /home/vincent/workplace/CS_287_-_Advanced_Robotics/homework/hw5/cs287hw5/ppo/run_scripts/data/parallel_mb_ppo/mbppo_HalfCheetah_l2_no_square//01

 ---------------- Iteration 0 ----------------
Obtaining random samples from the environment...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 0 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 1 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 2 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 3 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 4 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 5 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 6 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 7 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 8 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 9 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.148          |
| Data-EnvSampler-Poli... | 0.0475         |
| Data-EnvTrajs-Averag... | -75.9          |
| Data-EnvTrajs-MaxReturn | -29.7          |
| Data-EnvTrajs-MinReturn | -111           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 33.4           |
| Data-TimeEnvSampleProc  | 0.000492       |
| Data-TimeEnvSampling    | 0.208          |
| Iteration               | 0              |
| ItrTime                 | 8.81           |
| LossAfter               | -0.018476602   |
| LossBefore              | -1.4027323e-05 |
| Model-TimeModelFit      | 3.13           |
| ModelSampler-n_times... | 40000          |
| Policy-AverageAbsPol... | 0.71769905     |
| Policy-AverageDiscou... | -139           |
| Policy-AveragePolicyStd | 0.98480207     |
| Policy-AverageReturn    | -388           |
| Policy-MaxReturn        | 99.4           |
| Policy-MinReturn        | -4.72e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.04e+03       |
| Policy-TimeAlgoOpt      | 0.949          |
| Policy-TimeSampleProc   | 0.582          |
| Policy-TimeSampling     | 3.84           |
| Policy-TimeStep         | 5.46           |
| Time                    | 8.81           |
| n_timesteps             | 1000           |
--------------------------------------------

 ---------------- Iteration 1 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 10 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 11 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 12 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 13 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 14 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 15 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 16 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 17 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 18 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 19 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.226          |
| Data-EnvSampler-Poli... | 0.554          |
| Data-EnvTrajs-Averag... | -94.4          |
| Data-EnvTrajs-MaxReturn | -63.6          |
| Data-EnvTrajs-MinReturn | -128           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 26.6           |
| Data-TimeEnvSampleProc  | 0.0011         |
| Data-TimeEnvSampling    | 0.802          |
| Iteration               | 1              |
| ItrTime                 | 7.48           |
| LossAfter               | -0.016000716   |
| LossBefore              | -1.3571032e-05 |
| Model-TimeModelFit      | 4.02           |
| ModelSampler-n_times... | 80000          |
| Policy-AverageAbsPol... | 0.54665244     |
| Policy-AverageDiscou... | -59.3          |
| Policy-AveragePolicyStd | 0.94218415     |
| Policy-AverageReturn    | -134           |
| Policy-MaxReturn        | -101           |
| Policy-MinReturn        | -162           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 16.1           |
| Policy-TimeAlgoOpt      | 0.594          |
| Policy-TimeSampleProc   | 0.403          |
| Policy-TimeSampling     | 1.64           |
| Policy-TimeStep         | 2.65           |
| Time                    | 16.4           |
| n_timesteps             | 2000           |
--------------------------------------------

 ---------------- Iteration 2 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 20 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 21 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 22 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 23 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 24 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 25 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 26 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 27 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 28 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 29 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.275          |
| Data-EnvSampler-Poli... | 0.677          |
| Data-EnvTrajs-Averag... | -48.9          |
| Data-EnvTrajs-MaxReturn | -13.7          |
| Data-EnvTrajs-MinReturn | -89.3          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 28.7           |
| Data-TimeEnvSampleProc  | 0.00098        |
| Data-TimeEnvSampling    | 0.981          |
| Iteration               | 2              |
| ItrTime                 | 9.46           |
| LossAfter               | -0.014191318   |
| LossBefore              | -1.3427601e-05 |
| Model-TimeModelFit      | 5.76           |
| ModelSampler-n_times... | 120000         |
| Policy-AverageAbsPol... | 0.8426953      |
| Policy-AverageDiscou... | 1.2e+03        |
| Policy-AveragePolicyStd | 0.9281413      |
| Policy-AverageReturn    | 4.18e+03       |
| Policy-MaxReturn        | 5.16e+03       |
| Policy-MinReturn        | 1.91e+03       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 687            |
| Policy-TimeAlgoOpt      | 0.594          |
| Policy-TimeSampleProc   | 0.471          |
| Policy-TimeSampling     | 1.6            |
| Policy-TimeStep         | 2.71           |
| Time                    | 25.9           |
| n_timesteps             | 3000           |
--------------------------------------------

 ---------------- Iteration 3 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 30 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 31 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 32 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 33 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 34 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 35 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 36 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 37 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 38 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 39 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.298          |
| Data-EnvSampler-Poli... | 0.709          |
| Data-EnvTrajs-Averag... | -72.2          |
| Data-EnvTrajs-MaxReturn | -22.9          |
| Data-EnvTrajs-MinReturn | -107           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 32.7           |
| Data-TimeEnvSampleProc  | 0.000817       |
| Data-TimeEnvSampling    | 1.04           |
| Iteration               | 3              |
| ItrTime                 | 14.5           |
| LossAfter               | -0.014094324   |
| LossBefore              | -1.3365388e-05 |
| Model-TimeModelFit      | 9.7            |
| ModelSampler-n_times... | 160000         |
| Policy-AverageAbsPol... | 0.65657914     |
| Policy-AverageDiscou... | 60.6           |
| Policy-AveragePolicyStd | 0.9206027      |
| Policy-AverageReturn    | 129            |
| Policy-MaxReturn        | 195            |
| Policy-MinReturn        | -415           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 126            |
| Policy-TimeAlgoOpt      | 0.697          |
| Policy-TimeSampleProc   | 0.641          |
| Policy-TimeSampling     | 2.34           |
| Policy-TimeStep         | 3.71           |
| Time                    | 40.3           |
| n_timesteps             | 4000           |
--------------------------------------------

 ---------------- Iteration 4 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 40 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 41 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 42 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 43 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 44 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 45 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 46 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 47 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 48 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 49 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.251          |
| Data-EnvSampler-Poli... | 0.525          |
| Data-EnvTrajs-Averag... | -41.7          |
| Data-EnvTrajs-MaxReturn | -0.544         |
| Data-EnvTrajs-MinReturn | -63            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 22             |
| Data-TimeEnvSampleProc  | 0.00225        |
| Data-TimeEnvSampling    | 0.802          |
| Iteration               | 4              |
| ItrTime                 | 14.1           |
| LossAfter               | -0.021673886   |
| LossBefore              | -1.3237943e-05 |
| Model-TimeModelFit      | 10.6           |
| ModelSampler-n_times... | 200000         |
| Policy-AverageAbsPol... | 0.6755174      |
| Policy-AverageDiscou... | -202           |
| Policy-AveragePolicyStd | 0.90995526     |
| Policy-AverageReturn    | -572           |
| Policy-MaxReturn        | -288           |
| Policy-MinReturn        | -3.23e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 662            |
| Policy-TimeAlgoOpt      | 0.547          |
| Policy-TimeSampleProc   | 0.557          |
| Policy-TimeSampling     | 1.49           |
| Policy-TimeStep         | 2.64           |
| Time                    | 54.4           |
| n_timesteps             | 5000           |
--------------------------------------------

 ---------------- Iteration 5 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 50 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 51 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 52 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 53 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 54 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 55 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 56 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 57 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 58 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 59 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.324          |
| Data-EnvSampler-Poli... | 0.736          |
| Data-EnvTrajs-Averag... | -46.8          |
| Data-EnvTrajs-MaxReturn | -19.5          |
| Data-EnvTrajs-MinReturn | -77.4          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 18.8           |
| Data-TimeEnvSampleProc  | 0.000998       |
| Data-TimeEnvSampling    | 1.1            |
| Iteration               | 5              |
| ItrTime                 | 17.4           |
| LossAfter               | -0.016554687   |
| LossBefore              | -1.3223391e-05 |
| Model-TimeModelFit      | 13.4           |
| ModelSampler-n_times... | 240000         |
| Policy-AverageAbsPol... | 0.91672695     |
| Policy-AverageDiscou... | 603            |
| Policy-AveragePolicyStd | 0.90707314     |
| Policy-AverageReturn    | 2.59e+03       |
| Policy-MaxReturn        | 3.9e+03        |
| Policy-MinReturn        | -252           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.2e+03        |
| Policy-TimeAlgoOpt      | 0.568          |
| Policy-TimeSampleProc   | 0.701          |
| Policy-TimeSampling     | 1.59           |
| Policy-TimeStep         | 2.89           |
| Time                    | 71.8           |
| n_timesteps             | 6000           |
--------------------------------------------

 ---------------- Iteration 6 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 60 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 61 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 62 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 63 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 64 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 65 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 66 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 67 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 68 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 69 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.335          |
| Data-EnvSampler-Poli... | 0.774          |
| Data-EnvTrajs-Averag... | -46.7          |
| Data-EnvTrajs-MaxReturn | 17.5           |
| Data-EnvTrajs-MinReturn | -77.4          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 34.8           |
| Data-TimeEnvSampleProc  | 0.000937       |
| Data-TimeEnvSampling    | 1.14           |
| Iteration               | 6              |
| ItrTime                 | 20.2           |
| LossAfter               | -0.02044166    |
| LossBefore              | -1.3158019e-05 |
| Model-TimeModelFit      | 15.7           |
| ModelSampler-n_times... | 280000         |
| Policy-AverageAbsPol... | 0.83779246     |
| Policy-AverageDiscou... | -105           |
| Policy-AveragePolicyStd | 0.9012267      |
| Policy-AverageReturn    | -282           |
| Policy-MaxReturn        | -167           |
| Policy-MinReturn        | -973           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 216            |
| Policy-TimeAlgoOpt      | 0.853          |
| Policy-TimeSampleProc   | 0.478          |
| Policy-TimeSampling     | 1.98           |
| Policy-TimeStep         | 3.34           |
| Time                    | 92             |
| n_timesteps             | 7000           |
--------------------------------------------

 ---------------- Iteration 7 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 70 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 71 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 72 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 73 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 74 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 75 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 76 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 77 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 78 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 79 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.342          |
| Data-EnvSampler-Poli... | 0.802          |
| Data-EnvTrajs-Averag... | -59.3          |
| Data-EnvTrajs-MaxReturn | -1.86          |
| Data-EnvTrajs-MinReturn | -86            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 30.6           |
| Data-TimeEnvSampleProc  | 0.000747       |
| Data-TimeEnvSampling    | 1.18           |
| Iteration               | 7              |
| ItrTime                 | 20             |
| LossAfter               | -0.015161428   |
| LossBefore              | -1.2863555e-05 |
| Model-TimeModelFit      | 16.6           |
| ModelSampler-n_times... | 320000         |
| Policy-AverageAbsPol... | 0.65681744     |
| Policy-AverageDiscou... | 30.4           |
| Policy-AveragePolicyStd | 0.87560856     |
| Policy-AverageReturn    | 81.7           |
| Policy-MaxReturn        | 161            |
| Policy-MinReturn        | 37.8           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 31.2           |
| Policy-TimeAlgoOpt      | 0.468          |
| Policy-TimeSampleProc   | 0.399          |
| Policy-TimeSampling     | 1.29           |
| Policy-TimeStep         | 2.2            |
| Time                    | 112            |
| n_timesteps             | 8000           |
--------------------------------------------

 ---------------- Iteration 8 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 80 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 81 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 82 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 83 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 84 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 85 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 86 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 87 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 88 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 89 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.331           |
| Data-EnvSampler-Poli... | 0.801           |
| Data-EnvTrajs-Averag... | -57.2           |
| Data-EnvTrajs-MaxReturn | -17.9           |
| Data-EnvTrajs-MinReturn | -87.3           |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 25.5            |
| Data-TimeEnvSampleProc  | 0.000575        |
| Data-TimeEnvSampling    | 1.17            |
| Iteration               | 8               |
| ItrTime                 | 25.4            |
| LossAfter               | -0.02029365     |
| LossBefore              | -1.24406315e-05 |
| Model-TimeModelFit      | 21.5            |
| ModelSampler-n_times... | 360000          |
| Policy-AverageAbsPol... | 0.57328033      |
| Policy-AverageDiscou... | 10.3            |
| Policy-AveragePolicyStd | 0.84239244      |
| Policy-AverageReturn    | 21              |
| Policy-MaxReturn        | 95.6            |
| Policy-MinReturn        | -27.3           |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 27.6            |
| Policy-TimeAlgoOpt      | 0.61            |
| Policy-TimeSampleProc   | 0.434           |
| Policy-TimeSampling     | 1.64            |
| Policy-TimeStep         | 2.72            |
| Time                    | 137             |
| n_timesteps             | 9000            |
---------------------------------------------

 ---------------- Iteration 9 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 90 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 91 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 92 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 93 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 94 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 95 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 96 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 97 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 98 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 99 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.353          |
| Data-EnvSampler-Poli... | 0.924          |
| Data-EnvTrajs-Averag... | -74.9          |
| Data-EnvTrajs-MaxReturn | -13.5          |
| Data-EnvTrajs-MinReturn | -124           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 41.2           |
| Data-TimeEnvSampleProc  | 0.00139        |
| Data-TimeEnvSampling    | 1.31           |
| Iteration               | 9              |
| ItrTime                 | 27.5           |
| LossAfter               | -0.019500254   |
| LossBefore              | -1.2358623e-05 |
| Model-TimeModelFit      | 23.7           |
| ModelSampler-n_times... | 400000         |
| Policy-AverageAbsPol... | 0.62778705     |
| Policy-AverageDiscou... | -90.9          |
| Policy-AveragePolicyStd | 0.83204        |
| Policy-AverageReturn    | -216           |
| Policy-MaxReturn        | -144           |
| Policy-MinReturn        | -338           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 47.5           |
| Policy-TimeAlgoOpt      | 0.591          |
| Policy-TimeSampleProc   | 0.453          |
| Policy-TimeSampling     | 1.46           |
| Policy-TimeStep         | 2.52           |
| Time                    | 165            |
| n_timesteps             | 10000          |
--------------------------------------------

 ---------------- Iteration 10 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 100 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 101 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 102 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 103 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 104 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 105 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 106 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 107 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 108 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 109 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.383         |
| Data-EnvSampler-Poli... | 0.938         |
| Data-EnvTrajs-Averag... | -37.5         |
| Data-EnvTrajs-MaxReturn | -31.1         |
| Data-EnvTrajs-MinReturn | -53.1         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 8.11          |
| Data-TimeEnvSampleProc  | 0.000957      |
| Data-TimeEnvSampling    | 1.37          |
| Iteration               | 10            |
| ItrTime                 | 29.6          |
| LossAfter               | -0.017501412  |
| LossBefore              | -1.228329e-05 |
| Model-TimeModelFit      | 25.7          |
| ModelSampler-n_times... | 440000        |
| Policy-AverageAbsPol... | 0.630624      |
| Policy-AverageDiscou... | -39.8         |
| Policy-AveragePolicyStd | 0.82677376    |
| Policy-AverageReturn    | -77.8         |
| Policy-MaxReturn        | 8.92          |
| Policy-MinReturn        | -139          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 33.1          |
| Policy-TimeAlgoOpt      | 0.561         |
| Policy-TimeSampleProc   | 0.434         |
| Policy-TimeSampling     | 1.48          |
| Policy-TimeStep         | 2.5           |
| Time                    | 195           |
| n_timesteps             | 11000         |
-------------------------------------------

 ---------------- Iteration 11 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 110 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 111 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 112 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 113 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 114 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 115 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 116 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 117 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 118 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 119 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.341          |
| Data-EnvSampler-Poli... | 0.802          |
| Data-EnvTrajs-Averag... | -54.2          |
| Data-EnvTrajs-MaxReturn | -37.3          |
| Data-EnvTrajs-MinReturn | -71.9          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 12.7           |
| Data-TimeEnvSampleProc  | 0.000766       |
| Data-TimeEnvSampling    | 1.18           |
| Iteration               | 11             |
| ItrTime                 | 32             |
| LossAfter               | -0.017602181   |
| LossBefore              | -1.2215553e-05 |
| Model-TimeModelFit      | 28.3           |
| ModelSampler-n_times... | 480000         |
| Policy-AverageAbsPol... | 0.6034161      |
| Policy-AverageDiscou... | -112           |
| Policy-AveragePolicyStd | 0.8193459      |
| Policy-AverageReturn    | -342           |
| Policy-MaxReturn        | -205           |
| Policy-MinReturn        | -800           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 140            |
| Policy-TimeAlgoOpt      | 0.555          |
| Policy-TimeSampleProc   | 0.353          |
| Policy-TimeSampling     | 1.58           |
| Policy-TimeStep         | 2.52           |
| Time                    | 227            |
| n_timesteps             | 12000          |
--------------------------------------------

 ---------------- Iteration 12 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 120 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 121 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 122 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 123 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 124 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 125 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 126 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 127 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 128 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 129 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.322          |
| Data-EnvSampler-Poli... | 0.753          |
| Data-EnvTrajs-Averag... | -25.4          |
| Data-EnvTrajs-MaxReturn | 64.5           |
| Data-EnvTrajs-MinReturn | -90            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 52.8           |
| Data-TimeEnvSampleProc  | 0.000951       |
| Data-TimeEnvSampling    | 1.11           |
| Iteration               | 12             |
| ItrTime                 | 32.5           |
| LossAfter               | -0.015978128   |
| LossBefore              | -1.1901666e-05 |
| Model-TimeModelFit      | 29             |
| ModelSampler-n_times... | 520000         |
| Policy-AverageAbsPol... | 0.57704306     |
| Policy-AverageDiscou... | -10.9          |
| Policy-AveragePolicyStd | 0.79538214     |
| Policy-AverageReturn    | -22.3          |
| Policy-MaxReturn        | 32.7           |
| Policy-MinReturn        | -75.7          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 28.2           |
| Policy-TimeAlgoOpt      | 0.55           |
| Policy-TimeSampleProc   | 0.394          |
| Policy-TimeSampling     | 1.4            |
| Policy-TimeStep         | 2.37           |
| Time                    | 259            |
| n_timesteps             | 13000          |
--------------------------------------------

 ---------------- Iteration 13 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 130 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 131 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 132 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 133 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 134 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 135 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 136 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 137 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 138 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 139 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.531          |
| Data-EnvSampler-Poli... | 1.2            |
| Data-EnvTrajs-Averag... | -29.2          |
| Data-EnvTrajs-MaxReturn | 15             |
| Data-EnvTrajs-MinReturn | -98.6          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 41.2           |
| Data-TimeEnvSampleProc  | 0.00353        |
| Data-TimeEnvSampling    | 1.78           |
| Iteration               | 13             |
| ItrTime                 | 39.1           |
| LossAfter               | -0.018261056   |
| LossBefore              | -1.1577442e-05 |
| Model-TimeModelFit      | 33.7           |
| ModelSampler-n_times... | 560000         |
| Policy-AverageAbsPol... | 0.5873587      |
| Policy-AverageDiscou... | -64            |
| Policy-AveragePolicyStd | 0.7718051      |
| Policy-AverageReturn    | -147           |
| Policy-MaxReturn        | -53.6          |
| Policy-MinReturn        | -191           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 29.4           |
| Policy-TimeAlgoOpt      | 0.766          |
| Policy-TimeSampleProc   | 0.668          |
| Policy-TimeSampling     | 2.07           |
| Policy-TimeStep         | 3.56           |
| Time                    | 298            |
| n_timesteps             | 14000          |
--------------------------------------------

 ---------------- Iteration 14 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 140 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 141 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 142 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 143 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 144 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 145 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 146 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 147 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 148 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 149 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.924          |
| Data-EnvSampler-Poli... | 2.09           |
| Data-EnvTrajs-Averag... | -22.5          |
| Data-EnvTrajs-MaxReturn | 9.77           |
| Data-EnvTrajs-MinReturn | -52.8          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 25.2           |
| Data-TimeEnvSampleProc  | 0.00144        |
| Data-TimeEnvSampling    | 3.1            |
| Iteration               | 14             |
| ItrTime                 | 41.4           |
| LossAfter               | -0.016345296   |
| LossBefore              | -1.1316716e-05 |
| Model-TimeModelFit      | 33.9           |
| ModelSampler-n_times... | 600000         |
| Policy-AverageAbsPol... | 0.5592352      |
| Policy-AverageDiscou... | -33.7          |
| Policy-AveragePolicyStd | 0.75310403     |
| Policy-AverageReturn    | -77.9          |
| Policy-MaxReturn        | -28.3          |
| Policy-MinReturn        | -132           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 23.8           |
| Policy-TimeAlgoOpt      | 0.897          |
| Policy-TimeSampleProc   | 0.806          |
| Policy-TimeSampling     | 2.65           |
| Policy-TimeStep         | 4.39           |
| Time                    | 340            |
| n_timesteps             | 15000          |
--------------------------------------------

 ---------------- Iteration 15 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 150 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 151 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 152 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 153 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 154 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 155 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 156 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 157 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 158 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 159 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.603          |
| Data-EnvSampler-Poli... | 1.38           |
| Data-EnvTrajs-Averag... | -30.6          |
| Data-EnvTrajs-MaxReturn | 2.94           |
| Data-EnvTrajs-MinReturn | -53.5          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 20.8           |
| Data-TimeEnvSampleProc  | 0.00167        |
| Data-TimeEnvSampling    | 2.05           |
| Iteration               | 15             |
| ItrTime                 | 36             |
| LossAfter               | -0.01811487    |
| LossBefore              | -1.1074253e-05 |
| Model-TimeModelFit      | 29.9           |
| ModelSampler-n_times... | 640000         |
| Policy-AverageAbsPol... | 0.54481494     |
| Policy-AverageDiscou... | -47            |
| Policy-AveragePolicyStd | 0.733394       |
| Policy-AverageReturn    | -101           |
| Policy-MaxReturn        | -51.1          |
| Policy-MinReturn        | -171           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 30.4           |
| Policy-TimeAlgoOpt      | 0.933          |
| Policy-TimeSampleProc   | 0.591          |
| Policy-TimeSampling     | 2.56           |
| Policy-TimeStep         | 4.13           |
| Time                    | 376            |
| n_timesteps             | 16000          |
--------------------------------------------

 ---------------- Iteration 16 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 160 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 161 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 162 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 163 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 164 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 165 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 166 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 167 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 168 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 169 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.468          |
| Data-EnvSampler-Poli... | 1.16           |
| Data-EnvTrajs-Averag... | -3.95          |
| Data-EnvTrajs-MaxReturn | 49             |
| Data-EnvTrajs-MinReturn | -51.7          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 34.2           |
| Data-TimeEnvSampleProc  | 0.000852       |
| Data-TimeEnvSampling    | 1.67           |
| Iteration               | 16             |
| ItrTime                 | 39.4           |
| LossAfter               | -0.016853515   |
| LossBefore              | -1.0761124e-05 |
| Model-TimeModelFit      | 34.9           |
| ModelSampler-n_times... | 680000         |
| Policy-AverageAbsPol... | 0.5201989      |
| Policy-AverageDiscou... | -30.6          |
| Policy-AveragePolicyStd | 0.71052945     |
| Policy-AverageReturn    | -71.6          |
| Policy-MaxReturn        | -34.7          |
| Policy-MinReturn        | -151           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 25.5           |
| Policy-TimeAlgoOpt      | 0.564          |
| Policy-TimeSampleProc   | 0.616          |
| Policy-TimeSampling     | 1.6            |
| Policy-TimeStep         | 2.82           |
| Time                    | 415            |
| n_timesteps             | 17000          |
--------------------------------------------

 ---------------- Iteration 17 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 170 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 171 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 172 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 173 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 174 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 175 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 176 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 177 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 178 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 179 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.393          |
| Data-EnvSampler-Poli... | 0.896          |
| Data-EnvTrajs-Averag... | -43.3          |
| Data-EnvTrajs-MaxReturn | 38.7           |
| Data-EnvTrajs-MinReturn | -81.3          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 43.6           |
| Data-TimeEnvSampleProc  | 0.00091        |
| Data-TimeEnvSampling    | 1.33           |
| Iteration               | 17             |
| ItrTime                 | 43.1           |
| LossAfter               | -0.01810899    |
| LossBefore              | -1.0517757e-05 |
| Model-TimeModelFit      | 38.7           |
| ModelSampler-n_times... | 720000         |
| Policy-AverageAbsPol... | 0.47980273     |
| Policy-AverageDiscou... | -14            |
| Policy-AveragePolicyStd | 0.69404787     |
| Policy-AverageReturn    | -34.7          |
| Policy-MaxReturn        | 14             |
| Policy-MinReturn        | -121           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 39             |
| Policy-TimeAlgoOpt      | 0.608          |
| Policy-TimeSampleProc   | 0.633          |
| Policy-TimeSampling     | 1.84           |
| Policy-TimeStep         | 3.14           |
| Time                    | 458            |
| n_timesteps             | 18000          |
--------------------------------------------

 ---------------- Iteration 18 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 180 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 181 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 182 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 183 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 184 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 185 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 186 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 187 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 188 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 189 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.403          |
| Data-EnvSampler-Poli... | 0.976          |
| Data-EnvTrajs-Averag... | -27.7          |
| Data-EnvTrajs-MaxReturn | -5.57          |
| Data-EnvTrajs-MinReturn | -59.5          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 20.5           |
| Data-TimeEnvSampleProc  | 0.0011         |
| Data-TimeEnvSampling    | 1.42           |
| Iteration               | 18             |
| ItrTime                 | 39.9           |
| LossAfter               | -0.019357093   |
| LossBefore              | -1.0413214e-05 |
| Model-TimeModelFit      | 36             |
| ModelSampler-n_times... | 760000         |
| Policy-AverageAbsPol... | 0.51593167     |
| Policy-AverageDiscou... | -87.8          |
| Policy-AveragePolicyStd | 0.68679965     |
| Policy-AverageReturn    | -190           |
| Policy-MaxReturn        | -26.5          |
| Policy-MinReturn        | -373           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 98             |
| Policy-TimeAlgoOpt      | 0.601          |
| Policy-TimeSampleProc   | 0.47           |
| Policy-TimeSampling     | 1.36           |
| Policy-TimeStep         | 2.46           |
| Time                    | 498            |
| n_timesteps             | 19000          |
--------------------------------------------

 ---------------- Iteration 19 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 190 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 191 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 192 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 193 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 194 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 195 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 196 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 197 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 198 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 199 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.377          |
| Data-EnvSampler-Poli... | 0.907          |
| Data-EnvTrajs-Averag... | -54.6          |
| Data-EnvTrajs-MaxReturn | -6.53          |
| Data-EnvTrajs-MinReturn | -85.1          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 27.5           |
| Data-TimeEnvSampleProc  | 0.000956       |
| Data-TimeEnvSampling    | 1.32           |
| Iteration               | 19             |
| ItrTime                 | 39.1           |
| LossAfter               | -0.016672147   |
| LossBefore              | -1.0355271e-05 |
| Model-TimeModelFit      | 34.6           |
| ModelSampler-n_times... | 800000         |
| Policy-AverageAbsPol... | 0.516557       |
| Policy-AverageDiscou... | -25.8          |
| Policy-AveragePolicyStd | 0.68324786     |
| Policy-AverageReturn    | -60.4          |
| Policy-MaxReturn        | 46.7           |
| Policy-MinReturn        | -143           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 39.8           |
| Policy-TimeAlgoOpt      | 0.623          |
| Policy-TimeSampleProc   | 0.617          |
| Policy-TimeSampling     | 1.89           |
| Policy-TimeStep         | 3.2            |
| Time                    | 537            |
| n_timesteps             | 20000          |
--------------------------------------------

 ---------------- Iteration 20 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 200 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 201 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 202 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 203 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 204 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 205 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 206 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 207 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 208 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 209 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.524          |
| Data-EnvSampler-Poli... | 1.26           |
| Data-EnvTrajs-Averag... | -48.3          |
| Data-EnvTrajs-MaxReturn | -31.8          |
| Data-EnvTrajs-MinReturn | -59.7          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 9.41           |
| Data-TimeEnvSampleProc  | 0.00677        |
| Data-TimeEnvSampling    | 1.83           |
| Iteration               | 20             |
| ItrTime                 | 39.4           |
| LossAfter               | -0.018815897   |
| LossBefore              | -1.0155954e-05 |
| Model-TimeModelFit      | 34.7           |
| ModelSampler-n_times... | 840000         |
| Policy-AverageAbsPol... | 0.53852165     |
| Policy-AverageDiscou... | 38.1           |
| Policy-AveragePolicyStd | 0.66947407     |
| Policy-AverageReturn    | 106            |
| Policy-MaxReturn        | 228            |
| Policy-MinReturn        | 18             |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 68.4           |
| Policy-TimeAlgoOpt      | 0.612          |
| Policy-TimeSampleProc   | 0.582          |
| Policy-TimeSampling     | 1.6            |
| Policy-TimeStep         | 2.85           |
| Time                    | 577            |
| n_timesteps             | 21000          |
--------------------------------------------

 ---------------- Iteration 21 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 210 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 211 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 212 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 213 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 214 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 215 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 216 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 217 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 218 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 219 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.409         |
| Data-EnvSampler-Poli... | 0.973         |
| Data-EnvTrajs-Averag... | -42.7         |
| Data-EnvTrajs-MaxReturn | -12.7         |
| Data-EnvTrajs-MinReturn | -77           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 24.6          |
| Data-TimeEnvSampleProc  | 0.00103       |
| Data-TimeEnvSampling    | 1.42          |
| Iteration               | 21            |
| ItrTime                 | 41.5          |
| LossAfter               | -0.015874911  |
| LossBefore              | -9.974728e-06 |
| Model-TimeModelFit      | 37.6          |
| ModelSampler-n_times... | 880000        |
| Policy-AverageAbsPol... | 0.6045722     |
| Policy-AverageDiscou... | 23.2          |
| Policy-AveragePolicyStd | 0.657861      |
| Policy-AverageReturn    | 74.7          |
| Policy-MaxReturn        | 218           |
| Policy-MinReturn        | -29           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 50.9          |
| Policy-TimeAlgoOpt      | 0.607         |
| Policy-TimeSampleProc   | 0.438         |
| Policy-TimeSampling     | 1.45          |
| Policy-TimeStep         | 2.52          |
| Time                    | 618           |
| n_timesteps             | 22000         |
-------------------------------------------

 ---------------- Iteration 22 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 220 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 221 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 222 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 223 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 224 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 225 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 226 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 227 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 228 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 229 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.642         |
| Data-EnvSampler-Poli... | 1.59          |
| Data-EnvTrajs-Averag... | 30            |
| Data-EnvTrajs-MaxReturn | 60.2          |
| Data-EnvTrajs-MinReturn | -7.92         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 24.6          |
| Data-TimeEnvSampleProc  | 0.0016        |
| Data-TimeEnvSampling    | 2.31          |
| Iteration               | 22            |
| ItrTime                 | 41            |
| LossAfter               | -0.017535465  |
| LossBefore              | -9.742539e-06 |
| Model-TimeModelFit      | 34.7          |
| ModelSampler-n_times... | 920000        |
| Policy-AverageAbsPol... | 0.64979684    |
| Policy-AverageDiscou... | 87.5          |
| Policy-AveragePolicyStd | 0.64385056    |
| Policy-AverageReturn    | 243           |
| Policy-MaxReturn        | 452           |
| Policy-MinReturn        | 12            |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 109           |
| Policy-TimeAlgoOpt      | 0.79          |
| Policy-TimeSampleProc   | 0.704         |
| Policy-TimeSampling     | 2.46          |
| Policy-TimeStep         | 3.99          |
| Time                    | 659           |
| n_timesteps             | 23000         |
-------------------------------------------

 ---------------- Iteration 23 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 230 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 231 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 232 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 233 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 234 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 235 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 236 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 237 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 238 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 239 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.891         |
| Data-EnvSampler-Poli... | 2.24          |
| Data-EnvTrajs-Averag... | 25            |
| Data-EnvTrajs-MaxReturn | 73.2          |
| Data-EnvTrajs-MinReturn | -39.7         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 39.6          |
| Data-TimeEnvSampleProc  | 0.00466       |
| Data-TimeEnvSampling    | 3.22          |
| Iteration               | 23            |
| ItrTime                 | 50.8          |
| LossAfter               | -0.014388924  |
| LossBefore              | -9.570164e-06 |
| Model-TimeModelFit      | 42.3          |
| ModelSampler-n_times... | 960000        |
| Policy-AverageAbsPol... | 0.66798097    |
| Policy-AverageDiscou... | 24.2          |
| Policy-AveragePolicyStd | 0.632214      |
| Policy-AverageReturn    | 74.2          |
| Policy-MaxReturn        | 182           |
| Policy-MinReturn        | -28           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 59.2          |
| Policy-TimeAlgoOpt      | 1.07          |
| Policy-TimeSampleProc   | 1.02          |
| Policy-TimeSampling     | 3.12          |
| Policy-TimeStep         | 5.28          |
| Time                    | 710           |
| n_timesteps             | 24000         |
-------------------------------------------

 ---------------- Iteration 24 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 240 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 241 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 242 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 243 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 244 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 245 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 246 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 247 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 248 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 249 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.816         |
| Data-EnvSampler-Poli... | 1.91          |
| Data-EnvTrajs-Averag... | -9.83         |
| Data-EnvTrajs-MaxReturn | 74.5          |
| Data-EnvTrajs-MinReturn | -96.9         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 62.4          |
| Data-TimeEnvSampleProc  | 0.00141       |
| Data-TimeEnvSampling    | 2.81          |
| Iteration               | 24            |
| ItrTime                 | 48            |
| LossAfter               | -0.01770769   |
| LossBefore              | -9.473447e-06 |
| Model-TimeModelFit      | 42.2          |
| ModelSampler-n_times... | 1000000       |
| Policy-AverageAbsPol... | 0.688298      |
| Policy-AverageDiscou... | 51.8          |
| Policy-AveragePolicyStd | 0.6258287     |
| Policy-AverageReturn    | 182           |
| Policy-MaxReturn        | 323           |
| Policy-MinReturn        | -88.4         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 96.9          |
| Policy-TimeAlgoOpt      | 0.59          |
| Policy-TimeSampleProc   | 0.598         |
| Policy-TimeSampling     | 1.75          |
| Policy-TimeStep         | 2.97          |
| Time                    | 758           |
| n_timesteps             | 25000         |
-------------------------------------------

 ---------------- Iteration 25 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 250 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 251 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 252 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 253 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 254 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 255 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 256 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 257 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 258 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 259 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.44          |
| Data-EnvSampler-Poli... | 1.05          |
| Data-EnvTrajs-Averag... | 26.6          |
| Data-EnvTrajs-MaxReturn | 69.2          |
| Data-EnvTrajs-MinReturn | -9.82         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 26            |
| Data-TimeEnvSampleProc  | 0.000969      |
| Data-TimeEnvSampling    | 1.54          |
| Iteration               | 25            |
| ItrTime                 | 48            |
| LossAfter               | -0.018748345  |
| LossBefore              | -9.329426e-06 |
| Model-TimeModelFit      | 43.2          |
| ModelSampler-n_times... | 1040000       |
| Policy-AverageAbsPol... | 0.69713485    |
| Policy-AverageDiscou... | 62.9          |
| Policy-AveragePolicyStd | 0.6168628     |
| Policy-AverageReturn    | 168           |
| Policy-MaxReturn        | 329           |
| Policy-MinReturn        | -83.2         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 82.3          |
| Policy-TimeAlgoOpt      | 0.591         |
| Policy-TimeSampleProc   | 0.685         |
| Policy-TimeSampling     | 1.85          |
| Policy-TimeStep         | 3.21          |
| Time                    | 806           |
| n_timesteps             | 26000         |
-------------------------------------------

 ---------------- Iteration 26 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 260 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 261 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 262 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 263 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 264 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 265 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 266 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 267 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 268 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 269 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.462         |
| Data-EnvSampler-Poli... | 1.16          |
| Data-EnvTrajs-Averag... | 18.1          |
| Data-EnvTrajs-MaxReturn | 45.9          |
| Data-EnvTrajs-MinReturn | -18.1         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 24.1          |
| Data-TimeEnvSampleProc  | 0.000992      |
| Data-TimeEnvSampling    | 1.68          |
| Iteration               | 26            |
| ItrTime                 | 45.8          |
| LossAfter               | -0.019441042  |
| LossBefore              | -9.252187e-06 |
| Model-TimeModelFit      | 41.3          |
| ModelSampler-n_times... | 1080000       |
| Policy-AverageAbsPol... | 0.7466803     |
| Policy-AverageDiscou... | -79.1         |
| Policy-AveragePolicyStd | 0.6129605     |
| Policy-AverageReturn    | -188          |
| Policy-MaxReturn        | -56.4         |
| Policy-MinReturn        | -253          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 50.6          |
| Policy-TimeAlgoOpt      | 0.636         |
| Policy-TimeSampleProc   | 0.514         |
| Policy-TimeSampling     | 1.63          |
| Policy-TimeStep         | 2.8           |
| Time                    | 852           |
| n_timesteps             | 27000         |
-------------------------------------------

 ---------------- Iteration 27 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 270 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 271 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 272 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 273 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 274 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 275 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 276 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 277 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 278 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 279 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.468          |
| Data-EnvSampler-Poli... | 1.46           |
| Data-EnvTrajs-Averag... | 29.1           |
| Data-EnvTrajs-MaxReturn | 79.2           |
| Data-EnvTrajs-MinReturn | -27.1          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 33.7           |
| Data-TimeEnvSampleProc  | 0.00086        |
| Data-TimeEnvSampling    | 1.99           |
| Iteration               | 27             |
| ItrTime                 | 45             |
| LossAfter               | -0.018508743   |
| LossBefore              | -9.1054035e-06 |
| Model-TimeModelFit      | 40.1           |
| ModelSampler-n_times... | 1120000        |
| Policy-AverageAbsPol... | 0.7719639      |
| Policy-AverageDiscou... | -17.5          |
| Policy-AveragePolicyStd | 0.6032808      |
| Policy-AverageReturn    | -28.3          |
| Policy-MaxReturn        | 61.9           |
| Policy-MinReturn        | -111           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 51.9           |
| Policy-TimeAlgoOpt      | 0.628          |
| Policy-TimeSampleProc   | 0.546          |
| Policy-TimeSampling     | 1.8            |
| Policy-TimeStep         | 3              |
| Time                    | 897            |
| n_timesteps             | 28000          |
--------------------------------------------

 ---------------- Iteration 28 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 280 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 281 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 282 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 283 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 284 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 285 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 286 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 287 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 288 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 289 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.406         |
| Data-EnvSampler-Poli... | 0.979         |
| Data-EnvTrajs-Averag... | 20.5          |
| Data-EnvTrajs-MaxReturn | 48.1          |
| Data-EnvTrajs-MinReturn | -32.9         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 29.8          |
| Data-TimeEnvSampleProc  | 0.00141       |
| Data-TimeEnvSampling    | 1.43          |
| Iteration               | 28            |
| ItrTime                 | 44.7          |
| LossAfter               | -0.018927343  |
| LossBefore              | -8.850381e-06 |
| Model-TimeModelFit      | 39.8          |
| ModelSampler-n_times... | 1160000       |
| Policy-AverageAbsPol... | 0.79911065    |
| Policy-AverageDiscou... | 22.5          |
| Policy-AveragePolicyStd | 0.5889833     |
| Policy-AverageReturn    | 59.4          |
| Policy-MaxReturn        | 209           |
| Policy-MinReturn        | -47.5         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 59.7          |
| Policy-TimeAlgoOpt      | 0.592         |
| Policy-TimeSampleProc   | 0.807         |
| Policy-TimeSampling     | 2.03          |
| Policy-TimeStep         | 3.46          |
| Time                    | 942           |
| n_timesteps             | 29000         |
-------------------------------------------

 ---------------- Iteration 29 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 290 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 291 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 292 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 293 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 294 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 295 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 296 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 297 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 298 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 299 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.469         |
| Data-EnvSampler-Poli... | 1.57          |
| Data-EnvTrajs-Averag... | 0.561         |
| Data-EnvTrajs-MaxReturn | 16.4          |
| Data-EnvTrajs-MinReturn | -18.8         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 12.2          |
| Data-TimeEnvSampleProc  | 0.00192       |
| Data-TimeEnvSampling    | 2.11          |
| Iteration               | 29            |
| ItrTime                 | 45.9          |
| LossAfter               | -0.018135294  |
| LossBefore              | -8.633694e-06 |
| Model-TimeModelFit      | 38.7          |
| ModelSampler-n_times... | 1200000       |
| Policy-AverageAbsPol... | 0.8064891     |
| Policy-AverageDiscou... | 4.59          |
| Policy-AveragePolicyStd | 0.57579494    |
| Policy-AverageReturn    | 22.3          |
| Policy-MaxReturn        | 150           |
| Policy-MinReturn        | -283          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 85            |
| Policy-TimeAlgoOpt      | 0.907         |
| Policy-TimeSampleProc   | 1.14          |
| Policy-TimeSampling     | 3             |
| Policy-TimeStep         | 5.09          |
| Time                    | 988           |
| n_timesteps             | 30000         |
-------------------------------------------

 ---------------- Iteration 30 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 300 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 301 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 302 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 303 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 304 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 305 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 306 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 307 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 308 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 309 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.821          |
| Data-EnvSampler-Poli... | 2.09           |
| Data-EnvTrajs-Averag... | 14.3           |
| Data-EnvTrajs-MaxReturn | 20.1           |
| Data-EnvTrajs-MinReturn | 7.71           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 5.13           |
| Data-TimeEnvSampleProc  | 0.00159        |
| Data-TimeEnvSampling    | 2.99           |
| Iteration               | 30             |
| ItrTime                 | 44.2           |
| LossAfter               | -0.020735364   |
| LossBefore              | -8.3888135e-06 |
| Model-TimeModelFit      | 38.5           |
| ModelSampler-n_times... | 1240000        |
| Policy-AverageAbsPol... | 0.7599501      |
| Policy-AverageDiscou... | -32.8          |
| Policy-AveragePolicyStd | 0.56299883     |
| Policy-AverageReturn    | -69.4          |
| Policy-MaxReturn        | 42.5           |
| Policy-MinReturn        | -156           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 46.5           |
| Policy-TimeAlgoOpt      | 0.559          |
| Policy-TimeSampleProc   | 0.453          |
| Policy-TimeSampling     | 1.55           |
| Policy-TimeStep         | 2.63           |
| Time                    | 1.03e+03       |
| n_timesteps             | 31000          |
--------------------------------------------

 ---------------- Iteration 31 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 310 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 311 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 312 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 313 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 314 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 315 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 316 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 317 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 318 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 319 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.41          |
| Data-EnvSampler-Poli... | 1.02          |
| Data-EnvTrajs-Averag... | 68.4          |
| Data-EnvTrajs-MaxReturn | 145           |
| Data-EnvTrajs-MinReturn | -6.76         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 59.4          |
| Data-TimeEnvSampleProc  | 0.00127       |
| Data-TimeEnvSampling    | 1.47          |
| Iteration               | 31            |
| ItrTime                 | 44.3          |
| LossAfter               | -0.019237826  |
| LossBefore              | -8.237402e-06 |
| Model-TimeModelFit      | 40.2          |
| ModelSampler-n_times... | 1280000       |
| Policy-AverageAbsPol... | 0.73512954    |
| Policy-AverageDiscou... | 17.3          |
| Policy-AveragePolicyStd | 0.55352896    |
| Policy-AverageReturn    | 43            |
| Policy-MaxReturn        | 166           |
| Policy-MinReturn        | -59.1         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 56.1          |
| Policy-TimeAlgoOpt      | 0.611         |
| Policy-TimeSampleProc   | 0.485         |
| Policy-TimeSampling     | 1.51          |
| Policy-TimeStep         | 2.66          |
| Time                    | 1.08e+03      |
| n_timesteps             | 32000         |
-------------------------------------------

 ---------------- Iteration 32 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 320 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 321 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 322 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 323 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 324 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 325 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 326 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 327 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 328 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 329 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Data-EnvSampler-EnvE... | 0.366        |
| Data-EnvSampler-Poli... | 0.95         |
| Data-EnvTrajs-Averag... | 50.7         |
| Data-EnvTrajs-MaxReturn | 167          |
| Data-EnvTrajs-MinReturn | -46.4        |
| Data-EnvTrajs-NumTrajs  | 5            |
| Data-EnvTrajs-StdReturn | 75.8         |
| Data-TimeEnvSampleProc  | 0.000961     |
| Data-TimeEnvSampling    | 1.36         |
| Iteration               | 32           |
| ItrTime                 | 45.3         |
| LossAfter               | -0.018541567 |
| LossBefore              | -8.11673e-06 |
| Model-TimeModelFit      | 41.3         |
| ModelSampler-n_times... | 1320000      |
| Policy-AverageAbsPol... | 0.7141421    |
| Policy-AverageDiscou... | 48.7         |
| Policy-AveragePolicyStd | 0.5463859    |
| Policy-AverageReturn    | 137          |
| Policy-MaxReturn        | 270          |
| Policy-MinReturn        | 34.4         |
| Policy-NumTrajs         | 20           |
| Policy-StdReturn        | 56.6         |
| Policy-TimeAlgoOpt      | 0.546        |
| Policy-TimeSampleProc   | 0.54         |
| Policy-TimeSampling     | 1.54         |
| Policy-TimeStep         | 2.67         |
| Time                    | 1.12e+03     |
| n_timesteps             | 33000        |
------------------------------------------

 ---------------- Iteration 33 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 330 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 331 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 332 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 333 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 334 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 335 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 336 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 337 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 338 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 339 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.384         |
| Data-EnvSampler-Poli... | 0.973         |
| Data-EnvTrajs-Averag... | 82.3          |
| Data-EnvTrajs-MaxReturn | 136           |
| Data-EnvTrajs-MinReturn | 46.7          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 31.6          |
| Data-TimeEnvSampleProc  | 0.000957      |
| Data-TimeEnvSampling    | 1.4           |
| Iteration               | 33            |
| ItrTime                 | 47            |
| LossAfter               | -0.017046755  |
| LossBefore              | -7.978584e-06 |
| Model-TimeModelFit      | 42.2          |
| ModelSampler-n_times... | 1360000       |
| Policy-AverageAbsPol... | 0.73938775    |
| Policy-AverageDiscou... | -18.5         |
| Policy-AveragePolicyStd | 0.5376219     |
| Policy-AverageReturn    | -46.5         |
| Policy-MaxReturn        | 18.5          |
| Policy-MinReturn        | -115          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 35.7          |
| Policy-TimeAlgoOpt      | 0.772         |
| Policy-TimeSampleProc   | 0.564         |
| Policy-TimeSampling     | 2.01          |
| Policy-TimeStep         | 3.39          |
| Time                    | 1.17e+03      |
| n_timesteps             | 34000         |
-------------------------------------------

 ---------------- Iteration 34 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 340 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 341 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 342 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 343 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 344 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 345 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 346 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 347 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 348 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 349 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.361         |
| Data-EnvSampler-Poli... | 0.897         |
| Data-EnvTrajs-Averag... | 49.5          |
| Data-EnvTrajs-MaxReturn | 135           |
| Data-EnvTrajs-MinReturn | 0.283         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 47.2          |
| Data-TimeEnvSampleProc  | 0.000521      |
| Data-TimeEnvSampling    | 1.3           |
| Iteration               | 34            |
| ItrTime                 | 34.2          |
| LossAfter               | -0.020490965  |
| LossBefore              | -7.893437e-06 |
| Model-TimeModelFit      | 29            |
| ModelSampler-n_times... | 1400000       |
| Policy-AverageAbsPol... | 0.7482964     |
| Policy-AverageDiscou... | -34.2         |
| Policy-AveragePolicyStd | 0.53473175    |
| Policy-AverageReturn    | -79.5         |
| Policy-MaxReturn        | 49.9          |
| Policy-MinReturn        | -154          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 53.3          |
| Policy-TimeAlgoOpt      | 0.818         |
| Policy-TimeSampleProc   | 0.754         |
| Policy-TimeSampling     | 2.3           |
| Policy-TimeStep         | 3.91          |
| Time                    | 1.2e+03       |
| n_timesteps             | 35000         |
-------------------------------------------

 ---------------- Iteration 35 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 350 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 351 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 352 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 353 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 354 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 355 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 356 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 357 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 358 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 359 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.527         |
| Data-EnvSampler-Poli... | 1.16          |
| Data-EnvTrajs-Averag... | 66            |
| Data-EnvTrajs-MaxReturn | 130           |
| Data-EnvTrajs-MinReturn | 30.8          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 36.3          |
| Data-TimeEnvSampleProc  | 0.0015        |
| Data-TimeEnvSampling    | 1.75          |
| Iteration               | 35            |
| ItrTime                 | 33.8          |
| LossAfter               | -0.015692485  |
| LossBefore              | -7.743586e-06 |
| Model-TimeModelFit      | 29.3          |
| ModelSampler-n_times... | 1440000       |
| Policy-AverageAbsPol... | 0.7379295     |
| Policy-AverageDiscou... | -18.3         |
| Policy-AveragePolicyStd | 0.526304      |
| Policy-AverageReturn    | -28.9         |
| Policy-MaxReturn        | 54            |
| Policy-MinReturn        | -136          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 42.9          |
| Policy-TimeAlgoOpt      | 0.653         |
| Policy-TimeSampleProc   | 0.373         |
| Policy-TimeSampling     | 1.67          |
| Policy-TimeStep         | 2.74          |
| Time                    | 1.24e+03      |
| n_timesteps             | 36000         |
-------------------------------------------

 ---------------- Iteration 36 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 360 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 361 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 362 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 363 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 364 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 365 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 366 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 367 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 368 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 369 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.518          |
| Data-EnvSampler-Poli... | 1.25           |
| Data-EnvTrajs-Averag... | 72.5           |
| Data-EnvTrajs-MaxReturn | 146            |
| Data-EnvTrajs-MinReturn | 31.8           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 41.8           |
| Data-TimeEnvSampleProc  | 0.00162        |
| Data-TimeEnvSampling    | 1.82           |
| Iteration               | 36             |
| ItrTime                 | 36.2           |
| LossAfter               | -0.017772773   |
| LossBefore              | -7.5895073e-06 |
| Model-TimeModelFit      | 32             |
| ModelSampler-n_times... | 1480000        |
| Policy-AverageAbsPol... | 0.76357836     |
| Policy-AverageDiscou... | -64.4          |
| Policy-AveragePolicyStd | 0.5189071      |
| Policy-AverageReturn    | -137           |
| Policy-MaxReturn        | -82.4          |
| Policy-MinReturn        | -191           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 31.2           |
| Policy-TimeAlgoOpt      | 0.57           |
| Policy-TimeSampleProc   | 0.387          |
| Policy-TimeSampling     | 1.44           |
| Policy-TimeStep         | 2.42           |
| Time                    | 1.27e+03       |
| n_timesteps             | 37000          |
--------------------------------------------

 ---------------- Iteration 37 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 370 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 371 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 372 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 373 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 374 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 375 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 376 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 377 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 378 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 379 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.355          |
| Data-EnvSampler-Poli... | 0.879          |
| Data-EnvTrajs-Averag... | 60.8           |
| Data-EnvTrajs-MaxReturn | 118            |
| Data-EnvTrajs-MinReturn | 16.8           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 39             |
| Data-TimeEnvSampleProc  | 0.000601       |
| Data-TimeEnvSampling    | 1.28           |
| Iteration               | 37             |
| ItrTime                 | 36.7           |
| LossAfter               | -0.017507859   |
| LossBefore              | -7.4712684e-06 |
| Model-TimeModelFit      | 33.1           |
| ModelSampler-n_times... | 1520000        |
| Policy-AverageAbsPol... | 0.7921989      |
| Policy-AverageDiscou... | 124            |
| Policy-AveragePolicyStd | 0.51214087     |
| Policy-AverageReturn    | 532            |
| Policy-MaxReturn        | 9.95e+03       |
| Policy-MinReturn        | -54.8          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.16e+03       |
| Policy-TimeAlgoOpt      | 0.536          |
| Policy-TimeSampleProc   | 0.45           |
| Policy-TimeSampling     | 1.33           |
| Policy-TimeStep         | 2.38           |
| Time                    | 1.31e+03       |
| n_timesteps             | 38000          |
--------------------------------------------

 ---------------- Iteration 38 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 380 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 381 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 382 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 383 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 384 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 385 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 386 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 387 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 388 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 389 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.341         |
| Data-EnvSampler-Poli... | 0.922         |
| Data-EnvTrajs-Averag... | 101           |
| Data-EnvTrajs-MaxReturn | 216           |
| Data-EnvTrajs-MinReturn | 1.47          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 72.5          |
| Data-TimeEnvSampleProc  | 0.000959      |
| Data-TimeEnvSampling    | 1.3           |
| Iteration               | 38            |
| ItrTime                 | 38            |
| LossAfter               | -0.021959357  |
| LossBefore              | -7.408304e-06 |
| Model-TimeModelFit      | 34.5          |
| ModelSampler-n_times... | 1560000       |
| Policy-AverageAbsPol... | 0.8485194     |
| Policy-AverageDiscou... | 186           |
| Policy-AveragePolicyStd | 0.50824624    |
| Policy-AverageReturn    | 725           |
| Policy-MaxReturn        | 1.97e+03      |
| Policy-MinReturn        | -320          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 612           |
| Policy-TimeAlgoOpt      | 0.534         |
| Policy-TimeSampleProc   | 0.293         |
| Policy-TimeSampling     | 1.41          |
| Policy-TimeStep         | 2.27          |
| Time                    | 1.35e+03      |
| n_timesteps             | 39000         |
-------------------------------------------

 ---------------- Iteration 39 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 390 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 391 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 392 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 393 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 394 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 395 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 396 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 397 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 398 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 399 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.308          |
| Data-EnvSampler-Poli... | 0.74           |
| Data-EnvTrajs-Averag... | 55.1           |
| Data-EnvTrajs-MaxReturn | 81.1           |
| Data-EnvTrajs-MinReturn | 35             |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 14.8           |
| Data-TimeEnvSampleProc  | 0.000594       |
| Data-TimeEnvSampling    | 1.09           |
| Iteration               | 39             |
| ItrTime                 | 35.6           |
| LossAfter               | -0.022599326   |
| LossBefore              | -7.3191095e-06 |
| Model-TimeModelFit      | 32.1           |
| ModelSampler-n_times... | 1600000        |
| Policy-AverageAbsPol... | 0.8356679      |
| Policy-AverageDiscou... | 3.54           |
| Policy-AveragePolicyStd | 0.50527        |
| Policy-AverageReturn    | 16.5           |
| Policy-MaxReturn        | 3.29e+03       |
| Policy-MinReturn        | -2.72e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.24e+03       |
| Policy-TimeAlgoOpt      | 0.544          |
| Policy-TimeSampleProc   | 0.433          |
| Policy-TimeSampling     | 1.39           |
| Policy-TimeStep         | 2.4            |
| Time                    | 1.38e+03       |
| n_timesteps             | 40000          |
--------------------------------------------

 ---------------- Iteration 40 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 400 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 401 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 402 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 403 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 404 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 405 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 406 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 407 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 408 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 409 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.351          |
| Data-EnvSampler-Poli... | 0.861          |
| Data-EnvTrajs-Averag... | -22.7          |
| Data-EnvTrajs-MaxReturn | -8.53          |
| Data-EnvTrajs-MinReturn | -64.2          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 21             |
| Data-TimeEnvSampleProc  | 0.00206        |
| Data-TimeEnvSampling    | 1.25           |
| Iteration               | 40             |
| ItrTime                 | 39.2           |
| LossAfter               | -0.020065485   |
| LossBefore              | -7.3022097e-06 |
| Model-TimeModelFit      | 35.7           |
| ModelSampler-n_times... | 1640000        |
| Policy-AverageAbsPol... | 0.8213138      |
| Policy-AverageDiscou... | -135           |
| Policy-AveragePolicyStd | 0.5040673      |
| Policy-AverageReturn    | -739           |
| Policy-MaxReturn        | 255            |
| Policy-MinReturn        | -7.23e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.94e+03       |
| Policy-TimeAlgoOpt      | 0.551          |
| Policy-TimeSampleProc   | 0.352          |
| Policy-TimeSampling     | 1.33           |
| Policy-TimeStep         | 2.28           |
| Time                    | 1.42e+03       |
| n_timesteps             | 41000          |
--------------------------------------------

 ---------------- Iteration 41 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 410 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 411 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 412 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 413 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 414 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 415 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 416 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 417 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 418 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 419 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Data-EnvSampler-EnvE... | 0.323        |
| Data-EnvSampler-Poli... | 0.853        |
| Data-EnvTrajs-Averag... | -5.17        |
| Data-EnvTrajs-MaxReturn | 43.1         |
| Data-EnvTrajs-MinReturn | -70.8        |
| Data-EnvTrajs-NumTrajs  | 5            |
| Data-EnvTrajs-StdReturn | 49.4         |
| Data-TimeEnvSampleProc  | 0.000773     |
| Data-TimeEnvSampling    | 1.21         |
| Iteration               | 41           |
| ItrTime                 | 35.6         |
| LossAfter               | -0.024874778 |
| LossBefore              | -7.21511e-06 |
| Model-TimeModelFit      | 32.1         |
| ModelSampler-n_times... | 1680000      |
| Policy-AverageAbsPol... | 0.8167763    |
| Policy-AverageDiscou... | -91.3        |
| Policy-AveragePolicyStd | 0.49969286   |
| Policy-AverageReturn    | -541         |
| Policy-MaxReturn        | 127          |
| Policy-MinReturn        | -5.2e+03     |
| Policy-NumTrajs         | 20           |
| Policy-StdReturn        | 1.47e+03     |
| Policy-TimeAlgoOpt      | 0.599        |
| Policy-TimeSampleProc   | 0.329        |
| Policy-TimeSampling     | 1.39         |
| Policy-TimeStep         | 2.36         |
| Time                    | 1.46e+03     |
| n_timesteps             | 42000        |
------------------------------------------

 ---------------- Iteration 42 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 420 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 421 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 422 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 423 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 424 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 425 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 426 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 427 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 428 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 429 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.339          |
| Data-EnvSampler-Poli... | 0.8            |
| Data-EnvTrajs-Averag... | 4.57           |
| Data-EnvTrajs-MaxReturn | 32             |
| Data-EnvTrajs-MinReturn | -26.6          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 23.7           |
| Data-TimeEnvSampleProc  | 0.00081        |
| Data-TimeEnvSampling    | 1.17           |
| Iteration               | 42             |
| ItrTime                 | 37.6           |
| LossAfter               | -0.018231345   |
| LossBefore              | -7.1137883e-06 |
| Model-TimeModelFit      | 34             |
| ModelSampler-n_times... | 1720000        |
| Policy-AverageAbsPol... | 0.8216615      |
| Policy-AverageDiscou... | -39.6          |
| Policy-AveragePolicyStd | 0.49424246     |
| Policy-AverageReturn    | -239           |
| Policy-MaxReturn        | 215            |
| Policy-MinReturn        | -5.73e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.26e+03       |
| Policy-TimeAlgoOpt      | 0.533          |
| Policy-TimeSampleProc   | 0.375          |
| Policy-TimeSampling     | 1.51           |
| Policy-TimeStep         | 2.45           |
| Time                    | 1.5e+03        |
| n_timesteps             | 43000          |
--------------------------------------------

 ---------------- Iteration 43 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 430 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 431 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 432 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 433 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 434 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 435 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 436 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 437 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 438 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 439 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.317          |
| Data-EnvSampler-Poli... | 0.799          |
| Data-EnvTrajs-Averag... | 51.6           |
| Data-EnvTrajs-MaxReturn | 100            |
| Data-EnvTrajs-MinReturn | -78.7          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 65.7           |
| Data-TimeEnvSampleProc  | 0.00069        |
| Data-TimeEnvSampling    | 1.16           |
| Iteration               | 43             |
| ItrTime                 | 39             |
| LossAfter               | -0.023653291   |
| LossBefore              | -7.0478177e-06 |
| Model-TimeModelFit      | 34.5           |
| ModelSampler-n_times... | 1760000        |
| Policy-AverageAbsPol... | 0.8425423      |
| Policy-AverageDiscou... | -180           |
| Policy-AveragePolicyStd | 0.49146298     |
| Policy-AverageReturn    | -878           |
| Policy-MaxReturn        | 60             |
| Policy-MinReturn        | -6.75e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2e+03          |
| Policy-TimeAlgoOpt      | 0.68           |
| Policy-TimeSampleProc   | 0.661          |
| Policy-TimeSampling     | 1.99           |
| Policy-TimeStep         | 3.36           |
| Time                    | 1.53e+03       |
| n_timesteps             | 44000          |
--------------------------------------------

 ---------------- Iteration 44 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 440 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 441 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 442 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 443 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 444 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 445 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 446 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 447 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 448 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 449 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.316          |
| Data-EnvSampler-Poli... | 0.774          |
| Data-EnvTrajs-Averag... | 42.7           |
| Data-EnvTrajs-MaxReturn | 106            |
| Data-EnvTrajs-MinReturn | -7.01          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 39.4           |
| Data-TimeEnvSampleProc  | 0.000827       |
| Data-TimeEnvSampling    | 1.12           |
| Iteration               | 44             |
| ItrTime                 | 36.1           |
| LossAfter               | -0.025275148   |
| LossBefore              | -7.0316783e-06 |
| Model-TimeModelFit      | 30.8           |
| ModelSampler-n_times... | 1800000        |
| Policy-AverageAbsPol... | 0.8796821      |
| Policy-AverageDiscou... | -265           |
| Policy-AveragePolicyStd | 0.48998103     |
| Policy-AverageReturn    | -1.03e+03      |
| Policy-MaxReturn        | 54.4           |
| Policy-MinReturn        | -7.38e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.14e+03       |
| Policy-TimeAlgoOpt      | 0.812          |
| Policy-TimeSampleProc   | 0.785          |
| Policy-TimeSampling     | 2.53           |
| Policy-TimeStep         | 4.16           |
| Time                    | 1.57e+03       |
| n_timesteps             | 45000          |
--------------------------------------------

 ---------------- Iteration 45 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 450 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 451 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 452 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 453 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 454 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 455 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 456 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 457 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 458 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 459 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.561          |
| Data-EnvSampler-Poli... | 1.35           |
| Data-EnvTrajs-Averag... | 61.2           |
| Data-EnvTrajs-MaxReturn | 123            |
| Data-EnvTrajs-MinReturn | -38            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 53.5           |
| Data-TimeEnvSampleProc  | 0.00163        |
| Data-TimeEnvSampling    | 1.98           |
| Iteration               | 45             |
| ItrTime                 | 35.9           |
| LossAfter               | -0.01841896    |
| LossBefore              | -6.9403663e-06 |
| Model-TimeModelFit      | 30.6           |
| ModelSampler-n_times... | 1840000        |
| Policy-AverageAbsPol... | 0.78683203     |
| Policy-AverageDiscou... | -40.1          |
| Policy-AveragePolicyStd | 0.4852925      |
| Policy-AverageReturn    | -88.7          |
| Policy-MaxReturn        | 12.9           |
| Policy-MinReturn        | -185           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 55.8           |
| Policy-TimeAlgoOpt      | 0.743          |
| Policy-TimeSampleProc   | 0.553          |
| Policy-TimeSampling     | 2              |
| Policy-TimeStep         | 3.36           |
| Time                    | 1.61e+03       |
| n_timesteps             | 46000          |
--------------------------------------------

 ---------------- Iteration 46 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 460 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 461 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 462 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 463 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 464 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 465 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 466 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 467 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 468 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 469 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.538          |
| Data-EnvSampler-Poli... | 1.36           |
| Data-EnvTrajs-Averag... | 112            |
| Data-EnvTrajs-MaxReturn | 246            |
| Data-EnvTrajs-MinReturn | 68.2           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 67.2           |
| Data-TimeEnvSampleProc  | 0.00146        |
| Data-TimeEnvSampling    | 1.96           |
| Iteration               | 46             |
| ItrTime                 | 40.2           |
| LossAfter               | -0.019727467   |
| LossBefore              | -6.7394453e-06 |
| Model-TimeModelFit      | 35.9           |
| ModelSampler-n_times... | 1880000        |
| Policy-AverageAbsPol... | 0.7951938      |
| Policy-AverageDiscou... | 72.5           |
| Policy-AveragePolicyStd | 0.47740632     |
| Policy-AverageReturn    | 200            |
| Policy-MaxReturn        | 277            |
| Policy-MinReturn        | 126            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 48.1           |
| Policy-TimeAlgoOpt      | 0.53           |
| Policy-TimeSampleProc   | 0.371          |
| Policy-TimeSampling     | 1.46           |
| Policy-TimeStep         | 2.4            |
| Time                    | 1.65e+03       |
| n_timesteps             | 47000          |
--------------------------------------------

 ---------------- Iteration 47 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 470 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 471 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 472 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 473 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 474 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 475 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 476 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 477 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 478 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 479 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.315         |
| Data-EnvSampler-Poli... | 0.847         |
| Data-EnvTrajs-Averag... | 102           |
| Data-EnvTrajs-MaxReturn | 176           |
| Data-EnvTrajs-MinReturn | 57.9          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 42.4          |
| Data-TimeEnvSampleProc  | 0.000896      |
| Data-TimeEnvSampling    | 1.19          |
| Iteration               | 47            |
| ItrTime                 | 41            |
| LossAfter               | -0.021374363  |
| LossBefore              | -6.649316e-06 |
| Model-TimeModelFit      | 37.4          |
| ModelSampler-n_times... | 1920000       |
| Policy-AverageAbsPol... | 0.80101043    |
| Policy-AverageDiscou... | 46.8          |
| Policy-AveragePolicyStd | 0.47171262    |
| Policy-AverageReturn    | 141           |
| Policy-MaxReturn        | 318           |
| Policy-MinReturn        | 0.771         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 76.5          |
| Policy-TimeAlgoOpt      | 0.579         |
| Policy-TimeSampleProc   | 0.323         |
| Policy-TimeSampling     | 1.47          |
| Policy-TimeStep         | 2.4           |
| Time                    | 1.69e+03      |
| n_timesteps             | 48000         |
-------------------------------------------

 ---------------- Iteration 48 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 480 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 481 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 482 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 483 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 484 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 485 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 486 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 487 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 488 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 489 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.316         |
| Data-EnvSampler-Poli... | 0.76          |
| Data-EnvTrajs-Averag... | 95.4          |
| Data-EnvTrajs-MaxReturn | 160           |
| Data-EnvTrajs-MinReturn | 50.9          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 40.4          |
| Data-TimeEnvSampleProc  | 0.000923      |
| Data-TimeEnvSampling    | 1.11          |
| Iteration               | 48            |
| ItrTime                 | 41            |
| LossAfter               | -0.020693114  |
| LossBefore              | -6.537751e-06 |
| Model-TimeModelFit      | 37.5          |
| ModelSampler-n_times... | 1960000       |
| Policy-AverageAbsPol... | 0.8218769     |
| Policy-AverageDiscou... | 36.3          |
| Policy-AveragePolicyStd | 0.4668824     |
| Policy-AverageReturn    | 116           |
| Policy-MaxReturn        | 450           |
| Policy-MinReturn        | -87.7         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 102           |
| Policy-TimeAlgoOpt      | 0.556         |
| Policy-TimeSampleProc   | 0.401         |
| Policy-TimeSampling     | 1.42          |
| Policy-TimeStep         | 2.42          |
| Time                    | 1.73e+03      |
| n_timesteps             | 49000         |
-------------------------------------------

 ---------------- Iteration 49 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 490 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 491 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 492 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 493 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 494 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 495 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 496 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 497 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 498 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 499 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.312          |
| Data-EnvSampler-Poli... | 0.768          |
| Data-EnvTrajs-Averag... | 111            |
| Data-EnvTrajs-MaxReturn | 212            |
| Data-EnvTrajs-MinReturn | 30.3           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 65.9           |
| Data-TimeEnvSampleProc  | 0.000999       |
| Data-TimeEnvSampling    | 1.11           |
| Iteration               | 49             |
| ItrTime                 | 39.8           |
| LossAfter               | -0.016940711   |
| LossBefore              | -6.3022053e-06 |
| Model-TimeModelFit      | 34.7           |
| ModelSampler-n_times... | 2000000        |
| Policy-AverageAbsPol... | 0.8256193      |
| Policy-AverageDiscou... | 87.6           |
| Policy-AveragePolicyStd | 0.45570493     |
| Policy-AverageReturn    | 244            |
| Policy-MaxReturn        | 343            |
| Policy-MinReturn        | 169            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 45.4           |
| Policy-TimeAlgoOpt      | 0.836          |
| Policy-TimeSampleProc   | 0.661          |
| Policy-TimeSampling     | 2.43           |
| Policy-TimeStep         | 3.98           |
| Time                    | 1.77e+03       |
| n_timesteps             | 50000          |
--------------------------------------------

 ---------------- Iteration 50 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 500 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 501 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 502 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 503 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 504 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 505 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 506 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 507 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 508 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 509 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.527          |
| Data-EnvSampler-Poli... | 1.31           |
| Data-EnvTrajs-Averag... | 156            |
| Data-EnvTrajs-MaxReturn | 208            |
| Data-EnvTrajs-MinReturn | 82.7           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 41.3           |
| Data-TimeEnvSampleProc  | 0.00148        |
| Data-TimeEnvSampling    | 1.9            |
| Iteration               | 50             |
| ItrTime                 | 32.7           |
| LossAfter               | -0.017018804   |
| LossBefore              | -6.1197047e-06 |
| Model-TimeModelFit      | 29.2           |
| ModelSampler-n_times... | 2040000        |
| Policy-AverageAbsPol... | 0.83958155     |
| Policy-AverageDiscou... | 16.9           |
| Policy-AveragePolicyStd | 0.44812834     |
| Policy-AverageReturn    | 60.3           |
| Policy-MaxReturn        | 202            |
| Policy-MinReturn        | -72.1          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 77.3           |
| Policy-TimeAlgoOpt      | 0.435          |
| Policy-TimeSampleProc   | 0.174          |
| Policy-TimeSampling     | 0.919          |
| Policy-TimeStep         | 1.54           |
| Time                    | 1.8e+03        |
| n_timesteps             | 51000          |
--------------------------------------------
Training finished
