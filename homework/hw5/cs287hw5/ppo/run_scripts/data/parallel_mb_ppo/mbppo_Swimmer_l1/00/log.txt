Logging to /home/vincent/workplace/CS_287_-_Advanced_Robotics/homework/hw5/cs287hw5/ppo/run_scripts/data/parallel_mb_ppo/mbppo_Swimmer_l1//00

 ---------------- Iteration 0 ----------------
Obtaining random samples from the environment...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 0 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 1 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 2 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 3 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 4 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 5 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 6 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 7 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 8 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 9 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.142          |
| Data-EnvSampler-Poli... | 0.0424         |
| Data-EnvTrajs-Averag... | 1.84           |
| Data-EnvTrajs-MaxReturn | 7.52           |
| Data-EnvTrajs-MinReturn | -1.22          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 3.08           |
| Data-TimeEnvSampleProc  | 0.000528       |
| Data-TimeEnvSampling    | 0.196          |
| Iteration               | 0              |
| ItrTime                 | 9.43           |
| LossAfter               | -0.0032312898  |
| LossBefore              | -1.3910648e-05 |
| Model-TimeModelFit      | 3.14           |
| ModelSampler-n_times... | 40000          |
| Policy-AverageAbsPol... | 1.109603       |
| Policy-AverageDiscou... | 798            |
| Policy-AveragePolicyStd | 0.9714952      |
| Policy-AverageReturn    | 3.21e+03       |
| Policy-MaxReturn        | 3.62e+03       |
| Policy-MinReturn        | 2.56e+03       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 219            |
| Policy-TimeAlgoOpt      | 1.16           |
| Policy-TimeSampleProc   | 0.514          |
| Policy-TimeSampling     | 4.38           |
| Policy-TimeStep         | 6.1            |
| Time                    | 9.43           |
| n_timesteps             | 1000           |
--------------------------------------------

 ---------------- Iteration 1 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 10 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 11 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 12 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 13 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 14 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 15 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 16 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 17 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 18 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 19 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.228          |
| Data-EnvSampler-Poli... | 0.541          |
| Data-EnvTrajs-Averag... | 28.4           |
| Data-EnvTrajs-MaxReturn | 33.8           |
| Data-EnvTrajs-MinReturn | 23.3           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 3.75           |
| Data-TimeEnvSampleProc  | 0.000594       |
| Data-TimeEnvSampling    | 0.789          |
| Iteration               | 1              |
| ItrTime                 | 7.88           |
| LossAfter               | -0.0070897187  |
| LossBefore              | -1.3674205e-05 |
| Model-TimeModelFit      | 4.51           |
| ModelSampler-n_times... | 80000          |
| Policy-AverageAbsPol... | 1.4973825      |
| Policy-AverageDiscou... | 1.76e+03       |
| Policy-AveragePolicyStd | 0.9500595      |
| Policy-AverageReturn    | 4.45e+03       |
| Policy-MaxReturn        | 4.52e+03       |
| Policy-MinReturn        | 4.33e+03       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 43.6           |
| Policy-TimeAlgoOpt      | 0.567          |
| Policy-TimeSampleProc   | 0.411          |
| Policy-TimeSampling     | 1.55           |
| Policy-TimeStep         | 2.57           |
| Time                    | 17.5           |
| n_timesteps             | 2000           |
--------------------------------------------

 ---------------- Iteration 2 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 20 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 21 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 22 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 23 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 24 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 25 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 26 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 27 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 28 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 29 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.331          |
| Data-EnvSampler-Poli... | 0.576          |
| Data-EnvTrajs-Averag... | 27.3           |
| Data-EnvTrajs-MaxReturn | 31.1           |
| Data-EnvTrajs-MinReturn | 17.1           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 5.31           |
| Data-TimeEnvSampleProc  | 0.000616       |
| Data-TimeEnvSampling    | 0.938          |
| Iteration               | 2              |
| ItrTime                 | 10.3           |
| LossAfter               | -0.008021769   |
| LossBefore              | -1.3388263e-05 |
| Model-TimeModelFit      | 6.52           |
| ModelSampler-n_times... | 120000         |
| Policy-AverageAbsPol... | 0.40937275     |
| Policy-AverageDiscou... | 205            |
| Policy-AveragePolicyStd | 0.92218393     |
| Policy-AverageReturn    | 643            |
| Policy-MaxReturn        | 666            |
| Policy-MinReturn        | 629            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 9.31           |
| Policy-TimeAlgoOpt      | 0.585          |
| Policy-TimeSampleProc   | 0.425          |
| Policy-TimeSampling     | 1.74           |
| Policy-TimeStep         | 2.81           |
| Time                    | 27.8           |
| n_timesteps             | 3000           |
--------------------------------------------

 ---------------- Iteration 3 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 30 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 31 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 32 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 33 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 34 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 35 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 36 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 37 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 38 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 39 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.309         |
| Data-EnvSampler-Poli... | 0.635         |
| Data-EnvTrajs-Averag... | 27.6          |
| Data-EnvTrajs-MaxReturn | 30.3          |
| Data-EnvTrajs-MinReturn | 22.7          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 2.77          |
| Data-TimeEnvSampleProc  | 0.000759      |
| Data-TimeEnvSampling    | 0.979         |
| Iteration               | 3             |
| ItrTime                 | 13.5          |
| LossAfter               | -0.0038747585 |
| LossBefore              | -1.326893e-05 |
| Model-TimeModelFit      | 9.66          |
| ModelSampler-n_times... | 160000        |
| Policy-AverageAbsPol... | 0.91690487    |
| Policy-AverageDiscou... | -100          |
| Policy-AveragePolicyStd | 0.9114063     |
| Policy-AverageReturn    | -363          |
| Policy-MaxReturn        | -18.7         |
| Policy-MinReturn        | -1.5e+03      |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 494           |
| Policy-TimeAlgoOpt      | 0.6           |
| Policy-TimeSampleProc   | 0.374         |
| Policy-TimeSampling     | 1.79          |
| Policy-TimeStep         | 2.8           |
| Time                    | 41.3          |
| n_timesteps             | 4000          |
-------------------------------------------

 ---------------- Iteration 4 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 40 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 41 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 42 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 43 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 44 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 45 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 46 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 47 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 48 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 49 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.308          |
| Data-EnvSampler-Poli... | 0.596          |
| Data-EnvTrajs-Averag... | 16.6           |
| Data-EnvTrajs-MaxReturn | 24.1           |
| Data-EnvTrajs-MinReturn | 9.5            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 6.12           |
| Data-TimeEnvSampleProc  | 0.000599       |
| Data-TimeEnvSampling    | 0.932          |
| Iteration               | 4              |
| ItrTime                 | 15.5           |
| LossAfter               | -0.0022020235  |
| LossBefore              | -1.3118997e-05 |
| Model-TimeModelFit      | 11.3           |
| ModelSampler-n_times... | 200000         |
| Policy-AverageAbsPol... | 1.173656       |
| Policy-AverageDiscou... | -19.7          |
| Policy-AveragePolicyStd | 0.89823866     |
| Policy-AverageReturn    | -102           |
| Policy-MaxReturn        | 51.7           |
| Policy-MinReturn        | -367           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 143            |
| Policy-TimeAlgoOpt      | 0.587          |
| Policy-TimeSampleProc   | 0.611          |
| Policy-TimeSampling     | 1.96           |
| Policy-TimeStep         | 3.22           |
| Time                    | 56.8           |
| n_timesteps             | 5000           |
--------------------------------------------

 ---------------- Iteration 5 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 50 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 51 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 52 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 53 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 54 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 55 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 56 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 57 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 58 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 59 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.348         |
| Data-EnvSampler-Poli... | 0.643         |
| Data-EnvTrajs-Averag... | 25.6          |
| Data-EnvTrajs-MaxReturn | 30.6          |
| Data-EnvTrajs-MinReturn | 19.2          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 3.64          |
| Data-TimeEnvSampleProc  | 0.000605      |
| Data-TimeEnvSampling    | 1.02          |
| Iteration               | 5             |
| ItrTime                 | 16.6          |
| LossAfter               | -0.006232399  |
| LossBefore              | -1.316359e-05 |
| Model-TimeModelFit      | 12.8          |
| ModelSampler-n_times... | 240000        |
| Policy-AverageAbsPol... | 1.3265078     |
| Policy-AverageDiscou... | 23.2          |
| Policy-AveragePolicyStd | 0.9026252     |
| Policy-AverageReturn    | 55.2          |
| Policy-MaxReturn        | 117           |
| Policy-MinReturn        | 21            |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 21.6          |
| Policy-TimeAlgoOpt      | 0.58          |
| Policy-TimeSampleProc   | 0.521         |
| Policy-TimeSampling     | 1.61          |
| Policy-TimeStep         | 2.78          |
| Time                    | 73.4          |
| n_timesteps             | 6000          |
-------------------------------------------

 ---------------- Iteration 6 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 60 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 61 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 62 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 63 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 64 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 65 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 66 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 67 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 68 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 69 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.311          |
| Data-EnvSampler-Poli... | 0.608          |
| Data-EnvTrajs-Averag... | 31.2           |
| Data-EnvTrajs-MaxReturn | 35.7           |
| Data-EnvTrajs-MinReturn | 25.2           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 4.29           |
| Data-TimeEnvSampleProc  | 0.000871       |
| Data-TimeEnvSampling    | 0.946          |
| Iteration               | 6              |
| ItrTime                 | 19.6           |
| LossAfter               | -0.0041010054  |
| LossBefore              | -1.2974992e-05 |
| Model-TimeModelFit      | 15.9           |
| ModelSampler-n_times... | 280000         |
| Policy-AverageAbsPol... | 1.3916236      |
| Policy-AverageDiscou... | 72.9           |
| Policy-AveragePolicyStd | 0.8867617      |
| Policy-AverageReturn    | 181            |
| Policy-MaxReturn        | 220            |
| Policy-MinReturn        | 140            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 18.3           |
| Policy-TimeAlgoOpt      | 0.588          |
| Policy-TimeSampleProc   | 0.429          |
| Policy-TimeSampling     | 1.66           |
| Policy-TimeStep         | 2.73           |
| Time                    | 93             |
| n_timesteps             | 7000           |
--------------------------------------------

 ---------------- Iteration 7 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 70 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 71 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 72 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 73 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 74 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 75 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 76 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 77 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 78 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 79 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.332         |
| Data-EnvSampler-Poli... | 0.704         |
| Data-EnvTrajs-Averag... | 35.9          |
| Data-EnvTrajs-MaxReturn | 50.2          |
| Data-EnvTrajs-MinReturn | 26.6          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 8.63          |
| Data-TimeEnvSampleProc  | 0.000829      |
| Data-TimeEnvSampling    | 1.07          |
| Iteration               | 7             |
| ItrTime                 | 22            |
| LossAfter               | -0.0041264775 |
| LossBefore              | -1.304705e-05 |
| Model-TimeModelFit      | 18.2          |
| ModelSampler-n_times... | 320000        |
| Policy-AverageAbsPol... | 1.1954795     |
| Policy-AverageDiscou... | 88.5          |
| Policy-AveragePolicyStd | 0.8921349     |
| Policy-AverageReturn    | 204           |
| Policy-MaxReturn        | 329           |
| Policy-MinReturn        | 11            |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 85.7          |
| Policy-TimeAlgoOpt      | 0.626         |
| Policy-TimeSampleProc   | 0.357         |
| Policy-TimeSampling     | 1.68          |
| Policy-TimeStep         | 2.7           |
| Time                    | 115           |
| n_timesteps             | 8000          |
-------------------------------------------

 ---------------- Iteration 8 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 80 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 81 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 82 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 83 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 84 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 85 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 86 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 87 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 88 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 89 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.398          |
| Data-EnvSampler-Poli... | 0.788          |
| Data-EnvTrajs-Averag... | 33.4           |
| Data-EnvTrajs-MaxReturn | 43.6           |
| Data-EnvTrajs-MinReturn | 26.6           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 6.71           |
| Data-TimeEnvSampleProc  | 0.000896       |
| Data-TimeEnvSampling    | 1.22           |
| Iteration               | 8              |
| ItrTime                 | 23.7           |
| LossAfter               | -0.005520581   |
| LossBefore              | -1.2848052e-05 |
| Model-TimeModelFit      | 19.9           |
| ModelSampler-n_times... | 360000         |
| Policy-AverageAbsPol... | 1.309834       |
| Policy-AverageDiscou... | 196            |
| Policy-AveragePolicyStd | 0.8752933      |
| Policy-AverageReturn    | 582            |
| Policy-MaxReturn        | 627            |
| Policy-MinReturn        | 521            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 29             |
| Policy-TimeAlgoOpt      | 0.599          |
| Policy-TimeSampleProc   | 0.371          |
| Policy-TimeSampling     | 1.59           |
| Policy-TimeStep         | 2.59           |
| Time                    | 139            |
| n_timesteps             | 9000           |
--------------------------------------------

 ---------------- Iteration 9 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 90 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 91 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 92 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 93 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 94 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 95 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 96 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 97 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 98 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 99 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.466          |
| Data-EnvSampler-Poli... | 0.883          |
| Data-EnvTrajs-Averag... | 29.1           |
| Data-EnvTrajs-MaxReturn | 34.1           |
| Data-EnvTrajs-MinReturn | 20.7           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 4.7            |
| Data-TimeEnvSampleProc  | 0.00136        |
| Data-TimeEnvSampling    | 1.39           |
| Iteration               | 9              |
| ItrTime                 | 25.8           |
| LossAfter               | -0.004922338   |
| LossBefore              | -1.2747468e-05 |
| Model-TimeModelFit      | 21.8           |
| ModelSampler-n_times... | 400000         |
| Policy-AverageAbsPol... | 1.954633       |
| Policy-AverageDiscou... | 104            |
| Policy-AveragePolicyStd | 0.865028       |
| Policy-AverageReturn    | 265            |
| Policy-MaxReturn        | 297            |
| Policy-MinReturn        | 240            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 13.7           |
| Policy-TimeAlgoOpt      | 0.597          |
| Policy-TimeSampleProc   | 0.408          |
| Policy-TimeSampling     | 1.61           |
| Policy-TimeStep         | 2.66           |
| Time                    | 165            |
| n_timesteps             | 10000          |
--------------------------------------------

 ---------------- Iteration 10 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 100 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 101 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 102 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 103 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 104 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 105 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 106 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 107 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 108 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 109 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.383          |
| Data-EnvSampler-Poli... | 0.878          |
| Data-EnvTrajs-Averag... | 47.2           |
| Data-EnvTrajs-MaxReturn | 58.1           |
| Data-EnvTrajs-MinReturn | 21.4           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 13.4           |
| Data-TimeEnvSampleProc  | 0.00141        |
| Data-TimeEnvSampling    | 1.32           |
| Iteration               | 10             |
| ItrTime                 | 28             |
| LossAfter               | -0.0027185683  |
| LossBefore              | -1.2439003e-05 |
| Model-TimeModelFit      | 24.2           |
| ModelSampler-n_times... | 440000         |
| Policy-AverageAbsPol... | 1.7655313      |
| Policy-AverageDiscou... | 28.4           |
| Policy-AveragePolicyStd | 0.84119946     |
| Policy-AverageReturn    | 60.5           |
| Policy-MaxReturn        | 75.4           |
| Policy-MinReturn        | 44.3           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 9.61           |
| Policy-TimeAlgoOpt      | 0.629          |
| Policy-TimeSampleProc   | 0.34           |
| Policy-TimeSampling     | 1.51           |
| Policy-TimeStep         | 2.53           |
| Time                    | 193            |
| n_timesteps             | 11000          |
--------------------------------------------

 ---------------- Iteration 11 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 110 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 111 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 112 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 113 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 114 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 115 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 116 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 117 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 118 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 119 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.4            |
| Data-EnvSampler-Poli... | 0.88           |
| Data-EnvTrajs-Averag... | 40.5           |
| Data-EnvTrajs-MaxReturn | 52.8           |
| Data-EnvTrajs-MinReturn | 29.8           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 8.61           |
| Data-TimeEnvSampleProc  | 0.00105        |
| Data-TimeEnvSampling    | 1.33           |
| Iteration               | 11             |
| ItrTime                 | 30.8           |
| LossAfter               | -0.0026800453  |
| LossBefore              | -1.2161789e-05 |
| Model-TimeModelFit      | 26.8           |
| ModelSampler-n_times... | 480000         |
| Policy-AverageAbsPol... | 1.7989637      |
| Policy-AverageDiscou... | 51             |
| Policy-AveragePolicyStd | 0.8160731      |
| Policy-AverageReturn    | 110            |
| Policy-MaxReturn        | 125            |
| Policy-MinReturn        | 89.3           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 10.3           |
| Policy-TimeAlgoOpt      | 0.604          |
| Policy-TimeSampleProc   | 0.317          |
| Policy-TimeSampling     | 1.74           |
| Policy-TimeStep         | 2.7            |
| Time                    | 223            |
| n_timesteps             | 12000          |
--------------------------------------------

 ---------------- Iteration 12 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 120 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 121 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 122 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 123 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 124 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 125 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 126 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 127 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 128 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 129 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.392          |
| Data-EnvSampler-Poli... | 0.881          |
| Data-EnvTrajs-Averag... | 28.2           |
| Data-EnvTrajs-MaxReturn | 36.6           |
| Data-EnvTrajs-MinReturn | 18.4           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 5.92           |
| Data-TimeEnvSampleProc  | 0.0013         |
| Data-TimeEnvSampling    | 1.31           |
| Iteration               | 12             |
| ItrTime                 | 31.6           |
| LossAfter               | -0.003944338   |
| LossBefore              | -1.1958912e-05 |
| Model-TimeModelFit      | 27.7           |
| ModelSampler-n_times... | 520000         |
| Policy-AverageAbsPol... | 2.1316006      |
| Policy-AverageDiscou... | 54.1           |
| Policy-AveragePolicyStd | 0.80196095     |
| Policy-AverageReturn    | 130            |
| Policy-MaxReturn        | 199            |
| Policy-MinReturn        | 87.3           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 31.5           |
| Policy-TimeAlgoOpt      | 0.583          |
| Policy-TimeSampleProc   | 0.37           |
| Policy-TimeSampling     | 1.67           |
| Policy-TimeStep         | 2.67           |
| Time                    | 255            |
| n_timesteps             | 13000          |
--------------------------------------------

 ---------------- Iteration 13 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 130 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 131 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 132 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 133 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 134 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 135 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 136 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 137 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 138 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 139 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.435          |
| Data-EnvSampler-Poli... | 0.966          |
| Data-EnvTrajs-Averag... | 26.3           |
| Data-EnvTrajs-MaxReturn | 27.8           |
| Data-EnvTrajs-MinReturn | 24.8           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.21           |
| Data-TimeEnvSampleProc  | 0.00112        |
| Data-TimeEnvSampling    | 1.44           |
| Iteration               | 13             |
| ItrTime                 | 32.6           |
| LossAfter               | -0.0028447416  |
| LossBefore              | -1.1870159e-05 |
| Model-TimeModelFit      | 28.6           |
| ModelSampler-n_times... | 560000         |
| Policy-AverageAbsPol... | 2.18828        |
| Policy-AverageDiscou... | 24.1           |
| Policy-AveragePolicyStd | 0.79203045     |
| Policy-AverageReturn    | 48.8           |
| Policy-MaxReturn        | 77.1           |
| Policy-MinReturn        | 19.8           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 14.9           |
| Policy-TimeAlgoOpt      | 0.556          |
| Policy-TimeSampleProc   | 0.411          |
| Policy-TimeSampling     | 1.54           |
| Policy-TimeStep         | 2.54           |
| Time                    | 288            |
| n_timesteps             | 14000          |
--------------------------------------------

 ---------------- Iteration 14 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 140 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 141 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 142 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 143 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 144 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 145 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 146 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 147 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 148 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 149 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.383          |
| Data-EnvSampler-Poli... | 0.878          |
| Data-EnvTrajs-Averag... | 27.4           |
| Data-EnvTrajs-MaxReturn | 30.3           |
| Data-EnvTrajs-MinReturn | 23.9           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.22           |
| Data-TimeEnvSampleProc  | 0.000918       |
| Data-TimeEnvSampling    | 1.29           |
| Iteration               | 14             |
| ItrTime                 | 33.7           |
| LossAfter               | -0.0032781614  |
| LossBefore              | -1.1635179e-05 |
| Model-TimeModelFit      | 29.8           |
| ModelSampler-n_times... | 600000         |
| Policy-AverageAbsPol... | 2.1283274      |
| Policy-AverageDiscou... | 35.7           |
| Policy-AveragePolicyStd | 0.7748803      |
| Policy-AverageReturn    | 72.3           |
| Policy-MaxReturn        | 97.2           |
| Policy-MinReturn        | 44.5           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 13.5           |
| Policy-TimeAlgoOpt      | 0.585          |
| Policy-TimeSampleProc   | 0.362          |
| Policy-TimeSampling     | 1.65           |
| Policy-TimeStep         | 2.63           |
| Time                    | 321            |
| n_timesteps             | 15000          |
--------------------------------------------

 ---------------- Iteration 15 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 150 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 151 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 152 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 153 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 154 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 155 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 156 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 157 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 158 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 159 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.427          |
| Data-EnvSampler-Poli... | 0.919          |
| Data-EnvTrajs-Averag... | 27.5           |
| Data-EnvTrajs-MaxReturn | 29.8           |
| Data-EnvTrajs-MinReturn | 21.8           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.87           |
| Data-TimeEnvSampleProc  | 0.00101        |
| Data-TimeEnvSampling    | 1.38           |
| Iteration               | 15             |
| ItrTime                 | 32.8           |
| LossAfter               | -0.0036421386  |
| LossBefore              | -1.1337265e-05 |
| Model-TimeModelFit      | 28.9           |
| ModelSampler-n_times... | 640000         |
| Policy-AverageAbsPol... | 1.9689692      |
| Policy-AverageDiscou... | 5              |
| Policy-AveragePolicyStd | 0.75241745     |
| Policy-AverageReturn    | -11.4          |
| Policy-MaxReturn        | 12.6           |
| Policy-MinReturn        | -43.7          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 18.1           |
| Policy-TimeAlgoOpt      | 0.656          |
| Policy-TimeSampleProc   | 0.373          |
| Policy-TimeSampling     | 1.49           |
| Policy-TimeStep         | 2.54           |
| Time                    | 354            |
| n_timesteps             | 16000          |
--------------------------------------------

 ---------------- Iteration 16 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 160 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 161 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 162 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 163 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 164 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 165 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 166 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 167 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 168 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 169 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.408           |
| Data-EnvSampler-Poli... | 0.967           |
| Data-EnvTrajs-Averag... | 26.8            |
| Data-EnvTrajs-MaxReturn | 30.9            |
| Data-EnvTrajs-MinReturn | 20.9            |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 3.26            |
| Data-TimeEnvSampleProc  | 0.00102         |
| Data-TimeEnvSampling    | 1.41            |
| Iteration               | 16              |
| ItrTime                 | 32.8            |
| LossAfter               | -0.006573936    |
| LossBefore              | -1.10157725e-05 |
| Model-TimeModelFit      | 28.7            |
| ModelSampler-n_times... | 680000          |
| Policy-AverageAbsPol... | 1.9785998       |
| Policy-AverageDiscou... | 30.6            |
| Policy-AveragePolicyStd | 0.73008         |
| Policy-AverageReturn    | 51.6            |
| Policy-MaxReturn        | 72.8            |
| Policy-MinReturn        | 37.1            |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 9.97            |
| Policy-TimeAlgoOpt      | 0.576           |
| Policy-TimeSampleProc   | 0.448           |
| Policy-TimeSampling     | 1.69            |
| Policy-TimeStep         | 2.74            |
| Time                    | 387             |
| n_timesteps             | 17000           |
---------------------------------------------

 ---------------- Iteration 17 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 170 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 171 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 172 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 173 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 174 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 175 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 176 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 177 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 178 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 179 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.385          |
| Data-EnvSampler-Poli... | 0.836          |
| Data-EnvTrajs-Averag... | 30.5           |
| Data-EnvTrajs-MaxReturn | 32             |
| Data-EnvTrajs-MinReturn | 27.9           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.5            |
| Data-TimeEnvSampleProc  | 0.00106        |
| Data-TimeEnvSampling    | 1.26           |
| Iteration               | 17             |
| ItrTime                 | 32.9           |
| LossAfter               | -0.0032721178  |
| LossBefore              | -1.0852129e-05 |
| Model-TimeModelFit      | 28.8           |
| ModelSampler-n_times... | 720000         |
| Policy-AverageAbsPol... | 2.3313565      |
| Policy-AverageDiscou... | 28.4           |
| Policy-AveragePolicyStd | 0.717873       |
| Policy-AverageReturn    | 56.9           |
| Policy-MaxReturn        | 113            |
| Policy-MinReturn        | -1.37          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 28.4           |
| Policy-TimeAlgoOpt      | 0.66           |
| Policy-TimeSampleProc   | 0.374          |
| Policy-TimeSampling     | 1.76           |
| Policy-TimeStep         | 2.83           |
| Time                    | 420            |
| n_timesteps             | 18000          |
--------------------------------------------

 ---------------- Iteration 18 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 180 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 181 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 182 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 183 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 184 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 185 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 186 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 187 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 188 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 189 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.42           |
| Data-EnvSampler-Poli... | 0.926          |
| Data-EnvTrajs-Averag... | 29.2           |
| Data-EnvTrajs-MaxReturn | 30.8           |
| Data-EnvTrajs-MinReturn | 26.1           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.66           |
| Data-TimeEnvSampleProc  | 0.0011         |
| Data-TimeEnvSampling    | 1.38           |
| Iteration               | 18             |
| ItrTime                 | 34.2           |
| LossAfter               | -0.002822315   |
| LossBefore              | -1.0798713e-05 |
| Model-TimeModelFit      | 30.2           |
| ModelSampler-n_times... | 760000         |
| Policy-AverageAbsPol... | 2.2570553      |
| Policy-AverageDiscou... | 26.2           |
| Policy-AveragePolicyStd | 0.7135925      |
| Policy-AverageReturn    | 37.9           |
| Policy-MaxReturn        | 54             |
| Policy-MinReturn        | 21.5           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 8.1            |
| Policy-TimeAlgoOpt      | 0.556          |
| Policy-TimeSampleProc   | 0.371          |
| Policy-TimeSampling     | 1.63           |
| Policy-TimeStep         | 2.58           |
| Time                    | 454            |
| n_timesteps             | 19000          |
--------------------------------------------

 ---------------- Iteration 19 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 190 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 191 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 192 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 193 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 194 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 195 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 196 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 197 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 198 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 199 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.392          |
| Data-EnvSampler-Poli... | 0.886          |
| Data-EnvTrajs-Averag... | 30.5           |
| Data-EnvTrajs-MaxReturn | 32.2           |
| Data-EnvTrajs-MinReturn | 28.8           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.07           |
| Data-TimeEnvSampleProc  | 0.00106        |
| Data-TimeEnvSampling    | 1.32           |
| Iteration               | 19             |
| ItrTime                 | 34             |
| LossAfter               | -0.003220722   |
| LossBefore              | -1.0651679e-05 |
| Model-TimeModelFit      | 30             |
| ModelSampler-n_times... | 800000         |
| Policy-AverageAbsPol... | 1.9790053      |
| Policy-AverageDiscou... | 29.1           |
| Policy-AveragePolicyStd | 0.7034906      |
| Policy-AverageReturn    | 45.9           |
| Policy-MaxReturn        | 58.9           |
| Policy-MinReturn        | 37.3           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 5.36           |
| Policy-TimeAlgoOpt      | 0.6            |
| Policy-TimeSampleProc   | 0.51           |
| Policy-TimeSampling     | 1.58           |
| Policy-TimeStep         | 2.73           |
| Time                    | 488            |
| n_timesteps             | 20000          |
--------------------------------------------

 ---------------- Iteration 20 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 200 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 201 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 202 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 203 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 204 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 205 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 206 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 207 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 208 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 209 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.409          |
| Data-EnvSampler-Poli... | 0.942          |
| Data-EnvTrajs-Averag... | 31             |
| Data-EnvTrajs-MaxReturn | 34.6           |
| Data-EnvTrajs-MinReturn | 27.8           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.94           |
| Data-TimeEnvSampleProc  | 0.00107        |
| Data-TimeEnvSampling    | 1.39           |
| Iteration               | 20             |
| ItrTime                 | 33.5           |
| LossAfter               | -0.001550309   |
| LossBefore              | -1.0561874e-05 |
| Model-TimeModelFit      | 29.3           |
| ModelSampler-n_times... | 840000         |
| Policy-AverageAbsPol... | 1.7191758      |
| Policy-AverageDiscou... | 19.5           |
| Policy-AveragePolicyStd | 0.69653916     |
| Policy-AverageReturn    | 17.4           |
| Policy-MaxReturn        | 30.5           |
| Policy-MinReturn        | 8.12           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 6.72           |
| Policy-TimeAlgoOpt      | 0.633          |
| Policy-TimeSampleProc   | 0.458          |
| Policy-TimeSampling     | 1.65           |
| Policy-TimeStep         | 2.8            |
| Time                    | 522            |
| n_timesteps             | 21000          |
--------------------------------------------

 ---------------- Iteration 21 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...
Stopping DynamicsEnsemble Training since valid_loss_rolling_average decreased

 ---------------- Grad-Step 210 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 211 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 212 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 213 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 214 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 215 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 216 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 217 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 218 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 219 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.415          |
| Data-EnvSampler-Poli... | 1              |
| Data-EnvTrajs-Averag... | 31.1           |
| Data-EnvTrajs-MaxReturn | 34.8           |
| Data-EnvTrajs-MinReturn | 27.4           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 3.24           |
| Data-TimeEnvSampleProc  | 0.000607       |
| Data-TimeEnvSampling    | 1.46           |
| Iteration               | 21             |
| ItrTime                 | 30.5           |
| LossAfter               | -0.002787239   |
| LossBefore              | -1.0393122e-05 |
| Model-TimeModelFit      | 26             |
| ModelSampler-n_times... | 880000         |
| Policy-AverageAbsPol... | 1.9241804      |
| Policy-AverageDiscou... | 25.7           |
| Policy-AveragePolicyStd | 0.6857909      |
| Policy-AverageReturn    | 37             |
| Policy-MaxReturn        | 47.1           |
| Policy-MinReturn        | 26.5           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 5.77           |
| Policy-TimeAlgoOpt      | 0.646          |
| Policy-TimeSampleProc   | 0.514          |
| Policy-TimeSampling     | 1.81           |
| Policy-TimeStep         | 3.01           |
| Time                    | 552            |
| n_timesteps             | 22000          |
--------------------------------------------

 ---------------- Iteration 22 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 220 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 221 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 222 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 223 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 224 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 225 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 226 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 227 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 228 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 229 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.449           |
| Data-EnvSampler-Poli... | 1.09            |
| Data-EnvTrajs-Averag... | 31              |
| Data-EnvTrajs-MaxReturn | 32.6            |
| Data-EnvTrajs-MinReturn | 29.2            |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 1.09            |
| Data-TimeEnvSampleProc  | 0.00101         |
| Data-TimeEnvSampling    | 1.59            |
| Iteration               | 22              |
| ItrTime                 | 39.4            |
| LossAfter               | -0.0022580572   |
| LossBefore              | -1.04378905e-05 |
| Model-TimeModelFit      | 31.5            |
| ModelSampler-n_times... | 920000          |
| Policy-AverageAbsPol... | 2.0295174       |
| Policy-AverageDiscou... | 33              |
| Policy-AveragePolicyStd | 0.68716735      |
| Policy-AverageReturn    | 42.6            |
| Policy-MaxReturn        | 60.5            |
| Policy-MinReturn        | 22.3            |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 11              |
| Policy-TimeAlgoOpt      | 1.26            |
| Policy-TimeSampleProc   | 1.11            |
| Policy-TimeSampling     | 3.83            |
| Policy-TimeStep         | 6.31            |
| Time                    | 592             |
| n_timesteps             | 23000           |
---------------------------------------------

 ---------------- Iteration 23 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 230 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 231 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 232 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 233 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 234 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 235 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 236 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 237 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 238 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 239 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.641         |
| Data-EnvSampler-Poli... | 1.77          |
| Data-EnvTrajs-Averag... | 32.2          |
| Data-EnvTrajs-MaxReturn | 34.9          |
| Data-EnvTrajs-MinReturn | 29.2          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 2             |
| Data-TimeEnvSampleProc  | 0.0011        |
| Data-TimeEnvSampling    | 2.49          |
| Iteration               | 23            |
| ItrTime                 | 49.5          |
| LossAfter               | -0.003140802  |
| LossBefore              | -1.008487e-05 |
| Model-TimeModelFit      | 43.9          |
| ModelSampler-n_times... | 960000        |
| Policy-AverageAbsPol... | 1.7935523     |
| Policy-AverageDiscou... | 25.8          |
| Policy-AveragePolicyStd | 0.6661492     |
| Policy-AverageReturn    | 30.8          |
| Policy-MaxReturn        | 41.4          |
| Policy-MinReturn        | 13.9          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 7.57          |
| Policy-TimeAlgoOpt      | 0.71          |
| Policy-TimeSampleProc   | 0.447         |
| Policy-TimeSampling     | 1.83          |
| Policy-TimeStep         | 3.02          |
| Time                    | 641           |
| n_timesteps             | 24000         |
-------------------------------------------

 ---------------- Iteration 24 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 240 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 241 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 242 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 243 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 244 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 245 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 246 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 247 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 248 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 249 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.449          |
| Data-EnvSampler-Poli... | 1.01           |
| Data-EnvTrajs-Averag... | 32             |
| Data-EnvTrajs-MaxReturn | 34.6           |
| Data-EnvTrajs-MinReturn | 29.1           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.08           |
| Data-TimeEnvSampleProc  | 0.00104        |
| Data-TimeEnvSampling    | 1.5            |
| Iteration               | 24             |
| ItrTime                 | 37             |
| LossAfter               | -0.0037516588  |
| LossBefore              | -1.0133804e-05 |
| Model-TimeModelFit      | 32.6           |
| ModelSampler-n_times... | 1000000        |
| Policy-AverageAbsPol... | 1.8774898      |
| Policy-AverageDiscou... | 30.2           |
| Policy-AveragePolicyStd | 0.6688595      |
| Policy-AverageReturn    | 43.4           |
| Policy-MaxReturn        | 58.4           |
| Policy-MinReturn        | 34.7           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 6.2            |
| Policy-TimeAlgoOpt      | 0.645          |
| Policy-TimeSampleProc   | 0.441          |
| Policy-TimeSampling     | 1.7            |
| Policy-TimeStep         | 2.82           |
| Time                    | 678            |
| n_timesteps             | 25000          |
--------------------------------------------

 ---------------- Iteration 25 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 250 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 251 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 252 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 253 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 254 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 255 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 256 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 257 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 258 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 259 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.443          |
| Data-EnvSampler-Poli... | 0.986          |
| Data-EnvTrajs-Averag... | 33.3           |
| Data-EnvTrajs-MaxReturn | 35.2           |
| Data-EnvTrajs-MinReturn | 30.6           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.85           |
| Data-TimeEnvSampleProc  | 0.0011         |
| Data-TimeEnvSampling    | 1.47           |
| Iteration               | 25             |
| ItrTime                 | 35.6           |
| LossAfter               | -0.006528966   |
| LossBefore              | -1.0148182e-05 |
| Model-TimeModelFit      | 31.6           |
| ModelSampler-n_times... | 1040000        |
| Policy-AverageAbsPol... | 1.6686039      |
| Policy-AverageDiscou... | 27             |
| Policy-AveragePolicyStd | 0.6693367      |
| Policy-AverageReturn    | -22.4          |
| Policy-MaxReturn        | 150            |
| Policy-MinReturn        | -1.21e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 288            |
| Policy-TimeAlgoOpt      | 0.6            |
| Policy-TimeSampleProc   | 0.34           |
| Policy-TimeSampling     | 1.55           |
| Policy-TimeStep         | 2.53           |
| Time                    | 714            |
| n_timesteps             | 26000          |
--------------------------------------------

 ---------------- Iteration 26 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 260 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 261 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 262 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 263 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 264 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 265 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 266 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 267 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 268 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 269 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.379         |
| Data-EnvSampler-Poli... | 0.872         |
| Data-EnvTrajs-Averag... | 32.3          |
| Data-EnvTrajs-MaxReturn | 35.6          |
| Data-EnvTrajs-MinReturn | 29.1          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 2.42          |
| Data-TimeEnvSampleProc  | 0.00104       |
| Data-TimeEnvSampling    | 1.29          |
| Iteration               | 26            |
| ItrTime                 | 33.8          |
| LossAfter               | -0.0039424864 |
| LossBefore              | -9.985621e-06 |
| Model-TimeModelFit      | 29.9          |
| ModelSampler-n_times... | 1080000       |
| Policy-AverageAbsPol... | 1.1021237     |
| Policy-AverageDiscou... | 244           |
| Policy-AveragePolicyStd | 0.6596193     |
| Policy-AverageReturn    | 744           |
| Policy-MaxReturn        | 1.28e+03      |
| Policy-MinReturn        | 30.8          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 475           |
| Policy-TimeAlgoOpt      | 0.589         |
| Policy-TimeSampleProc   | 0.329         |
| Policy-TimeSampling     | 1.67          |
| Policy-TimeStep         | 2.64          |
| Time                    | 747           |
| n_timesteps             | 27000         |
-------------------------------------------

 ---------------- Iteration 27 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 270 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 271 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 272 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 273 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 274 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 275 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 276 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 277 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 278 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 279 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.389         |
| Data-EnvSampler-Poli... | 0.877         |
| Data-EnvTrajs-Averag... | 30.6          |
| Data-EnvTrajs-MaxReturn | 30.9          |
| Data-EnvTrajs-MinReturn | 30.3          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 0.254         |
| Data-TimeEnvSampleProc  | 0.00113       |
| Data-TimeEnvSampling    | 1.3           |
| Iteration               | 27            |
| ItrTime                 | 34.5          |
| LossAfter               | -0.0020460912 |
| LossBefore              | -9.827798e-06 |
| Model-TimeModelFit      | 30.6          |
| ModelSampler-n_times... | 1120000       |
| Policy-AverageAbsPol... | 1.4467102     |
| Policy-AverageDiscou... | 91.3          |
| Policy-AveragePolicyStd | 0.6470403     |
| Policy-AverageReturn    | 233           |
| Policy-MaxReturn        | 283           |
| Policy-MinReturn        | 17.1          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 72.9          |
| Policy-TimeAlgoOpt      | 0.656         |
| Policy-TimeSampleProc   | 0.371         |
| Policy-TimeSampling     | 1.58          |
| Policy-TimeStep         | 2.63          |
| Time                    | 782           |
| n_timesteps             | 28000         |
-------------------------------------------

 ---------------- Iteration 28 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 280 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 281 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 282 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 283 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 284 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 285 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 286 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 287 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 288 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 289 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.413          |
| Data-EnvSampler-Poli... | 0.908          |
| Data-EnvTrajs-Averag... | 30.3           |
| Data-EnvTrajs-MaxReturn | 32.7           |
| Data-EnvTrajs-MinReturn | 27.4           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.88           |
| Data-TimeEnvSampleProc  | 0.00108        |
| Data-TimeEnvSampling    | 1.36           |
| Iteration               | 28             |
| ItrTime                 | 34.6           |
| LossAfter               | -0.002259774   |
| LossBefore              | -9.7294105e-06 |
| Model-TimeModelFit      | 30.4           |
| ModelSampler-n_times... | 1160000        |
| Policy-AverageAbsPol... | 1.8590488      |
| Policy-AverageDiscou... | 25.4           |
| Policy-AveragePolicyStd | 0.6416694      |
| Policy-AverageReturn    | -0.0334        |
| Policy-MaxReturn        | 76.3           |
| Policy-MinReturn        | -97            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 48.2           |
| Policy-TimeAlgoOpt      | 0.591          |
| Policy-TimeSampleProc   | 0.547          |
| Policy-TimeSampling     | 1.72           |
| Policy-TimeStep         | 2.88           |
| Time                    | 817            |
| n_timesteps             | 29000          |
--------------------------------------------

 ---------------- Iteration 29 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 290 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 291 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 292 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 293 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 294 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 295 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 296 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 297 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 298 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 299 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.415         |
| Data-EnvSampler-Poli... | 1.03          |
| Data-EnvTrajs-Averag... | 31.1          |
| Data-EnvTrajs-MaxReturn | 33.4          |
| Data-EnvTrajs-MinReturn | 27.5          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 2.03          |
| Data-TimeEnvSampleProc  | 0.00105       |
| Data-TimeEnvSampling    | 1.48          |
| Iteration               | 29            |
| ItrTime                 | 34.6          |
| LossAfter               | -0.0027451743 |
| LossBefore              | -9.740684e-06 |
| Model-TimeModelFit      | 30.7          |
| ModelSampler-n_times... | 1200000       |
| Policy-AverageAbsPol... | 2.091569      |
| Policy-AverageDiscou... | 69            |
| Policy-AveragePolicyStd | 0.64268994    |
| Policy-AverageReturn    | 255           |
| Policy-MaxReturn        | 491           |
| Policy-MinReturn        | -34.5         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 176           |
| Policy-TimeAlgoOpt      | 0.605         |
| Policy-TimeSampleProc   | 0.272         |
| Policy-TimeSampling     | 1.48          |
| Policy-TimeStep         | 2.4           |
| Time                    | 851           |
| n_timesteps             | 30000         |
-------------------------------------------

 ---------------- Iteration 30 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 300 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 301 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 302 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 303 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 304 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 305 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 306 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 307 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 308 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 309 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.401          |
| Data-EnvSampler-Poli... | 0.873          |
| Data-EnvTrajs-Averag... | 29.1           |
| Data-EnvTrajs-MaxReturn | 32.6           |
| Data-EnvTrajs-MinReturn | 24.2           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 3.1            |
| Data-TimeEnvSampleProc  | 0.000676       |
| Data-TimeEnvSampling    | 1.31           |
| Iteration               | 30             |
| ItrTime                 | 34.8           |
| LossAfter               | -0.0042151297  |
| LossBefore              | -9.6664235e-06 |
| Model-TimeModelFit      | 30.8           |
| ModelSampler-n_times... | 1240000        |
| Policy-AverageAbsPol... | 1.9014832      |
| Policy-AverageDiscou... | 54             |
| Policy-AveragePolicyStd | 0.6406953      |
| Policy-AverageReturn    | 250            |
| Policy-MaxReturn        | 411            |
| Policy-MinReturn        | 57.8           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 104            |
| Policy-TimeAlgoOpt      | 0.599          |
| Policy-TimeSampleProc   | 0.341          |
| Policy-TimeSampling     | 1.62           |
| Policy-TimeStep         | 2.6            |
| Time                    | 886            |
| n_timesteps             | 31000          |
--------------------------------------------

 ---------------- Iteration 31 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 310 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 311 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 312 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 313 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 314 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 315 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 316 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 317 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 318 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 319 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.414         |
| Data-EnvSampler-Poli... | 0.975         |
| Data-EnvTrajs-Averag... | 31            |
| Data-EnvTrajs-MaxReturn | 34.3          |
| Data-EnvTrajs-MinReturn | 29.9          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.66          |
| Data-TimeEnvSampleProc  | 0.000818      |
| Data-TimeEnvSampling    | 1.43          |
| Iteration               | 31            |
| ItrTime                 | 35            |
| LossAfter               | 0.0028965625  |
| LossBefore              | -9.595835e-06 |
| Model-TimeModelFit      | 30.9          |
| ModelSampler-n_times... | 1280000       |
| Policy-AverageAbsPol... | 2.571855      |
| Policy-AverageDiscou... | 148           |
| Policy-AveragePolicyStd | 0.6339259     |
| Policy-AverageReturn    | 621           |
| Policy-MaxReturn        | 702           |
| Policy-MinReturn        | 510           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 53.7          |
| Policy-TimeAlgoOpt      | 0.648         |
| Policy-TimeSampleProc   | 0.418         |
| Policy-TimeSampling     | 1.62          |
| Policy-TimeStep         | 2.71          |
| Time                    | 921           |
| n_timesteps             | 32000         |
-------------------------------------------

 ---------------- Iteration 32 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 320 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 321 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 322 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 323 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 324 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 325 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 326 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 327 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 328 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 329 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.382          |
| Data-EnvSampler-Poli... | 0.89           |
| Data-EnvTrajs-Averag... | 33             |
| Data-EnvTrajs-MaxReturn | 36             |
| Data-EnvTrajs-MinReturn | 29.9           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.05           |
| Data-TimeEnvSampleProc  | 0.00109        |
| Data-TimeEnvSampling    | 1.31           |
| Iteration               | 32             |
| ItrTime                 | 35             |
| LossAfter               | -0.0055357413  |
| LossBefore              | -9.3216995e-06 |
| Model-TimeModelFit      | 31.2           |
| ModelSampler-n_times... | 1320000        |
| Policy-AverageAbsPol... | 2.3038988      |
| Policy-AverageDiscou... | 393            |
| Policy-AveragePolicyStd | 0.61617315     |
| Policy-AverageReturn    | 1.12e+03       |
| Policy-MaxReturn        | 1.16e+03       |
| Policy-MinReturn        | 1.02e+03       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 34.5           |
| Policy-TimeAlgoOpt      | 0.561          |
| Policy-TimeSampleProc   | 0.319          |
| Policy-TimeSampling     | 1.58           |
| Policy-TimeStep         | 2.49           |
| Time                    | 956            |
| n_timesteps             | 33000          |
--------------------------------------------

 ---------------- Iteration 33 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 330 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 331 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 332 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 333 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 334 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 335 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 336 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 337 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 338 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 339 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.407         |
| Data-EnvSampler-Poli... | 1             |
| Data-EnvTrajs-Averag... | 30.7          |
| Data-EnvTrajs-MaxReturn | 31.3          |
| Data-EnvTrajs-MinReturn | 29.8          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 0.552         |
| Data-TimeEnvSampleProc  | 0.00107       |
| Data-TimeEnvSampling    | 1.45          |
| Iteration               | 33            |
| ItrTime                 | 35.1          |
| LossAfter               | -0.0059220544 |
| LossBefore              | -9.220137e-06 |
| Model-TimeModelFit      | 31.2          |
| ModelSampler-n_times... | 1360000       |
| Policy-AverageAbsPol... | 2.0067866     |
| Policy-AverageDiscou... | 1.45e+03      |
| Policy-AveragePolicyStd | 0.6097206     |
| Policy-AverageReturn    | 6.51e+03      |
| Policy-MaxReturn        | 7.51e+03      |
| Policy-MinReturn        | 3.03e+03      |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.15e+03      |
| Policy-TimeAlgoOpt      | 0.625         |
| Policy-TimeSampleProc   | 0.244         |
| Policy-TimeSampling     | 1.53          |
| Policy-TimeStep         | 2.42          |
| Time                    | 991           |
| n_timesteps             | 34000         |
-------------------------------------------

 ---------------- Iteration 34 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 340 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 341 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 342 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 343 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 344 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 345 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 346 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 347 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 348 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 349 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.383         |
| Data-EnvSampler-Poli... | 0.872         |
| Data-EnvTrajs-Averag... | 30.9          |
| Data-EnvTrajs-MaxReturn | 34.1          |
| Data-EnvTrajs-MinReturn | 29.6          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.66          |
| Data-TimeEnvSampleProc  | 0.00115       |
| Data-TimeEnvSampling    | 1.29          |
| Iteration               | 34            |
| ItrTime                 | 35.7          |
| LossAfter               | -0.001741102  |
| LossBefore              | -9.009906e-06 |
| Model-TimeModelFit      | 31.5          |
| ModelSampler-n_times... | 1400000       |
| Policy-AverageAbsPol... | 1.7374732     |
| Policy-AverageDiscou... | 1.92e+03      |
| Policy-AveragePolicyStd | 0.59709495    |
| Policy-AverageReturn    | 7.48e+03      |
| Policy-MaxReturn        | 9.19e+03      |
| Policy-MinReturn        | 3.31e+03      |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.88e+03      |
| Policy-TimeAlgoOpt      | 0.647         |
| Policy-TimeSampleProc   | 0.363         |
| Policy-TimeSampling     | 1.8           |
| Policy-TimeStep         | 2.87          |
| Time                    | 1.03e+03      |
| n_timesteps             | 35000         |
-------------------------------------------

 ---------------- Iteration 35 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 350 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 351 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 352 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 353 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 354 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 355 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 356 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 357 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 358 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 359 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.427          |
| Data-EnvSampler-Poli... | 1.03           |
| Data-EnvTrajs-Averag... | 30.6           |
| Data-EnvTrajs-MaxReturn | 33.1           |
| Data-EnvTrajs-MinReturn | 27.8           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.04           |
| Data-TimeEnvSampleProc  | 0.00104        |
| Data-TimeEnvSampling    | 1.5            |
| Iteration               | 35             |
| ItrTime                 | 35.7           |
| LossAfter               | -0.002768363   |
| LossBefore              | -8.8511415e-06 |
| Model-TimeModelFit      | 31.5           |
| ModelSampler-n_times... | 1440000        |
| Policy-AverageAbsPol... | 2.045959       |
| Policy-AverageDiscou... | 341            |
| Policy-AveragePolicyStd | 0.5893834      |
| Policy-AverageReturn    | 1.56e+03       |
| Policy-MaxReturn        | 6.95e+03       |
| Policy-MinReturn        | 79.4           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.44e+03       |
| Policy-TimeAlgoOpt      | 0.594          |
| Policy-TimeSampleProc   | 0.437          |
| Policy-TimeSampling     | 1.63           |
| Policy-TimeStep         | 2.68           |
| Time                    | 1.06e+03       |
| n_timesteps             | 36000          |
--------------------------------------------

 ---------------- Iteration 36 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 360 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 361 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 362 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 363 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 364 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 365 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 366 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 367 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 368 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 369 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.427         |
| Data-EnvSampler-Poli... | 0.928         |
| Data-EnvTrajs-Averag... | 32.7          |
| Data-EnvTrajs-MaxReturn | 35.5          |
| Data-EnvTrajs-MinReturn | 30.2          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.93          |
| Data-TimeEnvSampleProc  | 0.00113       |
| Data-TimeEnvSampling    | 1.39          |
| Iteration               | 36            |
| ItrTime                 | 35.6          |
| LossAfter               | -0.0033723349 |
| LossBefore              | -8.696555e-06 |
| Model-TimeModelFit      | 31.5          |
| ModelSampler-n_times... | 1480000       |
| Policy-AverageAbsPol... | 2.000373      |
| Policy-AverageDiscou... | 1.67e+03      |
| Policy-AveragePolicyStd | 0.5791434     |
| Policy-AverageReturn    | 6.94e+03      |
| Policy-MaxReturn        | 1.15e+04      |
| Policy-MinReturn        | -17.6         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 4.04e+03      |
| Policy-TimeAlgoOpt      | 0.575         |
| Policy-TimeSampleProc   | 0.414         |
| Policy-TimeSampling     | 1.6           |
| Policy-TimeStep         | 2.62          |
| Time                    | 1.1e+03       |
| n_timesteps             | 37000         |
-------------------------------------------

 ---------------- Iteration 37 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 370 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 371 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 372 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 373 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 374 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 375 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 376 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 377 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 378 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 379 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.38          |
| Data-EnvSampler-Poli... | 0.861         |
| Data-EnvTrajs-Averag... | 31.5          |
| Data-EnvTrajs-MaxReturn | 34.6          |
| Data-EnvTrajs-MinReturn | 28.1          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 2.07          |
| Data-TimeEnvSampleProc  | 0.00104       |
| Data-TimeEnvSampling    | 1.28          |
| Iteration               | 37            |
| ItrTime                 | 35.2          |
| LossAfter               | -0.0020949142 |
| LossBefore              | -8.65208e-06  |
| Model-TimeModelFit      | 31.2          |
| ModelSampler-n_times... | 1520000       |
| Policy-AverageAbsPol... | 2.1213472     |
| Policy-AverageDiscou... | -218          |
| Policy-AveragePolicyStd | 0.5764867     |
| Policy-AverageReturn    | -1.09e+03     |
| Policy-MaxReturn        | 302           |
| Policy-MinReturn        | -5.74e+03     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.78e+03      |
| Policy-TimeAlgoOpt      | 0.658         |
| Policy-TimeSampleProc   | 0.386         |
| Policy-TimeSampling     | 1.66          |
| Policy-TimeStep         | 2.74          |
| Time                    | 1.13e+03      |
| n_timesteps             | 38000         |
-------------------------------------------

 ---------------- Iteration 38 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 380 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 381 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 382 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 383 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 384 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 385 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 386 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 387 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 388 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 389 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.472         |
| Data-EnvSampler-Poli... | 1.1           |
| Data-EnvTrajs-Averag... | 33.5          |
| Data-EnvTrajs-MaxReturn | 35.4          |
| Data-EnvTrajs-MinReturn | 31.5          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.3           |
| Data-TimeEnvSampleProc  | 0.00121       |
| Data-TimeEnvSampling    | 1.61          |
| Iteration               | 38            |
| ItrTime                 | 36.3          |
| LossAfter               | -0.0042652367 |
| LossBefore              | -8.452171e-06 |
| Model-TimeModelFit      | 32.1          |
| ModelSampler-n_times... | 1560000       |
| Policy-AverageAbsPol... | 2.0624244     |
| Policy-AverageDiscou... | -267          |
| Policy-AveragePolicyStd | 0.5651958     |
| Policy-AverageReturn    | -1.01e+03     |
| Policy-MaxReturn        | 91.8          |
| Policy-MinReturn        | -1.15e+04     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 3.24e+03      |
| Policy-TimeAlgoOpt      | 0.676         |
| Policy-TimeSampleProc   | 0.307         |
| Policy-TimeSampling     | 1.59          |
| Policy-TimeStep         | 2.58          |
| Time                    | 1.17e+03      |
| n_timesteps             | 39000         |
-------------------------------------------

 ---------------- Iteration 39 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 390 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 391 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 392 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 393 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 394 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 395 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 396 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 397 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 398 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 399 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Data-EnvSampler-EnvE... | 0.386       |
| Data-EnvSampler-Poli... | 0.918       |
| Data-EnvTrajs-Averag... | 32.4        |
| Data-EnvTrajs-MaxReturn | 35.1        |
| Data-EnvTrajs-MinReturn | 30.8        |
| Data-EnvTrajs-NumTrajs  | 5           |
| Data-EnvTrajs-StdReturn | 1.61        |
| Data-TimeEnvSampleProc  | 0.00123     |
| Data-TimeEnvSampling    | 1.34        |
| Iteration               | 39          |
| ItrTime                 | 35.8        |
| LossAfter               | -0.00529737 |
| LossBefore              | -8.386e-06  |
| Model-TimeModelFit      | 31.6        |
| ModelSampler-n_times... | 1600000     |
| Policy-AverageAbsPol... | 1.7009321   |
| Policy-AverageDiscou... | -375        |
| Policy-AveragePolicyStd | 0.5629073   |
| Policy-AverageReturn    | -1.31e+03   |
| Policy-MaxReturn        | 439         |
| Policy-MinReturn        | -1.37e+04   |
| Policy-NumTrajs         | 20          |
| Policy-StdReturn        | 4.02e+03    |
| Policy-TimeAlgoOpt      | 0.627       |
| Policy-TimeSampleProc   | 0.523       |
| Policy-TimeSampling     | 1.64        |
| Policy-TimeStep         | 2.82        |
| Time                    | 1.21e+03    |
| n_timesteps             | 40000       |
-----------------------------------------

 ---------------- Iteration 40 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 400 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 401 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 402 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 403 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 404 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 405 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 406 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 407 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 408 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 409 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.439         |
| Data-EnvSampler-Poli... | 1.05          |
| Data-EnvTrajs-Averag... | 33.7          |
| Data-EnvTrajs-MaxReturn | 37.6          |
| Data-EnvTrajs-MinReturn | 31.5          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 2.22          |
| Data-TimeEnvSampleProc  | 0.000913      |
| Data-TimeEnvSampling    | 1.53          |
| Iteration               | 40            |
| ItrTime                 | 36.4          |
| LossAfter               | -0.0041773114 |
| LossBefore              | -8.175307e-06 |
| Model-TimeModelFit      | 32.2          |
| ModelSampler-n_times... | 1640000       |
| Policy-AverageAbsPol... | 1.8515416     |
| Policy-AverageDiscou... | -284          |
| Policy-AveragePolicyStd | 0.55117404    |
| Policy-AverageReturn    | -1.72e+03     |
| Policy-MaxReturn        | 572           |
| Policy-MinReturn        | -3.86e+03     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.58e+03      |
| Policy-TimeAlgoOpt      | 0.559         |
| Policy-TimeSampleProc   | 0.456         |
| Policy-TimeSampling     | 1.68          |
| Policy-TimeStep         | 2.74          |
| Time                    | 1.24e+03      |
| n_timesteps             | 41000         |
-------------------------------------------

 ---------------- Iteration 41 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 410 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 411 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 412 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 413 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 414 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 415 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 416 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 417 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 418 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 419 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.423         |
| Data-EnvSampler-Poli... | 1.02          |
| Data-EnvTrajs-Averag... | 31.9          |
| Data-EnvTrajs-MaxReturn | 35.3          |
| Data-EnvTrajs-MinReturn | 30.1          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.91          |
| Data-TimeEnvSampleProc  | 0.00457       |
| Data-TimeEnvSampling    | 1.48          |
| Iteration               | 41            |
| ItrTime                 | 36.9          |
| LossAfter               | -0.0041278256 |
| LossBefore              | -7.966354e-06 |
| Model-TimeModelFit      | 32.6          |
| ModelSampler-n_times... | 1680000       |
| Policy-AverageAbsPol... | 2.9510312     |
| Policy-AverageDiscou... | -3.84e+03     |
| Policy-AveragePolicyStd | 0.53918386    |
| Policy-AverageReturn    | -1.04e+04     |
| Policy-MaxReturn        | 274           |
| Policy-MinReturn        | -1.38e+04     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 5.33e+03      |
| Policy-TimeAlgoOpt      | 0.624         |
| Policy-TimeSampleProc   | 0.348         |
| Policy-TimeSampling     | 1.78          |
| Policy-TimeStep         | 2.79          |
| Time                    | 1.28e+03      |
| n_timesteps             | 42000         |
-------------------------------------------

 ---------------- Iteration 42 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 420 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 421 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 422 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 423 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 424 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 425 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 426 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 427 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 428 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 429 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.403         |
| Data-EnvSampler-Poli... | 0.976         |
| Data-EnvTrajs-Averag... | 34.4          |
| Data-EnvTrajs-MaxReturn | 35.4          |
| Data-EnvTrajs-MinReturn | 33            |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 0.986         |
| Data-TimeEnvSampleProc  | 0.000602      |
| Data-TimeEnvSampling    | 1.43          |
| Iteration               | 42            |
| ItrTime                 | 36.8          |
| LossAfter               | -0.0041864486 |
| LossBefore              | -7.734039e-06 |
| Model-TimeModelFit      | 32.8          |
| ModelSampler-n_times... | 1720000       |
| Policy-AverageAbsPol... | 2.4262776     |
| Policy-AverageDiscou... | -1.91e+03     |
| Policy-AveragePolicyStd | 0.52795494    |
| Policy-AverageReturn    | -5.84e+03     |
| Policy-MaxReturn        | 190           |
| Policy-MinReturn        | -1.38e+04     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 6.09e+03      |
| Policy-TimeAlgoOpt      | 0.591         |
| Policy-TimeSampleProc   | 0.338         |
| Policy-TimeSampling     | 1.62          |
| Policy-TimeStep         | 2.59          |
| Time                    | 1.32e+03      |
| n_timesteps             | 43000         |
-------------------------------------------

 ---------------- Iteration 43 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 430 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 431 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 432 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 433 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 434 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 435 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 436 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 437 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 438 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 439 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.429         |
| Data-EnvSampler-Poli... | 0.949         |
| Data-EnvTrajs-Averag... | 32.9          |
| Data-EnvTrajs-MaxReturn | 35            |
| Data-EnvTrajs-MinReturn | 31.4          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.54          |
| Data-TimeEnvSampleProc  | 0.00102       |
| Data-TimeEnvSampling    | 1.42          |
| Iteration               | 43            |
| ItrTime                 | 37.1          |
| LossAfter               | -0.0018915206 |
| LossBefore              | -7.467841e-06 |
| Model-TimeModelFit      | 32.9          |
| ModelSampler-n_times... | 1760000       |
| Policy-AverageAbsPol... | 2.3584628     |
| Policy-AverageDiscou... | -556          |
| Policy-AveragePolicyStd | 0.51368195    |
| Policy-AverageReturn    | -2.23e+03     |
| Policy-MaxReturn        | 120           |
| Policy-MinReturn        | -1.01e+04     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 3.46e+03      |
| Policy-TimeAlgoOpt      | 0.619         |
| Policy-TimeSampleProc   | 0.468         |
| Policy-TimeSampling     | 1.7           |
| Policy-TimeStep         | 2.81          |
| Time                    | 1.35e+03      |
| n_timesteps             | 44000         |
-------------------------------------------

 ---------------- Iteration 44 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 440 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 441 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 442 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 443 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 444 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 445 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 446 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 447 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 448 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 449 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.371         |
| Data-EnvSampler-Poli... | 0.835         |
| Data-EnvTrajs-Averag... | 33.2          |
| Data-EnvTrajs-MaxReturn | 36.4          |
| Data-EnvTrajs-MinReturn | 30.8          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 2             |
| Data-TimeEnvSampleProc  | 0.000673      |
| Data-TimeEnvSampling    | 1.24          |
| Iteration               | 44            |
| ItrTime                 | 36            |
| LossAfter               | -0.002747159  |
| LossBefore              | -7.337662e-06 |
| Model-TimeModelFit      | 32.2          |
| ModelSampler-n_times... | 1800000       |
| Policy-AverageAbsPol... | 2.8100812     |
| Policy-AverageDiscou... | -1.63e+03     |
| Policy-AveragePolicyStd | 0.5078918     |
| Policy-AverageReturn    | -4.34e+03     |
| Policy-MaxReturn        | 92.6          |
| Policy-MinReturn        | -5.89e+03     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.94e+03      |
| Policy-TimeAlgoOpt      | 0.541         |
| Policy-TimeSampleProc   | 0.296         |
| Policy-TimeSampling     | 1.62          |
| Policy-TimeStep         | 2.51          |
| Time                    | 1.39e+03      |
| n_timesteps             | 45000         |
-------------------------------------------

 ---------------- Iteration 45 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 450 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 451 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 452 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 453 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 454 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 455 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 456 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 457 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 458 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 459 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.448          |
| Data-EnvSampler-Poli... | 1.02           |
| Data-EnvTrajs-Averag... | 32.5           |
| Data-EnvTrajs-MaxReturn | 36.1           |
| Data-EnvTrajs-MinReturn | 29.6           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.22           |
| Data-TimeEnvSampleProc  | 0.00121        |
| Data-TimeEnvSampling    | 1.51           |
| Iteration               | 45             |
| ItrTime                 | 37.3           |
| LossAfter               | -0.0060410104  |
| LossBefore              | -7.3319825e-06 |
| Model-TimeModelFit      | 33.1           |
| ModelSampler-n_times... | 1840000        |
| Policy-AverageAbsPol... | 2.7661688      |
| Policy-AverageDiscou... | 3.84e+03       |
| Policy-AveragePolicyStd | 0.5076992      |
| Policy-AverageReturn    | 1.28e+04       |
| Policy-MaxReturn        | 1.52e+04       |
| Policy-MinReturn        | 107            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 4.03e+03       |
| Policy-TimeAlgoOpt      | 0.625          |
| Policy-TimeSampleProc   | 0.397          |
| Policy-TimeSampling     | 1.61           |
| Policy-TimeStep         | 2.66           |
| Time                    | 1.43e+03       |
| n_timesteps             | 46000          |
--------------------------------------------

 ---------------- Iteration 46 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 460 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 461 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 462 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 463 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 464 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 465 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 466 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 467 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 468 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 469 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.402          |
| Data-EnvSampler-Poli... | 0.932          |
| Data-EnvTrajs-Averag... | 34             |
| Data-EnvTrajs-MaxReturn | 36.3           |
| Data-EnvTrajs-MinReturn | 31.6           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.9            |
| Data-TimeEnvSampleProc  | 0.00108        |
| Data-TimeEnvSampling    | 1.37           |
| Iteration               | 46             |
| ItrTime                 | 37.2           |
| LossAfter               | -0.0033426262  |
| LossBefore              | -7.2659973e-06 |
| Model-TimeModelFit      | 33.2           |
| ModelSampler-n_times... | 1880000        |
| Policy-AverageAbsPol... | 2.8763282      |
| Policy-AverageDiscou... | -3.97e+03      |
| Policy-AveragePolicyStd | 0.5040041      |
| Policy-AverageReturn    | -1.23e+04      |
| Policy-MaxReturn        | 83.3           |
| Policy-MinReturn        | -1.61e+04      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 6.21e+03       |
| Policy-TimeAlgoOpt      | 0.596          |
| Policy-TimeSampleProc   | 0.341          |
| Policy-TimeSampling     | 1.55           |
| Policy-TimeStep         | 2.53           |
| Time                    | 1.46e+03       |
| n_timesteps             | 47000          |
--------------------------------------------

 ---------------- Iteration 47 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 470 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 471 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 472 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 473 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 474 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 475 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 476 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 477 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 478 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 479 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.393          |
| Data-EnvSampler-Poli... | 0.955          |
| Data-EnvTrajs-Averag... | 34             |
| Data-EnvTrajs-MaxReturn | 35.3           |
| Data-EnvTrajs-MinReturn | 31.8           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.37           |
| Data-TimeEnvSampleProc  | 0.00104        |
| Data-TimeEnvSampling    | 1.39           |
| Iteration               | 47             |
| ItrTime                 | 37.6           |
| LossAfter               | -0.0016427487  |
| LossBefore              | -7.2251987e-06 |
| Model-TimeModelFit      | 33.4           |
| ModelSampler-n_times... | 1920000        |
| Policy-AverageAbsPol... | 2.4457107      |
| Policy-AverageDiscou... | 176            |
| Policy-AveragePolicyStd | 0.50255257     |
| Policy-AverageReturn    | 733            |
| Policy-MaxReturn        | 2.18e+03       |
| Policy-MinReturn        | 80.6           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 619            |
| Policy-TimeAlgoOpt      | 0.589          |
| Policy-TimeSampleProc   | 0.433          |
| Policy-TimeSampling     | 1.69           |
| Policy-TimeStep         | 2.74           |
| Time                    | 1.5e+03        |
| n_timesteps             | 48000          |
--------------------------------------------

 ---------------- Iteration 48 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 480 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 481 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 482 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 483 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 484 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 485 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 486 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 487 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 488 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 489 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.384         |
| Data-EnvSampler-Poli... | 0.897         |
| Data-EnvTrajs-Averag... | 33.9          |
| Data-EnvTrajs-MaxReturn | 35.6          |
| Data-EnvTrajs-MinReturn | 33.2          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 0.869         |
| Data-TimeEnvSampleProc  | 0.00104       |
| Data-TimeEnvSampling    | 1.31          |
| Iteration               | 48            |
| ItrTime                 | 37.4          |
| LossAfter               | -0.0025871766 |
| LossBefore              | -7.078882e-06 |
| Model-TimeModelFit      | 33.3          |
| ModelSampler-n_times... | 1960000       |
| Policy-AverageAbsPol... | 2.3322246     |
| Policy-AverageDiscou... | 1.91          |
| Policy-AveragePolicyStd | 0.49433684    |
| Policy-AverageReturn    | -38.4         |
| Policy-MaxReturn        | 96.9          |
| Policy-MinReturn        | -361          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 174           |
| Policy-TimeAlgoOpt      | 0.552         |
| Policy-TimeSampleProc   | 0.484         |
| Policy-TimeSampling     | 1.66          |
| Policy-TimeStep         | 2.76          |
| Time                    | 1.54e+03      |
| n_timesteps             | 49000         |
-------------------------------------------

 ---------------- Iteration 49 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 490 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 491 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 492 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 493 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 494 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 495 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 496 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 497 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 498 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 499 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.412         |
| Data-EnvSampler-Poli... | 0.949         |
| Data-EnvTrajs-Averag... | 33.9          |
| Data-EnvTrajs-MaxReturn | 36.8          |
| Data-EnvTrajs-MinReturn | 30.7          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.94          |
| Data-TimeEnvSampleProc  | 0.000766      |
| Data-TimeEnvSampling    | 1.4           |
| Iteration               | 49            |
| ItrTime                 | 37.8          |
| LossAfter               | -0.0022561757 |
| LossBefore              | -7.094154e-06 |
| Model-TimeModelFit      | 33.3          |
| ModelSampler-n_times... | 2000000       |
| Policy-AverageAbsPol... | 2.7117076     |
| Policy-AverageDiscou... | -121          |
| Policy-AveragePolicyStd | 0.49521562    |
| Policy-AverageReturn    | -613          |
| Policy-MaxReturn        | 82.1          |
| Policy-MinReturn        | -1.13e+03     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 437           |
| Policy-TimeAlgoOpt      | 0.575         |
| Policy-TimeSampleProc   | 0.6           |
| Policy-TimeSampling     | 1.83          |
| Policy-TimeStep         | 3.06          |
| Time                    | 1.58e+03      |
| n_timesteps             | 50000         |
-------------------------------------------

 ---------------- Iteration 50 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 500 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 501 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 502 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 503 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 504 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 505 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 506 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 507 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 508 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 509 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.408          |
| Data-EnvSampler-Poli... | 0.962          |
| Data-EnvTrajs-Averag... | 32.7           |
| Data-EnvTrajs-MaxReturn | 33.5           |
| Data-EnvTrajs-MinReturn | 30.8           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.03           |
| Data-TimeEnvSampleProc  | 0.00123        |
| Data-TimeEnvSampling    | 1.41           |
| Iteration               | 50             |
| ItrTime                 | 37.3           |
| LossAfter               | -0.004495404   |
| LossBefore              | -7.0721044e-06 |
| Model-TimeModelFit      | 33.3           |
| ModelSampler-n_times... | 2040000        |
| Policy-AverageAbsPol... | 2.2005508      |
| Policy-AverageDiscou... | 226            |
| Policy-AveragePolicyStd | 0.49327105     |
| Policy-AverageReturn    | 703            |
| Policy-MaxReturn        | 2.5e+03        |
| Policy-MinReturn        | -88.9          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 907            |
| Policy-TimeAlgoOpt      | 0.549          |
| Policy-TimeSampleProc   | 0.465          |
| Policy-TimeSampling     | 1.55           |
| Policy-TimeStep         | 2.61           |
| Time                    | 1.61e+03       |
| n_timesteps             | 51000          |
--------------------------------------------
Training finished
