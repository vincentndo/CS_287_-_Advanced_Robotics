Logging to /home/vincent/workplace/CS_287_-_Advanced_Robotics/homework/hw5/cs287hw5/ppo/run_scripts/data/parallel_mb_ppo/mbppo_Swimmer_l1//02

 ---------------- Iteration 0 ----------------
Obtaining random samples from the environment...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 0 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 1 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 2 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 3 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 4 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 5 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 6 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 7 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 8 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 9 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.136           |
| Data-EnvSampler-Poli... | 0.0419          |
| Data-EnvTrajs-Averag... | -0.764          |
| Data-EnvTrajs-MaxReturn | 1.48            |
| Data-EnvTrajs-MinReturn | -5.88           |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 2.8             |
| Data-TimeEnvSampleProc  | 0.000544        |
| Data-TimeEnvSampling    | 0.189           |
| Iteration               | 0               |
| ItrTime                 | 9.51            |
| LossAfter               | -0.0059926123   |
| LossBefore              | -1.40944785e-05 |
| Model-TimeModelFit      | 3.22            |
| ModelSampler-n_times... | 40000           |
| Policy-AverageAbsPol... | 0.94323266      |
| Policy-AverageDiscou... | -215            |
| Policy-AveragePolicyStd | 0.9911852       |
| Policy-AverageReturn    | -767            |
| Policy-MaxReturn        | -372            |
| Policy-MinReturn        | -2.02e+03       |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 445             |
| Policy-TimeAlgoOpt      | 1.15            |
| Policy-TimeSampleProc   | 0.433           |
| Policy-TimeSampling     | 4.47            |
| Policy-TimeStep         | 6.09            |
| Time                    | 9.51            |
| n_timesteps             | 1000            |
---------------------------------------------

 ---------------- Iteration 1 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 10 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 11 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 12 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 13 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 14 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 15 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 16 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 17 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 18 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 19 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.229          |
| Data-EnvSampler-Poli... | 0.499          |
| Data-EnvTrajs-Averag... | -10.2          |
| Data-EnvTrajs-MaxReturn | -5.26          |
| Data-EnvTrajs-MinReturn | -15.7          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 3.53           |
| Data-TimeEnvSampleProc  | 0.000641       |
| Data-TimeEnvSampling    | 0.747          |
| Iteration               | 1              |
| ItrTime                 | 8.03           |
| LossAfter               | -0.0031263817  |
| LossBefore              | -1.4037554e-05 |
| Model-TimeModelFit      | 4.66           |
| ModelSampler-n_times... | 80000          |
| Policy-AverageAbsPol... | 0.49147847     |
| Policy-AverageDiscou... | -326           |
| Policy-AveragePolicyStd | 0.98485        |
| Policy-AverageReturn    | -1.4e+03       |
| Policy-MaxReturn        | 75             |
| Policy-MinReturn        | -3.8e+03       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.51e+03       |
| Policy-TimeAlgoOpt      | 0.599          |
| Policy-TimeSampleProc   | 0.523          |
| Policy-TimeSampling     | 1.45           |
| Policy-TimeStep         | 2.61           |
| Time                    | 17.7           |
| n_timesteps             | 2000           |
--------------------------------------------

 ---------------- Iteration 2 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 20 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 21 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 22 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 23 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 24 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 25 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 26 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 27 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 28 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 29 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.251           |
| Data-EnvSampler-Poli... | 0.521           |
| Data-EnvTrajs-Averag... | -1.76           |
| Data-EnvTrajs-MaxReturn | 5.12            |
| Data-EnvTrajs-MinReturn | -7.19           |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 4.03            |
| Data-TimeEnvSampleProc  | 0.000607        |
| Data-TimeEnvSampling    | 0.797           |
| Iteration               | 2               |
| ItrTime                 | 10.2            |
| LossAfter               | -0.0037698385   |
| LossBefore              | -1.37300985e-05 |
| Model-TimeModelFit      | 6.71            |
| ModelSampler-n_times... | 120000          |
| Policy-AverageAbsPol... | 0.46063077      |
| Policy-AverageDiscou... | 35.3            |
| Policy-AveragePolicyStd | 0.95669997      |
| Policy-AverageReturn    | 166             |
| Policy-MaxReturn        | 506             |
| Policy-MinReturn        | -403            |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 277             |
| Policy-TimeAlgoOpt      | 0.539           |
| Policy-TimeSampleProc   | 0.415           |
| Policy-TimeSampling     | 1.67            |
| Policy-TimeStep         | 2.69            |
| Time                    | 27.9            |
| n_timesteps             | 3000            |
---------------------------------------------

 ---------------- Iteration 3 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 30 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 31 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 32 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 33 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 34 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 35 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 36 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 37 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 38 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 39 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.276          |
| Data-EnvSampler-Poli... | 0.521          |
| Data-EnvTrajs-Averag... | 12.8           |
| Data-EnvTrajs-MaxReturn | 18.7           |
| Data-EnvTrajs-MinReturn | 4.44           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 5.22           |
| Data-TimeEnvSampleProc  | 0.00059        |
| Data-TimeEnvSampling    | 0.827          |
| Iteration               | 3              |
| ItrTime                 | 13.3           |
| LossAfter               | -0.0016730574  |
| LossBefore              | -1.3673964e-05 |
| Model-TimeModelFit      | 9.67           |
| ModelSampler-n_times... | 160000         |
| Policy-AverageAbsPol... | 0.93080163     |
| Policy-AverageDiscou... | 125            |
| Policy-AveragePolicyStd | 0.94982994     |
| Policy-AverageReturn    | 418            |
| Policy-MaxReturn        | 799            |
| Policy-MinReturn        | -932           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 469            |
| Policy-TimeAlgoOpt      | 0.61           |
| Policy-TimeSampleProc   | 0.423          |
| Policy-TimeSampling     | 1.68           |
| Policy-TimeStep         | 2.79           |
| Time                    | 41.2           |
| n_timesteps             | 4000           |
--------------------------------------------

 ---------------- Iteration 4 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 40 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 41 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 42 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 43 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 44 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 45 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 46 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 47 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 48 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 49 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.312          |
| Data-EnvSampler-Poli... | 0.59           |
| Data-EnvTrajs-Averag... | 21.7           |
| Data-EnvTrajs-MaxReturn | 26.3           |
| Data-EnvTrajs-MinReturn | 17.9           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.84           |
| Data-TimeEnvSampleProc  | 0.000948       |
| Data-TimeEnvSampling    | 0.928          |
| Iteration               | 4              |
| ItrTime                 | 15.6           |
| LossAfter               | -0.0023889588  |
| LossBefore              | -1.3649209e-05 |
| Model-TimeModelFit      | 11.6           |
| ModelSampler-n_times... | 200000         |
| Policy-AverageAbsPol... | 0.75932276     |
| Policy-AverageDiscou... | 25.7           |
| Policy-AveragePolicyStd | 0.9451246      |
| Policy-AverageReturn    | 22.8           |
| Policy-MaxReturn        | 142            |
| Policy-MinReturn        | -1.21e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 287            |
| Policy-TimeAlgoOpt      | 0.612          |
| Policy-TimeSampleProc   | 0.491          |
| Policy-TimeSampling     | 1.89           |
| Policy-TimeStep         | 3.03           |
| Time                    | 56.8           |
| n_timesteps             | 5000           |
--------------------------------------------

 ---------------- Iteration 5 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 50 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 51 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 52 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 53 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 54 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 55 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 56 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 57 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 58 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 59 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.332          |
| Data-EnvSampler-Poli... | 0.639          |
| Data-EnvTrajs-Averag... | 25.3           |
| Data-EnvTrajs-MaxReturn | 27.4           |
| Data-EnvTrajs-MinReturn | 22.8           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.49           |
| Data-TimeEnvSampleProc  | 0.000947       |
| Data-TimeEnvSampling    | 1.03           |
| Iteration               | 5              |
| ItrTime                 | 16.7           |
| LossAfter               | -0.006518801   |
| LossBefore              | -1.3641185e-05 |
| Model-TimeModelFit      | 13             |
| ModelSampler-n_times... | 240000         |
| Policy-AverageAbsPol... | 1.204441       |
| Policy-AverageDiscou... | 664            |
| Policy-AveragePolicyStd | 0.94517446     |
| Policy-AverageReturn    | 2.86e+03       |
| Policy-MaxReturn        | 3.32e+03       |
| Policy-MinReturn        | 2.25e+03       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 217            |
| Policy-TimeAlgoOpt      | 0.603          |
| Policy-TimeSampleProc   | 0.428          |
| Policy-TimeSampling     | 1.65           |
| Policy-TimeStep         | 2.7            |
| Time                    | 73.5           |
| n_timesteps             | 6000           |
--------------------------------------------

 ---------------- Iteration 6 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 60 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 61 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 62 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 63 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 64 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 65 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 66 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 67 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 68 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 69 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.298          |
| Data-EnvSampler-Poli... | 0.574          |
| Data-EnvTrajs-Averag... | 29             |
| Data-EnvTrajs-MaxReturn | 31.7           |
| Data-EnvTrajs-MinReturn | 24.2           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.61           |
| Data-TimeEnvSampleProc  | 0.000997       |
| Data-TimeEnvSampling    | 0.899          |
| Iteration               | 6              |
| ItrTime                 | 19.8           |
| LossAfter               | -0.0017729156  |
| LossBefore              | -1.3589418e-05 |
| Model-TimeModelFit      | 16.2           |
| ModelSampler-n_times... | 280000         |
| Policy-AverageAbsPol... | 0.9808994      |
| Policy-AverageDiscou... | 14             |
| Policy-AveragePolicyStd | 0.9418668      |
| Policy-AverageReturn    | 7.88           |
| Policy-MaxReturn        | 75.6           |
| Policy-MinReturn        | -248           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 94.3           |
| Policy-TimeAlgoOpt      | 0.57           |
| Policy-TimeSampleProc   | 0.468          |
| Policy-TimeSampling     | 1.61           |
| Policy-TimeStep         | 2.7            |
| Time                    | 93.4           |
| n_timesteps             | 7000           |
--------------------------------------------

 ---------------- Iteration 7 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 70 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 71 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 72 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 73 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 74 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 75 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 76 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 77 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 78 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 79 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.32           |
| Data-EnvSampler-Poli... | 0.621          |
| Data-EnvTrajs-Averag... | 24.9           |
| Data-EnvTrajs-MaxReturn | 28.3           |
| Data-EnvTrajs-MinReturn | 22.4           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.24           |
| Data-TimeEnvSampleProc  | 0.000989       |
| Data-TimeEnvSampling    | 0.972          |
| Iteration               | 7              |
| ItrTime                 | 22.4           |
| LossAfter               | -0.0043615825  |
| LossBefore              | -1.3344945e-05 |
| Model-TimeModelFit      | 18.7           |
| ModelSampler-n_times... | 320000         |
| Policy-AverageAbsPol... | 0.57214177     |
| Policy-AverageDiscou... | 46.5           |
| Policy-AveragePolicyStd | 0.92151535     |
| Policy-AverageReturn    | 109            |
| Policy-MaxReturn        | 152            |
| Policy-MinReturn        | 15.6           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 28.1           |
| Policy-TimeAlgoOpt      | 0.553          |
| Policy-TimeSampleProc   | 0.594          |
| Policy-TimeSampling     | 1.56           |
| Policy-TimeStep         | 2.75           |
| Time                    | 116            |
| n_timesteps             | 8000           |
--------------------------------------------

 ---------------- Iteration 8 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 80 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 81 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 82 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 83 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 84 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 85 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 86 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 87 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 88 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 89 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.339          |
| Data-EnvSampler-Poli... | 0.646          |
| Data-EnvTrajs-Averag... | 19             |
| Data-EnvTrajs-MaxReturn | 30.8           |
| Data-EnvTrajs-MinReturn | 9.78           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 7.47           |
| Data-TimeEnvSampleProc  | 0.000971       |
| Data-TimeEnvSampling    | 1.02           |
| Iteration               | 8              |
| ItrTime                 | 24.4           |
| LossAfter               | -0.0043224082  |
| LossBefore              | -1.2891305e-05 |
| Model-TimeModelFit      | 20.6           |
| ModelSampler-n_times... | 360000         |
| Policy-AverageAbsPol... | 0.593938       |
| Policy-AverageDiscou... | 512            |
| Policy-AveragePolicyStd | 0.8791151      |
| Policy-AverageReturn    | 1.78e+03       |
| Policy-MaxReturn        | 1.83e+03       |
| Policy-MinReturn        | 1.66e+03       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 49.9           |
| Policy-TimeAlgoOpt      | 0.606          |
| Policy-TimeSampleProc   | 0.443          |
| Policy-TimeSampling     | 1.76           |
| Policy-TimeStep         | 2.84           |
| Time                    | 140            |
| n_timesteps             | 9000           |
--------------------------------------------

 ---------------- Iteration 9 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 90 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 91 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 92 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 93 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 94 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 95 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 96 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 97 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 98 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 99 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.353          |
| Data-EnvSampler-Poli... | 0.691          |
| Data-EnvTrajs-Averag... | 28.8           |
| Data-EnvTrajs-MaxReturn | 31             |
| Data-EnvTrajs-MinReturn | 25.4           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.06           |
| Data-TimeEnvSampleProc  | 0.00103        |
| Data-TimeEnvSampling    | 1.08           |
| Iteration               | 9              |
| ItrTime                 | 26.3           |
| LossAfter               | -0.005111804   |
| LossBefore              | -1.2714321e-05 |
| Model-TimeModelFit      | 22.7           |
| ModelSampler-n_times... | 400000         |
| Policy-AverageAbsPol... | 0.7264102      |
| Policy-AverageDiscou... | 445            |
| Policy-AveragePolicyStd | 0.8636903      |
| Policy-AverageReturn    | 1.89e+03       |
| Policy-MaxReturn        | 2.41e+03       |
| Policy-MinReturn        | -1.01e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 692            |
| Policy-TimeAlgoOpt      | 0.515          |
| Policy-TimeSampleProc   | 0.383          |
| Policy-TimeSampling     | 1.57           |
| Policy-TimeStep         | 2.52           |
| Time                    | 167            |
| n_timesteps             | 10000          |
--------------------------------------------

 ---------------- Iteration 10 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 100 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 101 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 102 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 103 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 104 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 105 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 106 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 107 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 108 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 109 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.34            |
| Data-EnvSampler-Poli... | 0.735           |
| Data-EnvTrajs-Averag... | 28.2            |
| Data-EnvTrajs-MaxReturn | 29              |
| Data-EnvTrajs-MinReturn | 26.2            |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 1.12            |
| Data-TimeEnvSampleProc  | 0.000783        |
| Data-TimeEnvSampling    | 1.11            |
| Iteration               | 10              |
| ItrTime                 | 28.4            |
| LossAfter               | -0.0055976114   |
| LossBefore              | -1.25478045e-05 |
| Model-TimeModelFit      | 24.7            |
| ModelSampler-n_times... | 440000          |
| Policy-AverageAbsPol... | 1.0350263       |
| Policy-AverageDiscou... | 338             |
| Policy-AveragePolicyStd | 0.85099417      |
| Policy-AverageReturn    | 1.73e+03        |
| Policy-MaxReturn        | 2.48e+03        |
| Policy-MinReturn        | 1.08e+03        |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 350             |
| Policy-TimeAlgoOpt      | 0.588           |
| Policy-TimeSampleProc   | 0.501           |
| Policy-TimeSampling     | 1.54            |
| Policy-TimeStep         | 2.66            |
| Time                    | 195             |
| n_timesteps             | 11000           |
---------------------------------------------

 ---------------- Iteration 11 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 110 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 111 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 112 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 113 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 114 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 115 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 116 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 117 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 118 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 119 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.401          |
| Data-EnvSampler-Poli... | 0.801          |
| Data-EnvTrajs-Averag... | 23.3           |
| Data-EnvTrajs-MaxReturn | 28.7           |
| Data-EnvTrajs-MinReturn | 14             |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 5.83           |
| Data-TimeEnvSampleProc  | 0.000685       |
| Data-TimeEnvSampling    | 1.24           |
| Iteration               | 11             |
| ItrTime                 | 31.5           |
| LossAfter               | -0.0048617804  |
| LossBefore              | -1.2435684e-05 |
| Model-TimeModelFit      | 27.6           |
| ModelSampler-n_times... | 480000         |
| Policy-AverageAbsPol... | 1.3057332      |
| Policy-AverageDiscou... | 651            |
| Policy-AveragePolicyStd | 0.8427532      |
| Policy-AverageReturn    | 2.91e+03       |
| Policy-MaxReturn        | 3.12e+03       |
| Policy-MinReturn        | 2.79e+03       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 93.1           |
| Policy-TimeAlgoOpt      | 0.566          |
| Policy-TimeSampleProc   | 0.493          |
| Policy-TimeSampling     | 1.61           |
| Policy-TimeStep         | 2.7            |
| Time                    | 226            |
| n_timesteps             | 12000          |
--------------------------------------------

 ---------------- Iteration 12 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 120 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 121 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 122 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 123 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 124 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 125 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 126 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 127 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 128 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 129 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.343          |
| Data-EnvSampler-Poli... | 0.66           |
| Data-EnvTrajs-Averag... | 28             |
| Data-EnvTrajs-MaxReturn | 29.2           |
| Data-EnvTrajs-MinReturn | 27             |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 0.702          |
| Data-TimeEnvSampleProc  | 0.000567       |
| Data-TimeEnvSampling    | 1.03           |
| Iteration               | 12             |
| ItrTime                 | 32.3           |
| LossAfter               | -0.002423295   |
| LossBefore              | -1.2348348e-05 |
| Model-TimeModelFit      | 28.2           |
| ModelSampler-n_times... | 520000         |
| Policy-AverageAbsPol... | 1.4110634      |
| Policy-AverageDiscou... | 421            |
| Policy-AveragePolicyStd | 0.83524024     |
| Policy-AverageReturn    | 1.89e+03       |
| Policy-MaxReturn        | 1.95e+03       |
| Policy-MinReturn        | 1.83e+03       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 33.5           |
| Policy-TimeAlgoOpt      | 0.662          |
| Policy-TimeSampleProc   | 0.483          |
| Policy-TimeSampling     | 1.82           |
| Policy-TimeStep         | 2.99           |
| Time                    | 259            |
| n_timesteps             | 13000          |
--------------------------------------------

 ---------------- Iteration 13 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 130 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 131 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 132 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 133 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 134 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 135 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 136 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 137 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 138 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 139 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.356         |
| Data-EnvSampler-Poli... | 0.731         |
| Data-EnvTrajs-Averag... | 28.8          |
| Data-EnvTrajs-MaxReturn | 29.9          |
| Data-EnvTrajs-MinReturn | 26.2          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.39          |
| Data-TimeEnvSampleProc  | 0.000792      |
| Data-TimeEnvSampling    | 1.12          |
| Iteration               | 13            |
| ItrTime                 | 32.3          |
| LossAfter               | -0.0044093374 |
| LossBefore              | -1.214158e-05 |
| Model-TimeModelFit      | 28.4          |
| ModelSampler-n_times... | 560000        |
| Policy-AverageAbsPol... | 1.169116      |
| Policy-AverageDiscou... | -210          |
| Policy-AveragePolicyStd | 0.8170358     |
| Policy-AverageReturn    | -668          |
| Policy-MaxReturn        | 321           |
| Policy-MinReturn        | -1e+03        |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 452           |
| Policy-TimeAlgoOpt      | 0.603         |
| Policy-TimeSampleProc   | 0.448         |
| Policy-TimeSampling     | 1.66          |
| Policy-TimeStep         | 2.77          |
| Time                    | 291           |
| n_timesteps             | 14000         |
-------------------------------------------

 ---------------- Iteration 14 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 140 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 141 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 142 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 143 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 144 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 145 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 146 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 147 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 148 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 149 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.414          |
| Data-EnvSampler-Poli... | 0.699          |
| Data-EnvTrajs-Averag... | 28.1           |
| Data-EnvTrajs-MaxReturn | 29.3           |
| Data-EnvTrajs-MinReturn | 26.8           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.07           |
| Data-TimeEnvSampleProc  | 0.000909       |
| Data-TimeEnvSampling    | 1.15           |
| Iteration               | 14             |
| ItrTime                 | 34.2           |
| LossAfter               | -0.004289125   |
| LossBefore              | -1.2210649e-05 |
| Model-TimeModelFit      | 30.2           |
| ModelSampler-n_times... | 600000         |
| Policy-AverageAbsPol... | 0.95864826     |
| Policy-AverageDiscou... | -4.76e+03      |
| Policy-AveragePolicyStd | 0.82140964     |
| Policy-AverageReturn    | -1.51e+04      |
| Policy-MaxReturn        | -1.45e+04      |
| Policy-MinReturn        | -1.57e+04      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 342            |
| Policy-TimeAlgoOpt      | 0.571          |
| Policy-TimeSampleProc   | 0.605          |
| Policy-TimeSampling     | 1.59           |
| Policy-TimeStep         | 2.8            |
| Time                    | 325            |
| n_timesteps             | 15000          |
--------------------------------------------

 ---------------- Iteration 15 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 150 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 151 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 152 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 153 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 154 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 155 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 156 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 157 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 158 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 159 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.385          |
| Data-EnvSampler-Poli... | 0.714          |
| Data-EnvTrajs-Averag... | 30.5           |
| Data-EnvTrajs-MaxReturn | 32.1           |
| Data-EnvTrajs-MinReturn | 29.3           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 0.912          |
| Data-TimeEnvSampleProc  | 0.000936       |
| Data-TimeEnvSampling    | 1.14           |
| Iteration               | 15             |
| ItrTime                 | 32.9           |
| LossAfter               | -0.007092752   |
| LossBefore              | -1.1981892e-05 |
| Model-TimeModelFit      | 29             |
| ModelSampler-n_times... | 640000         |
| Policy-AverageAbsPol... | 1.6586056      |
| Policy-AverageDiscou... | 86.6           |
| Policy-AveragePolicyStd | 0.8022367      |
| Policy-AverageReturn    | 218            |
| Policy-MaxReturn        | 248            |
| Policy-MinReturn        | 171            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 23.3           |
| Policy-TimeAlgoOpt      | 0.664          |
| Policy-TimeSampleProc   | 0.346          |
| Policy-TimeSampling     | 1.79           |
| Policy-TimeStep         | 2.82           |
| Time                    | 358            |
| n_timesteps             | 16000          |
--------------------------------------------

 ---------------- Iteration 16 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 160 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 161 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 162 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 163 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 164 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 165 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 166 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 167 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 168 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 169 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.417         |
| Data-EnvSampler-Poli... | 0.841         |
| Data-EnvTrajs-Averag... | 27.8          |
| Data-EnvTrajs-MaxReturn | 29.2          |
| Data-EnvTrajs-MinReturn | 26.8          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 0.825         |
| Data-TimeEnvSampleProc  | 0.000827      |
| Data-TimeEnvSampling    | 1.29          |
| Iteration               | 16            |
| ItrTime                 | 33            |
| LossAfter               | -0.002772393  |
| LossBefore              | -1.174152e-05 |
| Model-TimeModelFit      | 28.9          |
| ModelSampler-n_times... | 680000        |
| Policy-AverageAbsPol... | 0.9169312     |
| Policy-AverageDiscou... | -2.67e+03     |
| Policy-AveragePolicyStd | 0.7817107     |
| Policy-AverageReturn    | -1.03e+04     |
| Policy-MaxReturn        | -3.94e+03     |
| Policy-MinReturn        | -1.57e+04     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 3.57e+03      |
| Policy-TimeAlgoOpt      | 0.581         |
| Policy-TimeSampleProc   | 0.552         |
| Policy-TimeSampling     | 1.67          |
| Policy-TimeStep         | 2.82          |
| Time                    | 391           |
| n_timesteps             | 17000         |
-------------------------------------------

 ---------------- Iteration 17 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 170 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 171 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 172 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 173 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 174 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 175 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 176 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 177 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 178 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 179 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.418          |
| Data-EnvSampler-Poli... | 0.787          |
| Data-EnvTrajs-Averag... | 27.9           |
| Data-EnvTrajs-MaxReturn | 29.2           |
| Data-EnvTrajs-MinReturn | 27             |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 0.816          |
| Data-TimeEnvSampleProc  | 0.000875       |
| Data-TimeEnvSampling    | 1.25           |
| Iteration               | 17             |
| ItrTime                 | 33.2           |
| LossAfter               | -0.0011429038  |
| LossBefore              | -1.1582093e-05 |
| Model-TimeModelFit      | 29.1           |
| ModelSampler-n_times... | 720000         |
| Policy-AverageAbsPol... | 1.0759082      |
| Policy-AverageDiscou... | -1.25e+03      |
| Policy-AveragePolicyStd | 0.77043617     |
| Policy-AverageReturn    | -5.73e+03      |
| Policy-MaxReturn        | 72.1           |
| Policy-MinReturn        | -1.27e+04      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 4.2e+03        |
| Policy-TimeAlgoOpt      | 0.597          |
| Policy-TimeSampleProc   | 0.411          |
| Policy-TimeSampling     | 1.75           |
| Policy-TimeStep         | 2.8            |
| Time                    | 424            |
| n_timesteps             | 18000          |
--------------------------------------------

 ---------------- Iteration 18 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 180 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 181 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 182 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 183 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 184 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 185 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 186 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 187 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 188 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 189 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.401          |
| Data-EnvSampler-Poli... | 0.836          |
| Data-EnvTrajs-Averag... | 28.7           |
| Data-EnvTrajs-MaxReturn | 33.2           |
| Data-EnvTrajs-MinReturn | 25.9           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.56           |
| Data-TimeEnvSampleProc  | 0.00105        |
| Data-TimeEnvSampling    | 1.27           |
| Iteration               | 18             |
| ItrTime                 | 34.1           |
| LossAfter               | -0.0012386009  |
| LossBefore              | -1.1378337e-05 |
| Model-TimeModelFit      | 29.9           |
| ModelSampler-n_times... | 760000         |
| Policy-AverageAbsPol... | 1.5274436      |
| Policy-AverageDiscou... | -11.5          |
| Policy-AveragePolicyStd | 0.7550029      |
| Policy-AverageReturn    | -220           |
| Policy-MaxReturn        | 80.1           |
| Policy-MinReturn        | -3.15e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 771            |
| Policy-TimeAlgoOpt      | 0.549          |
| Policy-TimeSampleProc   | 0.48           |
| Policy-TimeSampling     | 1.85           |
| Policy-TimeStep         | 2.9            |
| Time                    | 459            |
| n_timesteps             | 19000          |
--------------------------------------------

 ---------------- Iteration 19 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 190 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 191 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 192 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 193 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 194 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 195 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 196 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 197 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 198 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 199 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.466          |
| Data-EnvSampler-Poli... | 0.872          |
| Data-EnvTrajs-Averag... | 29.1           |
| Data-EnvTrajs-MaxReturn | 31.4           |
| Data-EnvTrajs-MinReturn | 27             |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.74           |
| Data-TimeEnvSampleProc  | 0.000734       |
| Data-TimeEnvSampling    | 1.38           |
| Iteration               | 19             |
| ItrTime                 | 34.1           |
| LossAfter               | -0.0047223466  |
| LossBefore              | -1.1297995e-05 |
| Model-TimeModelFit      | 30             |
| ModelSampler-n_times... | 800000         |
| Policy-AverageAbsPol... | 1.0134519      |
| Policy-AverageDiscou... | -2.41e+03      |
| Policy-AveragePolicyStd | 0.74993944     |
| Policy-AverageReturn    | -9.55e+03      |
| Policy-MaxReturn        | -920           |
| Policy-MinReturn        | -1.49e+04      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 3.89e+03       |
| Policy-TimeAlgoOpt      | 0.552          |
| Policy-TimeSampleProc   | 0.476          |
| Policy-TimeSampling     | 1.63           |
| Policy-TimeStep         | 2.71           |
| Time                    | 493            |
| n_timesteps             | 20000          |
--------------------------------------------

 ---------------- Iteration 20 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 200 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 201 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 202 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 203 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 204 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 205 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 206 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 207 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 208 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 209 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.395          |
| Data-EnvSampler-Poli... | 0.765          |
| Data-EnvTrajs-Averag... | 30             |
| Data-EnvTrajs-MaxReturn | 34.2           |
| Data-EnvTrajs-MinReturn | 27.1           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.62           |
| Data-TimeEnvSampleProc  | 0.00108        |
| Data-TimeEnvSampling    | 1.2            |
| Iteration               | 20             |
| ItrTime                 | 34.8           |
| LossAfter               | -0.0034071961  |
| LossBefore              | -1.1128242e-05 |
| Model-TimeModelFit      | 30.4           |
| ModelSampler-n_times... | 840000         |
| Policy-AverageAbsPol... | 0.8008379      |
| Policy-AverageDiscou... | -3.22e+03      |
| Policy-AveragePolicyStd | 0.73720044     |
| Policy-AverageReturn    | -1.21e+04      |
| Policy-MaxReturn        | -9.45e+03      |
| Policy-MinReturn        | -1.46e+04      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.26e+03       |
| Policy-TimeAlgoOpt      | 0.663          |
| Policy-TimeSampleProc   | 0.431          |
| Policy-TimeSampling     | 2.06           |
| Policy-TimeStep         | 3.19           |
| Time                    | 527            |
| n_timesteps             | 21000          |
--------------------------------------------

 ---------------- Iteration 21 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 210 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 211 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 212 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 213 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 214 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 215 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 216 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 217 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 218 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 219 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.406          |
| Data-EnvSampler-Poli... | 0.893          |
| Data-EnvTrajs-Averag... | 26.8           |
| Data-EnvTrajs-MaxReturn | 29.2           |
| Data-EnvTrajs-MinReturn | 25             |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.8            |
| Data-TimeEnvSampleProc  | 0.00112        |
| Data-TimeEnvSampling    | 1.35           |
| Iteration               | 21             |
| ItrTime                 | 37.3           |
| LossAfter               | -0.0037019795  |
| LossBefore              | -1.1080703e-05 |
| Model-TimeModelFit      | 32.7           |
| ModelSampler-n_times... | 880000         |
| Policy-AverageAbsPol... | 1.446053       |
| Policy-AverageDiscou... | -722           |
| Policy-AveragePolicyStd | 0.73258466     |
| Policy-AverageReturn    | -3.86e+03      |
| Policy-MaxReturn        | 52.8           |
| Policy-MinReturn        | -8.28e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 3.07e+03       |
| Policy-TimeAlgoOpt      | 0.821          |
| Policy-TimeSampleProc   | 0.43           |
| Policy-TimeSampling     | 1.96           |
| Policy-TimeStep         | 3.26           |
| Time                    | 565            |
| n_timesteps             | 22000          |
--------------------------------------------

 ---------------- Iteration 22 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 220 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 221 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 222 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 223 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 224 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 225 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 226 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 227 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 228 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 229 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.36           |
| Data-EnvSampler-Poli... | 0.692          |
| Data-EnvTrajs-Averag... | 22             |
| Data-EnvTrajs-MaxReturn | 28.1           |
| Data-EnvTrajs-MinReturn | 17.5           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 3.54           |
| Data-TimeEnvSampleProc  | 0.00106        |
| Data-TimeEnvSampling    | 1.08           |
| Iteration               | 22             |
| ItrTime                 | 50.8           |
| LossAfter               | -0.0012686691  |
| LossBefore              | -1.0944008e-05 |
| Model-TimeModelFit      | 43.6           |
| ModelSampler-n_times... | 920000         |
| Policy-AverageAbsPol... | 1.9247273      |
| Policy-AverageDiscou... | 19.6           |
| Policy-AveragePolicyStd | 0.7238054      |
| Policy-AverageReturn    | 37.1           |
| Policy-MaxReturn        | 47.4           |
| Policy-MinReturn        | 25.8           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 5.93           |
| Policy-TimeAlgoOpt      | 1.31           |
| Policy-TimeSampleProc   | 0.979          |
| Policy-TimeSampling     | 3.71           |
| Policy-TimeStep         | 6.07           |
| Time                    | 615            |
| n_timesteps             | 23000          |
--------------------------------------------

 ---------------- Iteration 23 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 230 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 231 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 232 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 233 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 234 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 235 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 236 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 237 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 238 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 239 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.616          |
| Data-EnvSampler-Poli... | 1.66           |
| Data-EnvTrajs-Averag... | 25.2           |
| Data-EnvTrajs-MaxReturn | 28.4           |
| Data-EnvTrajs-MinReturn | 19.2           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 3.29           |
| Data-TimeEnvSampleProc  | 0.000675       |
| Data-TimeEnvSampling    | 2.34           |
| Iteration               | 23             |
| ItrTime                 | 37.6           |
| LossAfter               | -0.0026443496  |
| LossBefore              | -1.0881067e-05 |
| Model-TimeModelFit      | 32.3           |
| ModelSampler-n_times... | 960000         |
| Policy-AverageAbsPol... | 1.7416471      |
| Policy-AverageDiscou... | -4.46          |
| Policy-AveragePolicyStd | 0.7196534      |
| Policy-AverageReturn    | -55.5          |
| Policy-MaxReturn        | -10.3          |
| Policy-MinReturn        | -656           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 138            |
| Policy-TimeAlgoOpt      | 0.588          |
| Policy-TimeSampleProc   | 0.598          |
| Policy-TimeSampling     | 1.72           |
| Policy-TimeStep         | 2.94           |
| Time                    | 653            |
| n_timesteps             | 24000          |
--------------------------------------------

 ---------------- Iteration 24 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 240 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 241 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 242 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 243 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 244 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 245 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 246 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 247 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 248 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 249 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.391          |
| Data-EnvSampler-Poli... | 0.858          |
| Data-EnvTrajs-Averag... | 21.7           |
| Data-EnvTrajs-MaxReturn | 25             |
| Data-EnvTrajs-MinReturn | 19.8           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2              |
| Data-TimeEnvSampleProc  | 0.00106        |
| Data-TimeEnvSampling    | 1.28           |
| Iteration               | 24             |
| ItrTime                 | 36.5           |
| LossAfter               | -0.0031907677  |
| LossBefore              | -1.0761267e-05 |
| Model-TimeModelFit      | 32.5           |
| ModelSampler-n_times... | 1000000        |
| Policy-AverageAbsPol... | 1.6783922      |
| Policy-AverageDiscou... | 5.05           |
| Policy-AveragePolicyStd | 0.71180606     |
| Policy-AverageReturn    | -10.3          |
| Policy-MaxReturn        | 1.32           |
| Policy-MinReturn        | -26.4          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 6.31           |
| Policy-TimeAlgoOpt      | 0.615          |
| Policy-TimeSampleProc   | 0.446          |
| Policy-TimeSampling     | 1.66           |
| Policy-TimeStep         | 2.74           |
| Time                    | 690            |
| n_timesteps             | 25000          |
--------------------------------------------

 ---------------- Iteration 25 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 250 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 251 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 252 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 253 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 254 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 255 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 256 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 257 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 258 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 259 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.444          |
| Data-EnvSampler-Poli... | 0.943          |
| Data-EnvTrajs-Averag... | 24.5           |
| Data-EnvTrajs-MaxReturn | 27.6           |
| Data-EnvTrajs-MinReturn | 21.9           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.56           |
| Data-TimeEnvSampleProc  | 0.00106        |
| Data-TimeEnvSampling    | 1.44           |
| Iteration               | 25             |
| ItrTime                 | 35.6           |
| LossAfter               | -0.003495104   |
| LossBefore              | -1.0777202e-05 |
| Model-TimeModelFit      | 31.4           |
| ModelSampler-n_times... | 1040000        |
| Policy-AverageAbsPol... | 1.7285608      |
| Policy-AverageDiscou... | 13.9           |
| Policy-AveragePolicyStd | 0.71307606     |
| Policy-AverageReturn    | 11.6           |
| Policy-MaxReturn        | 16.7           |
| Policy-MinReturn        | 5.67           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.68           |
| Policy-TimeAlgoOpt      | 0.578          |
| Policy-TimeSampleProc   | 0.532          |
| Policy-TimeSampling     | 1.67           |
| Policy-TimeStep         | 2.81           |
| Time                    | 725            |
| n_timesteps             | 26000          |
--------------------------------------------

 ---------------- Iteration 26 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 260 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 261 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 262 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 263 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 264 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 265 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 266 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 267 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 268 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 269 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.483          |
| Data-EnvSampler-Poli... | 1.09           |
| Data-EnvTrajs-Averag... | 24.2           |
| Data-EnvTrajs-MaxReturn | 31             |
| Data-EnvTrajs-MinReturn | 21.3           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 3.48           |
| Data-TimeEnvSampleProc  | 0.00104        |
| Data-TimeEnvSampling    | 1.62           |
| Iteration               | 26             |
| ItrTime                 | 34.9           |
| LossAfter               | -0.0015470419  |
| LossBefore              | -1.0372442e-05 |
| Model-TimeModelFit      | 30.4           |
| ModelSampler-n_times... | 1080000        |
| Policy-AverageAbsPol... | 1.7501537      |
| Policy-AverageDiscou... | 17.4           |
| Policy-AveragePolicyStd | 0.6851721      |
| Policy-AverageReturn    | 21.5           |
| Policy-MaxReturn        | 27.5           |
| Policy-MinReturn        | 17.5           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.7            |
| Policy-TimeAlgoOpt      | 0.607          |
| Policy-TimeSampleProc   | 0.382          |
| Policy-TimeSampling     | 1.83           |
| Policy-TimeStep         | 2.86           |
| Time                    | 760            |
| n_timesteps             | 27000          |
--------------------------------------------

 ---------------- Iteration 27 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 270 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 271 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 272 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 273 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 274 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 275 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 276 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 277 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 278 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 279 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.428         |
| Data-EnvSampler-Poli... | 0.877         |
| Data-EnvTrajs-Averag... | 27.4          |
| Data-EnvTrajs-MaxReturn | 29.8          |
| Data-EnvTrajs-MinReturn | 24.8          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.65          |
| Data-TimeEnvSampleProc  | 0.00093       |
| Data-TimeEnvSampling    | 1.34          |
| Iteration               | 27            |
| ItrTime                 | 34.5          |
| LossAfter               | -0.0013412748 |
| LossBefore              | -9.895226e-06 |
| Model-TimeModelFit      | 30.6          |
| ModelSampler-n_times... | 1120000       |
| Policy-AverageAbsPol... | 1.8169397     |
| Policy-AverageDiscou... | 18.4          |
| Policy-AveragePolicyStd | 0.65599537    |
| Policy-AverageReturn    | 23.5          |
| Policy-MaxReturn        | 27.1          |
| Policy-MinReturn        | 18.8          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 2.45          |
| Policy-TimeAlgoOpt      | 0.589         |
| Policy-TimeSampleProc   | 0.349         |
| Policy-TimeSampling     | 1.61          |
| Policy-TimeStep         | 2.56          |
| Time                    | 795           |
| n_timesteps             | 28000         |
-------------------------------------------

 ---------------- Iteration 28 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 280 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 281 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 282 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 283 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 284 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 285 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 286 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 287 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 288 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 289 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.418          |
| Data-EnvSampler-Poli... | 0.927          |
| Data-EnvTrajs-Averag... | 27.6           |
| Data-EnvTrajs-MaxReturn | 29.8           |
| Data-EnvTrajs-MinReturn | 23.4           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.47           |
| Data-TimeEnvSampleProc  | 0.000634       |
| Data-TimeEnvSampling    | 1.38           |
| Iteration               | 28             |
| ItrTime                 | 34.7           |
| LossAfter               | -0.004135482   |
| LossBefore              | -9.3711005e-06 |
| Model-TimeModelFit      | 30.7           |
| ModelSampler-n_times... | 1160000        |
| Policy-AverageAbsPol... | 1.7578877      |
| Policy-AverageDiscou... | 10.6           |
| Policy-AveragePolicyStd | 0.62672377     |
| Policy-AverageReturn    | -6.49          |
| Policy-MaxReturn        | -2.72          |
| Policy-MinReturn        | -10.4          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.95           |
| Policy-TimeAlgoOpt      | 0.553          |
| Policy-TimeSampleProc   | 0.412          |
| Policy-TimeSampling     | 1.55           |
| Policy-TimeStep         | 2.57           |
| Time                    | 829            |
| n_timesteps             | 29000          |
--------------------------------------------

 ---------------- Iteration 29 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 290 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 291 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 292 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 293 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 294 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 295 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 296 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 297 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 298 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 299 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.432         |
| Data-EnvSampler-Poli... | 0.929         |
| Data-EnvTrajs-Averag... | 32.2          |
| Data-EnvTrajs-MaxReturn | 37.5          |
| Data-EnvTrajs-MinReturn | 27.1          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 3.43          |
| Data-TimeEnvSampleProc  | 0.00431       |
| Data-TimeEnvSampling    | 1.4           |
| Iteration               | 29            |
| ItrTime                 | 35.1          |
| LossAfter               | -0.0026486462 |
| LossBefore              | -8.85951e-06  |
| Model-TimeModelFit      | 30.9          |
| ModelSampler-n_times... | 1200000       |
| Policy-AverageAbsPol... | 1.7371509     |
| Policy-AverageDiscou... | 18.1          |
| Policy-AveragePolicyStd | 0.5996288     |
| Policy-AverageReturn    | 10.6          |
| Policy-MaxReturn        | 15.5          |
| Policy-MinReturn        | 6.79          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 2.45          |
| Policy-TimeAlgoOpt      | 0.591         |
| Policy-TimeSampleProc   | 0.461         |
| Policy-TimeSampling     | 1.68          |
| Policy-TimeStep         | 2.78          |
| Time                    | 864           |
| n_timesteps             | 30000         |
-------------------------------------------

 ---------------- Iteration 30 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 300 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 301 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 302 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 303 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 304 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 305 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 306 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 307 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 308 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 309 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.455         |
| Data-EnvSampler-Poli... | 0.964         |
| Data-EnvTrajs-Averag... | 32.4          |
| Data-EnvTrajs-MaxReturn | 35.4          |
| Data-EnvTrajs-MinReturn | 30.9          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.67          |
| Data-TimeEnvSampleProc  | 0.00107       |
| Data-TimeEnvSampling    | 1.46          |
| Iteration               | 30            |
| ItrTime                 | 35.2          |
| LossAfter               | -0.0025726391 |
| LossBefore              | -8.64518e-06  |
| Model-TimeModelFit      | 31.1          |
| ModelSampler-n_times... | 1240000       |
| Policy-AverageAbsPol... | 1.8390286     |
| Policy-AverageDiscou... | 20.7          |
| Policy-AveragePolicyStd | 0.58622634    |
| Policy-AverageReturn    | 21.7          |
| Policy-MaxReturn        | 31.7          |
| Policy-MinReturn        | 10.8          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 6.89          |
| Policy-TimeAlgoOpt      | 0.55          |
| Policy-TimeSampleProc   | 0.468         |
| Policy-TimeSampling     | 1.55          |
| Policy-TimeStep         | 2.6           |
| Time                    | 900           |
| n_timesteps             | 31000         |
-------------------------------------------

 ---------------- Iteration 31 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 310 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 311 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 312 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 313 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 314 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 315 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 316 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 317 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 318 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 319 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.462         |
| Data-EnvSampler-Poli... | 0.979         |
| Data-EnvTrajs-Averag... | 30.5          |
| Data-EnvTrajs-MaxReturn | 32.7          |
| Data-EnvTrajs-MinReturn | 27.3          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.76          |
| Data-TimeEnvSampleProc  | 0.00107       |
| Data-TimeEnvSampling    | 1.48          |
| Iteration               | 31            |
| ItrTime                 | 34.7          |
| LossAfter               | -0.0025864153 |
| LossBefore              | -8.381724e-06 |
| Model-TimeModelFit      | 30.6          |
| ModelSampler-n_times... | 1280000       |
| Policy-AverageAbsPol... | 1.8460969     |
| Policy-AverageDiscou... | 26.6          |
| Policy-AveragePolicyStd | 0.5725134     |
| Policy-AverageReturn    | 37.7          |
| Policy-MaxReturn        | 40.7          |
| Policy-MinReturn        | 33.5          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.86          |
| Policy-TimeAlgoOpt      | 0.619         |
| Policy-TimeSampleProc   | 0.275         |
| Policy-TimeSampling     | 1.64          |
| Policy-TimeStep         | 2.59          |
| Time                    | 934           |
| n_timesteps             | 32000         |
-------------------------------------------

 ---------------- Iteration 32 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 320 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 321 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 322 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 323 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 324 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 325 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 326 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 327 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 328 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 329 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.463         |
| Data-EnvSampler-Poli... | 0.979         |
| Data-EnvTrajs-Averag... | 31.8          |
| Data-EnvTrajs-MaxReturn | 35.3          |
| Data-EnvTrajs-MinReturn | 27            |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 2.81          |
| Data-TimeEnvSampleProc  | 0.000926      |
| Data-TimeEnvSampling    | 1.48          |
| Iteration               | 32            |
| ItrTime                 | 35.6          |
| LossAfter               | -0.0020131993 |
| LossBefore              | -8.163852e-06 |
| Model-TimeModelFit      | 31.4          |
| ModelSampler-n_times... | 1320000       |
| Policy-AverageAbsPol... | 1.8850764     |
| Policy-AverageDiscou... | 22.5          |
| Policy-AveragePolicyStd | 0.5603666     |
| Policy-AverageReturn    | 32.3          |
| Policy-MaxReturn        | 37.2          |
| Policy-MinReturn        | 28.8          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 2.22          |
| Policy-TimeAlgoOpt      | 0.558         |
| Policy-TimeSampleProc   | 0.487         |
| Policy-TimeSampling     | 1.67          |
| Policy-TimeStep         | 2.74          |
| Time                    | 970           |
| n_timesteps             | 33000         |
-------------------------------------------

 ---------------- Iteration 33 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 330 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 331 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 332 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 333 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 334 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 335 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 336 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 337 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 338 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 339 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.449         |
| Data-EnvSampler-Poli... | 0.993         |
| Data-EnvTrajs-Averag... | 34.5          |
| Data-EnvTrajs-MaxReturn | 36.4          |
| Data-EnvTrajs-MinReturn | 33            |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.21          |
| Data-TimeEnvSampleProc  | 0.00105       |
| Data-TimeEnvSampling    | 1.5           |
| Iteration               | 33            |
| ItrTime                 | 36            |
| LossAfter               | -0.0021071208 |
| LossBefore              | -7.897054e-06 |
| Model-TimeModelFit      | 31.7          |
| ModelSampler-n_times... | 1360000       |
| Policy-AverageAbsPol... | 2.036479      |
| Policy-AverageDiscou... | 30            |
| Policy-AveragePolicyStd | 0.5462609     |
| Policy-AverageReturn    | 41.6          |
| Policy-MaxReturn        | 49.8          |
| Policy-MinReturn        | 24.2          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 5.56          |
| Policy-TimeAlgoOpt      | 0.606         |
| Policy-TimeSampleProc   | 0.464         |
| Policy-TimeSampling     | 1.67          |
| Policy-TimeStep         | 2.75          |
| Time                    | 1.01e+03      |
| n_timesteps             | 34000         |
-------------------------------------------

 ---------------- Iteration 34 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 340 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 341 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 342 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 343 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 344 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 345 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 346 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 347 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 348 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 349 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.456          |
| Data-EnvSampler-Poli... | 0.956          |
| Data-EnvTrajs-Averag... | 36             |
| Data-EnvTrajs-MaxReturn | 37.1           |
| Data-EnvTrajs-MinReturn | 34.1           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.14           |
| Data-TimeEnvSampleProc  | 0.00103        |
| Data-TimeEnvSampling    | 1.45           |
| Iteration               | 34             |
| ItrTime                 | 35.8           |
| LossAfter               | -0.0046403785  |
| LossBefore              | -7.6833385e-06 |
| Model-TimeModelFit      | 31.7           |
| ModelSampler-n_times... | 1400000        |
| Policy-AverageAbsPol... | 1.9927056      |
| Policy-AverageDiscou... | 29.6           |
| Policy-AveragePolicyStd | 0.535828       |
| Policy-AverageReturn    | 42.5           |
| Policy-MaxReturn        | 47.3           |
| Policy-MinReturn        | 33.8           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 3.12           |
| Policy-TimeAlgoOpt      | 0.564          |
| Policy-TimeSampleProc   | 0.41           |
| Policy-TimeSampling     | 1.6            |
| Policy-TimeStep         | 2.59           |
| Time                    | 1.04e+03       |
| n_timesteps             | 35000          |
--------------------------------------------

 ---------------- Iteration 35 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 350 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 351 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 352 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 353 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 354 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 355 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 356 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 357 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 358 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 359 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.422          |
| Data-EnvSampler-Poli... | 0.835          |
| Data-EnvTrajs-Averag... | 34.9           |
| Data-EnvTrajs-MaxReturn | 36.4           |
| Data-EnvTrajs-MinReturn | 32.7           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.33           |
| Data-TimeEnvSampleProc  | 0.000996       |
| Data-TimeEnvSampling    | 1.3            |
| Iteration               | 35             |
| ItrTime                 | 36.2           |
| LossAfter               | -0.00019451015 |
| LossBefore              | -7.5065013e-06 |
| Model-TimeModelFit      | 32.2           |
| ModelSampler-n_times... | 1440000        |
| Policy-AverageAbsPol... | 1.8808923      |
| Policy-AverageDiscou... | 26.8           |
| Policy-AveragePolicyStd | 0.52630395     |
| Policy-AverageReturn    | 39.7           |
| Policy-MaxReturn        | 46.2           |
| Policy-MinReturn        | 34.1           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.62           |
| Policy-TimeAlgoOpt      | 0.592          |
| Policy-TimeSampleProc   | 0.431          |
| Policy-TimeSampling     | 1.67           |
| Policy-TimeStep         | 2.72           |
| Time                    | 1.08e+03       |
| n_timesteps             | 36000          |
--------------------------------------------

 ---------------- Iteration 36 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 360 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 361 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 362 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 363 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 364 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 365 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 366 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 367 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 368 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 369 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.485          |
| Data-EnvSampler-Poli... | 1              |
| Data-EnvTrajs-Averag... | 35             |
| Data-EnvTrajs-MaxReturn | 36.8           |
| Data-EnvTrajs-MinReturn | 33.6           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.33           |
| Data-TimeEnvSampleProc  | 0.00108        |
| Data-TimeEnvSampling    | 1.53           |
| Iteration               | 36             |
| ItrTime                 | 36.1           |
| LossAfter               | 0.00047435093  |
| LossBefore              | -7.3608944e-06 |
| Model-TimeModelFit      | 32             |
| ModelSampler-n_times... | 1480000        |
| Policy-AverageAbsPol... | 1.7897527      |
| Policy-AverageDiscou... | 27.7           |
| Policy-AveragePolicyStd | 0.52251256     |
| Policy-AverageReturn    | 44.7           |
| Policy-MaxReturn        | 54.5           |
| Policy-MinReturn        | 28.4           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 6.49           |
| Policy-TimeAlgoOpt      | 0.609          |
| Policy-TimeSampleProc   | 0.366          |
| Policy-TimeSampling     | 1.57           |
| Policy-TimeStep         | 2.57           |
| Time                    | 1.11e+03       |
| n_timesteps             | 37000          |
--------------------------------------------

 ---------------- Iteration 37 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 370 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 371 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 372 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 373 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 374 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 375 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 376 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 377 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 378 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 379 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.447          |
| Data-EnvSampler-Poli... | 0.929          |
| Data-EnvTrajs-Averag... | 34.7           |
| Data-EnvTrajs-MaxReturn | 36.2           |
| Data-EnvTrajs-MinReturn | 32.7           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.32           |
| Data-TimeEnvSampleProc  | 0.00109        |
| Data-TimeEnvSampling    | 1.42           |
| Iteration               | 37             |
| ItrTime                 | 35.8           |
| LossAfter               | -0.0033781503  |
| LossBefore              | -6.9744206e-06 |
| Model-TimeModelFit      | 31.7           |
| ModelSampler-n_times... | 1520000        |
| Policy-AverageAbsPol... | 1.7721262      |
| Policy-AverageDiscou... | 25.9           |
| Policy-AveragePolicyStd | 0.5043274      |
| Policy-AverageReturn    | 42.2           |
| Policy-MaxReturn        | 47.3           |
| Policy-MinReturn        | 37.2           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.56           |
| Policy-TimeAlgoOpt      | 0.597          |
| Policy-TimeSampleProc   | 0.43           |
| Policy-TimeSampling     | 1.55           |
| Policy-TimeStep         | 2.61           |
| Time                    | 1.15e+03       |
| n_timesteps             | 38000          |
--------------------------------------------

 ---------------- Iteration 38 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 380 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 381 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 382 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 383 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 384 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 385 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 386 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 387 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 388 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 389 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.408          |
| Data-EnvSampler-Poli... | 0.873          |
| Data-EnvTrajs-Averag... | 35.7           |
| Data-EnvTrajs-MaxReturn | 36.7           |
| Data-EnvTrajs-MinReturn | 34.5           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 0.828          |
| Data-TimeEnvSampleProc  | 0.00109        |
| Data-TimeEnvSampling    | 1.32           |
| Iteration               | 38             |
| ItrTime                 | 36             |
| LossAfter               | -0.0032500587  |
| LossBefore              | -6.5784975e-06 |
| Model-TimeModelFit      | 32             |
| ModelSampler-n_times... | 1560000        |
| Policy-AverageAbsPol... | 1.7599081      |
| Policy-AverageDiscou... | 27.1           |
| Policy-AveragePolicyStd | 0.4891214      |
| Policy-AverageReturn    | 33.3           |
| Policy-MaxReturn        | 48.3           |
| Policy-MinReturn        | 19.8           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 6.04           |
| Policy-TimeAlgoOpt      | 0.615          |
| Policy-TimeSampleProc   | 0.426          |
| Policy-TimeSampling     | 1.58           |
| Policy-TimeStep         | 2.68           |
| Time                    | 1.19e+03       |
| n_timesteps             | 39000          |
--------------------------------------------

 ---------------- Iteration 39 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 390 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 391 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 392 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 393 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 394 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 395 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 396 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 397 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 398 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 399 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.412          |
| Data-EnvSampler-Poli... | 0.945          |
| Data-EnvTrajs-Averag... | 36             |
| Data-EnvTrajs-MaxReturn | 38.1           |
| Data-EnvTrajs-MinReturn | 35.2           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.04           |
| Data-TimeEnvSampleProc  | 0.000915       |
| Data-TimeEnvSampling    | 1.39           |
| Iteration               | 39             |
| ItrTime                 | 36.1           |
| LossAfter               | -0.0027379724  |
| LossBefore              | -6.4295236e-06 |
| Model-TimeModelFit      | 31.9           |
| ModelSampler-n_times... | 1600000        |
| Policy-AverageAbsPol... | 1.877499       |
| Policy-AverageDiscou... | 21.5           |
| Policy-AveragePolicyStd | 0.4857679      |
| Policy-AverageReturn    | 10.6           |
| Policy-MaxReturn        | 32.4           |
| Policy-MinReturn        | -4.73          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 9.19           |
| Policy-TimeAlgoOpt      | 0.574          |
| Policy-TimeSampleProc   | 0.494          |
| Policy-TimeSampling     | 1.62           |
| Policy-TimeStep         | 2.73           |
| Time                    | 1.22e+03       |
| n_timesteps             | 40000          |
--------------------------------------------

 ---------------- Iteration 40 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 400 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 401 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 402 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 403 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 404 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 405 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 406 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 407 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 408 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 409 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.407         |
| Data-EnvSampler-Poli... | 0.869         |
| Data-EnvTrajs-Averag... | 35            |
| Data-EnvTrajs-MaxReturn | 36.6          |
| Data-EnvTrajs-MinReturn | 32.8          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.26          |
| Data-TimeEnvSampleProc  | 0.00133       |
| Data-TimeEnvSampling    | 1.32          |
| Iteration               | 40            |
| ItrTime                 | 36.3          |
| LossAfter               | -0.0028401706 |
| LossBefore              | -6.358851e-06 |
| Model-TimeModelFit      | 32.2          |
| ModelSampler-n_times... | 1640000       |
| Policy-AverageAbsPol... | 1.834478      |
| Policy-AverageDiscou... | 23.6          |
| Policy-AveragePolicyStd | 0.4847553     |
| Policy-AverageReturn    | 29.3          |
| Policy-MaxReturn        | 33            |
| Policy-MinReturn        | 24.7          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 2.19          |
| Policy-TimeAlgoOpt      | 0.642         |
| Policy-TimeSampleProc   | 0.398         |
| Policy-TimeSampling     | 1.67          |
| Policy-TimeStep         | 2.75          |
| Time                    | 1.26e+03      |
| n_timesteps             | 41000         |
-------------------------------------------

 ---------------- Iteration 41 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 410 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 411 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 412 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 413 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 414 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 415 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 416 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 417 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 418 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 419 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.414         |
| Data-EnvSampler-Poli... | 0.962         |
| Data-EnvTrajs-Averag... | 36.5          |
| Data-EnvTrajs-MaxReturn | 37.5          |
| Data-EnvTrajs-MinReturn | 35.7          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 0.651         |
| Data-TimeEnvSampleProc  | 0.00147       |
| Data-TimeEnvSampling    | 1.41          |
| Iteration               | 41            |
| ItrTime                 | 36.3          |
| LossAfter               | 0.0049735117  |
| LossBefore              | -6.256325e-06 |
| Model-TimeModelFit      | 32.2          |
| ModelSampler-n_times... | 1680000       |
| Policy-AverageAbsPol... | 1.9194963     |
| Policy-AverageDiscou... | 34.6          |
| Policy-AveragePolicyStd | 0.48463666    |
| Policy-AverageReturn    | 70.5          |
| Policy-MaxReturn        | 78.4          |
| Policy-MinReturn        | 60.9          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 4.31          |
| Policy-TimeAlgoOpt      | 0.571         |
| Policy-TimeSampleProc   | 0.422         |
| Policy-TimeSampling     | 1.68          |
| Policy-TimeStep         | 2.74          |
| Time                    | 1.29e+03      |
| n_timesteps             | 42000         |
-------------------------------------------

 ---------------- Iteration 42 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 420 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 421 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 422 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 423 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 424 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 425 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 426 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 427 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 428 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 429 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.39          |
| Data-EnvSampler-Poli... | 0.932         |
| Data-EnvTrajs-Averag... | 32.9          |
| Data-EnvTrajs-MaxReturn | 34.5          |
| Data-EnvTrajs-MinReturn | 31.3          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.11          |
| Data-TimeEnvSampleProc  | 0.00109       |
| Data-TimeEnvSampling    | 1.36          |
| Iteration               | 42            |
| ItrTime                 | 37.6          |
| LossAfter               | -0.0025382617 |
| LossBefore              | -6.014974e-06 |
| Model-TimeModelFit      | 33.7          |
| ModelSampler-n_times... | 1720000       |
| Policy-AverageAbsPol... | 2.0983975     |
| Policy-AverageDiscou... | 28.5          |
| Policy-AveragePolicyStd | 0.4745981     |
| Policy-AverageReturn    | 48.1          |
| Policy-MaxReturn        | 52.7          |
| Policy-MinReturn        | 36.7          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 3.93          |
| Policy-TimeAlgoOpt      | 0.561         |
| Policy-TimeSampleProc   | 0.357         |
| Policy-TimeSampling     | 1.56          |
| Policy-TimeStep         | 2.53          |
| Time                    | 1.33e+03      |
| n_timesteps             | 43000         |
-------------------------------------------

 ---------------- Iteration 43 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 430 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 431 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 432 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 433 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 434 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 435 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 436 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 437 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 438 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 439 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.427         |
| Data-EnvSampler-Poli... | 0.949         |
| Data-EnvTrajs-Averag... | 31.7          |
| Data-EnvTrajs-MaxReturn | 34            |
| Data-EnvTrajs-MinReturn | 29.8          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.4           |
| Data-TimeEnvSampleProc  | 0.0012        |
| Data-TimeEnvSampling    | 1.42          |
| Iteration               | 43            |
| ItrTime                 | 37            |
| LossAfter               | -0.003578274  |
| LossBefore              | -5.782957e-06 |
| Model-TimeModelFit      | 33            |
| ModelSampler-n_times... | 1760000       |
| Policy-AverageAbsPol... | 2.1767085     |
| Policy-AverageDiscou... | 32            |
| Policy-AveragePolicyStd | 0.46905255    |
| Policy-AverageReturn    | 57.5          |
| Policy-MaxReturn        | 61.4          |
| Policy-MinReturn        | 50.6          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 2.69          |
| Policy-TimeAlgoOpt      | 0.591         |
| Policy-TimeSampleProc   | 0.4           |
| Policy-TimeSampling     | 1.62          |
| Policy-TimeStep         | 2.64          |
| Time                    | 1.37e+03      |
| n_timesteps             | 44000         |
-------------------------------------------

 ---------------- Iteration 44 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 440 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 441 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 442 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 443 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 444 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 445 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 446 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 447 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 448 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 449 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.38           |
| Data-EnvSampler-Poli... | 0.887          |
| Data-EnvTrajs-Averag... | 31.8           |
| Data-EnvTrajs-MaxReturn | 34             |
| Data-EnvTrajs-MinReturn | 29.5           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.49           |
| Data-TimeEnvSampleProc  | 0.00134        |
| Data-TimeEnvSampling    | 1.3            |
| Iteration               | 44             |
| ItrTime                 | 37.3           |
| LossAfter               | -0.003001548   |
| LossBefore              | -5.4746197e-06 |
| Model-TimeModelFit      | 33.4           |
| ModelSampler-n_times... | 1800000        |
| Policy-AverageAbsPol... | 2.0671558      |
| Policy-AverageDiscou... | 25.9           |
| Policy-AveragePolicyStd | 0.4546588      |
| Policy-AverageReturn    | 30.9           |
| Policy-MaxReturn        | 33.1           |
| Policy-MinReturn        | 27.5           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.48           |
| Policy-TimeAlgoOpt      | 0.617          |
| Policy-TimeSampleProc   | 0.394          |
| Policy-TimeSampling     | 1.58           |
| Policy-TimeStep         | 2.62           |
| Time                    | 1.41e+03       |
| n_timesteps             | 45000          |
--------------------------------------------

 ---------------- Iteration 45 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 450 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 451 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 452 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 453 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 454 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 455 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 456 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 457 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 458 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 459 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.394          |
| Data-EnvSampler-Poli... | 0.867          |
| Data-EnvTrajs-Averag... | 32.6           |
| Data-EnvTrajs-MaxReturn | 34             |
| Data-EnvTrajs-MinReturn | 30.6           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.26           |
| Data-TimeEnvSampleProc  | 0.000656       |
| Data-TimeEnvSampling    | 1.3            |
| Iteration               | 45             |
| ItrTime                 | 37.7           |
| LossAfter               | -0.003545627   |
| LossBefore              | -5.1147595e-06 |
| Model-TimeModelFit      | 33.6           |
| ModelSampler-n_times... | 1840000        |
| Policy-AverageAbsPol... | 2.078919       |
| Policy-AverageDiscou... | 29.3           |
| Policy-AveragePolicyStd | 0.44121343     |
| Policy-AverageReturn    | 46.7           |
| Policy-MaxReturn        | 64.5           |
| Policy-MinReturn        | 35.2           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 7.62           |
| Policy-TimeAlgoOpt      | 0.617          |
| Policy-TimeSampleProc   | 0.484          |
| Policy-TimeSampling     | 1.66           |
| Policy-TimeStep         | 2.78           |
| Time                    | 1.44e+03       |
| n_timesteps             | 46000          |
--------------------------------------------

 ---------------- Iteration 46 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 460 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 461 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 462 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 463 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 464 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 465 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 466 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 467 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 468 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 469 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.398         |
| Data-EnvSampler-Poli... | 0.934         |
| Data-EnvTrajs-Averag... | 33.6          |
| Data-EnvTrajs-MaxReturn | 35.2          |
| Data-EnvTrajs-MinReturn | 32.2          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.06          |
| Data-TimeEnvSampleProc  | 0.000875      |
| Data-TimeEnvSampling    | 1.38          |
| Iteration               | 46            |
| ItrTime                 | 37.1          |
| LossAfter               | -0.0084045585 |
| LossBefore              | -4.664062e-06 |
| Model-TimeModelFit      | 33            |
| ModelSampler-n_times... | 1880000       |
| Policy-AverageAbsPol... | 2.1279907     |
| Policy-AverageDiscou... | 27.6          |
| Policy-AveragePolicyStd | 0.4242913     |
| Policy-AverageReturn    | 37.1          |
| Policy-MaxReturn        | 45.3          |
| Policy-MinReturn        | 29.6          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 3.87          |
| Policy-TimeAlgoOpt      | 0.627         |
| Policy-TimeSampleProc   | 0.393         |
| Policy-TimeSampling     | 1.57          |
| Policy-TimeStep         | 2.63          |
| Time                    | 1.48e+03      |
| n_timesteps             | 47000         |
-------------------------------------------

 ---------------- Iteration 47 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 470 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 471 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 472 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 473 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 474 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 475 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 476 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 477 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 478 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 479 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.424         |
| Data-EnvSampler-Poli... | 0.909         |
| Data-EnvTrajs-Averag... | 32.8          |
| Data-EnvTrajs-MaxReturn | 34.8          |
| Data-EnvTrajs-MinReturn | 31.3          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.32          |
| Data-TimeEnvSampleProc  | 0.00127       |
| Data-TimeEnvSampling    | 1.37          |
| Iteration               | 47            |
| ItrTime                 | 37.6          |
| LossAfter               | -0.005572088  |
| LossBefore              | -4.633512e-06 |
| Model-TimeModelFit      | 33.7          |
| ModelSampler-n_times... | 1920000       |
| Policy-AverageAbsPol... | 2.0952394     |
| Policy-AverageDiscou... | 26.4          |
| Policy-AveragePolicyStd | 0.42236063    |
| Policy-AverageReturn    | 34.1          |
| Policy-MaxReturn        | 37.7          |
| Policy-MinReturn        | 30.4          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.68          |
| Policy-TimeAlgoOpt      | 0.573         |
| Policy-TimeSampleProc   | 0.352         |
| Policy-TimeSampling     | 1.59          |
| Policy-TimeStep         | 2.54          |
| Time                    | 1.52e+03      |
| n_timesteps             | 48000         |
-------------------------------------------

 ---------------- Iteration 48 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 480 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 481 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 482 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 483 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 484 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 485 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 486 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 487 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 488 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 489 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.403         |
| Data-EnvSampler-Poli... | 0.961         |
| Data-EnvTrajs-Averag... | 31.7          |
| Data-EnvTrajs-MaxReturn | 33.3          |
| Data-EnvTrajs-MinReturn | 30.1          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.29          |
| Data-TimeEnvSampleProc  | 0.00107       |
| Data-TimeEnvSampling    | 1.4           |
| Iteration               | 48            |
| ItrTime                 | 37.8          |
| LossAfter               | -0.0030756053 |
| LossBefore              | -4.32474e-06  |
| Model-TimeModelFit      | 33.5          |
| ModelSampler-n_times... | 1960000       |
| Policy-AverageAbsPol... | 1.9218334     |
| Policy-AverageDiscou... | 36.3          |
| Policy-AveragePolicyStd | 0.41060835    |
| Policy-AverageReturn    | 59.3          |
| Policy-MaxReturn        | 70.4          |
| Policy-MinReturn        | 46.1          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 5.62          |
| Policy-TimeAlgoOpt      | 0.594         |
| Policy-TimeSampleProc   | 0.489         |
| Policy-TimeSampling     | 1.69          |
| Policy-TimeStep         | 2.86          |
| Time                    | 1.56e+03      |
| n_timesteps             | 49000         |
-------------------------------------------

 ---------------- Iteration 49 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 490 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 491 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 492 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 493 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 494 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 495 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 496 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 497 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 498 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 499 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.375         |
| Data-EnvSampler-Poli... | 0.848         |
| Data-EnvTrajs-Averag... | 30.9          |
| Data-EnvTrajs-MaxReturn | 32.5          |
| Data-EnvTrajs-MinReturn | 29.6          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.07          |
| Data-TimeEnvSampleProc  | 0.00117       |
| Data-TimeEnvSampling    | 1.26          |
| Iteration               | 49            |
| ItrTime                 | 37.8          |
| LossAfter               | -0.0056340112 |
| LossBefore              | -4.18724e-06  |
| Model-TimeModelFit      | 33.7          |
| ModelSampler-n_times... | 2000000       |
| Policy-AverageAbsPol... | 2.120154      |
| Policy-AverageDiscou... | 28.3          |
| Policy-AveragePolicyStd | 0.4066947     |
| Policy-AverageReturn    | 36.7          |
| Policy-MaxReturn        | 45.4          |
| Policy-MinReturn        | 28            |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 4.46          |
| Policy-TimeAlgoOpt      | 0.561         |
| Policy-TimeSampleProc   | 0.503         |
| Policy-TimeSampling     | 1.72          |
| Policy-TimeStep         | 2.83          |
| Time                    | 1.59e+03      |
| n_timesteps             | 50000         |
-------------------------------------------

 ---------------- Iteration 50 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 500 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 501 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 502 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 503 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 504 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 505 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 506 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 507 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 508 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 509 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.394         |
| Data-EnvSampler-Poli... | 0.926         |
| Data-EnvTrajs-Averag... | 30.6          |
| Data-EnvTrajs-MaxReturn | 32.1          |
| Data-EnvTrajs-MinReturn | 29.9          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 0.767         |
| Data-TimeEnvSampleProc  | 0.0011        |
| Data-TimeEnvSampling    | 1.35          |
| Iteration               | 50            |
| ItrTime                 | 32.7          |
| LossAfter               | -0.0041882247 |
| LossBefore              | -3.943134e-06 |
| Model-TimeModelFit      | 29.2          |
| ModelSampler-n_times... | 2040000       |
| Policy-AverageAbsPol... | 2.1668756     |
| Policy-AverageDiscou... | 30.1          |
| Policy-AveragePolicyStd | 0.4015578     |
| Policy-AverageReturn    | 48.7          |
| Policy-MaxReturn        | 60.9          |
| Policy-MinReturn        | 40.7          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 6             |
| Policy-TimeAlgoOpt      | 0.515         |
| Policy-TimeSampleProc   | 0.288         |
| Policy-TimeSampling     | 1.27          |
| Policy-TimeStep         | 2.1           |
| Time                    | 1.63e+03      |
| n_timesteps             | 51000         |
-------------------------------------------
Training finished
