Logging to /home/vincent/workplace/CS_287_-_Advanced_Robotics/homework/hw5/cs287hw5/ppo/run_scripts/data/parallel_mb_ppo/mbppo_Swimmer_l1//01

 ---------------- Iteration 0 ----------------
Obtaining random samples from the environment...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 0 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 1 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 2 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 3 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 4 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 5 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 6 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 7 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 8 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 9 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.137          |
| Data-EnvSampler-Poli... | 0.0424         |
| Data-EnvTrajs-Averag... | -0.58          |
| Data-EnvTrajs-MaxReturn | 2.64           |
| Data-EnvTrajs-MinReturn | -4.08          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.44           |
| Data-TimeEnvSampleProc  | 0.000539       |
| Data-TimeEnvSampling    | 0.19           |
| Iteration               | 0              |
| ItrTime                 | 9.45           |
| LossAfter               | -0.0062704026  |
| LossBefore              | -1.4080016e-05 |
| Model-TimeModelFit      | 3.27           |
| ModelSampler-n_times... | 40000          |
| Policy-AverageAbsPol... | 0.9351195      |
| Policy-AverageDiscou... | -122           |
| Policy-AveragePolicyStd | 0.99057496     |
| Policy-AverageReturn    | -493           |
| Policy-MaxReturn        | 30.5           |
| Policy-MinReturn        | -1.23e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 480            |
| Policy-TimeAlgoOpt      | 1.11           |
| Policy-TimeSampleProc   | 0.59           |
| Policy-TimeSampling     | 4.25           |
| Policy-TimeStep         | 5.99           |
| Time                    | 9.45           |
| n_timesteps             | 1000           |
--------------------------------------------

 ---------------- Iteration 1 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 10 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 11 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 12 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 13 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 14 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 15 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 16 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 17 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 18 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 19 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.261         |
| Data-EnvSampler-Poli... | 0.58          |
| Data-EnvTrajs-Averag... | -8.09         |
| Data-EnvTrajs-MaxReturn | -5.53         |
| Data-EnvTrajs-MinReturn | -12.1         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 2.22          |
| Data-TimeEnvSampleProc  | 0.000684      |
| Data-TimeEnvSampling    | 0.864         |
| Iteration               | 1             |
| ItrTime                 | 8.26          |
| LossAfter               | -0.0044330414 |
| LossBefore              | -1.39897e-05  |
| Model-TimeModelFit      | 4.81          |
| ModelSampler-n_times... | 80000         |
| Policy-AverageAbsPol... | 0.33587238    |
| Policy-AverageDiscou... | -12.7         |
| Policy-AveragePolicyStd | 0.9822552     |
| Policy-AverageReturn    | -41.2         |
| Policy-MaxReturn        | 10.6          |
| Policy-MinReturn        | -119          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 42.7          |
| Policy-TimeAlgoOpt      | 0.555         |
| Policy-TimeSampleProc   | 0.492         |
| Policy-TimeSampling     | 1.5           |
| Policy-TimeStep         | 2.58          |
| Time                    | 17.8          |
| n_timesteps             | 2000          |
-------------------------------------------

 ---------------- Iteration 2 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 20 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 21 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 22 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 23 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 24 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 25 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 26 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 27 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 28 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 29 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.305          |
| Data-EnvSampler-Poli... | 0.598          |
| Data-EnvTrajs-Averag... | -10.2          |
| Data-EnvTrajs-MaxReturn | -7.47          |
| Data-EnvTrajs-MinReturn | -13.7          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.2            |
| Data-TimeEnvSampleProc  | 0.001          |
| Data-TimeEnvSampling    | 0.93           |
| Iteration               | 2              |
| ItrTime                 | 10.4           |
| LossAfter               | -0.0039892793  |
| LossBefore              | -1.3941964e-05 |
| Model-TimeModelFit      | 6.89           |
| ModelSampler-n_times... | 120000         |
| Policy-AverageAbsPol... | 0.30803856     |
| Policy-AverageDiscou... | -14.2          |
| Policy-AveragePolicyStd | 0.97612756     |
| Policy-AverageReturn    | -166           |
| Policy-MaxReturn        | 311            |
| Policy-MinReturn        | -1.37e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 503            |
| Policy-TimeAlgoOpt      | 0.584          |
| Policy-TimeSampleProc   | 0.228          |
| Policy-TimeSampling     | 1.72           |
| Policy-TimeStep         | 2.54           |
| Time                    | 28.2           |
| n_timesteps             | 3000           |
--------------------------------------------

 ---------------- Iteration 3 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 30 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 31 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 32 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 33 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 34 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 35 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 36 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 37 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 38 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 39 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.3            |
| Data-EnvSampler-Poli... | 0.64           |
| Data-EnvTrajs-Averag... | 3.05           |
| Data-EnvTrajs-MaxReturn | 19.4           |
| Data-EnvTrajs-MinReturn | -3.86          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 8.48           |
| Data-TimeEnvSampleProc  | 0.000961       |
| Data-TimeEnvSampling    | 0.969          |
| Iteration               | 3              |
| ItrTime                 | 13.5           |
| LossAfter               | -0.0026760253  |
| LossBefore              | -1.3604756e-05 |
| Model-TimeModelFit      | 9.87           |
| ModelSampler-n_times... | 160000         |
| Policy-AverageAbsPol... | 0.6440342      |
| Policy-AverageDiscou... | 239            |
| Policy-AveragePolicyStd | 0.9457421      |
| Policy-AverageReturn    | 1.3e+03        |
| Policy-MaxReturn        | 2.82e+03       |
| Policy-MinReturn        | 7.6            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 849            |
| Policy-TimeAlgoOpt      | 0.564          |
| Policy-TimeSampleProc   | 0.424          |
| Policy-TimeSampling     | 1.63           |
| Policy-TimeStep         | 2.64           |
| Time                    | 41.7           |
| n_timesteps             | 4000           |
--------------------------------------------

 ---------------- Iteration 4 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 40 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 41 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 42 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 43 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 44 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 45 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 46 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 47 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 48 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 49 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.311          |
| Data-EnvSampler-Poli... | 0.69           |
| Data-EnvTrajs-Averag... | -3.29          |
| Data-EnvTrajs-MaxReturn | 0.988          |
| Data-EnvTrajs-MinReturn | -9.42          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 3.44           |
| Data-TimeEnvSampleProc  | 0.000741       |
| Data-TimeEnvSampling    | 1.03           |
| Iteration               | 4              |
| ItrTime                 | 15.5           |
| LossAfter               | -0.002222327   |
| LossBefore              | -1.3458125e-05 |
| Model-TimeModelFit      | 11.9           |
| ModelSampler-n_times... | 200000         |
| Policy-AverageAbsPol... | 0.48732287     |
| Policy-AverageDiscou... | 87.1           |
| Policy-AveragePolicyStd | 0.9301753      |
| Policy-AverageReturn    | 671            |
| Policy-MaxReturn        | 2.52e+03       |
| Policy-MinReturn        | -140           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 792            |
| Policy-TimeAlgoOpt      | 0.565          |
| Policy-TimeSampleProc   | 0.488          |
| Policy-TimeSampling     | 1.58           |
| Policy-TimeStep         | 2.65           |
| Time                    | 57.3           |
| n_timesteps             | 5000           |
--------------------------------------------

 ---------------- Iteration 5 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 50 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 51 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 52 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 53 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 54 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 55 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 56 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 57 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 58 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 59 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.331          |
| Data-EnvSampler-Poli... | 0.68           |
| Data-EnvTrajs-Averag... | -5.31          |
| Data-EnvTrajs-MaxReturn | 0.0791         |
| Data-EnvTrajs-MinReturn | -9.92          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 3.51           |
| Data-TimeEnvSampleProc  | 0.000715       |
| Data-TimeEnvSampling    | 1.04           |
| Iteration               | 5              |
| ItrTime                 | 16.5           |
| LossAfter               | -0.0033455647  |
| LossBefore              | -1.3275293e-05 |
| Model-TimeModelFit      | 13.1           |
| ModelSampler-n_times... | 240000         |
| Policy-AverageAbsPol... | 0.7890499      |
| Policy-AverageDiscou... | 12.1           |
| Policy-AveragePolicyStd | 0.9121814      |
| Policy-AverageReturn    | 5.11           |
| Policy-MaxReturn        | 38.4           |
| Policy-MinReturn        | -37.7          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 21.8           |
| Policy-TimeAlgoOpt      | 0.527          |
| Policy-TimeSampleProc   | 0.336          |
| Policy-TimeSampling     | 1.45           |
| Policy-TimeStep         | 2.36           |
| Time                    | 73.8           |
| n_timesteps             | 6000           |
--------------------------------------------

 ---------------- Iteration 6 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 60 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 61 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 62 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 63 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 64 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 65 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 66 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 67 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 68 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 69 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.315          |
| Data-EnvSampler-Poli... | 0.607          |
| Data-EnvTrajs-Averag... | 22.8           |
| Data-EnvTrajs-MaxReturn | 27             |
| Data-EnvTrajs-MinReturn | 18.9           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.77           |
| Data-TimeEnvSampleProc  | 0.000867       |
| Data-TimeEnvSampling    | 0.95           |
| Iteration               | 6              |
| ItrTime                 | 19.8           |
| LossAfter               | -0.005004948   |
| LossBefore              | -1.2843356e-05 |
| Model-TimeModelFit      | 16.3           |
| ModelSampler-n_times... | 280000         |
| Policy-AverageAbsPol... | 0.8511284      |
| Policy-AverageDiscou... | 13.8           |
| Policy-AveragePolicyStd | 0.87681115     |
| Policy-AverageReturn    | 21.4           |
| Policy-MaxReturn        | 34.6           |
| Policy-MinReturn        | -12.2          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 10.6           |
| Policy-TimeAlgoOpt      | 0.54           |
| Policy-TimeSampleProc   | 0.348          |
| Policy-TimeSampling     | 1.62           |
| Policy-TimeStep         | 2.53           |
| Time                    | 93.6           |
| n_timesteps             | 7000           |
--------------------------------------------

 ---------------- Iteration 7 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 70 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 71 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 72 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 73 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 74 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 75 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 76 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 77 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 78 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 79 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.334          |
| Data-EnvSampler-Poli... | 0.686          |
| Data-EnvTrajs-Averag... | 28.6           |
| Data-EnvTrajs-MaxReturn | 31.2           |
| Data-EnvTrajs-MinReturn | 22.4           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 3.24           |
| Data-TimeEnvSampleProc  | 0.000626       |
| Data-TimeEnvSampling    | 1.06           |
| Iteration               | 7              |
| ItrTime                 | 22.4           |
| LossAfter               | -0.001224307   |
| LossBefore              | -1.2462823e-05 |
| Model-TimeModelFit      | 18.8           |
| ModelSampler-n_times... | 320000         |
| Policy-AverageAbsPol... | 1.0156326      |
| Policy-AverageDiscou... | 24.7           |
| Policy-AveragePolicyStd | 0.8432446      |
| Policy-AverageReturn    | 51.3           |
| Policy-MaxReturn        | 66.6           |
| Policy-MinReturn        | 36.8           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 7.93           |
| Policy-TimeAlgoOpt      | 0.603          |
| Policy-TimeSampleProc   | 0.425          |
| Policy-TimeSampling     | 1.4            |
| Policy-TimeStep         | 2.45           |
| Time                    | 116            |
| n_timesteps             | 8000           |
--------------------------------------------

 ---------------- Iteration 8 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 80 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 81 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 82 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 83 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 84 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 85 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 86 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 87 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 88 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 89 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Data-EnvSampler-EnvE... | 0.342        |
| Data-EnvSampler-Poli... | 0.7          |
| Data-EnvTrajs-Averag... | 31.9         |
| Data-EnvTrajs-MaxReturn | 35.5         |
| Data-EnvTrajs-MinReturn | 27.8         |
| Data-EnvTrajs-NumTrajs  | 5            |
| Data-EnvTrajs-StdReturn | 3            |
| Data-TimeEnvSampleProc  | 0.00104      |
| Data-TimeEnvSampling    | 1.07         |
| Iteration               | 8            |
| ItrTime                 | 24.2         |
| LossAfter               | -0.00486253  |
| LossBefore              | -1.19418e-05 |
| Model-TimeModelFit      | 20.6         |
| ModelSampler-n_times... | 360000       |
| Policy-AverageAbsPol... | 1.0354674    |
| Policy-AverageDiscou... | 40.7         |
| Policy-AveragePolicyStd | 0.8024139    |
| Policy-AverageReturn    | 95.1         |
| Policy-MaxReturn        | 121          |
| Policy-MinReturn        | 73.4         |
| Policy-NumTrajs         | 20           |
| Policy-StdReturn        | 12.6         |
| Policy-TimeAlgoOpt      | 0.6          |
| Policy-TimeSampleProc   | 0.302        |
| Policy-TimeSampling     | 1.66         |
| Policy-TimeStep         | 2.58         |
| Time                    | 140          |
| n_timesteps             | 9000         |
------------------------------------------

 ---------------- Iteration 9 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 90 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 91 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 92 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 93 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 94 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 95 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 96 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 97 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 98 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 99 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.356          |
| Data-EnvSampler-Poli... | 0.72           |
| Data-EnvTrajs-Averag... | 29.2           |
| Data-EnvTrajs-MaxReturn | 31.5           |
| Data-EnvTrajs-MinReturn | 26.7           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.58           |
| Data-TimeEnvSampleProc  | 0.00115        |
| Data-TimeEnvSampling    | 1.11           |
| Iteration               | 9              |
| ItrTime                 | 26.6           |
| LossAfter               | -0.0023734737  |
| LossBefore              | -1.1528309e-05 |
| Model-TimeModelFit      | 23             |
| ModelSampler-n_times... | 400000         |
| Policy-AverageAbsPol... | 1.0738056      |
| Policy-AverageDiscou... | 18.1           |
| Policy-AveragePolicyStd | 0.7683467      |
| Policy-AverageReturn    | 31.5           |
| Policy-MaxReturn        | 36.3           |
| Policy-MinReturn        | 15.2           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 5.14           |
| Policy-TimeAlgoOpt      | 0.564          |
| Policy-TimeSampleProc   | 0.455          |
| Policy-TimeSampling     | 1.4            |
| Policy-TimeStep         | 2.44           |
| Time                    | 167            |
| n_timesteps             | 10000          |
--------------------------------------------

 ---------------- Iteration 10 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 100 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 101 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 102 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 103 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 104 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 105 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 106 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 107 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 108 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 109 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.313         |
| Data-EnvSampler-Poli... | 0.633         |
| Data-EnvTrajs-Averag... | 28.9          |
| Data-EnvTrajs-MaxReturn | 30.4          |
| Data-EnvTrajs-MinReturn | 26.4          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.44          |
| Data-TimeEnvSampleProc  | 0.00059       |
| Data-TimeEnvSampling    | 0.974         |
| Iteration               | 10            |
| ItrTime                 | 28.4          |
| LossAfter               | -0.005435699  |
| LossBefore              | -1.129285e-05 |
| Model-TimeModelFit      | 24.8          |
| ModelSampler-n_times... | 440000        |
| Policy-AverageAbsPol... | 0.7633779     |
| Policy-AverageDiscou... | -90.6         |
| Policy-AveragePolicyStd | 0.7522797     |
| Policy-AverageReturn    | -592          |
| Policy-MaxReturn        | -47.8         |
| Policy-MinReturn        | -2.72e+03     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 898           |
| Policy-TimeAlgoOpt      | 0.593         |
| Policy-TimeSampleProc   | 0.413         |
| Policy-TimeSampling     | 1.57          |
| Policy-TimeStep         | 2.6           |
| Time                    | 195           |
| n_timesteps             | 11000         |
-------------------------------------------

 ---------------- Iteration 11 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 110 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 111 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 112 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 113 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 114 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 115 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 116 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 117 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 118 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 119 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.386          |
| Data-EnvSampler-Poli... | 0.792          |
| Data-EnvTrajs-Averag... | 25.4           |
| Data-EnvTrajs-MaxReturn | 29.5           |
| Data-EnvTrajs-MinReturn | 21.8           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.92           |
| Data-TimeEnvSampleProc  | 0.00124        |
| Data-TimeEnvSampling    | 1.21           |
| Iteration               | 11             |
| ItrTime                 | 31.4           |
| LossAfter               | -0.0030018918  |
| LossBefore              | -1.1179287e-05 |
| Model-TimeModelFit      | 27.5           |
| ModelSampler-n_times... | 480000         |
| Policy-AverageAbsPol... | 0.7437246      |
| Policy-AverageDiscou... | 9.48           |
| Policy-AveragePolicyStd | 0.743189       |
| Policy-AverageReturn    | 6.28           |
| Policy-MaxReturn        | 19.9           |
| Policy-MinReturn        | -3.61          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 6.46           |
| Policy-TimeAlgoOpt      | 0.553          |
| Policy-TimeSampleProc   | 0.376          |
| Policy-TimeSampling     | 1.74           |
| Policy-TimeStep         | 2.72           |
| Time                    | 227            |
| n_timesteps             | 12000          |
--------------------------------------------

 ---------------- Iteration 12 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 120 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 121 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 122 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 123 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 124 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 125 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 126 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 127 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 128 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 129 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.297          |
| Data-EnvSampler-Poli... | 0.592          |
| Data-EnvTrajs-Averag... | 25.8           |
| Data-EnvTrajs-MaxReturn | 28.6           |
| Data-EnvTrajs-MinReturn | 23.1           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.89           |
| Data-TimeEnvSampleProc  | 0.00101        |
| Data-TimeEnvSampling    | 0.918          |
| Iteration               | 12             |
| ItrTime                 | 32.2           |
| LossAfter               | -0.0028640197  |
| LossBefore              | -1.1063362e-05 |
| Model-TimeModelFit      | 28.2           |
| ModelSampler-n_times... | 520000         |
| Policy-AverageAbsPol... | 0.8473328      |
| Policy-AverageDiscou... | -1.5e+03       |
| Policy-AveragePolicyStd | 0.73761886     |
| Policy-AverageReturn    | -7.43e+03      |
| Policy-MaxReturn        | -5.25e+03      |
| Policy-MinReturn        | -8.88e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.09e+03       |
| Policy-TimeAlgoOpt      | 0.572          |
| Policy-TimeSampleProc   | 0.741          |
| Policy-TimeSampling     | 1.68           |
| Policy-TimeStep         | 3.02           |
| Time                    | 259            |
| n_timesteps             | 13000          |
--------------------------------------------

 ---------------- Iteration 13 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 130 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 131 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 132 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 133 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 134 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 135 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 136 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 137 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 138 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 139 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.357          |
| Data-EnvSampler-Poli... | 0.639          |
| Data-EnvTrajs-Averag... | 26.3           |
| Data-EnvTrajs-MaxReturn | 28.9           |
| Data-EnvTrajs-MinReturn | 21.8           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.45           |
| Data-TimeEnvSampleProc  | 0.00103        |
| Data-TimeEnvSampling    | 1.03           |
| Iteration               | 13             |
| ItrTime                 | 32.4           |
| LossAfter               | -0.002678906   |
| LossBefore              | -1.1032951e-05 |
| Model-TimeModelFit      | 28.6           |
| ModelSampler-n_times... | 560000         |
| Policy-AverageAbsPol... | 0.8467324      |
| Policy-AverageDiscou... | 25.1           |
| Policy-AveragePolicyStd | 0.73534405     |
| Policy-AverageReturn    | 50.4           |
| Policy-MaxReturn        | 62.1           |
| Policy-MinReturn        | 39.6           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 5.36           |
| Policy-TimeAlgoOpt      | 0.551          |
| Policy-TimeSampleProc   | 0.423          |
| Policy-TimeSampling     | 1.69           |
| Policy-TimeStep         | 2.7            |
| Time                    | 291            |
| n_timesteps             | 14000          |
--------------------------------------------

 ---------------- Iteration 14 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 140 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 141 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 142 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 143 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 144 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 145 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 146 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 147 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 148 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 149 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.364         |
| Data-EnvSampler-Poli... | 0.709         |
| Data-EnvTrajs-Averag... | 26.3          |
| Data-EnvTrajs-MaxReturn | 31.1          |
| Data-EnvTrajs-MinReturn | 22            |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 3.01          |
| Data-TimeEnvSampleProc  | 0.00112       |
| Data-TimeEnvSampling    | 1.11          |
| Iteration               | 14            |
| ItrTime                 | 34.2          |
| LossAfter               | -0.0019399626 |
| LossBefore              | -1.078523e-05 |
| Model-TimeModelFit      | 30.4          |
| ModelSampler-n_times... | 600000        |
| Policy-AverageAbsPol... | 0.9545394     |
| Policy-AverageDiscou... | 15.6          |
| Policy-AveragePolicyStd | 0.7170249     |
| Policy-AverageReturn    | 22.9          |
| Policy-MaxReturn        | 27.9          |
| Policy-MinReturn        | 17.5          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 3.06          |
| Policy-TimeAlgoOpt      | 0.553         |
| Policy-TimeSampleProc   | 0.425         |
| Policy-TimeSampling     | 1.65          |
| Policy-TimeStep         | 2.65          |
| Time                    | 325           |
| n_timesteps             | 15000         |
-------------------------------------------

 ---------------- Iteration 15 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 150 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 151 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 152 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 153 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 154 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 155 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 156 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 157 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 158 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 159 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.347         |
| Data-EnvSampler-Poli... | 0.698         |
| Data-EnvTrajs-Averag... | 25.1          |
| Data-EnvTrajs-MaxReturn | 29.6          |
| Data-EnvTrajs-MinReturn | 20.1          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 3.48          |
| Data-TimeEnvSampleProc  | 0.000879      |
| Data-TimeEnvSampling    | 1.08          |
| Iteration               | 15            |
| ItrTime                 | 33.3          |
| LossAfter               | -0.0046266266 |
| LossBefore              | -1.032198e-05 |
| Model-TimeModelFit      | 29.3          |
| ModelSampler-n_times... | 640000        |
| Policy-AverageAbsPol... | 0.8757367     |
| Policy-AverageDiscou... | 24            |
| Policy-AveragePolicyStd | 0.68456787    |
| Policy-AverageReturn    | 35            |
| Policy-MaxReturn        | 39.7          |
| Policy-MinReturn        | 29.5          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 2.76          |
| Policy-TimeAlgoOpt      | 0.655         |
| Policy-TimeSampleProc   | 0.489         |
| Policy-TimeSampling     | 1.69          |
| Policy-TimeStep         | 2.88          |
| Time                    | 359           |
| n_timesteps             | 16000         |
-------------------------------------------

 ---------------- Iteration 16 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 160 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 161 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 162 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 163 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 164 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 165 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 166 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 167 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 168 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 169 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.357          |
| Data-EnvSampler-Poli... | 0.719          |
| Data-EnvTrajs-Averag... | 30.3           |
| Data-EnvTrajs-MaxReturn | 34.5           |
| Data-EnvTrajs-MinReturn | 27             |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.49           |
| Data-TimeEnvSampleProc  | 0.00105        |
| Data-TimeEnvSampling    | 1.11           |
| Iteration               | 16             |
| ItrTime                 | 33.1           |
| LossAfter               | -0.0029242155  |
| LossBefore              | -1.0172036e-05 |
| Model-TimeModelFit      | 29.4           |
| ModelSampler-n_times... | 680000         |
| Policy-AverageAbsPol... | 1.0268708      |
| Policy-AverageDiscou... | 26.7           |
| Policy-AveragePolicyStd | 0.6751956      |
| Policy-AverageReturn    | 49.9           |
| Policy-MaxReturn        | 55.5           |
| Policy-MinReturn        | 42             |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 3.41           |
| Policy-TimeAlgoOpt      | 0.545          |
| Policy-TimeSampleProc   | 0.334          |
| Policy-TimeSampling     | 1.71           |
| Policy-TimeStep         | 2.64           |
| Time                    | 392            |
| n_timesteps             | 17000          |
--------------------------------------------

 ---------------- Iteration 17 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 170 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 171 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 172 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 173 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 174 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 175 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 176 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 177 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 178 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 179 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.386          |
| Data-EnvSampler-Poli... | 0.814          |
| Data-EnvTrajs-Averag... | 26.2           |
| Data-EnvTrajs-MaxReturn | 36.3           |
| Data-EnvTrajs-MinReturn | 19.6           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 5.47           |
| Data-TimeEnvSampleProc  | 0.000749       |
| Data-TimeEnvSampling    | 1.24           |
| Iteration               | 17             |
| ItrTime                 | 33.1           |
| LossAfter               | -0.0036604074  |
| LossBefore              | -1.0280307e-05 |
| Model-TimeModelFit      | 29.2           |
| ModelSampler-n_times... | 720000         |
| Policy-AverageAbsPol... | 0.86531615     |
| Policy-AverageDiscou... | 29.1           |
| Policy-AveragePolicyStd | 0.68365014     |
| Policy-AverageReturn    | 41             |
| Policy-MaxReturn        | 45.7           |
| Policy-MinReturn        | 32.5           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.69           |
| Policy-TimeAlgoOpt      | 0.562          |
| Policy-TimeSampleProc   | 0.474          |
| Policy-TimeSampling     | 1.54           |
| Policy-TimeStep         | 2.6            |
| Time                    | 425            |
| n_timesteps             | 18000          |
--------------------------------------------

 ---------------- Iteration 18 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 180 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 181 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 182 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 183 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 184 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 185 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 186 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 187 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 188 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 189 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.37          |
| Data-EnvSampler-Poli... | 0.763         |
| Data-EnvTrajs-Averag... | 32.1          |
| Data-EnvTrajs-MaxReturn | 34.2          |
| Data-EnvTrajs-MinReturn | 30.8          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.29          |
| Data-TimeEnvSampleProc  | 0.00101       |
| Data-TimeEnvSampling    | 1.17          |
| Iteration               | 18            |
| ItrTime                 | 34.3          |
| LossAfter               | -0.003372795  |
| LossBefore              | -9.650131e-06 |
| Model-TimeModelFit      | 30.2          |
| ModelSampler-n_times... | 760000        |
| Policy-AverageAbsPol... | 0.68869513    |
| Policy-AverageDiscou... | 20.4          |
| Policy-AveragePolicyStd | 0.6425837     |
| Policy-AverageReturn    | 16.6          |
| Policy-MaxReturn        | 35            |
| Policy-MinReturn        | 6.13          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 6.76          |
| Policy-TimeAlgoOpt      | 0.609         |
| Policy-TimeSampleProc   | 0.336         |
| Policy-TimeSampling     | 1.97          |
| Policy-TimeStep         | 2.93          |
| Time                    | 459           |
| n_timesteps             | 19000         |
-------------------------------------------

 ---------------- Iteration 19 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 190 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 191 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 192 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 193 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 194 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 195 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 196 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 197 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 198 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 199 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.412         |
| Data-EnvSampler-Poli... | 0.859         |
| Data-EnvTrajs-Averag... | 32.4          |
| Data-EnvTrajs-MaxReturn | 35            |
| Data-EnvTrajs-MinReturn | 28.5          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 2.31          |
| Data-TimeEnvSampleProc  | 0.00126       |
| Data-TimeEnvSampling    | 1.31          |
| Iteration               | 19            |
| ItrTime                 | 33.8          |
| LossAfter               | -0.004896304  |
| LossBefore              | -9.091316e-06 |
| Model-TimeModelFit      | 29.7          |
| ModelSampler-n_times... | 800000        |
| Policy-AverageAbsPol... | 0.92379665    |
| Policy-AverageDiscou... | 26.3          |
| Policy-AveragePolicyStd | 0.60831064    |
| Policy-AverageReturn    | 36.8          |
| Policy-MaxReturn        | 40.9          |
| Policy-MinReturn        | 30.8          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 2.68          |
| Policy-TimeAlgoOpt      | 0.598         |
| Policy-TimeSampleProc   | 0.389         |
| Policy-TimeSampling     | 1.69          |
| Policy-TimeStep         | 2.71          |
| Time                    | 493           |
| n_timesteps             | 20000         |
-------------------------------------------

 ---------------- Iteration 20 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 200 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 201 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 202 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 203 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 204 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 205 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 206 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 207 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 208 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 209 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.38          |
| Data-EnvSampler-Poli... | 0.736         |
| Data-EnvTrajs-Averag... | 33.5          |
| Data-EnvTrajs-MaxReturn | 34.6          |
| Data-EnvTrajs-MinReturn | 32.6          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 0.718         |
| Data-TimeEnvSampleProc  | 0.00116       |
| Data-TimeEnvSampling    | 1.15          |
| Iteration               | 20            |
| ItrTime                 | 34.8          |
| LossAfter               | -0.0018804116 |
| LossBefore              | -8.847961e-06 |
| Model-TimeModelFit      | 30.5          |
| ModelSampler-n_times... | 840000        |
| Policy-AverageAbsPol... | 0.81772727    |
| Policy-AverageDiscou... | 33.7          |
| Policy-AveragePolicyStd | 0.59549403    |
| Policy-AverageReturn    | 59.2          |
| Policy-MaxReturn        | 67.5          |
| Policy-MinReturn        | 49            |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 4.76          |
| Policy-TimeAlgoOpt      | 0.64          |
| Policy-TimeSampleProc   | 0.651         |
| Policy-TimeSampling     | 1.82          |
| Policy-TimeStep         | 3.16          |
| Time                    | 528           |
| n_timesteps             | 21000         |
-------------------------------------------

 ---------------- Iteration 21 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 210 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 211 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 212 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 213 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 214 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 215 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 216 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 217 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 218 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 219 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.391         |
| Data-EnvSampler-Poli... | 0.846         |
| Data-EnvTrajs-Averag... | 33.7          |
| Data-EnvTrajs-MaxReturn | 35.3          |
| Data-EnvTrajs-MinReturn | 29.8          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 2.02          |
| Data-TimeEnvSampleProc  | 0.00125       |
| Data-TimeEnvSampling    | 1.27          |
| Iteration               | 21            |
| ItrTime                 | 36.9          |
| LossAfter               | -0.0008325189 |
| LossBefore              | -8.657073e-06 |
| Model-TimeModelFit      | 32.4          |
| ModelSampler-n_times... | 880000        |
| Policy-AverageAbsPol... | 0.9423595     |
| Policy-AverageDiscou... | 42.1          |
| Policy-AveragePolicyStd | 0.58216304    |
| Policy-AverageReturn    | 93.6          |
| Policy-MaxReturn        | 280           |
| Policy-MinReturn        | 24.6          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 65.7          |
| Policy-TimeAlgoOpt      | 0.602         |
| Policy-TimeSampleProc   | 0.659         |
| Policy-TimeSampling     | 1.88          |
| Policy-TimeStep         | 3.18          |
| Time                    | 565           |
| n_timesteps             | 22000         |
-------------------------------------------

 ---------------- Iteration 22 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 220 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 221 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 222 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 223 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 224 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 225 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 226 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 227 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 228 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 229 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.354         |
| Data-EnvSampler-Poli... | 0.699         |
| Data-EnvTrajs-Averag... | 32.7          |
| Data-EnvTrajs-MaxReturn | 33.9          |
| Data-EnvTrajs-MinReturn | 31.6          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 0.784         |
| Data-TimeEnvSampleProc  | 0.000684      |
| Data-TimeEnvSampling    | 1.08          |
| Iteration               | 22            |
| ItrTime                 | 52.2          |
| LossAfter               | -0.002685582  |
| LossBefore              | -8.406536e-06 |
| Model-TimeModelFit      | 45.3          |
| ModelSampler-n_times... | 920000        |
| Policy-AverageAbsPol... | 0.824762      |
| Policy-AverageDiscou... | 16.8          |
| Policy-AveragePolicyStd | 0.5692147     |
| Policy-AverageReturn    | 11.1          |
| Policy-MaxReturn        | 16            |
| Policy-MinReturn        | 5.17          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 2.56          |
| Policy-TimeAlgoOpt      | 1.04          |
| Policy-TimeSampleProc   | 1.26          |
| Policy-TimeSampling     | 3.41          |
| Policy-TimeStep         | 5.77          |
| Time                    | 617           |
| n_timesteps             | 23000         |
-------------------------------------------

 ---------------- Iteration 23 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 230 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 231 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 232 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 233 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 234 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 235 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 236 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 237 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 238 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 239 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.395         |
| Data-EnvSampler-Poli... | 1.01          |
| Data-EnvTrajs-Averag... | 34.3          |
| Data-EnvTrajs-MaxReturn | 35.6          |
| Data-EnvTrajs-MinReturn | 33.2          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 0.878         |
| Data-TimeEnvSampleProc  | 0.00108       |
| Data-TimeEnvSampling    | 1.44          |
| Iteration               | 23            |
| ItrTime                 | 36.7          |
| LossAfter               | -0.0028561472 |
| LossBefore              | -8.277035e-06 |
| Model-TimeModelFit      | 32.3          |
| ModelSampler-n_times... | 960000        |
| Policy-AverageAbsPol... | 1.015967      |
| Policy-AverageDiscou... | 19.3          |
| Policy-AveragePolicyStd | 0.56384325    |
| Policy-AverageReturn    | 16.5          |
| Policy-MaxReturn        | 25.7          |
| Policy-MinReturn        | 9.82          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 4.37          |
| Policy-TimeAlgoOpt      | 0.542         |
| Policy-TimeSampleProc   | 0.599         |
| Policy-TimeSampling     | 1.71          |
| Policy-TimeStep         | 2.92          |
| Time                    | 654           |
| n_timesteps             | 24000         |
-------------------------------------------

 ---------------- Iteration 24 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 240 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 241 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 242 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 243 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 244 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 245 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 246 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 247 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 248 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 249 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.426         |
| Data-EnvSampler-Poli... | 0.928         |
| Data-EnvTrajs-Averag... | 34.5          |
| Data-EnvTrajs-MaxReturn | 37.2          |
| Data-EnvTrajs-MinReturn | 29.9          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 2.68          |
| Data-TimeEnvSampleProc  | 0.0011        |
| Data-TimeEnvSampling    | 1.39          |
| Iteration               | 24            |
| ItrTime                 | 37            |
| LossAfter               | -0.0019427078 |
| LossBefore              | -8.126302e-06 |
| Model-TimeModelFit      | 32.9          |
| ModelSampler-n_times... | 1000000       |
| Policy-AverageAbsPol... | 1.1934803     |
| Policy-AverageDiscou... | 23.5          |
| Policy-AveragePolicyStd | 0.5558546     |
| Policy-AverageReturn    | 31.8          |
| Policy-MaxReturn        | 43.5          |
| Policy-MinReturn        | 29.1          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 2.95          |
| Policy-TimeAlgoOpt      | 0.619         |
| Policy-TimeSampleProc   | 0.432         |
| Policy-TimeSampling     | 1.64          |
| Policy-TimeStep         | 2.74          |
| Time                    | 691           |
| n_timesteps             | 25000         |
-------------------------------------------

 ---------------- Iteration 25 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 250 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 251 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 252 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 253 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 254 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 255 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 256 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 257 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 258 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 259 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.425         |
| Data-EnvSampler-Poli... | 0.938         |
| Data-EnvTrajs-Averag... | 37            |
| Data-EnvTrajs-MaxReturn | 38.9          |
| Data-EnvTrajs-MinReturn | 34.8          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.47          |
| Data-TimeEnvSampleProc  | 0.00139       |
| Data-TimeEnvSampling    | 1.4           |
| Iteration               | 25            |
| ItrTime                 | 36.2          |
| LossAfter               | -0.0016948191 |
| LossBefore              | -8.041973e-06 |
| Model-TimeModelFit      | 32.1          |
| ModelSampler-n_times... | 1040000       |
| Policy-AverageAbsPol... | 1.2658454     |
| Policy-AverageDiscou... | 23.8          |
| Policy-AveragePolicyStd | 0.54999965    |
| Policy-AverageReturn    | 28.4          |
| Policy-MaxReturn        | 33.4          |
| Policy-MinReturn        | 24.7          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 2.2           |
| Policy-TimeAlgoOpt      | 0.567         |
| Policy-TimeSampleProc   | 0.416         |
| Policy-TimeSampling     | 1.62          |
| Policy-TimeStep         | 2.63          |
| Time                    | 727           |
| n_timesteps             | 26000         |
-------------------------------------------

 ---------------- Iteration 26 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 260 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 261 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 262 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 263 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 264 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 265 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 266 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 267 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 268 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 269 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Data-EnvSampler-EnvE... | 0.403        |
| Data-EnvSampler-Poli... | 0.935        |
| Data-EnvTrajs-Averag... | 36           |
| Data-EnvTrajs-MaxReturn | 39.1         |
| Data-EnvTrajs-MinReturn | 33           |
| Data-EnvTrajs-NumTrajs  | 5            |
| Data-EnvTrajs-StdReturn | 2.1          |
| Data-TimeEnvSampleProc  | 0.00103      |
| Data-TimeEnvSampling    | 1.37         |
| Iteration               | 26           |
| ItrTime                 | 34.9         |
| LossAfter               | -0.002191853 |
| LossBefore              | -7.74392e-06 |
| Model-TimeModelFit      | 30.8         |
| ModelSampler-n_times... | 1080000      |
| Policy-AverageAbsPol... | 1.5082778    |
| Policy-AverageDiscou... | 29.2         |
| Policy-AveragePolicyStd | 0.53788674   |
| Policy-AverageReturn    | 47.6         |
| Policy-MaxReturn        | 51.9         |
| Policy-MinReturn        | 43.8         |
| Policy-NumTrajs         | 20           |
| Policy-StdReturn        | 2.15         |
| Policy-TimeAlgoOpt      | 0.569        |
| Policy-TimeSampleProc   | 0.351        |
| Policy-TimeSampling     | 1.7          |
| Policy-TimeStep         | 2.66         |
| Time                    | 762          |
| n_timesteps             | 27000        |
------------------------------------------

 ---------------- Iteration 27 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 270 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 271 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 272 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 273 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 274 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 275 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 276 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 277 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 278 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 279 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.398          |
| Data-EnvSampler-Poli... | 0.91           |
| Data-EnvTrajs-Averag... | 38.2           |
| Data-EnvTrajs-MaxReturn | 39.5           |
| Data-EnvTrajs-MinReturn | 36.8           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 0.997          |
| Data-TimeEnvSampleProc  | 0.00111        |
| Data-TimeEnvSampling    | 1.34           |
| Iteration               | 27             |
| ItrTime                 | 34.5           |
| LossAfter               | -0.0024474266  |
| LossBefore              | -7.6029974e-06 |
| Model-TimeModelFit      | 30.8           |
| ModelSampler-n_times... | 1120000        |
| Policy-AverageAbsPol... | 1.6342485      |
| Policy-AverageDiscou... | 30.9           |
| Policy-AveragePolicyStd | 0.5309728      |
| Policy-AverageReturn    | 51.9           |
| Policy-MaxReturn        | 69.8           |
| Policy-MinReturn        | 44.2           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 6.19           |
| Policy-TimeAlgoOpt      | 0.574          |
| Policy-TimeSampleProc   | 0.3            |
| Policy-TimeSampling     | 1.5            |
| Policy-TimeStep         | 2.39           |
| Time                    | 796            |
| n_timesteps             | 28000          |
--------------------------------------------

 ---------------- Iteration 28 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 280 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 281 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 282 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 283 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 284 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 285 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 286 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 287 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 288 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 289 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.439          |
| Data-EnvSampler-Poli... | 1.04           |
| Data-EnvTrajs-Averag... | 33.6           |
| Data-EnvTrajs-MaxReturn | 36.1           |
| Data-EnvTrajs-MinReturn | 28.8           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.61           |
| Data-TimeEnvSampleProc  | 0.00123        |
| Data-TimeEnvSampling    | 1.51           |
| Iteration               | 28             |
| ItrTime                 | 34.9           |
| LossAfter               | -0.0018737173  |
| LossBefore              | -7.3195783e-06 |
| Model-TimeModelFit      | 31.1           |
| ModelSampler-n_times... | 1160000        |
| Policy-AverageAbsPol... | 1.628167       |
| Policy-AverageDiscou... | 31.8           |
| Policy-AveragePolicyStd | 0.515644       |
| Policy-AverageReturn    | 61.7           |
| Policy-MaxReturn        | 73.7           |
| Policy-MinReturn        | 55.7           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 4.39           |
| Policy-TimeAlgoOpt      | 0.524          |
| Policy-TimeSampleProc   | 0.367          |
| Policy-TimeSampling     | 1.43           |
| Policy-TimeStep         | 2.34           |
| Time                    | 831            |
| n_timesteps             | 29000          |
--------------------------------------------

 ---------------- Iteration 29 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 290 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 291 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 292 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 293 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 294 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 295 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 296 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 297 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 298 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 299 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.413         |
| Data-EnvSampler-Poli... | 0.903         |
| Data-EnvTrajs-Averag... | 36.7          |
| Data-EnvTrajs-MaxReturn | 38            |
| Data-EnvTrajs-MinReturn | 34.6          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.15          |
| Data-TimeEnvSampleProc  | 0.00108       |
| Data-TimeEnvSampling    | 1.35          |
| Iteration               | 29            |
| ItrTime                 | 35.4          |
| LossAfter               | -0.0075548277 |
| LossBefore              | -7.110878e-06 |
| Model-TimeModelFit      | 31.7          |
| ModelSampler-n_times... | 1200000       |
| Policy-AverageAbsPol... | 1.6775702     |
| Policy-AverageDiscou... | 16.1          |
| Policy-AveragePolicyStd | 0.50599337    |
| Policy-AverageReturn    | 14.7          |
| Policy-MaxReturn        | 17.4          |
| Policy-MinReturn        | 12.4          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.55          |
| Policy-TimeAlgoOpt      | 0.563         |
| Policy-TimeSampleProc   | 0.332         |
| Policy-TimeSampling     | 1.51          |
| Policy-TimeStep         | 2.43          |
| Time                    | 867           |
| n_timesteps             | 30000         |
-------------------------------------------

 ---------------- Iteration 30 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 300 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 301 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 302 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 303 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 304 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 305 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 306 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 307 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 308 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 309 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.391          |
| Data-EnvSampler-Poli... | 0.908          |
| Data-EnvTrajs-Averag... | 36             |
| Data-EnvTrajs-MaxReturn | 38.9           |
| Data-EnvTrajs-MinReturn | 33             |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.96           |
| Data-TimeEnvSampleProc  | 0.00107        |
| Data-TimeEnvSampling    | 1.34           |
| Iteration               | 30             |
| ItrTime                 | 35.3           |
| LossAfter               | -0.0027424076  |
| LossBefore              | -6.8195163e-06 |
| Model-TimeModelFit      | 31.5           |
| ModelSampler-n_times... | 1240000        |
| Policy-AverageAbsPol... | 1.8085713      |
| Policy-AverageDiscou... | 19.2           |
| Policy-AveragePolicyStd | 0.49236414     |
| Policy-AverageReturn    | 20.1           |
| Policy-MaxReturn        | 25.1           |
| Policy-MinReturn        | 16.1           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.25           |
| Policy-TimeAlgoOpt      | 0.585          |
| Policy-TimeSampleProc   | 0.285          |
| Policy-TimeSampling     | 1.52           |
| Policy-TimeStep         | 2.4            |
| Time                    | 902            |
| n_timesteps             | 31000          |
--------------------------------------------

 ---------------- Iteration 31 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 310 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 311 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 312 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 313 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 314 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 315 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 316 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 317 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 318 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 319 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.451         |
| Data-EnvSampler-Poli... | 1.01          |
| Data-EnvTrajs-Averag... | 38.9          |
| Data-EnvTrajs-MaxReturn | 41.4          |
| Data-EnvTrajs-MinReturn | 36            |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.94          |
| Data-TimeEnvSampleProc  | 0.00113       |
| Data-TimeEnvSampling    | 1.51          |
| Iteration               | 31            |
| ItrTime                 | 35.5          |
| LossAfter               | -0.0023917635 |
| LossBefore              | -6.796602e-06 |
| Model-TimeModelFit      | 31.4          |
| ModelSampler-n_times... | 1280000       |
| Policy-AverageAbsPol... | 1.6433926     |
| Policy-AverageDiscou... | 16.1          |
| Policy-AveragePolicyStd | 0.49242517    |
| Policy-AverageReturn    | 5.16          |
| Policy-MaxReturn        | 8             |
| Policy-MinReturn        | 1.4           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.66          |
| Policy-TimeAlgoOpt      | 0.574         |
| Policy-TimeSampleProc   | 0.437         |
| Policy-TimeSampling     | 1.51          |
| Policy-TimeStep         | 2.57          |
| Time                    | 937           |
| n_timesteps             | 32000         |
-------------------------------------------

 ---------------- Iteration 32 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 320 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 321 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 322 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 323 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 324 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 325 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 326 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 327 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 328 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 329 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.405          |
| Data-EnvSampler-Poli... | 0.91           |
| Data-EnvTrajs-Averag... | 37.7           |
| Data-EnvTrajs-MaxReturn | 39.5           |
| Data-EnvTrajs-MinReturn | 36.6           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 0.959          |
| Data-TimeEnvSampleProc  | 0.00103        |
| Data-TimeEnvSampling    | 1.36           |
| Iteration               | 32             |
| ItrTime                 | 35.1           |
| LossAfter               | -0.0019529491  |
| LossBefore              | -6.5084682e-06 |
| Model-TimeModelFit      | 31.4           |
| ModelSampler-n_times... | 1320000        |
| Policy-AverageAbsPol... | 1.6657645      |
| Policy-AverageDiscou... | 37.4           |
| Policy-AveragePolicyStd | 0.480809       |
| Policy-AverageReturn    | 69             |
| Policy-MaxReturn        | 82             |
| Policy-MinReturn        | 60.7           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 5.42           |
| Policy-TimeAlgoOpt      | 0.58           |
| Policy-TimeSampleProc   | 0.245          |
| Policy-TimeSampling     | 1.47           |
| Policy-TimeStep         | 2.31           |
| Time                    | 972            |
| n_timesteps             | 33000          |
--------------------------------------------

 ---------------- Iteration 33 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 330 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 331 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 332 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 333 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 334 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 335 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 336 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 337 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 338 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 339 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.374          |
| Data-EnvSampler-Poli... | 0.848          |
| Data-EnvTrajs-Averag... | 36.4           |
| Data-EnvTrajs-MaxReturn | 38             |
| Data-EnvTrajs-MinReturn | 31.3           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.54           |
| Data-TimeEnvSampleProc  | 0.00102        |
| Data-TimeEnvSampling    | 1.26           |
| Iteration               | 33             |
| ItrTime                 | 35.3           |
| LossAfter               | -0.0008173523  |
| LossBefore              | -6.1657793e-06 |
| Model-TimeModelFit      | 31.8           |
| ModelSampler-n_times... | 1360000        |
| Policy-AverageAbsPol... | 1.7105438      |
| Policy-AverageDiscou... | 35.8           |
| Policy-AveragePolicyStd | 0.46472284     |
| Policy-AverageReturn    | 57.2           |
| Policy-MaxReturn        | 67.1           |
| Policy-MinReturn        | 50.2           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 3.97           |
| Policy-TimeAlgoOpt      | 0.515          |
| Policy-TimeSampleProc   | 0.304          |
| Policy-TimeSampling     | 1.43           |
| Policy-TimeStep         | 2.28           |
| Time                    | 1.01e+03       |
| n_timesteps             | 34000          |
--------------------------------------------

 ---------------- Iteration 34 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 340 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 341 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 342 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 343 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 344 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 345 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 346 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 347 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 348 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 349 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.417         |
| Data-EnvSampler-Poli... | 0.914         |
| Data-EnvTrajs-Averag... | 36.3          |
| Data-EnvTrajs-MaxReturn | 37.9          |
| Data-EnvTrajs-MinReturn | 33.8          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.46          |
| Data-TimeEnvSampleProc  | 0.00106       |
| Data-TimeEnvSampling    | 1.38          |
| Iteration               | 34            |
| ItrTime                 | 35.4          |
| LossAfter               | -0.0034075158 |
| LossBefore              | -5.875163e-06 |
| Model-TimeModelFit      | 31.6          |
| ModelSampler-n_times... | 1400000       |
| Policy-AverageAbsPol... | 1.7625998     |
| Policy-AverageDiscou... | 30.9          |
| Policy-AveragePolicyStd | 0.45482844    |
| Policy-AverageReturn    | 53.2          |
| Policy-MaxReturn        | 61.3          |
| Policy-MinReturn        | 44.8          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 4.58          |
| Policy-TimeAlgoOpt      | 0.545         |
| Policy-TimeSampleProc   | 0.308         |
| Policy-TimeSampling     | 1.54          |
| Policy-TimeStep         | 2.42          |
| Time                    | 1.04e+03      |
| n_timesteps             | 35000         |
-------------------------------------------

 ---------------- Iteration 35 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 350 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 351 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 352 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 353 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 354 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 355 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 356 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 357 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 358 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 359 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.385         |
| Data-EnvSampler-Poli... | 0.885         |
| Data-EnvTrajs-Averag... | 38.6          |
| Data-EnvTrajs-MaxReturn | 40.1          |
| Data-EnvTrajs-MinReturn | 36.4          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.51          |
| Data-TimeEnvSampleProc  | 0.00103       |
| Data-TimeEnvSampling    | 1.31          |
| Iteration               | 35            |
| ItrTime                 | 36.3          |
| LossAfter               | 0.00021180065 |
| LossBefore              | -5.757503e-06 |
| Model-TimeModelFit      | 32.5          |
| ModelSampler-n_times... | 1440000       |
| Policy-AverageAbsPol... | 1.8923064     |
| Policy-AverageDiscou... | 14.2          |
| Policy-AveragePolicyStd | 0.44989747    |
| Policy-AverageReturn    | 7.74          |
| Policy-MaxReturn        | 15.5          |
| Policy-MinReturn        | -37.9         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 10.8          |
| Policy-TimeAlgoOpt      | 0.594         |
| Policy-TimeSampleProc   | 0.375         |
| Policy-TimeSampling     | 1.56          |
| Policy-TimeStep         | 2.58          |
| Time                    | 1.08e+03      |
| n_timesteps             | 36000         |
-------------------------------------------

 ---------------- Iteration 36 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 360 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 361 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 362 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 363 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 364 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 365 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 366 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 367 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 368 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 369 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.401          |
| Data-EnvSampler-Poli... | 0.872          |
| Data-EnvTrajs-Averag... | 36.6           |
| Data-EnvTrajs-MaxReturn | 40             |
| Data-EnvTrajs-MinReturn | 34.7           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.91           |
| Data-TimeEnvSampleProc  | 0.00107        |
| Data-TimeEnvSampling    | 1.31           |
| Iteration               | 36             |
| ItrTime                 | 36.1           |
| LossAfter               | -0.0043983404  |
| LossBefore              | -5.6283575e-06 |
| Model-TimeModelFit      | 32.4           |
| ModelSampler-n_times... | 1480000        |
| Policy-AverageAbsPol... | 1.9837725      |
| Policy-AverageDiscou... | 17.5           |
| Policy-AveragePolicyStd | 0.44421613     |
| Policy-AverageReturn    | 19.2           |
| Policy-MaxReturn        | 24.6           |
| Policy-MinReturn        | 13             |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.86           |
| Policy-TimeAlgoOpt      | 0.542          |
| Policy-TimeSampleProc   | 0.415          |
| Policy-TimeSampling     | 1.42           |
| Policy-TimeStep         | 2.44           |
| Time                    | 1.12e+03       |
| n_timesteps             | 37000          |
--------------------------------------------

 ---------------- Iteration 37 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 370 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 371 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 372 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 373 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 374 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 375 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 376 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 377 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 378 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 379 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.445          |
| Data-EnvSampler-Poli... | 0.978          |
| Data-EnvTrajs-Averag... | 38.2           |
| Data-EnvTrajs-MaxReturn | 41.4           |
| Data-EnvTrajs-MinReturn | 35.6           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.28           |
| Data-TimeEnvSampleProc  | 0.00116        |
| Data-TimeEnvSampling    | 1.47           |
| Iteration               | 37             |
| ItrTime                 | 36.4           |
| LossAfter               | -0.0030155706  |
| LossBefore              | -5.6680847e-06 |
| Model-TimeModelFit      | 32.5           |
| ModelSampler-n_times... | 1520000        |
| Policy-AverageAbsPol... | 2.1235569      |
| Policy-AverageDiscou... | 14.6           |
| Policy-AveragePolicyStd | 0.44620723     |
| Policy-AverageReturn    | 7.35           |
| Policy-MaxReturn        | 27.5           |
| Policy-MinReturn        | -0.505         |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 6.21           |
| Policy-TimeAlgoOpt      | 0.535          |
| Policy-TimeSampleProc   | 0.395          |
| Policy-TimeSampling     | 1.44           |
| Policy-TimeStep         | 2.43           |
| Time                    | 1.15e+03       |
| n_timesteps             | 38000          |
--------------------------------------------

 ---------------- Iteration 38 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 380 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 381 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 382 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 383 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 384 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 385 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 386 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 387 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 388 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 389 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.384          |
| Data-EnvSampler-Poli... | 0.926          |
| Data-EnvTrajs-Averag... | 40.2           |
| Data-EnvTrajs-MaxReturn | 41.2           |
| Data-EnvTrajs-MinReturn | 38.7           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 0.884          |
| Data-TimeEnvSampleProc  | 0.000901       |
| Data-TimeEnvSampling    | 1.35           |
| Iteration               | 38             |
| ItrTime                 | 36.7           |
| LossAfter               | -0.0032881945  |
| LossBefore              | -5.3514004e-06 |
| Model-TimeModelFit      | 32.8           |
| ModelSampler-n_times... | 1560000        |
| Policy-AverageAbsPol... | 2.1792457      |
| Policy-AverageDiscou... | 31.7           |
| Policy-AveragePolicyStd | 0.4365054      |
| Policy-AverageReturn    | 58.6           |
| Policy-MaxReturn        | 63.7           |
| Policy-MinReturn        | 54.7           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.56           |
| Policy-TimeAlgoOpt      | 0.526          |
| Policy-TimeSampleProc   | 0.486          |
| Policy-TimeSampling     | 1.56           |
| Policy-TimeStep         | 2.61           |
| Time                    | 1.19e+03       |
| n_timesteps             | 39000          |
--------------------------------------------

 ---------------- Iteration 39 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 390 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 391 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 392 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 393 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 394 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 395 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 396 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 397 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 398 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 399 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.439         |
| Data-EnvSampler-Poli... | 0.966         |
| Data-EnvTrajs-Averag... | 37.9          |
| Data-EnvTrajs-MaxReturn | 39.6          |
| Data-EnvTrajs-MinReturn | 35.7          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.67          |
| Data-TimeEnvSampleProc  | 0.00111       |
| Data-TimeEnvSampling    | 1.45          |
| Iteration               | 39            |
| ItrTime                 | 36.5          |
| LossAfter               | -0.0025044258 |
| LossBefore              | -5.064318e-06 |
| Model-TimeModelFit      | 32.5          |
| ModelSampler-n_times... | 1600000       |
| Policy-AverageAbsPol... | 2.3854554     |
| Policy-AverageDiscou... | 27.6          |
| Policy-AveragePolicyStd | 0.42697626    |
| Policy-AverageReturn    | 36.6          |
| Policy-MaxReturn        | 54.9          |
| Policy-MinReturn        | 17.3          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 8.17          |
| Policy-TimeAlgoOpt      | 0.599         |
| Policy-TimeSampleProc   | 0.382         |
| Policy-TimeSampling     | 1.62          |
| Policy-TimeStep         | 2.62          |
| Time                    | 1.23e+03      |
| n_timesteps             | 40000         |
-------------------------------------------

 ---------------- Iteration 40 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 400 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 401 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 402 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 403 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 404 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 405 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 406 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 407 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 408 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 409 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.448         |
| Data-EnvSampler-Poli... | 1.04          |
| Data-EnvTrajs-Averag... | 35.9          |
| Data-EnvTrajs-MaxReturn | 38.6          |
| Data-EnvTrajs-MinReturn | 33.4          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.89          |
| Data-TimeEnvSampleProc  | 0.00116       |
| Data-TimeEnvSampling    | 1.53          |
| Iteration               | 40            |
| ItrTime                 | 36.9          |
| LossAfter               | 0.0055298186  |
| LossBefore              | -4.679686e-06 |
| Model-TimeModelFit      | 32.6          |
| ModelSampler-n_times... | 1640000       |
| Policy-AverageAbsPol... | 2.445141      |
| Policy-AverageDiscou... | 31.8          |
| Policy-AveragePolicyStd | 0.41611677    |
| Policy-AverageReturn    | 57.2          |
| Policy-MaxReturn        | 63.6          |
| Policy-MinReturn        | 49.8          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 3.36          |
| Policy-TimeAlgoOpt      | 0.619         |
| Policy-TimeSampleProc   | 0.405         |
| Policy-TimeSampling     | 1.63          |
| Policy-TimeStep         | 2.69          |
| Time                    | 1.26e+03      |
| n_timesteps             | 41000         |
-------------------------------------------

 ---------------- Iteration 41 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 410 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 411 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 412 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 413 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 414 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 415 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 416 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 417 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 418 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 419 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.393         |
| Data-EnvSampler-Poli... | 0.891         |
| Data-EnvTrajs-Averag... | 34            |
| Data-EnvTrajs-MaxReturn | 38.9          |
| Data-EnvTrajs-MinReturn | 29.7          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 3.14          |
| Data-TimeEnvSampleProc  | 0.00112       |
| Data-TimeEnvSampling    | 1.32          |
| Iteration               | 41            |
| ItrTime                 | 36.5          |
| LossAfter               | -0.0014893336 |
| LossBefore              | -4.548443e-06 |
| Model-TimeModelFit      | 32.1          |
| ModelSampler-n_times... | 1680000       |
| Policy-AverageAbsPol... | 2.6706424     |
| Policy-AverageDiscou... | 28.8          |
| Policy-AveragePolicyStd | 0.41365796    |
| Policy-AverageReturn    | 29.7          |
| Policy-MaxReturn        | 48.9          |
| Policy-MinReturn        | -125          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 36            |
| Policy-TimeAlgoOpt      | 0.678         |
| Policy-TimeSampleProc   | 0.34          |
| Policy-TimeSampling     | 2             |
| Policy-TimeStep         | 3.05          |
| Time                    | 1.3e+03       |
| n_timesteps             | 42000         |
-------------------------------------------

 ---------------- Iteration 42 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 420 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 421 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 422 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 423 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 424 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 425 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 426 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 427 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 428 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 429 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.465         |
| Data-EnvSampler-Poli... | 0.983         |
| Data-EnvTrajs-Averag... | 33.4          |
| Data-EnvTrajs-MaxReturn | 35.9          |
| Data-EnvTrajs-MinReturn | 29.8          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 2.14          |
| Data-TimeEnvSampleProc  | 0.00125       |
| Data-TimeEnvSampling    | 1.49          |
| Iteration               | 42            |
| ItrTime                 | 37.3          |
| LossAfter               | -0.0028909564 |
| LossBefore              | -4.471798e-06 |
| Model-TimeModelFit      | 33            |
| ModelSampler-n_times... | 1720000       |
| Policy-AverageAbsPol... | 2.6172447     |
| Policy-AverageDiscou... | -89.4         |
| Policy-AveragePolicyStd | 0.4115989     |
| Policy-AverageReturn    | -698          |
| Policy-MaxReturn        | 5.52          |
| Policy-MinReturn        | -3.57e+03     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1e+03         |
| Policy-TimeAlgoOpt      | 0.604         |
| Policy-TimeSampleProc   | 0.412         |
| Policy-TimeSampling     | 1.72          |
| Policy-TimeStep         | 2.81          |
| Time                    | 1.34e+03      |
| n_timesteps             | 43000         |
-------------------------------------------

 ---------------- Iteration 43 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 430 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 431 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 432 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 433 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 434 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 435 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 436 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 437 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 438 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 439 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.434         |
| Data-EnvSampler-Poli... | 0.986         |
| Data-EnvTrajs-Averag... | 33.4          |
| Data-EnvTrajs-MaxReturn | 37.4          |
| Data-EnvTrajs-MinReturn | 29.7          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 2.79          |
| Data-TimeEnvSampleProc  | 0.00143       |
| Data-TimeEnvSampling    | 1.46          |
| Iteration               | 43            |
| ItrTime                 | 37.4          |
| LossAfter               | 0.008578158   |
| LossBefore              | -4.295468e-06 |
| Model-TimeModelFit      | 33.3          |
| ModelSampler-n_times... | 1760000       |
| Policy-AverageAbsPol... | 2.547873      |
| Policy-AverageDiscou... | 34.3          |
| Policy-AveragePolicyStd | 0.40686783    |
| Policy-AverageReturn    | 66.2          |
| Policy-MaxReturn        | 71.1          |
| Policy-MinReturn        | 50.4          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 4.96          |
| Policy-TimeAlgoOpt      | 0.605         |
| Policy-TimeSampleProc   | 0.377         |
| Policy-TimeSampling     | 1.63          |
| Policy-TimeStep         | 2.64          |
| Time                    | 1.37e+03      |
| n_timesteps             | 44000         |
-------------------------------------------

 ---------------- Iteration 44 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 440 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 441 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 442 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 443 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 444 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 445 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 446 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 447 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 448 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 449 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.417          |
| Data-EnvSampler-Poli... | 1.02           |
| Data-EnvTrajs-Averag... | 30.4           |
| Data-EnvTrajs-MaxReturn | 34.6           |
| Data-EnvTrajs-MinReturn | 20.9           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 4.88           |
| Data-TimeEnvSampleProc  | 0.0011         |
| Data-TimeEnvSampling    | 1.47           |
| Iteration               | 44             |
| ItrTime                 | 37.3           |
| LossAfter               | -0.002469929   |
| LossBefore              | -4.1855674e-06 |
| Model-TimeModelFit      | 33.1           |
| ModelSampler-n_times... | 1800000        |
| Policy-AverageAbsPol... | 2.2570736      |
| Policy-AverageDiscou... | -3.19e+03      |
| Policy-AveragePolicyStd | 0.40231854     |
| Policy-AverageReturn    | -1.13e+04      |
| Policy-MaxReturn        | -1.55e+03      |
| Policy-MinReturn        | -1.52e+04      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 4.33e+03       |
| Policy-TimeAlgoOpt      | 0.605          |
| Policy-TimeSampleProc   | 0.451          |
| Policy-TimeSampling     | 1.63           |
| Policy-TimeStep         | 2.72           |
| Time                    | 1.41e+03       |
| n_timesteps             | 45000          |
--------------------------------------------

 ---------------- Iteration 45 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 450 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 451 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 452 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 453 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 454 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 455 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 456 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 457 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 458 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 459 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.419          |
| Data-EnvSampler-Poli... | 1.04           |
| Data-EnvTrajs-Averag... | 39.2           |
| Data-EnvTrajs-MaxReturn | 40.4           |
| Data-EnvTrajs-MinReturn | 36.8           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.28           |
| Data-TimeEnvSampleProc  | 0.00107        |
| Data-TimeEnvSampling    | 1.5            |
| Iteration               | 45             |
| ItrTime                 | 37.7           |
| LossAfter               | -0.0026667654  |
| LossBefore              | -4.2081106e-06 |
| Model-TimeModelFit      | 33.5           |
| ModelSampler-n_times... | 1840000        |
| Policy-AverageAbsPol... | 2.4508696      |
| Policy-AverageDiscou... | -1.99e+03      |
| Policy-AveragePolicyStd | 0.40509254     |
| Policy-AverageReturn    | -8.36e+03      |
| Policy-MaxReturn        | -4.62          |
| Policy-MinReturn        | -1.15e+04      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 4.23e+03       |
| Policy-TimeAlgoOpt      | 0.573          |
| Policy-TimeSampleProc   | 0.447          |
| Policy-TimeSampling     | 1.66           |
| Policy-TimeStep         | 2.71           |
| Time                    | 1.45e+03       |
| n_timesteps             | 46000          |
--------------------------------------------

 ---------------- Iteration 46 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 460 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 461 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 462 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 463 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 464 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 465 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 466 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 467 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 468 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 469 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.468          |
| Data-EnvSampler-Poli... | 1.03           |
| Data-EnvTrajs-Averag... | 38.2           |
| Data-EnvTrajs-MaxReturn | 40.2           |
| Data-EnvTrajs-MinReturn | 36.9           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.35           |
| Data-TimeEnvSampleProc  | 0.000945       |
| Data-TimeEnvSampling    | 1.53           |
| Iteration               | 46             |
| ItrTime                 | 37.8           |
| LossAfter               | -0.0010746852  |
| LossBefore              | -4.0241853e-06 |
| Model-TimeModelFit      | 33.7           |
| ModelSampler-n_times... | 1880000        |
| Policy-AverageAbsPol... | 2.5615659      |
| Policy-AverageDiscou... | 31.7           |
| Policy-AveragePolicyStd | 0.3985477      |
| Policy-AverageReturn    | 35.8           |
| Policy-MaxReturn        | 56.3           |
| Policy-MinReturn        | 18.5           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 9.69           |
| Policy-TimeAlgoOpt      | 0.548          |
| Policy-TimeSampleProc   | 0.445          |
| Policy-TimeSampling     | 1.61           |
| Policy-TimeStep         | 2.64           |
| Time                    | 1.49e+03       |
| n_timesteps             | 47000          |
--------------------------------------------

 ---------------- Iteration 47 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 470 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 471 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 472 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 473 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 474 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 475 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 476 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 477 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 478 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 479 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.413          |
| Data-EnvSampler-Poli... | 0.879          |
| Data-EnvTrajs-Averag... | 37.8           |
| Data-EnvTrajs-MaxReturn | 38.8           |
| Data-EnvTrajs-MinReturn | 35.4           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.25           |
| Data-TimeEnvSampleProc  | 0.00105        |
| Data-TimeEnvSampling    | 1.33           |
| Iteration               | 47             |
| ItrTime                 | 37.7           |
| LossAfter               | 0.0022780888   |
| LossBefore              | -3.6565698e-06 |
| Model-TimeModelFit      | 33.5           |
| ModelSampler-n_times... | 1920000        |
| Policy-AverageAbsPol... | 2.5112135      |
| Policy-AverageDiscou... | 39.7           |
| Policy-AveragePolicyStd | 0.38715634     |
| Policy-AverageReturn    | 86.4           |
| Policy-MaxReturn        | 97.5           |
| Policy-MinReturn        | 73.9           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 5.83           |
| Policy-TimeAlgoOpt      | 0.666          |
| Policy-TimeSampleProc   | 0.43           |
| Policy-TimeSampling     | 1.76           |
| Policy-TimeStep         | 2.87           |
| Time                    | 1.52e+03       |
| n_timesteps             | 48000          |
--------------------------------------------

 ---------------- Iteration 48 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 480 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 481 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 482 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 483 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 484 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 485 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 486 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 487 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 488 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 489 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.411          |
| Data-EnvSampler-Poli... | 1.06           |
| Data-EnvTrajs-Averag... | 37.4           |
| Data-EnvTrajs-MaxReturn | 39.3           |
| Data-EnvTrajs-MinReturn | 35.5           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.48           |
| Data-TimeEnvSampleProc  | 0.00104        |
| Data-TimeEnvSampling    | 1.51           |
| Iteration               | 48             |
| ItrTime                 | 37.4           |
| LossAfter               | -0.0049336287  |
| LossBefore              | -3.2957141e-06 |
| Model-TimeModelFit      | 33.3           |
| ModelSampler-n_times... | 1960000        |
| Policy-AverageAbsPol... | 2.4756598      |
| Policy-AverageDiscou... | 29.2           |
| Policy-AveragePolicyStd | 0.37511584     |
| Policy-AverageReturn    | 36.5           |
| Policy-MaxReturn        | 43.2           |
| Policy-MinReturn        | 24.6           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 4.46           |
| Policy-TimeAlgoOpt      | 0.572          |
| Policy-TimeSampleProc   | 0.414          |
| Policy-TimeSampling     | 1.54           |
| Policy-TimeStep         | 2.56           |
| Time                    | 1.56e+03       |
| n_timesteps             | 49000          |
--------------------------------------------

 ---------------- Iteration 49 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 490 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 491 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 492 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 493 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 494 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 495 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 496 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 497 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 498 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 499 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.384          |
| Data-EnvSampler-Poli... | 0.871          |
| Data-EnvTrajs-Averag... | 37.1           |
| Data-EnvTrajs-MaxReturn | 39.3           |
| Data-EnvTrajs-MinReturn | 36.2           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.14           |
| Data-TimeEnvSampleProc  | 0.00104        |
| Data-TimeEnvSampling    | 1.29           |
| Iteration               | 49             |
| ItrTime                 | 38             |
| LossAfter               | -0.0017573602  |
| LossBefore              | -3.1489465e-06 |
| Model-TimeModelFit      | 33.7           |
| ModelSampler-n_times... | 2000000        |
| Policy-AverageAbsPol... | 2.3950577      |
| Policy-AverageDiscou... | 46.3           |
| Policy-AveragePolicyStd | 0.37115595     |
| Policy-AverageReturn    | 62.4           |
| Policy-MaxReturn        | 116            |
| Policy-MinReturn        | -769           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 191            |
| Policy-TimeAlgoOpt      | 0.604          |
| Policy-TimeSampleProc   | 0.428          |
| Policy-TimeSampling     | 1.87           |
| Policy-TimeStep         | 2.93           |
| Time                    | 1.6e+03        |
| n_timesteps             | 50000          |
--------------------------------------------

 ---------------- Iteration 50 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 500 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 501 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 502 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 503 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 504 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 505 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 506 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 507 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 508 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 509 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.424          |
| Data-EnvSampler-Poli... | 0.968          |
| Data-EnvTrajs-Averag... | 37.4           |
| Data-EnvTrajs-MaxReturn | 38.8           |
| Data-EnvTrajs-MinReturn | 36.5           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 0.855          |
| Data-TimeEnvSampleProc  | 0.00109        |
| Data-TimeEnvSampling    | 1.43           |
| Iteration               | 50             |
| ItrTime                 | 30.2           |
| LossAfter               | -0.0020696667  |
| LossBefore              | -3.0621438e-06 |
| Model-TimeModelFit      | 27.3           |
| ModelSampler-n_times... | 2040000        |
| Policy-AverageAbsPol... | 2.9757607      |
| Policy-AverageDiscou... | -717           |
| Policy-AveragePolicyStd | 0.368373       |
| Policy-AverageReturn    | -2.82e+03      |
| Policy-MaxReturn        | -2.23e+03      |
| Policy-MinReturn        | -3.23e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 208            |
| Policy-TimeAlgoOpt      | 0.423          |
| Policy-TimeSampleProc   | 0.193          |
| Policy-TimeSampling     | 0.876          |
| Policy-TimeStep         | 1.5            |
| Time                    | 1.63e+03       |
| n_timesteps             | 51000          |
--------------------------------------------
Training finished
