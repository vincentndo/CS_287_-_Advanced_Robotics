Logging to /home/vincent/workplace/CS_287_-_Advanced_Robotics/homework/hw5/cs287hw5/ppo/run_scripts/data/parallel_mb_ppo/mbppo_Hopper_l1//01

 ---------------- Iteration 0 ----------------
Obtaining random samples from the environment...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 0 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 1 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 2 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 3 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 4 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 5 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 6 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 7 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 8 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 9 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.18            |
| Data-EnvSampler-Poli... | 0.0396          |
| Data-EnvTrajs-Averag... | -283            |
| Data-EnvTrajs-MaxReturn | -222            |
| Data-EnvTrajs-MinReturn | -329            |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 40.7            |
| Data-TimeEnvSampleProc  | 0.000527        |
| Data-TimeEnvSampling    | 0.23            |
| Iteration               | 0               |
| ItrTime                 | 9.29            |
| LossAfter               | -0.005943949    |
| LossBefore              | -1.37853485e-05 |
| Model-TimeModelFit      | 3.03            |
| ModelSampler-n_times... | 40000           |
| Policy-AverageAbsPol... | 0.61231256      |
| Policy-AverageDiscou... | -2.01e+06       |
| Policy-AveragePolicyStd | 0.96026874      |
| Policy-AverageReturn    | -5.29e+06       |
| Policy-MaxReturn        | -5.07e+06       |
| Policy-MinReturn        | -5.42e+06       |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 9.02e+04        |
| Policy-TimeAlgoOpt      | 1.02            |
| Policy-TimeSampleProc   | 0.408           |
| Policy-TimeSampling     | 4.57            |
| Policy-TimeStep         | 6.03            |
| Time                    | 9.29            |
| n_timesteps             | 1000            |
---------------------------------------------

 ---------------- Iteration 1 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 10 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 11 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 12 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 13 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 14 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 15 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 16 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 17 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 18 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 19 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.287          |
| Data-EnvSampler-Poli... | 0.535          |
| Data-EnvTrajs-Averag... | 40.5           |
| Data-EnvTrajs-MaxReturn | 266            |
| Data-EnvTrajs-MinReturn | -332           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 259            |
| Data-TimeEnvSampleProc  | 0.000827       |
| Data-TimeEnvSampling    | 0.842          |
| Iteration               | 1              |
| ItrTime                 | 7.8            |
| LossAfter               | -0.004974858   |
| LossBefore              | -1.3513562e-05 |
| Model-TimeModelFit      | 4.21           |
| ModelSampler-n_times... | 80000          |
| Policy-AverageAbsPol... | 0.48395744     |
| Policy-AverageDiscou... | -1.19e+06      |
| Policy-AveragePolicyStd | 0.9343707      |
| Policy-AverageReturn    | -4.02e+06      |
| Policy-MaxReturn        | -3.71e+06      |
| Policy-MinReturn        | -5.29e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 4.2e+05        |
| Policy-TimeAlgoOpt      | 0.608          |
| Policy-TimeSampleProc   | 0.282          |
| Policy-TimeSampling     | 1.83           |
| Policy-TimeStep         | 2.75           |
| Time                    | 17.3           |
| n_timesteps             | 2000           |
--------------------------------------------

 ---------------- Iteration 2 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 20 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 21 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 22 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 23 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 24 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 25 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 26 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 27 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 28 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 29 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.391          |
| Data-EnvSampler-Poli... | 0.62           |
| Data-EnvTrajs-Averag... | -159           |
| Data-EnvTrajs-MaxReturn | 264            |
| Data-EnvTrajs-MinReturn | -358           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 220            |
| Data-TimeEnvSampleProc  | 0.00051        |
| Data-TimeEnvSampling    | 1.04           |
| Iteration               | 2              |
| ItrTime                 | 10.1           |
| LossAfter               | -0.004054198   |
| LossBefore              | -1.3389078e-05 |
| Model-TimeModelFit      | 6.32           |
| ModelSampler-n_times... | 120000         |
| Policy-AverageAbsPol... | 1.0722203      |
| Policy-AverageDiscou... | -1.97e+06      |
| Policy-AveragePolicyStd | 0.92269826     |
| Policy-AverageReturn    | -5.22e+06      |
| Policy-MaxReturn        | -5.19e+06      |
| Policy-MinReturn        | -5.25e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.56e+04       |
| Policy-TimeAlgoOpt      | 0.579          |
| Policy-TimeSampleProc   | 0.559          |
| Policy-TimeSampling     | 1.54           |
| Policy-TimeStep         | 2.77           |
| Time                    | 27.5           |
| n_timesteps             | 3000           |
--------------------------------------------

 ---------------- Iteration 3 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 30 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 31 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 32 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 33 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 34 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 35 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 36 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 37 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 38 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 39 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.356          |
| Data-EnvSampler-Poli... | 0.491          |
| Data-EnvTrajs-Averag... | 193            |
| Data-EnvTrajs-MaxReturn | 271            |
| Data-EnvTrajs-MinReturn | 86.5           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 66.2           |
| Data-TimeEnvSampleProc  | 0.000594       |
| Data-TimeEnvSampling    | 0.872          |
| Iteration               | 3              |
| ItrTime                 | 12.1           |
| LossAfter               | -0.0077685984  |
| LossBefore              | -1.3223401e-05 |
| Model-TimeModelFit      | 8.45           |
| ModelSampler-n_times... | 160000         |
| Policy-AverageAbsPol... | 0.5108987      |
| Policy-AverageDiscou... | -431           |
| Policy-AveragePolicyStd | 0.9077095      |
| Policy-AverageReturn    | -1.04e+03      |
| Policy-MaxReturn        | -947           |
| Policy-MinReturn        | -1.14e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 49.3           |
| Policy-TimeAlgoOpt      | 0.515          |
| Policy-TimeSampleProc   | 0.656          |
| Policy-TimeSampling     | 1.58           |
| Policy-TimeStep         | 2.81           |
| Time                    | 39.6           |
| n_timesteps             | 4000           |
--------------------------------------------

 ---------------- Iteration 4 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 40 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 41 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 42 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 43 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 44 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 45 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 46 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 47 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 48 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 49 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.377          |
| Data-EnvSampler-Poli... | 0.57           |
| Data-EnvTrajs-Averag... | 51.8           |
| Data-EnvTrajs-MaxReturn | 249            |
| Data-EnvTrajs-MinReturn | -106           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 116            |
| Data-TimeEnvSampleProc  | 0.000585       |
| Data-TimeEnvSampling    | 0.973          |
| Iteration               | 4              |
| ItrTime                 | 14.2           |
| LossAfter               | -0.004457143   |
| LossBefore              | -1.3165631e-05 |
| Model-TimeModelFit      | 10.6           |
| ModelSampler-n_times... | 200000         |
| Policy-AverageAbsPol... | 0.92637306     |
| Policy-AverageDiscou... | -1.92e+06      |
| Policy-AveragePolicyStd | 0.9027659      |
| Policy-AverageReturn    | -5.16e+06      |
| Policy-MaxReturn        | -5.1e+06       |
| Policy-MinReturn        | -5.21e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.6e+04        |
| Policy-TimeAlgoOpt      | 0.594          |
| Policy-TimeSampleProc   | 0.347          |
| Policy-TimeSampling     | 1.64           |
| Policy-TimeStep         | 2.65           |
| Time                    | 53.8           |
| n_timesteps             | 5000           |
--------------------------------------------

 ---------------- Iteration 5 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 50 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 51 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 52 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 53 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 54 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 55 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 56 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 57 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 58 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 59 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.336          |
| Data-EnvSampler-Poli... | 0.495          |
| Data-EnvTrajs-Averag... | -325           |
| Data-EnvTrajs-MaxReturn | -227           |
| Data-EnvTrajs-MinReturn | -448           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 80.8           |
| Data-TimeEnvSampleProc  | 0.000571       |
| Data-TimeEnvSampling    | 0.854          |
| Iteration               | 5              |
| ItrTime                 | 16.3           |
| LossAfter               | -0.006501794   |
| LossBefore              | -1.3153336e-05 |
| Model-TimeModelFit      | 12.5           |
| ModelSampler-n_times... | 240000         |
| Policy-AverageAbsPol... | 0.65659994     |
| Policy-AverageDiscou... | -3.93e+05      |
| Policy-AveragePolicyStd | 0.90093195     |
| Policy-AverageReturn    | -1.79e+06      |
| Policy-MaxReturn        | -896           |
| Policy-MinReturn        | -4.12e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.15e+06       |
| Policy-TimeAlgoOpt      | 0.592          |
| Policy-TimeSampleProc   | 0.566          |
| Policy-TimeSampling     | 1.78           |
| Policy-TimeStep         | 2.98           |
| Time                    | 70.2           |
| n_timesteps             | 6000           |
--------------------------------------------

 ---------------- Iteration 6 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 60 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 61 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 62 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 63 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 64 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 65 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 66 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 67 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 68 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 69 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.311          |
| Data-EnvSampler-Poli... | 0.447          |
| Data-EnvTrajs-Averag... | -57.5          |
| Data-EnvTrajs-MaxReturn | 123            |
| Data-EnvTrajs-MinReturn | -222           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 118            |
| Data-TimeEnvSampleProc  | 0.000685       |
| Data-TimeEnvSampling    | 0.781          |
| Iteration               | 6              |
| ItrTime                 | 18.2           |
| LossAfter               | -0.003193596   |
| LossBefore              | -1.3014014e-05 |
| Model-TimeModelFit      | 14.6           |
| ModelSampler-n_times... | 280000         |
| Policy-AverageAbsPol... | 0.53839475     |
| Policy-AverageDiscou... | -336           |
| Policy-AveragePolicyStd | 0.88882095     |
| Policy-AverageReturn    | -914           |
| Policy-MaxReturn        | -832           |
| Policy-MinReturn        | -969           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 36             |
| Policy-TimeAlgoOpt      | 0.577          |
| Policy-TimeSampleProc   | 0.484          |
| Policy-TimeSampling     | 1.65           |
| Policy-TimeStep         | 2.75           |
| Time                    | 88.4           |
| n_timesteps             | 7000           |
--------------------------------------------

 ---------------- Iteration 7 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 70 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 71 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 72 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 73 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 74 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 75 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 76 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 77 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 78 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 79 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.299          |
| Data-EnvSampler-Poli... | 0.384          |
| Data-EnvTrajs-Averag... | 122            |
| Data-EnvTrajs-MaxReturn | 223            |
| Data-EnvTrajs-MinReturn | -10.6          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 82.2           |
| Data-TimeEnvSampleProc  | 0.000574       |
| Data-TimeEnvSampling    | 0.703          |
| Iteration               | 7              |
| ItrTime                 | 21             |
| LossAfter               | -0.004202712   |
| LossBefore              | -1.2868175e-05 |
| Model-TimeModelFit      | 17.3           |
| ModelSampler-n_times... | 320000         |
| Policy-AverageAbsPol... | 0.6087709      |
| Policy-AverageDiscou... | -8.83e+05      |
| Policy-AveragePolicyStd | 0.87755895     |
| Policy-AverageReturn    | -2.72e+06      |
| Policy-MaxReturn        | -581           |
| Policy-MinReturn        | -4.89e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.23e+06       |
| Policy-TimeAlgoOpt      | 0.553          |
| Policy-TimeSampleProc   | 0.671          |
| Policy-TimeSampling     | 1.67           |
| Policy-TimeStep         | 2.96           |
| Time                    | 109            |
| n_timesteps             | 8000           |
--------------------------------------------

 ---------------- Iteration 8 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 80 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 81 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 82 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 83 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 84 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 85 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 86 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 87 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 88 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 89 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.306          |
| Data-EnvSampler-Poli... | 0.383          |
| Data-EnvTrajs-Averag... | -315           |
| Data-EnvTrajs-MaxReturn | -283           |
| Data-EnvTrajs-MinReturn | -334           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 20             |
| Data-TimeEnvSampleProc  | 0.000512       |
| Data-TimeEnvSampling    | 0.709          |
| Iteration               | 8              |
| ItrTime                 | 22.2           |
| LossAfter               | -0.0074178623  |
| LossBefore              | -1.2903665e-05 |
| Model-TimeModelFit      | 18.6           |
| ModelSampler-n_times... | 360000         |
| Policy-AverageAbsPol... | 0.94935024     |
| Policy-AverageDiscou... | -1.27e+06      |
| Policy-AveragePolicyStd | 0.879386       |
| Policy-AverageReturn    | -4.09e+06      |
| Policy-MaxReturn        | -3.28e+03      |
| Policy-MinReturn        | -4.56e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 9.73e+05       |
| Policy-TimeAlgoOpt      | 0.666          |
| Policy-TimeSampleProc   | 0.362          |
| Policy-TimeSampling     | 1.78           |
| Policy-TimeStep         | 2.88           |
| Time                    | 132            |
| n_timesteps             | 9000           |
--------------------------------------------

 ---------------- Iteration 9 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 90 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 91 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 92 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 93 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 94 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 95 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 96 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 97 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 98 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 99 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.308          |
| Data-EnvSampler-Poli... | 0.408          |
| Data-EnvTrajs-Averag... | -97.2          |
| Data-EnvTrajs-MaxReturn | 110            |
| Data-EnvTrajs-MinReturn | -324           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 152            |
| Data-TimeEnvSampleProc  | 0.000586       |
| Data-TimeEnvSampling    | 0.737          |
| Iteration               | 9              |
| ItrTime                 | 24.3           |
| LossAfter               | -0.004795936   |
| LossBefore              | -1.2942447e-05 |
| Model-TimeModelFit      | 20.7           |
| ModelSampler-n_times... | 400000         |
| Policy-AverageAbsPol... | 0.42385784     |
| Policy-AverageDiscou... | -5.03e+04      |
| Policy-AveragePolicyStd | 0.8830321      |
| Policy-AverageReturn    | -1.85e+05      |
| Policy-MaxReturn        | 18.4           |
| Policy-MinReturn        | -3.7e+06       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 8.07e+05       |
| Policy-TimeAlgoOpt      | 0.691          |
| Policy-TimeSampleProc   | 0.392          |
| Policy-TimeSampling     | 1.7            |
| Policy-TimeStep         | 2.81           |
| Time                    | 156            |
| n_timesteps             | 10000          |
--------------------------------------------

 ---------------- Iteration 10 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 100 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 101 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 102 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 103 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 104 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 105 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 106 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 107 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 108 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 109 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.328          |
| Data-EnvSampler-Poli... | 0.399          |
| Data-EnvTrajs-Averag... | -43            |
| Data-EnvTrajs-MaxReturn | 255            |
| Data-EnvTrajs-MinReturn | -246           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 173            |
| Data-TimeEnvSampleProc  | 0.000542       |
| Data-TimeEnvSampling    | 0.748          |
| Iteration               | 10             |
| ItrTime                 | 26.5           |
| LossAfter               | -0.0048356857  |
| LossBefore              | -1.2767252e-05 |
| Model-TimeModelFit      | 22.9           |
| ModelSampler-n_times... | 440000         |
| Policy-AverageAbsPol... | 0.98564255     |
| Policy-AverageDiscou... | -1.71e+06      |
| Policy-AveragePolicyStd | 0.8673449      |
| Policy-AverageReturn    | -4.9e+06       |
| Policy-MaxReturn        | -4.86e+06      |
| Policy-MinReturn        | -4.94e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.37e+04       |
| Policy-TimeAlgoOpt      | 0.584          |
| Policy-TimeSampleProc   | 0.526          |
| Policy-TimeSampling     | 1.62           |
| Policy-TimeStep         | 2.75           |
| Time                    | 182            |
| n_timesteps             | 11000          |
--------------------------------------------

 ---------------- Iteration 11 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 110 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 111 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 112 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 113 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 114 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 115 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 116 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 117 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 118 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 119 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.335          |
| Data-EnvSampler-Poli... | 0.404          |
| Data-EnvTrajs-Averag... | -311           |
| Data-EnvTrajs-MaxReturn | -159           |
| Data-EnvTrajs-MinReturn | -437           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 89.5           |
| Data-TimeEnvSampleProc  | 0.000835       |
| Data-TimeEnvSampling    | 0.76           |
| Iteration               | 11             |
| ItrTime                 | 28.6           |
| LossAfter               | -0.0063399714  |
| LossBefore              | -1.2716322e-05 |
| Model-TimeModelFit      | 25.1           |
| ModelSampler-n_times... | 480000         |
| Policy-AverageAbsPol... | 0.6271242      |
| Policy-AverageDiscou... | -9.16e+03      |
| Policy-AveragePolicyStd | 0.864275       |
| Policy-AverageReturn    | -5.58e+04      |
| Policy-MaxReturn        | -480           |
| Policy-MinReturn        | -1.09e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.36e+05       |
| Policy-TimeAlgoOpt      | 0.583          |
| Policy-TimeSampleProc   | 0.446          |
| Policy-TimeSampling     | 1.67           |
| Policy-TimeStep         | 2.72           |
| Time                    | 211            |
| n_timesteps             | 12000          |
--------------------------------------------

 ---------------- Iteration 12 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 120 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 121 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 122 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 123 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 124 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 125 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 126 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 127 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 128 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 129 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.375          |
| Data-EnvSampler-Poli... | 0.517          |
| Data-EnvTrajs-Averag... | -395           |
| Data-EnvTrajs-MaxReturn | -356           |
| Data-EnvTrajs-MinReturn | -414           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 20.5           |
| Data-TimeEnvSampleProc  | 0.000518       |
| Data-TimeEnvSampling    | 0.921          |
| Iteration               | 12             |
| ItrTime                 | 29.1           |
| LossAfter               | -0.004701626   |
| LossBefore              | -1.2550428e-05 |
| Model-TimeModelFit      | 25.5           |
| ModelSampler-n_times... | 520000         |
| Policy-AverageAbsPol... | 0.6607713      |
| Policy-AverageDiscou... | -1.48e+05      |
| Policy-AveragePolicyStd | 0.84870917     |
| Policy-AverageReturn    | -7.06e+05      |
| Policy-MaxReturn        | -225           |
| Policy-MinReturn        | -2.57e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.09e+06       |
| Policy-TimeAlgoOpt      | 0.657          |
| Policy-TimeSampleProc   | 0.253          |
| Policy-TimeSampling     | 1.78           |
| Policy-TimeStep         | 2.73           |
| Time                    | 240            |
| n_timesteps             | 13000          |
--------------------------------------------

 ---------------- Iteration 13 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 130 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 131 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 132 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 133 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 134 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 135 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 136 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 137 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 138 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 139 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.415          |
| Data-EnvSampler-Poli... | 0.634          |
| Data-EnvTrajs-Averag... | -249           |
| Data-EnvTrajs-MaxReturn | -190           |
| Data-EnvTrajs-MinReturn | -316           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 42.5           |
| Data-TimeEnvSampleProc  | 0.000725       |
| Data-TimeEnvSampling    | 1.08           |
| Iteration               | 13             |
| ItrTime                 | 28.7           |
| LossAfter               | -0.0065444508  |
| LossBefore              | -1.2429259e-05 |
| Model-TimeModelFit      | 24.9           |
| ModelSampler-n_times... | 560000         |
| Policy-AverageAbsPol... | 0.67837745     |
| Policy-AverageDiscou... | -7.48e+05      |
| Policy-AveragePolicyStd | 0.8396097      |
| Policy-AverageReturn    | -2.88e+06      |
| Policy-MaxReturn        | -455           |
| Policy-MinReturn        | -4.17e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.23e+06       |
| Policy-TimeAlgoOpt      | 0.596          |
| Policy-TimeSampleProc   | 0.457          |
| Policy-TimeSampling     | 1.69           |
| Policy-TimeStep         | 2.77           |
| Time                    | 269            |
| n_timesteps             | 14000          |
--------------------------------------------

 ---------------- Iteration 14 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 140 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 141 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 142 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 143 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 144 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 145 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 146 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 147 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 148 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 149 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.378          |
| Data-EnvSampler-Poli... | 0.673          |
| Data-EnvTrajs-Averag... | 51.1           |
| Data-EnvTrajs-MaxReturn | 85.5           |
| Data-EnvTrajs-MinReturn | 29.4           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 21.6           |
| Data-TimeEnvSampleProc  | 0.000746       |
| Data-TimeEnvSampling    | 1.08           |
| Iteration               | 14             |
| ItrTime                 | 29.9           |
| LossAfter               | -0.005770269   |
| LossBefore              | -1.2342232e-05 |
| Model-TimeModelFit      | 26.1           |
| ModelSampler-n_times... | 600000         |
| Policy-AverageAbsPol... | 0.59230715     |
| Policy-AverageDiscou... | 27.4           |
| Policy-AveragePolicyStd | 0.83198535     |
| Policy-AverageReturn    | 0.518          |
| Policy-MaxReturn        | 87.7           |
| Policy-MinReturn        | -113           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 42.3           |
| Policy-TimeAlgoOpt      | 0.62           |
| Policy-TimeSampleProc   | 0.433          |
| Policy-TimeSampling     | 1.59           |
| Policy-TimeStep         | 2.68           |
| Time                    | 299            |
| n_timesteps             | 15000          |
--------------------------------------------

 ---------------- Iteration 15 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 150 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 151 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 152 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 153 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 154 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 155 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 156 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 157 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 158 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 159 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.481          |
| Data-EnvSampler-Poli... | 0.768          |
| Data-EnvTrajs-Averag... | 151            |
| Data-EnvTrajs-MaxReturn | 226            |
| Data-EnvTrajs-MinReturn | 66             |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 68.9           |
| Data-TimeEnvSampleProc  | 0.000562       |
| Data-TimeEnvSampling    | 1.28           |
| Iteration               | 15             |
| ItrTime                 | 30.2           |
| LossAfter               | -0.006597668   |
| LossBefore              | -1.2261683e-05 |
| Model-TimeModelFit      | 26.2           |
| ModelSampler-n_times... | 640000         |
| Policy-AverageAbsPol... | 0.644718       |
| Policy-AverageDiscou... | -1.73e+05      |
| Policy-AveragePolicyStd | 0.8248638      |
| Policy-AverageReturn    | -8.53e+05      |
| Policy-MaxReturn        | -178           |
| Policy-MinReturn        | -3.21e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.04e+06       |
| Policy-TimeAlgoOpt      | 0.553          |
| Policy-TimeSampleProc   | 0.399          |
| Policy-TimeSampling     | 1.62           |
| Policy-TimeStep         | 2.69           |
| Time                    | 329            |
| n_timesteps             | 16000          |
--------------------------------------------

 ---------------- Iteration 16 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 160 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 161 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 162 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 163 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 164 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 165 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 166 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 167 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 168 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 169 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.38           |
| Data-EnvSampler-Poli... | 0.704          |
| Data-EnvTrajs-Averag... | 197            |
| Data-EnvTrajs-MaxReturn | 236            |
| Data-EnvTrajs-MinReturn | 135            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 36.9           |
| Data-TimeEnvSampleProc  | 0.000555       |
| Data-TimeEnvSampling    | 1.11           |
| Iteration               | 16             |
| ItrTime                 | 30.9           |
| LossAfter               | -0.004761444   |
| LossBefore              | -1.1923491e-05 |
| Model-TimeModelFit      | 27.2           |
| ModelSampler-n_times... | 680000         |
| Policy-AverageAbsPol... | 0.56598943     |
| Policy-AverageDiscou... | -438           |
| Policy-AveragePolicyStd | 0.798333       |
| Policy-AverageReturn    | -3.59e+03      |
| Policy-MaxReturn        | 191            |
| Policy-MinReturn        | -6.98e+04      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.52e+04       |
| Policy-TimeAlgoOpt      | 0.628          |
| Policy-TimeSampleProc   | 0.436          |
| Policy-TimeSampling     | 1.55           |
| Policy-TimeStep         | 2.65           |
| Time                    | 360            |
| n_timesteps             | 17000          |
--------------------------------------------

 ---------------- Iteration 17 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 170 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 171 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 172 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 173 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 174 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 175 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 176 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 177 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 178 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 179 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.435          |
| Data-EnvSampler-Poli... | 0.745          |
| Data-EnvTrajs-Averag... | 204            |
| Data-EnvTrajs-MaxReturn | 247            |
| Data-EnvTrajs-MinReturn | 105            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 52.2           |
| Data-TimeEnvSampleProc  | 0.000555       |
| Data-TimeEnvSampling    | 1.21           |
| Iteration               | 17             |
| ItrTime                 | 30.1           |
| LossAfter               | -0.002505359   |
| LossBefore              | -1.1584424e-05 |
| Model-TimeModelFit      | 26.2           |
| ModelSampler-n_times... | 720000         |
| Policy-AverageAbsPol... | 0.44995162     |
| Policy-AverageDiscou... | 78.2           |
| Policy-AveragePolicyStd | 0.77144426     |
| Policy-AverageReturn    | 166            |
| Policy-MaxReturn        | 212            |
| Policy-MinReturn        | 75.2           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 35.8           |
| Policy-TimeAlgoOpt      | 0.529          |
| Policy-TimeSampleProc   | 0.475          |
| Policy-TimeSampling     | 1.63           |
| Policy-TimeStep         | 2.66           |
| Time                    | 390            |
| n_timesteps             | 18000          |
--------------------------------------------

 ---------------- Iteration 18 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 180 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 181 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 182 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 183 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 184 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 185 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 186 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 187 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 188 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 189 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.488          |
| Data-EnvSampler-Poli... | 0.764          |
| Data-EnvTrajs-Averag... | 258            |
| Data-EnvTrajs-MaxReturn | 287            |
| Data-EnvTrajs-MinReturn | 239            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 16.8           |
| Data-TimeEnvSampleProc  | 0.000875       |
| Data-TimeEnvSampling    | 1.29           |
| Iteration               | 18             |
| ItrTime                 | 29.9           |
| LossAfter               | -0.0033762204  |
| LossBefore              | -1.1555311e-05 |
| Model-TimeModelFit      | 26             |
| ModelSampler-n_times... | 760000         |
| Policy-AverageAbsPol... | 0.49671367     |
| Policy-AverageDiscou... | -813           |
| Policy-AveragePolicyStd | 0.76905406     |
| Policy-AverageReturn    | -5.82e+03      |
| Policy-MaxReturn        | 4.32           |
| Policy-MinReturn        | -1.11e+05      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.41e+04       |
| Policy-TimeAlgoOpt      | 0.588          |
| Policy-TimeSampleProc   | 0.441          |
| Policy-TimeSampling     | 1.47           |
| Policy-TimeStep         | 2.52           |
| Time                    | 420            |
| n_timesteps             | 19000          |
--------------------------------------------

 ---------------- Iteration 19 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 190 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 191 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 192 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 193 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 194 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 195 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 196 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 197 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 198 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 199 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.537          |
| Data-EnvSampler-Poli... | 0.834          |
| Data-EnvTrajs-Averag... | 262            |
| Data-EnvTrajs-MaxReturn | 280            |
| Data-EnvTrajs-MinReturn | 237            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 16.3           |
| Data-TimeEnvSampleProc  | 0.000882       |
| Data-TimeEnvSampling    | 1.41           |
| Iteration               | 19             |
| ItrTime                 | 30.6           |
| LossAfter               | -0.005307247   |
| LossBefore              | -1.1593483e-05 |
| Model-TimeModelFit      | 26.7           |
| ModelSampler-n_times... | 800000         |
| Policy-AverageAbsPol... | 0.4331419      |
| Policy-AverageDiscou... | 65.7           |
| Policy-AveragePolicyStd | 0.77141625     |
| Policy-AverageReturn    | 153            |
| Policy-MaxReturn        | 215            |
| Policy-MinReturn        | 72.8           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 39.7           |
| Policy-TimeAlgoOpt      | 0.604          |
| Policy-TimeSampleProc   | 0.37           |
| Policy-TimeSampling     | 1.51           |
| Policy-TimeStep         | 2.51           |
| Time                    | 450            |
| n_timesteps             | 20000          |
--------------------------------------------

 ---------------- Iteration 20 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 200 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 201 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 202 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 203 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 204 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 205 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 206 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 207 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 208 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 209 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.531          |
| Data-EnvSampler-Poli... | 1.04           |
| Data-EnvTrajs-Averag... | 272            |
| Data-EnvTrajs-MaxReturn | 281            |
| Data-EnvTrajs-MinReturn | 250            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 11.9           |
| Data-TimeEnvSampleProc  | 0.000688       |
| Data-TimeEnvSampling    | 1.61           |
| Iteration               | 20             |
| ItrTime                 | 30             |
| LossAfter               | -0.0039289515  |
| LossBefore              | -1.1315597e-05 |
| Model-TimeModelFit      | 26             |
| ModelSampler-n_times... | 840000         |
| Policy-AverageAbsPol... | 0.4615492      |
| Policy-AverageDiscou... | 105            |
| Policy-AveragePolicyStd | 0.751135       |
| Policy-AverageReturn    | 183            |
| Policy-MaxReturn        | 328            |
| Policy-MinReturn        | -659           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 249            |
| Policy-TimeAlgoOpt      | 0.628          |
| Policy-TimeSampleProc   | 0.398          |
| Policy-TimeSampling     | 1.4            |
| Policy-TimeStep         | 2.46           |
| Time                    | 480            |
| n_timesteps             | 21000          |
--------------------------------------------

 ---------------- Iteration 21 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 210 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 211 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 212 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 213 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 214 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 215 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 216 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 217 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 218 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 219 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.45           |
| Data-EnvSampler-Poli... | 0.892          |
| Data-EnvTrajs-Averag... | 296            |
| Data-EnvTrajs-MaxReturn | 314            |
| Data-EnvTrajs-MinReturn | 281            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 13.1           |
| Data-TimeEnvSampleProc  | 0.000901       |
| Data-TimeEnvSampling    | 1.37           |
| Iteration               | 21             |
| ItrTime                 | 30.9           |
| LossAfter               | -0.0037103356  |
| LossBefore              | -1.1240823e-05 |
| Model-TimeModelFit      | 27.1           |
| ModelSampler-n_times... | 880000         |
| Policy-AverageAbsPol... | 0.41191232     |
| Policy-AverageDiscou... | 113            |
| Policy-AveragePolicyStd | 0.7438221      |
| Policy-AverageReturn    | 279            |
| Policy-MaxReturn        | 381            |
| Policy-MinReturn        | 161            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 58.3           |
| Policy-TimeAlgoOpt      | 0.557          |
| Policy-TimeSampleProc   | 0.299          |
| Policy-TimeSampling     | 1.48           |
| Policy-TimeStep         | 2.38           |
| Time                    | 511            |
| n_timesteps             | 22000          |
--------------------------------------------

 ---------------- Iteration 22 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 220 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 221 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 222 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 223 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 224 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 225 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 226 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 227 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 228 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 229 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.525          |
| Data-EnvSampler-Poli... | 0.978          |
| Data-EnvTrajs-Averag... | 186            |
| Data-EnvTrajs-MaxReturn | 237            |
| Data-EnvTrajs-MinReturn | 137            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 34.2           |
| Data-TimeEnvSampleProc  | 0.000753       |
| Data-TimeEnvSampling    | 1.55           |
| Iteration               | 22             |
| ItrTime                 | 31.6           |
| LossAfter               | -0.0057770982  |
| LossBefore              | -1.1141448e-05 |
| Model-TimeModelFit      | 27.6           |
| ModelSampler-n_times... | 920000         |
| Policy-AverageAbsPol... | 0.48703703     |
| Policy-AverageDiscou... | -2.95e+04      |
| Policy-AveragePolicyStd | 0.73731196     |
| Policy-AverageReturn    | -1.84e+05      |
| Policy-MaxReturn        | 310            |
| Policy-MinReturn        | -1.22e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 3.82e+05       |
| Policy-TimeAlgoOpt      | 0.612          |
| Policy-TimeSampleProc   | 0.352          |
| Policy-TimeSampling     | 1.56           |
| Policy-TimeStep         | 2.54           |
| Time                    | 543            |
| n_timesteps             | 23000          |
--------------------------------------------

 ---------------- Iteration 23 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 230 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 231 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 232 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 233 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 234 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 235 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 236 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 237 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 238 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 239 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.514         |
| Data-EnvSampler-Poli... | 0.956         |
| Data-EnvTrajs-Averag... | 296           |
| Data-EnvTrajs-MaxReturn | 299           |
| Data-EnvTrajs-MinReturn | 291           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 2.72          |
| Data-TimeEnvSampleProc  | 0.00102       |
| Data-TimeEnvSampling    | 1.52          |
| Iteration               | 23            |
| ItrTime                 | 31.6          |
| LossAfter               | -0.005783045  |
| LossBefore              | -1.104278e-05 |
| Model-TimeModelFit      | 27.7          |
| ModelSampler-n_times... | 960000        |
| Policy-AverageAbsPol... | 0.48758003    |
| Policy-AverageDiscou... | 50.6          |
| Policy-AveragePolicyStd | 0.7310196     |
| Policy-AverageReturn    | 129           |
| Policy-MaxReturn        | 213           |
| Policy-MinReturn        | 60.7          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 31            |
| Policy-TimeAlgoOpt      | 0.547         |
| Policy-TimeSampleProc   | 0.305         |
| Policy-TimeSampling     | 1.42          |
| Policy-TimeStep         | 2.3           |
| Time                    | 574           |
| n_timesteps             | 24000         |
-------------------------------------------

 ---------------- Iteration 24 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 240 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 241 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 242 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 243 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 244 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 245 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 246 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 247 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 248 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 249 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.499          |
| Data-EnvSampler-Poli... | 0.842          |
| Data-EnvTrajs-Averag... | 240            |
| Data-EnvTrajs-MaxReturn | 244            |
| Data-EnvTrajs-MinReturn | 236            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.78           |
| Data-TimeEnvSampleProc  | 0.000561       |
| Data-TimeEnvSampling    | 1.38           |
| Iteration               | 24             |
| ItrTime                 | 31.4           |
| LossAfter               | -0.0059859706  |
| LossBefore              | -1.0684753e-05 |
| Model-TimeModelFit      | 27.7           |
| ModelSampler-n_times... | 1000000        |
| Policy-AverageAbsPol... | 0.4417242      |
| Policy-AverageDiscou... | 123            |
| Policy-AveragePolicyStd | 0.70580226     |
| Policy-AverageReturn    | 294            |
| Policy-MaxReturn        | 368            |
| Policy-MinReturn        | 248            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 23.1           |
| Policy-TimeAlgoOpt      | 0.584          |
| Policy-TimeSampleProc   | 0.288          |
| Policy-TimeSampling     | 1.42           |
| Policy-TimeStep         | 2.33           |
| Time                    | 606            |
| n_timesteps             | 25000          |
--------------------------------------------

 ---------------- Iteration 25 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 250 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 251 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 252 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 253 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 254 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 255 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 256 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 257 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 258 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 259 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.477          |
| Data-EnvSampler-Poli... | 0.877          |
| Data-EnvTrajs-Averag... | 221            |
| Data-EnvTrajs-MaxReturn | 269            |
| Data-EnvTrajs-MinReturn | 179            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 34.8           |
| Data-TimeEnvSampleProc  | 0.00102        |
| Data-TimeEnvSampling    | 1.4            |
| Iteration               | 25             |
| ItrTime                 | 31.4           |
| LossAfter               | -0.0034835266  |
| LossBefore              | -1.0588409e-05 |
| Model-TimeModelFit      | 27.8           |
| ModelSampler-n_times... | 1040000        |
| Policy-AverageAbsPol... | 0.46330118     |
| Policy-AverageDiscou... | -297           |
| Policy-AveragePolicyStd | 0.6989173      |
| Policy-AverageReturn    | -2.68e+03      |
| Policy-MaxReturn        | 237            |
| Policy-MinReturn        | -5.7e+04       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.25e+04       |
| Policy-TimeAlgoOpt      | 0.519          |
| Policy-TimeSampleProc   | 0.244          |
| Policy-TimeSampling     | 1.48           |
| Policy-TimeStep         | 2.27           |
| Time                    | 637            |
| n_timesteps             | 26000          |
--------------------------------------------

 ---------------- Iteration 26 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 260 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 261 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 262 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 263 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 264 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 265 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 266 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 267 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 268 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 269 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.482          |
| Data-EnvSampler-Poli... | 0.854          |
| Data-EnvTrajs-Averag... | 237            |
| Data-EnvTrajs-MaxReturn | 262            |
| Data-EnvTrajs-MinReturn | 211            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 17.5           |
| Data-TimeEnvSampleProc  | 0.000792       |
| Data-TimeEnvSampling    | 1.37           |
| Iteration               | 26             |
| ItrTime                 | 31.5           |
| LossAfter               | -0.0020742354  |
| LossBefore              | -1.0438918e-05 |
| Model-TimeModelFit      | 27.9           |
| ModelSampler-n_times... | 1080000        |
| Policy-AverageAbsPol... | 0.45026684     |
| Policy-AverageDiscou... | 91.4           |
| Policy-AveragePolicyStd | 0.6852217      |
| Policy-AverageReturn    | 191            |
| Policy-MaxReturn        | 247            |
| Policy-MinReturn        | 92.8           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 39.7           |
| Policy-TimeAlgoOpt      | 0.505          |
| Policy-TimeSampleProc   | 0.308          |
| Policy-TimeSampling     | 1.38           |
| Policy-TimeStep         | 2.23           |
| Time                    | 669            |
| n_timesteps             | 27000          |
--------------------------------------------

 ---------------- Iteration 27 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 270 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 271 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 272 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 273 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 274 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 275 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 276 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 277 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 278 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 279 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.468          |
| Data-EnvSampler-Poli... | 0.902          |
| Data-EnvTrajs-Averag... | 244            |
| Data-EnvTrajs-MaxReturn | 269            |
| Data-EnvTrajs-MinReturn | 235            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 12.3           |
| Data-TimeEnvSampleProc  | 0.000836       |
| Data-TimeEnvSampling    | 1.4            |
| Iteration               | 27             |
| ItrTime                 | 32             |
| LossAfter               | -0.0050249817  |
| LossBefore              | -1.0227423e-05 |
| Model-TimeModelFit      | 28.3           |
| ModelSampler-n_times... | 1120000        |
| Policy-AverageAbsPol... | 0.54036903     |
| Policy-AverageDiscou... | -1.61e+05      |
| Policy-AveragePolicyStd | 0.67280906     |
| Policy-AverageReturn    | -4.73e+05      |
| Policy-MaxReturn        | 168            |
| Policy-MinReturn        | -4.86e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.42e+06       |
| Policy-TimeAlgoOpt      | 0.56           |
| Policy-TimeSampleProc   | 0.289          |
| Policy-TimeSampling     | 1.39           |
| Policy-TimeStep         | 2.25           |
| Time                    | 701            |
| n_timesteps             | 28000          |
--------------------------------------------

 ---------------- Iteration 28 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 280 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 281 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 282 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 283 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 284 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 285 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 286 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 287 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 288 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 289 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.51          |
| Data-EnvSampler-Poli... | 0.867         |
| Data-EnvTrajs-Averag... | 229           |
| Data-EnvTrajs-MaxReturn | 252           |
| Data-EnvTrajs-MinReturn | 221           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 11.5          |
| Data-TimeEnvSampleProc  | 0.00101       |
| Data-TimeEnvSampling    | 1.41          |
| Iteration               | 28            |
| ItrTime                 | 32.4          |
| LossAfter               | -0.0039905324 |
| LossBefore              | -9.872653e-06 |
| Model-TimeModelFit      | 28.7          |
| ModelSampler-n_times... | 1160000       |
| Policy-AverageAbsPol... | 0.47844934    |
| Policy-AverageDiscou... | -9.31e+04     |
| Policy-AveragePolicyStd | 0.6511898     |
| Policy-AverageReturn    | -3.35e+05     |
| Policy-MaxReturn        | 256           |
| Policy-MinReturn        | -4.58e+06     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.03e+06      |
| Policy-TimeAlgoOpt      | 0.528         |
| Policy-TimeSampleProc   | 0.247         |
| Policy-TimeSampling     | 1.48          |
| Policy-TimeStep         | 2.27          |
| Time                    | 733           |
| n_timesteps             | 29000         |
-------------------------------------------

 ---------------- Iteration 29 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 290 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 291 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 292 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 293 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 294 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 295 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 296 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 297 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 298 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 299 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.596         |
| Data-EnvSampler-Poli... | 0.928         |
| Data-EnvTrajs-Averag... | 192           |
| Data-EnvTrajs-MaxReturn | 215           |
| Data-EnvTrajs-MinReturn | 173           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 14.7          |
| Data-TimeEnvSampleProc  | 0.00106       |
| Data-TimeEnvSampling    | 1.56          |
| Iteration               | 29            |
| ItrTime                 | 32.3          |
| LossAfter               | -0.0025616314 |
| LossBefore              | -9.810303e-06 |
| Model-TimeModelFit      | 28.5          |
| ModelSampler-n_times... | 1200000       |
| Policy-AverageAbsPol... | 0.3667325     |
| Policy-AverageDiscou... | 106           |
| Policy-AveragePolicyStd | 0.6457862     |
| Policy-AverageReturn    | 205           |
| Policy-MaxReturn        | 244           |
| Policy-MinReturn        | 138           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 28.8          |
| Policy-TimeAlgoOpt      | 0.522         |
| Policy-TimeSampleProc   | 0.261         |
| Policy-TimeSampling     | 1.36          |
| Policy-TimeStep         | 2.17          |
| Time                    | 765           |
| n_timesteps             | 30000         |
-------------------------------------------

 ---------------- Iteration 30 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 300 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 301 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 302 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 303 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 304 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 305 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 306 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 307 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 308 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 309 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.524         |
| Data-EnvSampler-Poli... | 0.922         |
| Data-EnvTrajs-Averag... | 279           |
| Data-EnvTrajs-MaxReturn | 282           |
| Data-EnvTrajs-MinReturn | 276           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 2.52          |
| Data-TimeEnvSampleProc  | 0.000925      |
| Data-TimeEnvSampling    | 1.48          |
| Iteration               | 30            |
| ItrTime                 | 32.1          |
| LossAfter               | -0.004906466  |
| LossBefore              | -9.705951e-06 |
| Model-TimeModelFit      | 28.2          |
| ModelSampler-n_times... | 1240000       |
| Policy-AverageAbsPol... | 0.3674316     |
| Policy-AverageDiscou... | 119           |
| Policy-AveragePolicyStd | 0.6383513     |
| Policy-AverageReturn    | 291           |
| Policy-MaxReturn        | 340           |
| Policy-MinReturn        | 223           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 21.8          |
| Policy-TimeAlgoOpt      | 0.542         |
| Policy-TimeSampleProc   | 0.339         |
| Policy-TimeSampling     | 1.44          |
| Policy-TimeStep         | 2.36          |
| Time                    | 798           |
| n_timesteps             | 31000         |
-------------------------------------------

 ---------------- Iteration 31 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 310 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 311 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 312 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 313 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 314 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 315 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 316 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 317 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 318 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 319 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.456         |
| Data-EnvSampler-Poli... | 0.82          |
| Data-EnvTrajs-Averag... | 243           |
| Data-EnvTrajs-MaxReturn | 264           |
| Data-EnvTrajs-MinReturn | 225           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 13.3          |
| Data-TimeEnvSampleProc  | 0.00112       |
| Data-TimeEnvSampling    | 1.31          |
| Iteration               | 31            |
| ItrTime                 | 32.8          |
| LossAfter               | -0.0024698884 |
| LossBefore              | -9.525649e-06 |
| Model-TimeModelFit      | 28.7          |
| ModelSampler-n_times... | 1280000       |
| Policy-AverageAbsPol... | 0.34106335    |
| Policy-AverageDiscou... | 116           |
| Policy-AveragePolicyStd | 0.62740505    |
| Policy-AverageReturn    | 245           |
| Policy-MaxReturn        | 296           |
| Policy-MinReturn        | 190           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 27.5          |
| Policy-TimeAlgoOpt      | 0.625         |
| Policy-TimeSampleProc   | 0.473         |
| Policy-TimeSampling     | 1.68          |
| Policy-TimeStep         | 2.81          |
| Time                    | 830           |
| n_timesteps             | 32000         |
-------------------------------------------

 ---------------- Iteration 32 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 320 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 321 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 322 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 323 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 324 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 325 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 326 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 327 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 328 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 329 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.51          |
| Data-EnvSampler-Poli... | 0.924         |
| Data-EnvTrajs-Averag... | 291           |
| Data-EnvTrajs-MaxReturn | 302           |
| Data-EnvTrajs-MinReturn | 279           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 9.48          |
| Data-TimeEnvSampleProc  | 0.000916      |
| Data-TimeEnvSampling    | 1.48          |
| Iteration               | 32            |
| ItrTime                 | 33            |
| LossAfter               | -0.004823192  |
| LossBefore              | -9.471705e-06 |
| Model-TimeModelFit      | 29            |
| ModelSampler-n_times... | 1320000       |
| Policy-AverageAbsPol... | 0.45289153    |
| Policy-AverageDiscou... | -6.08e+04     |
| Policy-AveragePolicyStd | 0.6238622     |
| Policy-AverageReturn    | -3.51e+05     |
| Policy-MaxReturn        | 335           |
| Policy-MinReturn        | -2.54e+06     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 5.77e+05      |
| Policy-TimeAlgoOpt      | 0.563         |
| Policy-TimeSampleProc   | 0.412         |
| Policy-TimeSampling     | 1.49          |
| Policy-TimeStep         | 2.52          |
| Time                    | 863           |
| n_timesteps             | 33000         |
-------------------------------------------

 ---------------- Iteration 33 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 330 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 331 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 332 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 333 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 334 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 335 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 336 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 337 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 338 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 339 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.442         |
| Data-EnvSampler-Poli... | 0.803         |
| Data-EnvTrajs-Averag... | 276           |
| Data-EnvTrajs-MaxReturn | 295           |
| Data-EnvTrajs-MinReturn | 259           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 14.5          |
| Data-TimeEnvSampleProc  | 0.000761      |
| Data-TimeEnvSampling    | 1.28          |
| Iteration               | 33            |
| ItrTime                 | 33            |
| LossAfter               | -0.004781735  |
| LossBefore              | -9.088699e-06 |
| Model-TimeModelFit      | 29            |
| ModelSampler-n_times... | 1360000       |
| Policy-AverageAbsPol... | 0.36963162    |
| Policy-AverageDiscou... | 133           |
| Policy-AveragePolicyStd | 0.6018431     |
| Policy-AverageReturn    | 303           |
| Policy-MaxReturn        | 323           |
| Policy-MinReturn        | 282           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 10.8          |
| Policy-TimeAlgoOpt      | 0.564         |
| Policy-TimeSampleProc   | 0.432         |
| Policy-TimeSampling     | 1.66          |
| Policy-TimeStep         | 2.73          |
| Time                    | 896           |
| n_timesteps             | 34000         |
-------------------------------------------

 ---------------- Iteration 34 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 340 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 341 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 342 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 343 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 344 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 345 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 346 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 347 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 348 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 349 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.494         |
| Data-EnvSampler-Poli... | 0.78          |
| Data-EnvTrajs-Averag... | 254           |
| Data-EnvTrajs-MaxReturn | 323           |
| Data-EnvTrajs-MinReturn | 208           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 45.2          |
| Data-TimeEnvSampleProc  | 0.00074       |
| Data-TimeEnvSampling    | 1.31          |
| Iteration               | 34            |
| ItrTime                 | 34.5          |
| LossAfter               | -0.0028455171 |
| LossBefore              | -8.923515e-06 |
| Model-TimeModelFit      | 30.4          |
| ModelSampler-n_times... | 1400000       |
| Policy-AverageAbsPol... | 0.38485563    |
| Policy-AverageDiscou... | 135           |
| Policy-AveragePolicyStd | 0.5900503     |
| Policy-AverageReturn    | 282           |
| Policy-MaxReturn        | 384           |
| Policy-MinReturn        | -495          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 223           |
| Policy-TimeAlgoOpt      | 0.563         |
| Policy-TimeSampleProc   | 0.423         |
| Policy-TimeSampling     | 1.75          |
| Policy-TimeStep         | 2.83          |
| Time                    | 931           |
| n_timesteps             | 35000         |
-------------------------------------------

 ---------------- Iteration 35 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 350 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 351 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 352 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 353 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 354 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 355 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 356 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 357 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 358 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 359 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.439         |
| Data-EnvSampler-Poli... | 0.656         |
| Data-EnvTrajs-Averag... | 275           |
| Data-EnvTrajs-MaxReturn | 322           |
| Data-EnvTrajs-MinReturn | 231           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 39.1          |
| Data-TimeEnvSampleProc  | 0.00124       |
| Data-TimeEnvSampling    | 1.13          |
| Iteration               | 35            |
| ItrTime                 | 33.9          |
| LossAfter               | -0.0055663805 |
| LossBefore              | -8.78494e-06  |
| Model-TimeModelFit      | 30.2          |
| ModelSampler-n_times... | 1440000       |
| Policy-AverageAbsPol... | 0.37298965    |
| Policy-AverageDiscou... | -6.77e+03     |
| Policy-AveragePolicyStd | 0.5836825     |
| Policy-AverageReturn    | -4.69e+04     |
| Policy-MaxReturn        | 321           |
| Policy-MinReturn        | -4.88e+05     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.41e+05      |
| Policy-TimeAlgoOpt      | 0.625         |
| Policy-TimeSampleProc   | 0.328         |
| Policy-TimeSampling     | 1.52          |
| Policy-TimeStep         | 2.53          |
| Time                    | 965           |
| n_timesteps             | 36000         |
-------------------------------------------

 ---------------- Iteration 36 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 360 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 361 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 362 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 363 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 364 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 365 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 366 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 367 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 368 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 369 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.457         |
| Data-EnvSampler-Poli... | 0.808         |
| Data-EnvTrajs-Averag... | 320           |
| Data-EnvTrajs-MaxReturn | 328           |
| Data-EnvTrajs-MinReturn | 316           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 4.95          |
| Data-TimeEnvSampleProc  | 0.000793      |
| Data-TimeEnvSampling    | 1.31          |
| Iteration               | 36            |
| ItrTime                 | 33.9          |
| LossAfter               | -0.0040809945 |
| LossBefore              | -8.668065e-06 |
| Model-TimeModelFit      | 30.2          |
| ModelSampler-n_times... | 1480000       |
| Policy-AverageAbsPol... | 0.37937215    |
| Policy-AverageDiscou... | -5.82e+03     |
| Policy-AveragePolicyStd | 0.5768144     |
| Policy-AverageReturn    | -4.08e+04     |
| Policy-MaxReturn        | 246           |
| Policy-MinReturn        | -4.35e+05     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.23e+05      |
| Policy-TimeAlgoOpt      | 0.555         |
| Policy-TimeSampleProc   | 0.272         |
| Policy-TimeSampling     | 1.59          |
| Policy-TimeStep         | 2.45          |
| Time                    | 999           |
| n_timesteps             | 37000         |
-------------------------------------------

 ---------------- Iteration 37 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 370 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 371 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 372 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 373 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 374 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 375 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 376 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 377 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 378 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 379 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.474         |
| Data-EnvSampler-Poli... | 0.927         |
| Data-EnvTrajs-Averag... | 314           |
| Data-EnvTrajs-MaxReturn | 316           |
| Data-EnvTrajs-MinReturn | 311           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.68          |
| Data-TimeEnvSampleProc  | 0.00121       |
| Data-TimeEnvSampling    | 1.44          |
| Iteration               | 37            |
| ItrTime                 | 33.1          |
| LossAfter               | -0.0035555256 |
| LossBefore              | -8.569365e-06 |
| Model-TimeModelFit      | 29.1          |
| ModelSampler-n_times... | 1520000       |
| Policy-AverageAbsPol... | 0.34601706    |
| Policy-AverageDiscou... | -653          |
| Policy-AveragePolicyStd | 0.57021713    |
| Policy-AverageReturn    | -5.42e+03     |
| Policy-MaxReturn        | 378           |
| Policy-MinReturn        | -1.13e+05     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 2.47e+04      |
| Policy-TimeAlgoOpt      | 0.532         |
| Policy-TimeSampleProc   | 0.426         |
| Policy-TimeSampling     | 1.51          |
| Policy-TimeStep         | 2.5           |
| Time                    | 1.03e+03      |
| n_timesteps             | 38000         |
-------------------------------------------

 ---------------- Iteration 38 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 380 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 381 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 382 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 383 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 384 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 385 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 386 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 387 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 388 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 389 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.616         |
| Data-EnvSampler-Poli... | 1.05          |
| Data-EnvTrajs-Averag... | 318           |
| Data-EnvTrajs-MaxReturn | 330           |
| Data-EnvTrajs-MinReturn | 308           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 7.55          |
| Data-TimeEnvSampleProc  | 0.00102       |
| Data-TimeEnvSampling    | 1.71          |
| Iteration               | 38            |
| ItrTime                 | 33.8          |
| LossAfter               | -0.0049625975 |
| LossBefore              | -8.400497e-06 |
| Model-TimeModelFit      | 29.5          |
| ModelSampler-n_times... | 1560000       |
| Policy-AverageAbsPol... | 0.4348618     |
| Policy-AverageDiscou... | -1.64e+03     |
| Policy-AveragePolicyStd | 0.56092626    |
| Policy-AverageReturn    | -1.22e+04     |
| Policy-MaxReturn        | 318           |
| Policy-MinReturn        | -2.37e+05     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 5.17e+04      |
| Policy-TimeAlgoOpt      | 0.597         |
| Policy-TimeSampleProc   | 0.438         |
| Policy-TimeSampling     | 1.53          |
| Policy-TimeStep         | 2.59          |
| Time                    | 1.07e+03      |
| n_timesteps             | 39000         |
-------------------------------------------

 ---------------- Iteration 39 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 390 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 391 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 392 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 393 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 394 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 395 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 396 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 397 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 398 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 399 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.537         |
| Data-EnvSampler-Poli... | 0.996         |
| Data-EnvTrajs-Averag... | 292           |
| Data-EnvTrajs-MaxReturn | 309           |
| Data-EnvTrajs-MinReturn | 282           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 9.56          |
| Data-TimeEnvSampleProc  | 0.000745      |
| Data-TimeEnvSampling    | 1.57          |
| Iteration               | 39            |
| ItrTime                 | 34.6          |
| LossAfter               | -0.004686506  |
| LossBefore              | -8.357479e-06 |
| Model-TimeModelFit      | 30.5          |
| ModelSampler-n_times... | 1600000       |
| Policy-AverageAbsPol... | 0.40489724    |
| Policy-AverageDiscou... | -92.9         |
| Policy-AveragePolicyStd | 0.55875087    |
| Policy-AverageReturn    | -1.39e+03     |
| Policy-MaxReturn        | 411           |
| Policy-MinReturn        | -3.48e+04     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 7.67e+03      |
| Policy-TimeAlgoOpt      | 0.601         |
| Policy-TimeSampleProc   | 0.377         |
| Policy-TimeSampling     | 1.45          |
| Policy-TimeStep         | 2.47          |
| Time                    | 1.1e+03       |
| n_timesteps             | 40000         |
-------------------------------------------

 ---------------- Iteration 40 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 400 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 401 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 402 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 403 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 404 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 405 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 406 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 407 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 408 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 409 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.503         |
| Data-EnvSampler-Poli... | 0.899         |
| Data-EnvTrajs-Averag... | 291           |
| Data-EnvTrajs-MaxReturn | 307           |
| Data-EnvTrajs-MinReturn | 275           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 11.9          |
| Data-TimeEnvSampleProc  | 0.000896      |
| Data-TimeEnvSampling    | 1.44          |
| Iteration               | 40            |
| ItrTime                 | 33.8          |
| LossAfter               | -0.0043317983 |
| LossBefore              | -8.142393e-06 |
| Model-TimeModelFit      | 29.7          |
| ModelSampler-n_times... | 1640000       |
| Policy-AverageAbsPol... | 0.29345024    |
| Policy-AverageDiscou... | 130           |
| Policy-AveragePolicyStd | 0.5465555     |
| Policy-AverageReturn    | 295           |
| Policy-MaxReturn        | 308           |
| Policy-MinReturn        | 262           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 11            |
| Policy-TimeAlgoOpt      | 0.596         |
| Policy-TimeSampleProc   | 0.398         |
| Policy-TimeSampling     | 1.58          |
| Policy-TimeStep         | 2.62          |
| Time                    | 1.13e+03      |
| n_timesteps             | 41000         |
-------------------------------------------

 ---------------- Iteration 41 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 410 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 411 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 412 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 413 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 414 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 415 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 416 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 417 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 418 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 419 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.513         |
| Data-EnvSampler-Poli... | 0.994         |
| Data-EnvTrajs-Averag... | 250           |
| Data-EnvTrajs-MaxReturn | 282           |
| Data-EnvTrajs-MinReturn | 210           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 26.7          |
| Data-TimeEnvSampleProc  | 0.000592      |
| Data-TimeEnvSampling    | 1.54          |
| Iteration               | 41            |
| ItrTime                 | 34.1          |
| LossAfter               | -0.0039535644 |
| LossBefore              | -7.829344e-06 |
| Model-TimeModelFit      | 30.1          |
| ModelSampler-n_times... | 1680000       |
| Policy-AverageAbsPol... | 0.26458183    |
| Policy-AverageDiscou... | 143           |
| Policy-AveragePolicyStd | 0.5293234     |
| Policy-AverageReturn    | 326           |
| Policy-MaxReturn        | 342           |
| Policy-MinReturn        | 288           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 13.6          |
| Policy-TimeAlgoOpt      | 0.563         |
| Policy-TimeSampleProc   | 0.298         |
| Policy-TimeSampling     | 1.51          |
| Policy-TimeStep         | 2.38          |
| Time                    | 1.17e+03      |
| n_timesteps             | 42000         |
-------------------------------------------

 ---------------- Iteration 42 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 420 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 421 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 422 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 423 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 424 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 425 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 426 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 427 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 428 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 429 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.463         |
| Data-EnvSampler-Poli... | 0.771         |
| Data-EnvTrajs-Averag... | 226           |
| Data-EnvTrajs-MaxReturn | 251           |
| Data-EnvTrajs-MinReturn | 203           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 17.6          |
| Data-TimeEnvSampleProc  | 0.000842      |
| Data-TimeEnvSampling    | 1.27          |
| Iteration               | 42            |
| ItrTime                 | 35.2          |
| LossAfter               | -0.005180796  |
| LossBefore              | -7.541442e-06 |
| Model-TimeModelFit      | 31.6          |
| ModelSampler-n_times... | 1720000       |
| Policy-AverageAbsPol... | 0.2662002     |
| Policy-AverageDiscou... | 131           |
| Policy-AveragePolicyStd | 0.51425934    |
| Policy-AverageReturn    | 311           |
| Policy-MaxReturn        | 370           |
| Policy-MinReturn        | 260           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 20.8          |
| Policy-TimeAlgoOpt      | 0.557         |
| Policy-TimeSampleProc   | 0.321         |
| Policy-TimeSampling     | 1.45          |
| Policy-TimeStep         | 2.36          |
| Time                    | 1.2e+03       |
| n_timesteps             | 43000         |
-------------------------------------------

 ---------------- Iteration 43 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 430 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 431 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 432 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 433 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 434 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 435 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 436 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 437 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 438 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 439 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.534         |
| Data-EnvSampler-Poli... | 1.13          |
| Data-EnvTrajs-Averag... | 311           |
| Data-EnvTrajs-MaxReturn | 327           |
| Data-EnvTrajs-MinReturn | 295           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 9.97          |
| Data-TimeEnvSampleProc  | 0.000981      |
| Data-TimeEnvSampling    | 1.71          |
| Iteration               | 43            |
| ItrTime                 | 37.5          |
| LossAfter               | -0.0025385295 |
| LossBefore              | -7.483391e-06 |
| Model-TimeModelFit      | 32.9          |
| ModelSampler-n_times... | 1760000       |
| Policy-AverageAbsPol... | 0.33342865    |
| Policy-AverageDiscou... | 104           |
| Policy-AveragePolicyStd | 0.51154464    |
| Policy-AverageReturn    | 126           |
| Policy-MaxReturn        | 177           |
| Policy-MinReturn        | 76            |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 28.3          |
| Policy-TimeAlgoOpt      | 0.582         |
| Policy-TimeSampleProc   | 0.491         |
| Policy-TimeSampling     | 1.81          |
| Policy-TimeStep         | 2.93          |
| Time                    | 1.24e+03      |
| n_timesteps             | 44000         |
-------------------------------------------

 ---------------- Iteration 44 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 440 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 441 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 442 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 443 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 444 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 445 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 446 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 447 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 448 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 449 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.488         |
| Data-EnvSampler-Poli... | 1.01          |
| Data-EnvTrajs-Averag... | 328           |
| Data-EnvTrajs-MaxReturn | 336           |
| Data-EnvTrajs-MinReturn | 319           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 5.5           |
| Data-TimeEnvSampleProc  | 0.000995      |
| Data-TimeEnvSampling    | 1.54          |
| Iteration               | 44            |
| ItrTime                 | 34.3          |
| LossAfter               | -0.0032692305 |
| LossBefore              | -7.522713e-06 |
| Model-TimeModelFit      | 30.3          |
| ModelSampler-n_times... | 1800000       |
| Policy-AverageAbsPol... | 0.31570497    |
| Policy-AverageDiscou... | 144           |
| Policy-AveragePolicyStd | 0.5135149     |
| Policy-AverageReturn    | 343           |
| Policy-MaxReturn        | 367           |
| Policy-MinReturn        | 316           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 16.4          |
| Policy-TimeAlgoOpt      | 0.537         |
| Policy-TimeSampleProc   | 0.388         |
| Policy-TimeSampling     | 1.51          |
| Policy-TimeStep         | 2.47          |
| Time                    | 1.28e+03      |
| n_timesteps             | 45000         |
-------------------------------------------

 ---------------- Iteration 45 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 450 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 451 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 452 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 453 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 454 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 455 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 456 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 457 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 458 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 459 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.461         |
| Data-EnvSampler-Poli... | 0.849         |
| Data-EnvTrajs-Averag... | 290           |
| Data-EnvTrajs-MaxReturn | 335           |
| Data-EnvTrajs-MinReturn | 234           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 34.3          |
| Data-TimeEnvSampleProc  | 0.000988      |
| Data-TimeEnvSampling    | 1.35          |
| Iteration               | 45            |
| ItrTime                 | 34.4          |
| LossAfter               | -0.0034909588 |
| LossBefore              | -7.339261e-06 |
| Model-TimeModelFit      | 30.7          |
| ModelSampler-n_times... | 1840000       |
| Policy-AverageAbsPol... | 0.32301447    |
| Policy-AverageDiscou... | -2.88e+03     |
| Policy-AveragePolicyStd | 0.50556344    |
| Policy-AverageReturn    | -2.06e+04     |
| Policy-MaxReturn        | 440           |
| Policy-MinReturn        | -4.18e+05     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 9.12e+04      |
| Policy-TimeAlgoOpt      | 0.562         |
| Policy-TimeSampleProc   | 0.341         |
| Policy-TimeSampling     | 1.48          |
| Policy-TimeStep         | 2.43          |
| Time                    | 1.31e+03      |
| n_timesteps             | 46000         |
-------------------------------------------

 ---------------- Iteration 46 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 460 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 461 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 462 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 463 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 464 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 465 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 466 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 467 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 468 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 469 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.457          |
| Data-EnvSampler-Poli... | 0.856          |
| Data-EnvTrajs-Averag... | 312            |
| Data-EnvTrajs-MaxReturn | 356            |
| Data-EnvTrajs-MinReturn | 265            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 36.2           |
| Data-TimeEnvSampleProc  | 0.00105        |
| Data-TimeEnvSampling    | 1.35           |
| Iteration               | 46             |
| ItrTime                 | 34.6           |
| LossAfter               | -0.0042714197  |
| LossBefore              | -7.2024395e-06 |
| Model-TimeModelFit      | 30.4           |
| ModelSampler-n_times... | 1880000        |
| Policy-AverageAbsPol... | 0.34636128     |
| Policy-AverageDiscou... | -2.16e+03      |
| Policy-AveragePolicyStd | 0.49809375     |
| Policy-AverageReturn    | -1.58e+04      |
| Policy-MaxReturn        | 354            |
| Policy-MinReturn        | -3.21e+05      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 7.01e+04       |
| Policy-TimeAlgoOpt      | 0.673          |
| Policy-TimeSampleProc   | 0.406          |
| Policy-TimeSampling     | 1.69           |
| Policy-TimeStep         | 2.83           |
| Time                    | 1.34e+03       |
| n_timesteps             | 47000          |
--------------------------------------------

 ---------------- Iteration 47 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 470 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 471 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 472 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 473 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 474 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 475 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 476 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 477 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 478 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 479 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.503          |
| Data-EnvSampler-Poli... | 0.937          |
| Data-EnvTrajs-Averag... | 327            |
| Data-EnvTrajs-MaxReturn | 334            |
| Data-EnvTrajs-MinReturn | 318            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 6.1            |
| Data-TimeEnvSampleProc  | 0.00105        |
| Data-TimeEnvSampling    | 1.48           |
| Iteration               | 47             |
| ItrTime                 | 35.7           |
| LossAfter               | -0.004253091   |
| LossBefore              | -7.0872397e-06 |
| Model-TimeModelFit      | 31.5           |
| ModelSampler-n_times... | 1920000        |
| Policy-AverageAbsPol... | 0.29436305     |
| Policy-AverageDiscou... | -4.45e+03      |
| Policy-AveragePolicyStd | 0.4904761      |
| Policy-AverageReturn    | -3.05e+04      |
| Policy-MaxReturn        | 362            |
| Policy-MinReturn        | -5.89e+05      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.28e+05       |
| Policy-TimeAlgoOpt      | 0.631          |
| Policy-TimeSampleProc   | 0.504          |
| Policy-TimeSampling     | 1.55           |
| Policy-TimeStep         | 2.72           |
| Time                    | 1.38e+03       |
| n_timesteps             | 48000          |
--------------------------------------------

 ---------------- Iteration 48 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 480 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 481 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 482 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 483 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 484 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 485 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 486 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 487 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 488 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 489 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.453          |
| Data-EnvSampler-Poli... | 0.9            |
| Data-EnvTrajs-Averag... | 316            |
| Data-EnvTrajs-MaxReturn | 335            |
| Data-EnvTrajs-MinReturn | 291            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 18.6           |
| Data-TimeEnvSampleProc  | 0.001          |
| Data-TimeEnvSampling    | 1.39           |
| Iteration               | 48             |
| ItrTime                 | 36.6           |
| LossAfter               | -0.006047204   |
| LossBefore              | -6.9186344e-06 |
| Model-TimeModelFit      | 32.5           |
| ModelSampler-n_times... | 1960000        |
| Policy-AverageAbsPol... | 0.30818802     |
| Policy-AverageDiscou... | 133            |
| Policy-AveragePolicyStd | 0.48353857     |
| Policy-AverageReturn    | 306            |
| Policy-MaxReturn        | 340            |
| Policy-MinReturn        | 245            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 32.6           |
| Policy-TimeAlgoOpt      | 0.57           |
| Policy-TimeSampleProc   | 0.506          |
| Policy-TimeSampling     | 1.57           |
| Policy-TimeStep         | 2.68           |
| Time                    | 1.42e+03       |
| n_timesteps             | 49000          |
--------------------------------------------

 ---------------- Iteration 49 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 490 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 491 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 492 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 493 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 494 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 495 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 496 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 497 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 498 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 499 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.469         |
| Data-EnvSampler-Poli... | 0.838         |
| Data-EnvTrajs-Averag... | 340           |
| Data-EnvTrajs-MaxReturn | 347           |
| Data-EnvTrajs-MinReturn | 333           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 6.16          |
| Data-TimeEnvSampleProc  | 0.00103       |
| Data-TimeEnvSampling    | 1.34          |
| Iteration               | 49            |
| ItrTime                 | 27.4          |
| LossAfter               | -0.008342357  |
| LossBefore              | -6.838138e-06 |
| Model-TimeModelFit      | 24            |
| ModelSampler-n_times... | 2000000       |
| Policy-AverageAbsPol... | 0.27472875    |
| Policy-AverageDiscou... | -5.66e+04     |
| Policy-AveragePolicyStd | 0.47955883    |
| Policy-AverageReturn    | -1.97e+05     |
| Policy-MaxReturn        | 383           |
| Policy-MinReturn        | -3.95e+06     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 8.61e+05      |
| Policy-TimeAlgoOpt      | 0.552         |
| Policy-TimeSampleProc   | 0.269         |
| Policy-TimeSampling     | 1.24          |
| Policy-TimeStep         | 2.08          |
| Time                    | 1.44e+03      |
| n_timesteps             | 50000         |
-------------------------------------------

 ---------------- Iteration 50 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 500 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 501 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 502 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 503 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 504 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 505 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 506 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 507 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 508 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 509 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.37          |
| Data-EnvSampler-Poli... | 0.547         |
| Data-EnvTrajs-Averag... | 264           |
| Data-EnvTrajs-MaxReturn | 298           |
| Data-EnvTrajs-MinReturn | 212           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 29.7          |
| Data-TimeEnvSampleProc  | 0.000851      |
| Data-TimeEnvSampling    | 0.945         |
| Iteration               | 50            |
| ItrTime                 | 25.2          |
| LossAfter               | -0.0027450633 |
| LossBefore              | -6.807505e-06 |
| Model-TimeModelFit      | 22.1          |
| ModelSampler-n_times... | 2040000       |
| Policy-AverageAbsPol... | 0.2813744     |
| Policy-AverageDiscou... | 131           |
| Policy-AveragePolicyStd | 0.47705525    |
| Policy-AverageReturn    | 267           |
| Policy-MaxReturn        | 339           |
| Policy-MinReturn        | 204           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 30.9          |
| Policy-TimeAlgoOpt      | 0.536         |
| Policy-TimeSampleProc   | 0.288         |
| Policy-TimeSampling     | 1.32          |
| Policy-TimeStep         | 2.16          |
| Time                    | 1.47e+03      |
| n_timesteps             | 51000         |
-------------------------------------------
Training finished
