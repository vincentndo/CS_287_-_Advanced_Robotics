Logging to /home/vincent/workplace/CS_287_-_Advanced_Robotics/homework/hw5/cs287hw5/ppo/run_scripts/data/parallel_mb_ppo/mbppo_Hopper_l1//00

 ---------------- Iteration 0 ----------------
Obtaining random samples from the environment...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 0 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 1 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 2 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 3 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 4 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 5 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 6 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 7 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 8 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 9 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.188          |
| Data-EnvSampler-Poli... | 0.0396         |
| Data-EnvTrajs-Averag... | -261           |
| Data-EnvTrajs-MaxReturn | -167           |
| Data-EnvTrajs-MinReturn | -340           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 71.8           |
| Data-TimeEnvSampleProc  | 0.000448       |
| Data-TimeEnvSampling    | 0.238          |
| Iteration               | 0              |
| ItrTime                 | 9.45           |
| LossAfter               | -0.00854748    |
| LossBefore              | -1.3817618e-05 |
| Model-TimeModelFit      | 3.07           |
| ModelSampler-n_times... | 40000          |
| Policy-AverageAbsPol... | 0.35547185     |
| Policy-AverageDiscou... | -2.01e+06      |
| Policy-AveragePolicyStd | 0.9629686      |
| Policy-AverageReturn    | -5.28e+06      |
| Policy-MaxReturn        | -5.12e+06      |
| Policy-MinReturn        | -5.37e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 5.76e+04       |
| Policy-TimeAlgoOpt      | 0.996          |
| Policy-TimeSampleProc   | 0.431          |
| Policy-TimeSampling     | 4.68           |
| Policy-TimeStep         | 6.14           |
| Time                    | 9.45           |
| n_timesteps             | 1000           |
--------------------------------------------

 ---------------- Iteration 1 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 10 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 11 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 12 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 13 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 14 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 15 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 16 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 17 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 18 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 19 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.275           |
| Data-EnvSampler-Poli... | 0.523           |
| Data-EnvTrajs-Averag... | -276            |
| Data-EnvTrajs-MaxReturn | -160            |
| Data-EnvTrajs-MinReturn | -342            |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 62.9            |
| Data-TimeEnvSampleProc  | 0.000764        |
| Data-TimeEnvSampling    | 0.818           |
| Iteration               | 1               |
| ItrTime                 | 7.91            |
| LossAfter               | -0.0025541908   |
| LossBefore              | -1.35467035e-05 |
| Model-TimeModelFit      | 4.36            |
| ModelSampler-n_times... | 80000           |
| Policy-AverageAbsPol... | 0.55759305      |
| Policy-AverageDiscou... | -1.94e+06       |
| Policy-AveragePolicyStd | 0.937692        |
| Policy-AverageReturn    | -5.2e+06        |
| Policy-MaxReturn        | -5.09e+06       |
| Policy-MinReturn        | -5.26e+06       |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 4.29e+04        |
| Policy-TimeAlgoOpt      | 0.529           |
| Policy-TimeSampleProc   | 0.484           |
| Policy-TimeSampling     | 1.67            |
| Policy-TimeStep         | 2.73            |
| Time                    | 17.5            |
| n_timesteps             | 2000            |
---------------------------------------------

 ---------------- Iteration 2 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 20 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 21 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 22 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 23 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 24 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 25 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 26 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 27 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 28 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 29 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.366          |
| Data-EnvSampler-Poli... | 0.544          |
| Data-EnvTrajs-Averag... | -368           |
| Data-EnvTrajs-MaxReturn | -247           |
| Data-EnvTrajs-MinReturn | -443           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 67.9           |
| Data-TimeEnvSampleProc  | 0.0009         |
| Data-TimeEnvSampling    | 0.935          |
| Iteration               | 2              |
| ItrTime                 | 10             |
| LossAfter               | -0.0052949633  |
| LossBefore              | -1.3373771e-05 |
| Model-TimeModelFit      | 6.37           |
| ModelSampler-n_times... | 120000         |
| Policy-AverageAbsPol... | 0.4008405      |
| Policy-AverageDiscou... | -7.67e+05      |
| Policy-AveragePolicyStd | 0.9216095      |
| Policy-AverageReturn    | -3.05e+06      |
| Policy-MaxReturn        | -1.9e+06       |
| Policy-MinReturn        | -4.65e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 7.79e+05       |
| Policy-TimeAlgoOpt      | 0.566          |
| Policy-TimeSampleProc   | 0.471          |
| Policy-TimeSampling     | 1.67           |
| Policy-TimeStep         | 2.74           |
| Time                    | 27.6           |
| n_timesteps             | 3000           |
--------------------------------------------

 ---------------- Iteration 3 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 30 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 31 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 32 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 33 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 34 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 35 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 36 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 37 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 38 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 39 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.333          |
| Data-EnvSampler-Poli... | 0.506          |
| Data-EnvTrajs-Averag... | 140            |
| Data-EnvTrajs-MaxReturn | 236            |
| Data-EnvTrajs-MinReturn | 68.6           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 65.1           |
| Data-TimeEnvSampleProc  | 0.000915       |
| Data-TimeEnvSampling    | 0.865          |
| Iteration               | 3              |
| ItrTime                 | 12.3           |
| LossAfter               | -0.008739675   |
| LossBefore              | -1.3186351e-05 |
| Model-TimeModelFit      | 8.62           |
| ModelSampler-n_times... | 160000         |
| Policy-AverageAbsPol... | 0.32062945     |
| Policy-AverageDiscou... | -1.59e+04      |
| Policy-AveragePolicyStd | 0.90443945     |
| Policy-AverageReturn    | -8.69e+04      |
| Policy-MaxReturn        | -240           |
| Policy-MinReturn        | -1.71e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 3.72e+05       |
| Policy-TimeAlgoOpt      | 0.638          |
| Policy-TimeSampleProc   | 0.457          |
| Policy-TimeSampling     | 1.71           |
| Policy-TimeStep         | 2.84           |
| Time                    | 39.9           |
| n_timesteps             | 4000           |
--------------------------------------------

 ---------------- Iteration 4 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 40 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 41 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 42 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 43 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 44 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 45 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 46 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 47 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 48 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 49 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.329          |
| Data-EnvSampler-Poli... | 0.443          |
| Data-EnvTrajs-Averag... | 49.6           |
| Data-EnvTrajs-MaxReturn | 266            |
| Data-EnvTrajs-MinReturn | -142           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 130            |
| Data-TimeEnvSampleProc  | 0.000879       |
| Data-TimeEnvSampling    | 0.796          |
| Iteration               | 4              |
| ItrTime                 | 14             |
| LossAfter               | -0.0038721825  |
| LossBefore              | -1.2979137e-05 |
| Model-TimeModelFit      | 10.5           |
| ModelSampler-n_times... | 200000         |
| Policy-AverageAbsPol... | 0.529393       |
| Policy-AverageDiscou... | -1.12e+06      |
| Policy-AveragePolicyStd | 0.88750356     |
| Policy-AverageReturn    | -3.6e+06       |
| Policy-MaxReturn        | -1.14e+06      |
| Policy-MinReturn        | -4.96e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.5e+06        |
| Policy-TimeAlgoOpt      | 0.556          |
| Policy-TimeSampleProc   | 0.495          |
| Policy-TimeSampling     | 1.58           |
| Policy-TimeStep         | 2.68           |
| Time                    | 53.9           |
| n_timesteps             | 5000           |
--------------------------------------------

 ---------------- Iteration 5 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 50 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 51 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 52 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 53 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 54 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 55 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 56 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 57 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 58 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 59 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.325          |
| Data-EnvSampler-Poli... | 0.432          |
| Data-EnvTrajs-Averag... | -303           |
| Data-EnvTrajs-MaxReturn | -242           |
| Data-EnvTrajs-MinReturn | -362           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 41.7           |
| Data-TimeEnvSampleProc  | 0.000671       |
| Data-TimeEnvSampling    | 0.781          |
| Iteration               | 5              |
| ItrTime                 | 16.3           |
| LossAfter               | -0.0069941645  |
| LossBefore              | -1.2870552e-05 |
| Model-TimeModelFit      | 12.7           |
| ModelSampler-n_times... | 240000         |
| Policy-AverageAbsPol... | 0.5195925      |
| Policy-AverageDiscou... | -5.36e+05      |
| Policy-AveragePolicyStd | 0.87667876     |
| Policy-AverageReturn    | -1.77e+06      |
| Policy-MaxReturn        | -473           |
| Policy-MinReturn        | -4.68e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.06e+06       |
| Policy-TimeAlgoOpt      | 0.58           |
| Policy-TimeSampleProc   | 0.399          |
| Policy-TimeSampling     | 1.76           |
| Policy-TimeStep         | 2.76           |
| Time                    | 70.2           |
| n_timesteps             | 6000           |
--------------------------------------------

 ---------------- Iteration 6 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 60 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 61 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 62 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 63 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 64 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 65 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 66 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 67 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 68 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 69 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.293          |
| Data-EnvSampler-Poli... | 0.418          |
| Data-EnvTrajs-Averag... | -408           |
| Data-EnvTrajs-MaxReturn | -387           |
| Data-EnvTrajs-MinReturn | -438           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 16.7           |
| Data-TimeEnvSampleProc  | 0.000549       |
| Data-TimeEnvSampling    | 0.733          |
| Iteration               | 6              |
| ItrTime                 | 18.2           |
| LossAfter               | -0.004263556   |
| LossBefore              | -1.2738072e-05 |
| Model-TimeModelFit      | 14.6           |
| ModelSampler-n_times... | 280000         |
| Policy-AverageAbsPol... | 0.48920056     |
| Policy-AverageDiscou... | -307           |
| Policy-AveragePolicyStd | 0.864038       |
| Policy-AverageReturn    | -792           |
| Policy-MaxReturn        | -543           |
| Policy-MinReturn        | -953           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 120            |
| Policy-TimeAlgoOpt      | 0.528          |
| Policy-TimeSampleProc   | 0.721          |
| Policy-TimeSampling     | 1.55           |
| Policy-TimeStep         | 2.85           |
| Time                    | 88.4           |
| n_timesteps             | 7000           |
--------------------------------------------

 ---------------- Iteration 7 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 70 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 71 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 72 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 73 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 74 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 75 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 76 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 77 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 78 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 79 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.28           |
| Data-EnvSampler-Poli... | 0.369          |
| Data-EnvTrajs-Averag... | -349           |
| Data-EnvTrajs-MaxReturn | -333           |
| Data-EnvTrajs-MinReturn | -357           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 8.38           |
| Data-TimeEnvSampleProc  | 0.000902       |
| Data-TimeEnvSampling    | 0.67           |
| Iteration               | 7              |
| ItrTime                 | 20.8           |
| LossAfter               | -0.005200248   |
| LossBefore              | -1.2613877e-05 |
| Model-TimeModelFit      | 17.4           |
| ModelSampler-n_times... | 320000         |
| Policy-AverageAbsPol... | 0.5162102      |
| Policy-AverageDiscou... | -2.23e+04      |
| Policy-AveragePolicyStd | 0.8547168      |
| Policy-AverageReturn    | -1.11e+05      |
| Policy-MaxReturn        | -820           |
| Policy-MinReturn        | -2.2e+06       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 4.78e+05       |
| Policy-TimeAlgoOpt      | 0.574          |
| Policy-TimeSampleProc   | 0.487          |
| Policy-TimeSampling     | 1.59           |
| Policy-TimeStep         | 2.71           |
| Time                    | 109            |
| n_timesteps             | 8000           |
--------------------------------------------

 ---------------- Iteration 8 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 80 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 81 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 82 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 83 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 84 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 85 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 86 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 87 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 88 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 89 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.314          |
| Data-EnvSampler-Poli... | 0.42           |
| Data-EnvTrajs-Averag... | -114           |
| Data-EnvTrajs-MaxReturn | -13.9          |
| Data-EnvTrajs-MinReturn | -205           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 64.8           |
| Data-TimeEnvSampleProc  | 0.000578       |
| Data-TimeEnvSampling    | 0.756          |
| Iteration               | 8              |
| ItrTime                 | 22.3           |
| LossAfter               | -0.0037437538  |
| LossBefore              | -1.2568753e-05 |
| Model-TimeModelFit      | 18.6           |
| ModelSampler-n_times... | 360000         |
| Policy-AverageAbsPol... | 0.525118       |
| Policy-AverageDiscou... | -259           |
| Policy-AveragePolicyStd | 0.85195994     |
| Policy-AverageReturn    | -806           |
| Policy-MaxReturn        | -685           |
| Policy-MinReturn        | -1.07e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 93.3           |
| Policy-TimeAlgoOpt      | 0.572          |
| Policy-TimeSampleProc   | 0.546          |
| Policy-TimeSampling     | 1.78           |
| Policy-TimeStep         | 2.95           |
| Time                    | 132            |
| n_timesteps             | 9000           |
--------------------------------------------

 ---------------- Iteration 9 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 90 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 91 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 92 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 93 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 94 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 95 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 96 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 97 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 98 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 99 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.308          |
| Data-EnvSampler-Poli... | 0.398          |
| Data-EnvTrajs-Averag... | -228           |
| Data-EnvTrajs-MaxReturn | -108           |
| Data-EnvTrajs-MinReturn | -327           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 75.7           |
| Data-TimeEnvSampleProc  | 0.000933       |
| Data-TimeEnvSampling    | 0.728          |
| Iteration               | 9              |
| ItrTime                 | 24.2           |
| LossAfter               | -0.0054521654  |
| LossBefore              | -1.2563092e-05 |
| Model-TimeModelFit      | 20.8           |
| ModelSampler-n_times... | 400000         |
| Policy-AverageAbsPol... | 0.4964996      |
| Policy-AverageDiscou... | -136           |
| Policy-AveragePolicyStd | 0.84988946     |
| Policy-AverageReturn    | -479           |
| Policy-MaxReturn        | -276           |
| Policy-MinReturn        | -577           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 80.3           |
| Policy-TimeAlgoOpt      | 0.665          |
| Policy-TimeSampleProc   | 0.44           |
| Policy-TimeSampling     | 1.58           |
| Policy-TimeStep         | 2.73           |
| Time                    | 156            |
| n_timesteps             | 10000          |
--------------------------------------------

 ---------------- Iteration 10 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 100 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 101 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 102 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 103 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 104 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 105 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 106 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 107 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 108 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 109 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.306          |
| Data-EnvSampler-Poli... | 0.383          |
| Data-EnvTrajs-Averag... | -321           |
| Data-EnvTrajs-MaxReturn | -253           |
| Data-EnvTrajs-MinReturn | -360           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 40.7           |
| Data-TimeEnvSampleProc  | 0.00081        |
| Data-TimeEnvSampling    | 0.709          |
| Iteration               | 10             |
| ItrTime                 | 26.5           |
| LossAfter               | -0.0040030824  |
| LossBefore              | -1.2469345e-05 |
| Model-TimeModelFit      | 22.9           |
| ModelSampler-n_times... | 440000         |
| Policy-AverageAbsPol... | 0.608295       |
| Policy-AverageDiscou... | -119           |
| Policy-AveragePolicyStd | 0.84142375     |
| Policy-AverageReturn    | -433           |
| Policy-MaxReturn        | -271           |
| Policy-MinReturn        | -563           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 72.1           |
| Policy-TimeAlgoOpt      | 0.603          |
| Policy-TimeSampleProc   | 0.505          |
| Policy-TimeSampling     | 1.65           |
| Policy-TimeStep         | 2.86           |
| Time                    | 182            |
| n_timesteps             | 11000          |
--------------------------------------------

 ---------------- Iteration 11 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 110 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 111 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 112 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 113 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 114 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 115 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 116 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 117 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 118 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 119 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.306          |
| Data-EnvSampler-Poli... | 0.382          |
| Data-EnvTrajs-Averag... | -210           |
| Data-EnvTrajs-MaxReturn | -130           |
| Data-EnvTrajs-MinReturn | -297           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 62             |
| Data-TimeEnvSampleProc  | 0.000564       |
| Data-TimeEnvSampling    | 0.709          |
| Iteration               | 11             |
| ItrTime                 | 29.1           |
| LossAfter               | -0.0037656482  |
| LossBefore              | -1.2438661e-05 |
| Model-TimeModelFit      | 25.6           |
| ModelSampler-n_times... | 480000         |
| Policy-AverageAbsPol... | 0.6427571      |
| Policy-AverageDiscou... | -3.76e+04      |
| Policy-AveragePolicyStd | 0.83994395     |
| Policy-AverageReturn    | -1.96e+05      |
| Policy-MaxReturn        | -8.31          |
| Policy-MinReturn        | -1.97e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 5.87e+05       |
| Policy-TimeAlgoOpt      | 0.512          |
| Policy-TimeSampleProc   | 0.61           |
| Policy-TimeSampling     | 1.58           |
| Policy-TimeStep         | 2.74           |
| Time                    | 211            |
| n_timesteps             | 12000          |
--------------------------------------------

 ---------------- Iteration 12 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 120 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 121 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 122 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 123 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 124 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 125 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 126 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 127 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 128 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 129 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.301          |
| Data-EnvSampler-Poli... | 0.399          |
| Data-EnvTrajs-Averag... | -65.5          |
| Data-EnvTrajs-MaxReturn | 49.9           |
| Data-EnvTrajs-MinReturn | -128           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 65             |
| Data-TimeEnvSampleProc  | 0.000544       |
| Data-TimeEnvSampling    | 0.722          |
| Iteration               | 12             |
| ItrTime                 | 29.4           |
| LossAfter               | -0.005985876   |
| LossBefore              | -1.2247487e-05 |
| Model-TimeModelFit      | 26             |
| ModelSampler-n_times... | 520000         |
| Policy-AverageAbsPol... | 1.1497656      |
| Policy-AverageDiscou... | -1.02e+06      |
| Policy-AveragePolicyStd | 0.8238477      |
| Policy-AverageReturn    | -3.73e+06      |
| Policy-MaxReturn        | -3.43e+06      |
| Policy-MinReturn        | -3.93e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.08e+05       |
| Policy-TimeAlgoOpt      | 0.596          |
| Policy-TimeSampleProc   | 0.422          |
| Policy-TimeSampling     | 1.69           |
| Policy-TimeStep         | 2.73           |
| Time                    | 241            |
| n_timesteps             | 13000          |
--------------------------------------------

 ---------------- Iteration 13 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 130 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 131 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 132 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 133 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 134 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 135 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 136 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 137 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 138 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 139 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.323          |
| Data-EnvSampler-Poli... | 0.475          |
| Data-EnvTrajs-Averag... | -341           |
| Data-EnvTrajs-MaxReturn | -316           |
| Data-EnvTrajs-MinReturn | -359           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 15.3           |
| Data-TimeEnvSampleProc  | 0.0007         |
| Data-TimeEnvSampling    | 0.822          |
| Iteration               | 13             |
| ItrTime                 | 28.7           |
| LossAfter               | -0.0044668494  |
| LossBefore              | -1.2169474e-05 |
| Model-TimeModelFit      | 25.2           |
| ModelSampler-n_times... | 560000         |
| Policy-AverageAbsPol... | 0.6636728      |
| Policy-AverageDiscou... | -62.2          |
| Policy-AveragePolicyStd | 0.8141862      |
| Policy-AverageReturn    | -205           |
| Policy-MaxReturn        | -71.5          |
| Policy-MinReturn        | -389           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 81.3           |
| Policy-TimeAlgoOpt      | 0.559          |
| Policy-TimeSampleProc   | 0.546          |
| Policy-TimeSampling     | 1.55           |
| Policy-TimeStep         | 2.69           |
| Time                    | 269            |
| n_timesteps             | 14000          |
--------------------------------------------

 ---------------- Iteration 14 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 140 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 141 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 142 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 143 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 144 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 145 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 146 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 147 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 148 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 149 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.335          |
| Data-EnvSampler-Poli... | 0.474          |
| Data-EnvTrajs-Averag... | -165           |
| Data-EnvTrajs-MaxReturn | -144           |
| Data-EnvTrajs-MinReturn | -203           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 22.3           |
| Data-TimeEnvSampleProc  | 0.000931       |
| Data-TimeEnvSampling    | 0.835          |
| Iteration               | 14             |
| ItrTime                 | 30.1           |
| LossAfter               | -0.0059008137  |
| LossBefore              | -1.2097119e-05 |
| Model-TimeModelFit      | 26.5           |
| ModelSampler-n_times... | 600000         |
| Policy-AverageAbsPol... | 0.6100648      |
| Policy-AverageDiscou... | -1.4e+04       |
| Policy-AveragePolicyStd | 0.81018794     |
| Policy-AverageReturn    | -7.82e+04      |
| Policy-MaxReturn        | -73.9          |
| Policy-MinReturn        | -1.56e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 3.4e+05        |
| Policy-TimeAlgoOpt      | 0.623          |
| Policy-TimeSampleProc   | 0.447          |
| Policy-TimeSampling     | 1.63           |
| Policy-TimeStep         | 2.72           |
| Time                    | 300            |
| n_timesteps             | 15000          |
--------------------------------------------

 ---------------- Iteration 15 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 150 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 151 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 152 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 153 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 154 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 155 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 156 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 157 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 158 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 159 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.351           |
| Data-EnvSampler-Poli... | 0.509           |
| Data-EnvTrajs-Averag... | -143            |
| Data-EnvTrajs-MaxReturn | -52.7           |
| Data-EnvTrajs-MinReturn | -194            |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 49              |
| Data-TimeEnvSampleProc  | 0.000783        |
| Data-TimeEnvSampling    | 0.886           |
| Iteration               | 15              |
| ItrTime                 | 30.1            |
| LossAfter               | -0.003694038    |
| LossBefore              | -1.19351425e-05 |
| Model-TimeModelFit      | 26.7            |
| ModelSampler-n_times... | 640000          |
| Policy-AverageAbsPol... | 0.7405636       |
| Policy-AverageDiscou... | -5.3e+05        |
| Policy-AveragePolicyStd | 0.79951155      |
| Policy-AverageReturn    | -2.47e+06       |
| Policy-MaxReturn        | -1.82e+06       |
| Policy-MinReturn        | -3.09e+06       |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 3.5e+05         |
| Policy-TimeAlgoOpt      | 0.577           |
| Policy-TimeSampleProc   | 0.348           |
| Policy-TimeSampling     | 1.49            |
| Policy-TimeStep         | 2.5             |
| Time                    | 330             |
| n_timesteps             | 16000           |
---------------------------------------------

 ---------------- Iteration 16 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 160 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 161 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 162 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 163 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 164 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 165 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 166 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 167 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 168 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 169 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.331          |
| Data-EnvSampler-Poli... | 0.475          |
| Data-EnvTrajs-Averag... | -19.7          |
| Data-EnvTrajs-MaxReturn | 8.91           |
| Data-EnvTrajs-MinReturn | -78.6          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 33.5           |
| Data-TimeEnvSampleProc  | 0.000963       |
| Data-TimeEnvSampling    | 0.831          |
| Iteration               | 16             |
| ItrTime                 | 30.7           |
| LossAfter               | -0.006691839   |
| LossBefore              | -1.1729438e-05 |
| Model-TimeModelFit      | 27.3           |
| ModelSampler-n_times... | 680000         |
| Policy-AverageAbsPol... | 0.59800994     |
| Policy-AverageDiscou... | -217           |
| Policy-AveragePolicyStd | 0.7807038      |
| Policy-AverageReturn    | -1.57e+03      |
| Policy-MaxReturn        | -111           |
| Policy-MinReturn        | -1.91e+04      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 4.46e+03       |
| Policy-TimeAlgoOpt      | 0.606          |
| Policy-TimeSampleProc   | 0.355          |
| Policy-TimeSampling     | 1.64           |
| Policy-TimeStep         | 2.64           |
| Time                    | 360            |
| n_timesteps             | 17000          |
--------------------------------------------

 ---------------- Iteration 17 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 170 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 171 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 172 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 173 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 174 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 175 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 176 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 177 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 178 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 179 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.38           |
| Data-EnvSampler-Poli... | 0.619          |
| Data-EnvTrajs-Averag... | 40.8           |
| Data-EnvTrajs-MaxReturn | 76.2           |
| Data-EnvTrajs-MinReturn | -7.11          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 27.9           |
| Data-TimeEnvSampleProc  | 0.000774       |
| Data-TimeEnvSampling    | 1.03           |
| Iteration               | 17             |
| ItrTime                 | 30.4           |
| LossAfter               | -0.00478959    |
| LossBefore              | -1.1687074e-05 |
| Model-TimeModelFit      | 26.8           |
| ModelSampler-n_times... | 720000         |
| Policy-AverageAbsPol... | 0.5268064      |
| Policy-AverageDiscou... | 24.2           |
| Policy-AveragePolicyStd | 0.77951515     |
| Policy-AverageReturn    | 22.4           |
| Policy-MaxReturn        | 145            |
| Policy-MinReturn        | -118           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 86.3           |
| Policy-TimeAlgoOpt      | 0.575          |
| Policy-TimeSampleProc   | 0.347          |
| Policy-TimeSampling     | 1.66           |
| Policy-TimeStep         | 2.6            |
| Time                    | 391            |
| n_timesteps             | 18000          |
--------------------------------------------

 ---------------- Iteration 18 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 180 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 181 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 182 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 183 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 184 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 185 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 186 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 187 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 188 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 189 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.394          |
| Data-EnvSampler-Poli... | 0.615          |
| Data-EnvTrajs-Averag... | 147            |
| Data-EnvTrajs-MaxReturn | 165            |
| Data-EnvTrajs-MinReturn | 121            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 15.5           |
| Data-TimeEnvSampleProc  | 0.000859       |
| Data-TimeEnvSampling    | 1.04           |
| Iteration               | 18             |
| ItrTime                 | 30             |
| LossAfter               | -0.0046705757  |
| LossBefore              | -1.1480336e-05 |
| Model-TimeModelFit      | 26.5           |
| ModelSampler-n_times... | 760000         |
| Policy-AverageAbsPol... | 0.9172845      |
| Policy-AverageDiscou... | -1.22e+06      |
| Policy-AveragePolicyStd | 0.7632552      |
| Policy-AverageReturn    | -4.12e+06      |
| Policy-MaxReturn        | -3.87e+06      |
| Policy-MinReturn        | -4.29e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.33e+05       |
| Policy-TimeAlgoOpt      | 0.633          |
| Policy-TimeSampleProc   | 0.263          |
| Policy-TimeSampling     | 1.56           |
| Policy-TimeStep         | 2.47           |
| Time                    | 421            |
| n_timesteps             | 19000          |
--------------------------------------------

 ---------------- Iteration 19 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 190 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 191 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 192 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 193 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 194 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 195 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 196 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 197 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 198 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 199 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.395          |
| Data-EnvSampler-Poli... | 0.693          |
| Data-EnvTrajs-Averag... | 289            |
| Data-EnvTrajs-MaxReturn | 347            |
| Data-EnvTrajs-MinReturn | 205            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 49.1           |
| Data-TimeEnvSampleProc  | 0.000849       |
| Data-TimeEnvSampling    | 1.12           |
| Iteration               | 19             |
| ItrTime                 | 31.1           |
| LossAfter               | -0.004190001   |
| LossBefore              | -1.1264207e-05 |
| Model-TimeModelFit      | 27.6           |
| ModelSampler-n_times... | 800000         |
| Policy-AverageAbsPol... | 0.5629223      |
| Policy-AverageDiscou... | 54.9           |
| Policy-AveragePolicyStd | 0.7467495      |
| Policy-AverageReturn    | 87.1           |
| Policy-MaxReturn        | 144            |
| Policy-MinReturn        | -38.7          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 38.4           |
| Policy-TimeAlgoOpt      | 0.529          |
| Policy-TimeSampleProc   | 0.421          |
| Policy-TimeSampling     | 1.34           |
| Policy-TimeStep         | 2.33           |
| Time                    | 452            |
| n_timesteps             | 20000          |
--------------------------------------------

 ---------------- Iteration 20 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 200 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 201 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 202 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 203 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 204 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 205 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 206 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 207 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 208 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 209 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.431          |
| Data-EnvSampler-Poli... | 0.714          |
| Data-EnvTrajs-Averag... | 186            |
| Data-EnvTrajs-MaxReturn | 248            |
| Data-EnvTrajs-MinReturn | 137            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 46.5           |
| Data-TimeEnvSampleProc  | 0.000915       |
| Data-TimeEnvSampling    | 1.18           |
| Iteration               | 20             |
| ItrTime                 | 30.7           |
| LossAfter               | -0.004375636   |
| LossBefore              | -1.0894443e-05 |
| Model-TimeModelFit      | 27.1           |
| ModelSampler-n_times... | 840000         |
| Policy-AverageAbsPol... | 0.6481278      |
| Policy-AverageDiscou... | -7.57e+05      |
| Policy-AveragePolicyStd | 0.71939236     |
| Policy-AverageReturn    | -2.68e+06      |
| Policy-MaxReturn        | 82.7           |
| Policy-MinReturn        | -4.29e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.79e+06       |
| Policy-TimeAlgoOpt      | 0.592          |
| Policy-TimeSampleProc   | 0.346          |
| Policy-TimeSampling     | 1.52           |
| Policy-TimeStep         | 2.48           |
| Time                    | 483            |
| n_timesteps             | 21000          |
--------------------------------------------

 ---------------- Iteration 21 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 210 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 211 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 212 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 213 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 214 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 215 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 216 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 217 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 218 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 219 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.469          |
| Data-EnvSampler-Poli... | 0.735          |
| Data-EnvTrajs-Averag... | 129            |
| Data-EnvTrajs-MaxReturn | 146            |
| Data-EnvTrajs-MinReturn | 112            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 12.9           |
| Data-TimeEnvSampleProc  | 0.000805       |
| Data-TimeEnvSampling    | 1.24           |
| Iteration               | 21             |
| ItrTime                 | 30.9           |
| LossAfter               | -0.0053138956  |
| LossBefore              | -1.0440809e-05 |
| Model-TimeModelFit      | 27.3           |
| ModelSampler-n_times... | 880000         |
| Policy-AverageAbsPol... | 0.67687917     |
| Policy-AverageDiscou... | -1.14e+05      |
| Policy-AveragePolicyStd | 0.6878003      |
| Policy-AverageReturn    | -4.97e+05      |
| Policy-MaxReturn        | -200           |
| Policy-MinReturn        | -3.79e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.05e+06       |
| Policy-TimeAlgoOpt      | 0.53           |
| Policy-TimeSampleProc   | 0.336          |
| Policy-TimeSampling     | 1.44           |
| Policy-TimeStep         | 2.33           |
| Time                    | 513            |
| n_timesteps             | 22000          |
--------------------------------------------

 ---------------- Iteration 22 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 220 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 221 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 222 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 223 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 224 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 225 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 226 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 227 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 228 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 229 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.543         |
| Data-EnvSampler-Poli... | 0.867         |
| Data-EnvTrajs-Averag... | -43.9         |
| Data-EnvTrajs-MaxReturn | 9.37          |
| Data-EnvTrajs-MinReturn | -127          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 49.7          |
| Data-TimeEnvSampleProc  | 0.000837      |
| Data-TimeEnvSampling    | 1.44          |
| Iteration               | 22            |
| ItrTime                 | 32.3          |
| LossAfter               | -0.003983417  |
| LossBefore              | -1.017895e-05 |
| Model-TimeModelFit      | 28.3          |
| ModelSampler-n_times... | 920000        |
| Policy-AverageAbsPol... | 0.6646551     |
| Policy-AverageDiscou... | -5.8e+05      |
| Policy-AveragePolicyStd | 0.670704      |
| Policy-AverageReturn    | -2.56e+06     |
| Policy-MaxReturn        | -5.74e+05     |
| Policy-MinReturn        | -3.75e+06     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 7.15e+05      |
| Policy-TimeAlgoOpt      | 0.602         |
| Policy-TimeSampleProc   | 0.352         |
| Policy-TimeSampling     | 1.57          |
| Policy-TimeStep         | 2.55          |
| Time                    | 546           |
| n_timesteps             | 23000         |
-------------------------------------------

 ---------------- Iteration 23 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 230 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 231 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 232 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 233 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 234 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 235 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 236 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 237 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 238 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 239 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.53          |
| Data-EnvSampler-Poli... | 0.968         |
| Data-EnvTrajs-Averag... | 178           |
| Data-EnvTrajs-MaxReturn | 205           |
| Data-EnvTrajs-MinReturn | 163           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 14.7          |
| Data-TimeEnvSampleProc  | 0.00104       |
| Data-TimeEnvSampling    | 1.54          |
| Iteration               | 23            |
| ItrTime                 | 31.9          |
| LossAfter               | -0.0037200458 |
| LossBefore              | -9.848311e-06 |
| Model-TimeModelFit      | 28            |
| ModelSampler-n_times... | 960000        |
| Policy-AverageAbsPol... | 0.39826888    |
| Policy-AverageDiscou... | 116           |
| Policy-AveragePolicyStd | 0.65014935    |
| Policy-AverageReturn    | 245           |
| Policy-MaxReturn        | 284           |
| Policy-MinReturn        | 180           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 23            |
| Policy-TimeAlgoOpt      | 0.583         |
| Policy-TimeSampleProc   | 0.312         |
| Policy-TimeSampling     | 1.45          |
| Policy-TimeStep         | 2.37          |
| Time                    | 578           |
| n_timesteps             | 24000         |
-------------------------------------------

 ---------------- Iteration 24 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 240 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 241 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 242 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 243 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 244 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 245 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 246 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 247 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 248 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 249 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.464         |
| Data-EnvSampler-Poli... | 0.819         |
| Data-EnvTrajs-Averag... | 9.06          |
| Data-EnvTrajs-MaxReturn | 26.7          |
| Data-EnvTrajs-MinReturn | -35.6         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 23.3          |
| Data-TimeEnvSampleProc  | 0.000965      |
| Data-TimeEnvSampling    | 1.32          |
| Iteration               | 24            |
| ItrTime                 | 31.4          |
| LossAfter               | -0.008210747  |
| LossBefore              | -9.490957e-06 |
| Model-TimeModelFit      | 27.7          |
| ModelSampler-n_times... | 1000000       |
| Policy-AverageAbsPol... | 0.3326817     |
| Policy-AverageDiscou... | 148           |
| Policy-AveragePolicyStd | 0.6265813     |
| Policy-AverageReturn    | 361           |
| Policy-MaxReturn        | 393           |
| Policy-MinReturn        | 299           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 23.3          |
| Policy-TimeAlgoOpt      | 0.601         |
| Policy-TimeSampleProc   | 0.261         |
| Policy-TimeSampling     | 1.48          |
| Policy-TimeStep         | 2.37          |
| Time                    | 609           |
| n_timesteps             | 25000         |
-------------------------------------------

 ---------------- Iteration 25 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 250 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 251 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 252 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 253 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 254 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 255 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 256 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 257 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 258 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 259 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.481         |
| Data-EnvSampler-Poli... | 0.883         |
| Data-EnvTrajs-Averag... | -28.7         |
| Data-EnvTrajs-MaxReturn | -1.83         |
| Data-EnvTrajs-MinReturn | -41.6         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 14.3          |
| Data-TimeEnvSampleProc  | 0.000945      |
| Data-TimeEnvSampling    | 1.4           |
| Iteration               | 25            |
| ItrTime                 | 31.2          |
| LossAfter               | -0.007188449  |
| LossBefore              | -9.167227e-06 |
| Model-TimeModelFit      | 27.4          |
| ModelSampler-n_times... | 1040000       |
| Policy-AverageAbsPol... | 0.30524886    |
| Policy-AverageDiscou... | 130           |
| Policy-AveragePolicyStd | 0.60558355    |
| Policy-AverageReturn    | 307           |
| Policy-MaxReturn        | 340           |
| Policy-MinReturn        | 241           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 26.8          |
| Policy-TimeAlgoOpt      | 0.571         |
| Policy-TimeSampleProc   | 0.258         |
| Policy-TimeSampling     | 1.56          |
| Policy-TimeStep         | 2.4           |
| Time                    | 640           |
| n_timesteps             | 26000         |
-------------------------------------------

 ---------------- Iteration 26 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 260 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 261 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 262 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 263 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 264 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 265 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 266 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 267 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 268 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 269 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Data-EnvSampler-EnvE... | 0.505        |
| Data-EnvSampler-Poli... | 0.867        |
| Data-EnvTrajs-Averag... | -92.9        |
| Data-EnvTrajs-MaxReturn | -84.6        |
| Data-EnvTrajs-MinReturn | -98.6        |
| Data-EnvTrajs-NumTrajs  | 5            |
| Data-EnvTrajs-StdReturn | 5.91         |
| Data-TimeEnvSampleProc  | 0.000987     |
| Data-TimeEnvSampling    | 1.41         |
| Iteration               | 26           |
| ItrTime                 | 31.4         |
| LossAfter               | -0.004644844 |
| LossBefore              | -9.016e-06   |
| Model-TimeModelFit      | 27.7         |
| ModelSampler-n_times... | 1080000      |
| Policy-AverageAbsPol... | 0.39752066   |
| Policy-AverageDiscou... | -3.84e+05    |
| Policy-AveragePolicyStd | 0.5958731    |
| Policy-AverageReturn    | -1.28e+06    |
| Policy-MaxReturn        | 337          |
| Policy-MinReturn        | -4.7e+06     |
| Policy-NumTrajs         | 20           |
| Policy-StdReturn        | 1.9e+06      |
| Policy-TimeAlgoOpt      | 0.53         |
| Policy-TimeSampleProc   | 0.316        |
| Policy-TimeSampling     | 1.39         |
| Policy-TimeStep         | 2.26         |
| Time                    | 672          |
| n_timesteps             | 27000        |
------------------------------------------

 ---------------- Iteration 27 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 270 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 271 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 272 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 273 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 274 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 275 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 276 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 277 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 278 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 279 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.485         |
| Data-EnvSampler-Poli... | 0.925         |
| Data-EnvTrajs-Averag... | -47.6         |
| Data-EnvTrajs-MaxReturn | -17.7         |
| Data-EnvTrajs-MinReturn | -78           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 19.6          |
| Data-TimeEnvSampleProc  | 0.000966      |
| Data-TimeEnvSampling    | 1.44          |
| Iteration               | 27            |
| ItrTime                 | 31.5          |
| LossAfter               | -0.0015603014 |
| LossBefore              | -9.0871e-06   |
| Model-TimeModelFit      | 27.8          |
| ModelSampler-n_times... | 1120000       |
| Policy-AverageAbsPol... | 0.5283068     |
| Policy-AverageDiscou... | -1.16e+03     |
| Policy-AveragePolicyStd | 0.6009325     |
| Policy-AverageReturn    | -7.63e+03     |
| Policy-MaxReturn        | -1.03e+03     |
| Policy-MinReturn        | -1.22e+05     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 2.63e+04      |
| Policy-TimeAlgoOpt      | 0.545         |
| Policy-TimeSampleProc   | 0.333         |
| Policy-TimeSampling     | 1.38          |
| Policy-TimeStep         | 2.3           |
| Time                    | 703           |
| n_timesteps             | 28000         |
-------------------------------------------

 ---------------- Iteration 28 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...
Stopping DynamicsEnsemble Training since valid_loss_rolling_average decreased

 ---------------- Grad-Step 280 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 281 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 282 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 283 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 284 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 285 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 286 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 287 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 288 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 289 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.515         |
| Data-EnvSampler-Poli... | 0.902         |
| Data-EnvTrajs-Averag... | -78.1         |
| Data-EnvTrajs-MaxReturn | -74.6         |
| Data-EnvTrajs-MinReturn | -80.4         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.94          |
| Data-TimeEnvSampleProc  | 0.000939      |
| Data-TimeEnvSampling    | 1.45          |
| Iteration               | 28            |
| ItrTime                 | 32.2          |
| LossAfter               | -0.0054849777 |
| LossBefore              | -8.999737e-06 |
| Model-TimeModelFit      | 28.6          |
| ModelSampler-n_times... | 1160000       |
| Policy-AverageAbsPol... | 0.82511085    |
| Policy-AverageDiscou... | -8.98e+05     |
| Policy-AveragePolicyStd | 0.5955541     |
| Policy-AverageReturn    | -3.45e+06     |
| Policy-MaxReturn        | -3.09e+06     |
| Policy-MinReturn        | -3.95e+06     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 2.18e+05      |
| Policy-TimeAlgoOpt      | 0.5           |
| Policy-TimeSampleProc   | 0.294         |
| Policy-TimeSampling     | 1.36          |
| Policy-TimeStep         | 2.21          |
| Time                    | 736           |
| n_timesteps             | 29000         |
-------------------------------------------

 ---------------- Iteration 29 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 290 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 291 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 292 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 293 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 294 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 295 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 296 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 297 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 298 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 299 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.47          |
| Data-EnvSampler-Poli... | 0.862         |
| Data-EnvTrajs-Averag... | 56.6          |
| Data-EnvTrajs-MaxReturn | 108           |
| Data-EnvTrajs-MinReturn | 26.6          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 28.5          |
| Data-TimeEnvSampleProc  | 0.000823      |
| Data-TimeEnvSampling    | 1.37          |
| Iteration               | 29            |
| ItrTime                 | 32.6          |
| LossAfter               | -0.006411962  |
| LossBefore              | -8.842292e-06 |
| Model-TimeModelFit      | 28.9          |
| ModelSampler-n_times... | 1200000       |
| Policy-AverageAbsPol... | 0.57596856    |
| Policy-AverageDiscou... | -1.54e+04     |
| Policy-AveragePolicyStd | 0.58660865    |
| Policy-AverageReturn    | -1.07e+05     |
| Policy-MaxReturn        | 310           |
| Policy-MinReturn        | -6.6e+05      |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.85e+05      |
| Policy-TimeAlgoOpt      | 0.549         |
| Policy-TimeSampleProc   | 0.365         |
| Policy-TimeSampling     | 1.42          |
| Policy-TimeStep         | 2.35          |
| Time                    | 768           |
| n_timesteps             | 30000         |
-------------------------------------------

 ---------------- Iteration 30 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 300 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 301 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 302 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 303 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 304 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 305 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 306 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 307 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 308 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 309 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.494         |
| Data-EnvSampler-Poli... | 0.891         |
| Data-EnvTrajs-Averag... | 236           |
| Data-EnvTrajs-MaxReturn | 263           |
| Data-EnvTrajs-MinReturn | 201           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 22.5          |
| Data-TimeEnvSampleProc  | 0.00109       |
| Data-TimeEnvSampling    | 1.42          |
| Iteration               | 30            |
| ItrTime                 | 32.2          |
| LossAfter               | -0.0068571577 |
| LossBefore              | -8.715392e-06 |
| Model-TimeModelFit      | 28.4          |
| ModelSampler-n_times... | 1240000       |
| Policy-AverageAbsPol... | 0.3705609     |
| Policy-AverageDiscou... | -264          |
| Policy-AveragePolicyStd | 0.5801848     |
| Policy-AverageReturn    | -1.78e+03     |
| Policy-MaxReturn        | -201          |
| Policy-MinReturn        | -2.52e+04     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 5.45e+03      |
| Policy-TimeAlgoOpt      | 0.597         |
| Policy-TimeSampleProc   | 0.272         |
| Policy-TimeSampling     | 1.49          |
| Policy-TimeStep         | 2.38          |
| Time                    | 800           |
| n_timesteps             | 31000         |
-------------------------------------------

 ---------------- Iteration 31 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 310 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 311 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 312 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 313 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 314 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 315 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 316 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 317 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 318 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 319 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.486         |
| Data-EnvSampler-Poli... | 0.85          |
| Data-EnvTrajs-Averag... | 151           |
| Data-EnvTrajs-MaxReturn | 187           |
| Data-EnvTrajs-MinReturn | 110           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 31.3          |
| Data-TimeEnvSampleProc  | 0.000993      |
| Data-TimeEnvSampling    | 1.37          |
| Iteration               | 31            |
| ItrTime                 | 32.9          |
| LossAfter               | -0.005222387  |
| LossBefore              | -8.532193e-06 |
| Model-TimeModelFit      | 29.1          |
| ModelSampler-n_times... | 1280000       |
| Policy-AverageAbsPol... | 0.34910607    |
| Policy-AverageDiscou... | 106           |
| Policy-AveragePolicyStd | 0.5689927     |
| Policy-AverageReturn    | 223           |
| Policy-MaxReturn        | 320           |
| Policy-MinReturn        | 152           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 39            |
| Policy-TimeAlgoOpt      | 0.569         |
| Policy-TimeSampleProc   | 0.369         |
| Policy-TimeSampling     | 1.45          |
| Policy-TimeStep         | 2.44          |
| Time                    | 833           |
| n_timesteps             | 32000         |
-------------------------------------------

 ---------------- Iteration 32 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 320 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 321 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 322 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 323 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 324 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 325 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 326 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 327 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 328 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 329 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.49           |
| Data-EnvSampler-Poli... | 0.868          |
| Data-EnvTrajs-Averag... | 75.3           |
| Data-EnvTrajs-MaxReturn | 102            |
| Data-EnvTrajs-MinReturn | 10.8           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 32.7           |
| Data-TimeEnvSampleProc  | 0.000939       |
| Data-TimeEnvSampling    | 1.39           |
| Iteration               | 32             |
| ItrTime                 | 32.6           |
| LossAfter               | -0.005381308   |
| LossBefore              | -8.4708845e-06 |
| Model-TimeModelFit      | 29.1           |
| ModelSampler-n_times... | 1320000        |
| Policy-AverageAbsPol... | 0.37271103     |
| Policy-AverageDiscou... | -1.32e+03      |
| Policy-AveragePolicyStd | 0.5667882      |
| Policy-AverageReturn    | -9.75e+03      |
| Policy-MaxReturn        | 314            |
| Policy-MinReturn        | -1.67e+05      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 3.66e+04       |
| Policy-TimeAlgoOpt      | 0.538          |
| Policy-TimeSampleProc   | 0.218          |
| Policy-TimeSampling     | 1.33           |
| Policy-TimeStep         | 2.11           |
| Time                    | 866            |
| n_timesteps             | 33000          |
--------------------------------------------

 ---------------- Iteration 33 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 330 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 331 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 332 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 333 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 334 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 335 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 336 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 337 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 338 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 339 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.492         |
| Data-EnvSampler-Poli... | 0.858         |
| Data-EnvTrajs-Averag... | 45.2          |
| Data-EnvTrajs-MaxReturn | 95.7          |
| Data-EnvTrajs-MinReturn | 6.28          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 32.3          |
| Data-TimeEnvSampleProc  | 0.000663      |
| Data-TimeEnvSampling    | 1.39          |
| Iteration               | 33            |
| ItrTime                 | 32.9          |
| LossAfter               | -0.0031720607 |
| LossBefore              | -8.415257e-06 |
| Model-TimeModelFit      | 29.4          |
| ModelSampler-n_times... | 1360000       |
| Policy-AverageAbsPol... | 0.72589016    |
| Policy-AverageDiscou... | -2.98e+05     |
| Policy-AveragePolicyStd | 0.5625481     |
| Policy-AverageReturn    | -1.61e+06     |
| Policy-MaxReturn        | -4.94e+05     |
| Policy-MinReturn        | -2.22e+06     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 4.35e+05      |
| Policy-TimeAlgoOpt      | 0.532         |
| Policy-TimeSampleProc   | 0.334         |
| Policy-TimeSampling     | 1.25          |
| Policy-TimeStep         | 2.13          |
| Time                    | 899           |
| n_timesteps             | 34000         |
-------------------------------------------

 ---------------- Iteration 34 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 340 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 341 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 342 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 343 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 344 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 345 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 346 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 347 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 348 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 349 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.477         |
| Data-EnvSampler-Poli... | 0.792         |
| Data-EnvTrajs-Averag... | 40.7          |
| Data-EnvTrajs-MaxReturn | 118           |
| Data-EnvTrajs-MinReturn | -93.9         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 83.9          |
| Data-TimeEnvSampleProc  | 0.001         |
| Data-TimeEnvSampling    | 1.3           |
| Iteration               | 34            |
| ItrTime                 | 33.9          |
| LossAfter               | -0.0019201625 |
| LossBefore              | -8.250425e-06 |
| Model-TimeModelFit      | 30.3          |
| ModelSampler-n_times... | 1400000       |
| Policy-AverageAbsPol... | 0.4509233     |
| Policy-AverageDiscou... | 106           |
| Policy-AveragePolicyStd | 0.55411685    |
| Policy-AverageReturn    | 163           |
| Policy-MaxReturn        | 309           |
| Policy-MinReturn        | -155          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 120           |
| Policy-TimeAlgoOpt      | 0.49          |
| Policy-TimeSampleProc   | 0.284         |
| Policy-TimeSampling     | 1.48          |
| Policy-TimeStep         | 2.27          |
| Time                    | 933           |
| n_timesteps             | 35000         |
-------------------------------------------

 ---------------- Iteration 35 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 350 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 351 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 352 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 353 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 354 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 355 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 356 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 357 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 358 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 359 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.468         |
| Data-EnvSampler-Poli... | 0.808         |
| Data-EnvTrajs-Averag... | -43.5         |
| Data-EnvTrajs-MaxReturn | -8.47         |
| Data-EnvTrajs-MinReturn | -65.8         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 24.7          |
| Data-TimeEnvSampleProc  | 0.000978      |
| Data-TimeEnvSampling    | 1.31          |
| Iteration               | 35            |
| ItrTime                 | 34.2          |
| LossAfter               | -0.008715681  |
| LossBefore              | -8.212479e-06 |
| Model-TimeModelFit      | 30.7          |
| ModelSampler-n_times... | 1440000       |
| Policy-AverageAbsPol... | 0.3997474     |
| Policy-AverageDiscou... | 67.6          |
| Policy-AveragePolicyStd | 0.5505745     |
| Policy-AverageReturn    | 112           |
| Policy-MaxReturn        | 179           |
| Policy-MinReturn        | 37.9          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 36.2          |
| Policy-TimeAlgoOpt      | 0.603         |
| Policy-TimeSampleProc   | 0.183         |
| Policy-TimeSampling     | 1.4           |
| Policy-TimeStep         | 2.2           |
| Time                    | 967           |
| n_timesteps             | 36000         |
-------------------------------------------

 ---------------- Iteration 36 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 360 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 361 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 362 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 363 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 364 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 365 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 366 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 367 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 368 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 369 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.598         |
| Data-EnvSampler-Poli... | 1.07          |
| Data-EnvTrajs-Averag... | 0.809         |
| Data-EnvTrajs-MaxReturn | 21.5          |
| Data-EnvTrajs-MinReturn | -6.5          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 10.4          |
| Data-TimeEnvSampleProc  | 0.00103       |
| Data-TimeEnvSampling    | 1.72          |
| Iteration               | 36            |
| ItrTime                 | 34.5          |
| LossAfter               | -0.002057832  |
| LossBefore              | -7.947788e-06 |
| Model-TimeModelFit      | 30.6          |
| ModelSampler-n_times... | 1480000       |
| Policy-AverageAbsPol... | 0.44342345    |
| Policy-AverageDiscou... | 55.1          |
| Policy-AveragePolicyStd | 0.53630775    |
| Policy-AverageReturn    | 19.3          |
| Policy-MaxReturn        | 53.5          |
| Policy-MinReturn        | -31.3         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 24.6          |
| Policy-TimeAlgoOpt      | 0.519         |
| Policy-TimeSampleProc   | 0.333         |
| Policy-TimeSampling     | 1.3           |
| Policy-TimeStep         | 2.19          |
| Time                    | 1e+03         |
| n_timesteps             | 37000         |
-------------------------------------------

 ---------------- Iteration 37 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 370 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 371 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 372 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 373 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 374 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 375 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 376 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 377 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 378 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 379 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.515         |
| Data-EnvSampler-Poli... | 0.913         |
| Data-EnvTrajs-Averag... | 253           |
| Data-EnvTrajs-MaxReturn | 264           |
| Data-EnvTrajs-MinReturn | 242           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 8.99          |
| Data-TimeEnvSampleProc  | 0.000952      |
| Data-TimeEnvSampling    | 1.47          |
| Iteration               | 37            |
| ItrTime                 | 33.6          |
| LossAfter               | -0.004423029  |
| LossBefore              | -7.689995e-06 |
| Model-TimeModelFit      | 29.9          |
| ModelSampler-n_times... | 1520000       |
| Policy-AverageAbsPol... | 0.4253859     |
| Policy-AverageDiscou... | 106           |
| Policy-AveragePolicyStd | 0.5216298     |
| Policy-AverageReturn    | 228           |
| Policy-MaxReturn        | 245           |
| Policy-MinReturn        | 189           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 11.6          |
| Policy-TimeAlgoOpt      | 0.543         |
| Policy-TimeSampleProc   | 0.307         |
| Policy-TimeSampling     | 1.42          |
| Policy-TimeStep         | 2.29          |
| Time                    | 1.04e+03      |
| n_timesteps             | 38000         |
-------------------------------------------

 ---------------- Iteration 38 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 380 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 381 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 382 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 383 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 384 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 385 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 386 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 387 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 388 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 389 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.447         |
| Data-EnvSampler-Poli... | 0.843         |
| Data-EnvTrajs-Averag... | 247           |
| Data-EnvTrajs-MaxReturn | 271           |
| Data-EnvTrajs-MinReturn | 218           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 23            |
| Data-TimeEnvSampleProc  | 0.000954      |
| Data-TimeEnvSampling    | 1.32          |
| Iteration               | 38            |
| ItrTime                 | 33.7          |
| LossAfter               | -0.0062061604 |
| LossBefore              | -7.129865e-06 |
| Model-TimeModelFit      | 30.2          |
| ModelSampler-n_times... | 1560000       |
| Policy-AverageAbsPol... | 0.3121151     |
| Policy-AverageDiscou... | 80.8          |
| Policy-AveragePolicyStd | 0.4947327     |
| Policy-AverageReturn    | 131           |
| Policy-MaxReturn        | 147           |
| Policy-MinReturn        | 97.8          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 12.4          |
| Policy-TimeAlgoOpt      | 0.533         |
| Policy-TimeSampleProc   | 0.247         |
| Policy-TimeSampling     | 1.38          |
| Policy-TimeStep         | 2.19          |
| Time                    | 1.07e+03      |
| n_timesteps             | 39000         |
-------------------------------------------

 ---------------- Iteration 39 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 390 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 391 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 392 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 393 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 394 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 395 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 396 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 397 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 398 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 399 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.473          |
| Data-EnvSampler-Poli... | 0.903          |
| Data-EnvTrajs-Averag... | 30.5           |
| Data-EnvTrajs-MaxReturn | 40.2           |
| Data-EnvTrajs-MinReturn | 21.9           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 6.04           |
| Data-TimeEnvSampleProc  | 0.00106        |
| Data-TimeEnvSampling    | 1.41           |
| Iteration               | 39             |
| ItrTime                 | 34.6           |
| LossAfter               | -0.0031196126  |
| LossBefore              | -6.9676917e-06 |
| Model-TimeModelFit      | 31.1           |
| ModelSampler-n_times... | 1600000        |
| Policy-AverageAbsPol... | 0.28431422     |
| Policy-AverageDiscou... | -2.59e+03      |
| Policy-AveragePolicyStd | 0.48476425     |
| Policy-AverageReturn    | -1.86e+04      |
| Policy-MaxReturn        | 83             |
| Policy-MinReturn        | -3.56e+05      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 7.74e+04       |
| Policy-TimeAlgoOpt      | 0.522          |
| Policy-TimeSampleProc   | 0.292          |
| Policy-TimeSampling     | 1.34           |
| Policy-TimeStep         | 2.17           |
| Time                    | 1.1e+03        |
| n_timesteps             | 40000          |
--------------------------------------------

 ---------------- Iteration 40 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 400 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 401 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 402 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 403 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 404 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 405 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 406 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 407 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 408 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 409 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.481         |
| Data-EnvSampler-Poli... | 0.866         |
| Data-EnvTrajs-Averag... | 9.44          |
| Data-EnvTrajs-MaxReturn | 28.3          |
| Data-EnvTrajs-MinReturn | -18.5         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 18.3          |
| Data-TimeEnvSampleProc  | 0.00083       |
| Data-TimeEnvSampling    | 1.38          |
| Iteration               | 40            |
| ItrTime                 | 34.4          |
| LossAfter               | -0.0024444838 |
| LossBefore              | -6.897798e-06 |
| Model-TimeModelFit      | 30.7          |
| ModelSampler-n_times... | 1640000       |
| Policy-AverageAbsPol... | 0.33445844    |
| Policy-AverageDiscou... | 129           |
| Policy-AveragePolicyStd | 0.4829195     |
| Policy-AverageReturn    | 226           |
| Policy-MaxReturn        | 440           |
| Policy-MinReturn        | -1.28e+03     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 474           |
| Policy-TimeAlgoOpt      | 0.513         |
| Policy-TimeSampleProc   | 0.302         |
| Policy-TimeSampling     | 1.48          |
| Policy-TimeStep         | 2.34          |
| Time                    | 1.14e+03      |
| n_timesteps             | 41000         |
-------------------------------------------

 ---------------- Iteration 41 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 410 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 411 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 412 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 413 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 414 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 415 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 416 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 417 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 418 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 419 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.489          |
| Data-EnvSampler-Poli... | 0.878          |
| Data-EnvTrajs-Averag... | -34.7          |
| Data-EnvTrajs-MaxReturn | -26.6          |
| Data-EnvTrajs-MinReturn | -44            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 5.93           |
| Data-TimeEnvSampleProc  | 0.000949       |
| Data-TimeEnvSampling    | 1.4            |
| Iteration               | 41             |
| ItrTime                 | 34.5           |
| LossAfter               | -0.0060185282  |
| LossBefore              | -6.7755077e-06 |
| Model-TimeModelFit      | 30.5           |
| ModelSampler-n_times... | 1680000        |
| Policy-AverageAbsPol... | 0.3293743      |
| Policy-AverageDiscou... | -1.05e+04      |
| Policy-AveragePolicyStd | 0.4759366      |
| Policy-AverageReturn    | -6.47e+04      |
| Policy-MaxReturn        | 377            |
| Policy-MinReturn        | -1.17e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.56e+05       |
| Policy-TimeAlgoOpt      | 0.612          |
| Policy-TimeSampleProc   | 0.444          |
| Policy-TimeSampling     | 1.51           |
| Policy-TimeStep         | 2.59           |
| Time                    | 1.17e+03       |
| n_timesteps             | 42000          |
--------------------------------------------

 ---------------- Iteration 42 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 420 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 421 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 422 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 423 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 424 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 425 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 426 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 427 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 428 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 429 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.548          |
| Data-EnvSampler-Poli... | 0.901          |
| Data-EnvTrajs-Averag... | -26.1          |
| Data-EnvTrajs-MaxReturn | -10.9          |
| Data-EnvTrajs-MinReturn | -46.7          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 13.5           |
| Data-TimeEnvSampleProc  | 0.00102        |
| Data-TimeEnvSampling    | 1.49           |
| Iteration               | 42             |
| ItrTime                 | 35.4           |
| LossAfter               | -0.006802042   |
| LossBefore              | -6.6566645e-06 |
| Model-TimeModelFit      | 31.2           |
| ModelSampler-n_times... | 1720000        |
| Policy-AverageAbsPol... | 0.32221457     |
| Policy-AverageDiscou... | -9.12e+03      |
| Policy-AveragePolicyStd | 0.4696732      |
| Policy-AverageReturn    | -6.29e+04      |
| Policy-MaxReturn        | 34.4           |
| Policy-MinReturn        | -5.68e+05      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.56e+05       |
| Policy-TimeAlgoOpt      | 0.617          |
| Policy-TimeSampleProc   | 0.408          |
| Policy-TimeSampling     | 1.61           |
| Policy-TimeStep         | 2.66           |
| Time                    | 1.21e+03       |
| n_timesteps             | 43000          |
--------------------------------------------

 ---------------- Iteration 43 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 430 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 431 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 432 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 433 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 434 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 435 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 436 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 437 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 438 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 439 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.522         |
| Data-EnvSampler-Poli... | 0.925         |
| Data-EnvTrajs-Averag... | 79.1          |
| Data-EnvTrajs-MaxReturn | 176           |
| Data-EnvTrajs-MinReturn | 36.5          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 50            |
| Data-TimeEnvSampleProc  | 0.00109       |
| Data-TimeEnvSampling    | 1.48          |
| Iteration               | 43            |
| ItrTime                 | 38.1          |
| LossAfter               | -0.0064284815 |
| LossBefore              | -6.449674e-06 |
| Model-TimeModelFit      | 33.8          |
| ModelSampler-n_times... | 1760000       |
| Policy-AverageAbsPol... | 0.36173177    |
| Policy-AverageDiscou... | -6.37e+04     |
| Policy-AveragePolicyStd | 0.4617381     |
| Policy-AverageReturn    | -3.61e+05     |
| Policy-MaxReturn        | -29.5         |
| Policy-MinReturn        | -1.84e+06     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 6.4e+05       |
| Policy-TimeAlgoOpt      | 0.577         |
| Policy-TimeSampleProc   | 0.334         |
| Policy-TimeSampling     | 1.9           |
| Policy-TimeStep         | 2.83          |
| Time                    | 1.25e+03      |
| n_timesteps             | 44000         |
-------------------------------------------

 ---------------- Iteration 44 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 440 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 441 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 442 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 443 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 444 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 445 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 446 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 447 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 448 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 449 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.467          |
| Data-EnvSampler-Poli... | 0.828          |
| Data-EnvTrajs-Averag... | 211            |
| Data-EnvTrajs-MaxReturn | 235            |
| Data-EnvTrajs-MinReturn | 187            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 15.6           |
| Data-TimeEnvSampleProc  | 0.00086        |
| Data-TimeEnvSampling    | 1.33           |
| Iteration               | 44             |
| ItrTime                 | 34.3           |
| LossAfter               | -0.0026267602  |
| LossBefore              | -6.2844465e-06 |
| Model-TimeModelFit      | 30.6           |
| ModelSampler-n_times... | 1800000        |
| Policy-AverageAbsPol... | 0.29535404     |
| Policy-AverageDiscou... | 124            |
| Policy-AveragePolicyStd | 0.45289803     |
| Policy-AverageReturn    | 265            |
| Policy-MaxReturn        | 320            |
| Policy-MinReturn        | 231            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 24.8           |
| Policy-TimeAlgoOpt      | 0.588          |
| Policy-TimeSampleProc   | 0.357          |
| Policy-TimeSampling     | 1.4            |
| Policy-TimeStep         | 2.38           |
| Time                    | 1.28e+03       |
| n_timesteps             | 45000          |
--------------------------------------------

 ---------------- Iteration 45 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 450 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 451 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 452 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 453 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 454 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 455 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 456 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 457 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 458 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 459 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.421         |
| Data-EnvSampler-Poli... | 0.738         |
| Data-EnvTrajs-Averag... | 236           |
| Data-EnvTrajs-MaxReturn | 266           |
| Data-EnvTrajs-MinReturn | 223           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 16            |
| Data-TimeEnvSampleProc  | 0.00102       |
| Data-TimeEnvSampling    | 1.19          |
| Iteration               | 45            |
| ItrTime                 | 35.3          |
| LossAfter               | -0.0021261654 |
| LossBefore              | -6.017323e-06 |
| Model-TimeModelFit      | 31.7          |
| ModelSampler-n_times... | 1840000       |
| Policy-AverageAbsPol... | 0.27423248    |
| Policy-AverageDiscou... | 111           |
| Policy-AveragePolicyStd | 0.44154736    |
| Policy-AverageReturn    | 195           |
| Policy-MaxReturn        | 241           |
| Policy-MinReturn        | 127           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 33.7          |
| Policy-TimeAlgoOpt      | 0.575         |
| Policy-TimeSampleProc   | 0.368         |
| Policy-TimeSampling     | 1.46          |
| Policy-TimeStep         | 2.43          |
| Time                    | 1.32e+03      |
| n_timesteps             | 46000         |
-------------------------------------------

 ---------------- Iteration 46 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 460 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 461 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 462 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 463 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 464 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 465 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 466 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 467 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 468 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 469 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.414          |
| Data-EnvSampler-Poli... | 0.754          |
| Data-EnvTrajs-Averag... | 179            |
| Data-EnvTrajs-MaxReturn | 226            |
| Data-EnvTrajs-MinReturn | 144            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 28.5           |
| Data-TimeEnvSampleProc  | 0.000942       |
| Data-TimeEnvSampling    | 1.2            |
| Iteration               | 46             |
| ItrTime                 | 35.4           |
| LossAfter               | -0.008756667   |
| LossBefore              | -5.7391185e-06 |
| Model-TimeModelFit      | 31.7           |
| ModelSampler-n_times... | 1880000        |
| Policy-AverageAbsPol... | 0.3099018      |
| Policy-AverageDiscou... | -1.04e+03      |
| Policy-AveragePolicyStd | 0.42988187     |
| Policy-AverageReturn    | -8.05e+03      |
| Policy-MaxReturn        | 183            |
| Policy-MinReturn        | -9.08e+04      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.34e+04       |
| Policy-TimeAlgoOpt      | 0.56           |
| Policy-TimeSampleProc   | 0.425          |
| Policy-TimeSampling     | 1.42           |
| Policy-TimeStep         | 2.42           |
| Time                    | 1.35e+03       |
| n_timesteps             | 47000          |
--------------------------------------------

 ---------------- Iteration 47 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 470 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 471 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 472 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 473 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 474 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 475 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 476 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 477 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 478 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 479 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.47           |
| Data-EnvSampler-Poli... | 0.786          |
| Data-EnvTrajs-Averag... | 215            |
| Data-EnvTrajs-MaxReturn | 229            |
| Data-EnvTrajs-MinReturn | 198            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 13.4           |
| Data-TimeEnvSampleProc  | 0.00097        |
| Data-TimeEnvSampling    | 1.29           |
| Iteration               | 47             |
| ItrTime                 | 36.3           |
| LossAfter               | -0.0026078     |
| LossBefore              | -5.5432693e-06 |
| Model-TimeModelFit      | 32.6           |
| ModelSampler-n_times... | 1920000        |
| Policy-AverageAbsPol... | 0.3509999      |
| Policy-AverageDiscou... | -20.4          |
| Policy-AveragePolicyStd | 0.42141056     |
| Policy-AverageReturn    | -905           |
| Policy-MaxReturn        | 431            |
| Policy-MinReturn        | -2.45e+04      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 5.41e+03       |
| Policy-TimeAlgoOpt      | 0.569          |
| Policy-TimeSampleProc   | 0.343          |
| Policy-TimeSampling     | 1.46           |
| Policy-TimeStep         | 2.43           |
| Time                    | 1.39e+03       |
| n_timesteps             | 48000          |
--------------------------------------------

 ---------------- Iteration 48 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 480 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 481 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 482 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 483 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 484 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 485 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 486 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 487 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 488 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 489 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.486         |
| Data-EnvSampler-Poli... | 0.849         |
| Data-EnvTrajs-Averag... | 225           |
| Data-EnvTrajs-MaxReturn | 272           |
| Data-EnvTrajs-MinReturn | 188           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 30            |
| Data-TimeEnvSampleProc  | 0.00101       |
| Data-TimeEnvSampling    | 1.37          |
| Iteration               | 48            |
| ItrTime                 | 36.5          |
| LossAfter               | -0.005647051  |
| LossBefore              | -5.301223e-06 |
| Model-TimeModelFit      | 32.6          |
| ModelSampler-n_times... | 1960000       |
| Policy-AverageAbsPol... | 0.28790247    |
| Policy-AverageDiscou... | 120           |
| Policy-AveragePolicyStd | 0.4104555     |
| Policy-AverageReturn    | 247           |
| Policy-MaxReturn        | 285           |
| Policy-MinReturn        | 202           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 24.8          |
| Policy-TimeAlgoOpt      | 0.534         |
| Policy-TimeSampleProc   | 0.322         |
| Policy-TimeSampling     | 1.61          |
| Policy-TimeStep         | 2.49          |
| Time                    | 1.42e+03      |
| n_timesteps             | 49000         |
-------------------------------------------

 ---------------- Iteration 49 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 490 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 491 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 492 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 493 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 494 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 495 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 496 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 497 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 498 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 499 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.354         |
| Data-EnvSampler-Poli... | 0.54          |
| Data-EnvTrajs-Averag... | 260           |
| Data-EnvTrajs-MaxReturn | 273           |
| Data-EnvTrajs-MinReturn | 247           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 10.1          |
| Data-TimeEnvSampleProc  | 0.000679      |
| Data-TimeEnvSampling    | 0.921         |
| Iteration               | 49            |
| ItrTime                 | 25.5          |
| LossAfter               | -0.002509921  |
| LossBefore              | -5.191567e-06 |
| Model-TimeModelFit      | 22.5          |
| ModelSampler-n_times... | 2000000       |
| Policy-AverageAbsPol... | 0.4138383     |
| Policy-AverageDiscou... | 23            |
| Policy-AveragePolicyStd | 0.40663135    |
| Policy-AverageReturn    | -187          |
| Policy-MaxReturn        | -50.7         |
| Policy-MinReturn        | -606          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 116           |
| Policy-TimeAlgoOpt      | 0.52          |
| Policy-TimeSampleProc   | 0.265         |
| Policy-TimeSampling     | 1.24          |
| Policy-TimeStep         | 2.05          |
| Time                    | 1.45e+03      |
| n_timesteps             | 50000         |
-------------------------------------------

 ---------------- Iteration 50 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 500 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 501 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 502 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 503 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 504 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 505 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 506 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 507 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 508 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 509 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.374         |
| Data-EnvSampler-Poli... | 0.513         |
| Data-EnvTrajs-Averag... | 209           |
| Data-EnvTrajs-MaxReturn | 223           |
| Data-EnvTrajs-MinReturn | 199           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 8.9           |
| Data-TimeEnvSampleProc  | 0.000676      |
| Data-TimeEnvSampling    | 0.913         |
| Iteration               | 50            |
| ItrTime                 | 23.7          |
| LossAfter               | -0.0042920024 |
| LossBefore              | -5.05249e-06  |
| Model-TimeModelFit      | 21.4          |
| ModelSampler-n_times... | 2040000       |
| Policy-AverageAbsPol... | 0.28054884    |
| Policy-AverageDiscou... | 133           |
| Policy-AveragePolicyStd | 0.40234923    |
| Policy-AverageReturn    | 281           |
| Policy-MaxReturn        | 353           |
| Policy-MinReturn        | 145           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 47.5          |
| Policy-TimeAlgoOpt      | 0.414         |
| Policy-TimeSampleProc   | 0.177         |
| Policy-TimeSampling     | 0.861         |
| Policy-TimeStep         | 1.46          |
| Time                    | 1.47e+03      |
| n_timesteps             | 51000         |
-------------------------------------------
Training finished
