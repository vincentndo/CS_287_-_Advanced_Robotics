Logging to /home/vincent/workplace/CS_287_-_Advanced_Robotics/homework/hw5/cs287hw5/ppo/run_scripts/data/parallel_mb_ppo/mbppo_Swimmer//00

 ---------------- Iteration 0 ----------------
Obtaining random samples from the environment...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 0 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 1 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 2 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 3 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 4 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 5 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 6 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 7 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 8 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 9 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.14           |
| Data-EnvSampler-Poli... | 0.0428         |
| Data-EnvTrajs-Averag... | 0.81           |
| Data-EnvTrajs-MaxReturn | 4.78           |
| Data-EnvTrajs-MinReturn | -3.95          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 3.34           |
| Data-TimeEnvSampleProc  | 0.000546       |
| Data-TimeEnvSampling    | 0.194          |
| Iteration               | 0              |
| ItrTime                 | 9.57           |
| LossAfter               | -0.005635958   |
| LossBefore              | -1.4031053e-05 |
| Model-TimeModelFit      | 3.18           |
| ModelSampler-n_times... | 40000          |
| Policy-AverageAbsPol... | 0.538533       |
| Policy-AverageDiscou... | 20.7           |
| Policy-AveragePolicyStd | 0.98401076     |
| Policy-AverageReturn    | 30.5           |
| Policy-MaxReturn        | 114            |
| Policy-MinReturn        | -463           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 125            |
| Policy-TimeAlgoOpt      | 1.11           |
| Policy-TimeSampleProc   | 0.628          |
| Policy-TimeSampling     | 4.42           |
| Policy-TimeStep         | 6.19           |
| Time                    | 9.57           |
| n_timesteps             | 1000           |
--------------------------------------------

 ---------------- Iteration 1 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 10 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 11 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 12 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 13 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 14 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 15 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 16 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 17 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 18 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 19 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.221          |
| Data-EnvSampler-Poli... | 0.659          |
| Data-EnvTrajs-Averag... | 24             |
| Data-EnvTrajs-MaxReturn | 32.8           |
| Data-EnvTrajs-MinReturn | 12.1           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 7.62           |
| Data-TimeEnvSampleProc  | 0.000557       |
| Data-TimeEnvSampling    | 0.901          |
| Iteration               | 1              |
| ItrTime                 | 8.12           |
| LossAfter               | -0.0019536258  |
| LossBefore              | -1.3788764e-05 |
| Model-TimeModelFit      | 4.55           |
| ModelSampler-n_times... | 80000          |
| Policy-AverageAbsPol... | 0.55960345     |
| Policy-AverageDiscou... | 19.5           |
| Policy-AveragePolicyStd | 0.9580514      |
| Policy-AverageReturn    | -13.2          |
| Policy-MaxReturn        | 182            |
| Policy-MinReturn        | -1.03e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 337            |
| Policy-TimeAlgoOpt      | 0.511          |
| Policy-TimeSampleProc   | 0.547          |
| Policy-TimeSampling     | 1.55           |
| Policy-TimeStep         | 2.68           |
| Time                    | 17.9           |
| n_timesteps             | 2000           |
--------------------------------------------

 ---------------- Iteration 2 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 20 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 21 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 22 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 23 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 24 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 25 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 26 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 27 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 28 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 29 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.245           |
| Data-EnvSampler-Poli... | 0.541           |
| Data-EnvTrajs-Averag... | 13.4            |
| Data-EnvTrajs-MaxReturn | 16.1            |
| Data-EnvTrajs-MinReturn | 10.3            |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 2.12            |
| Data-TimeEnvSampleProc  | 0.000574        |
| Data-TimeEnvSampling    | 0.809           |
| Iteration               | 2               |
| ItrTime                 | 10.6            |
| LossAfter               | -0.005016532    |
| LossBefore              | -1.38278265e-05 |
| Model-TimeModelFit      | 7.04            |
| ModelSampler-n_times... | 120000          |
| Policy-AverageAbsPol... | 0.97780764      |
| Policy-AverageDiscou... | 52.8            |
| Policy-AveragePolicyStd | 0.96368325      |
| Policy-AverageReturn    | 180             |
| Policy-MaxReturn        | 328             |
| Policy-MinReturn        | 23.7            |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 97.8            |
| Policy-TimeAlgoOpt      | 0.606           |
| Policy-TimeSampleProc   | 0.472           |
| Policy-TimeSampling     | 1.67            |
| Policy-TimeStep         | 2.78            |
| Time                    | 28.5            |
| n_timesteps             | 3000            |
---------------------------------------------

 ---------------- Iteration 3 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 30 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 31 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 32 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 33 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 34 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 35 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 36 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 37 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 38 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 39 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.296         |
| Data-EnvSampler-Poli... | 0.571         |
| Data-EnvTrajs-Averag... | 24.9          |
| Data-EnvTrajs-MaxReturn | 39.8          |
| Data-EnvTrajs-MinReturn | 7.91          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 11.4          |
| Data-TimeEnvSampleProc  | 0.00055       |
| Data-TimeEnvSampling    | 0.89          |
| Iteration               | 3             |
| ItrTime                 | 12            |
| LossAfter               | -0.0038498507 |
| LossBefore              | -1.369084e-05 |
| Model-TimeModelFit      | 8.35          |
| ModelSampler-n_times... | 160000        |
| Policy-AverageAbsPol... | 1.1886009     |
| Policy-AverageDiscou... | 533           |
| Policy-AveragePolicyStd | 0.9507034     |
| Policy-AverageReturn    | 2.68e+03      |
| Policy-MaxReturn        | 5.67e+03      |
| Policy-MinReturn        | 32.6          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.69e+03      |
| Policy-TimeAlgoOpt      | 0.576         |
| Policy-TimeSampleProc   | 0.505         |
| Policy-TimeSampling     | 1.7           |
| Policy-TimeStep         | 2.81          |
| Time                    | 40.6          |
| n_timesteps             | 4000          |
-------------------------------------------

 ---------------- Iteration 4 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 40 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 41 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 42 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 43 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 44 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 45 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 46 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 47 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 48 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 49 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.298          |
| Data-EnvSampler-Poli... | 0.583          |
| Data-EnvTrajs-Averag... | 26.4           |
| Data-EnvTrajs-MaxReturn | 28.9           |
| Data-EnvTrajs-MinReturn | 23.6           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.93           |
| Data-TimeEnvSampleProc  | 0.000821       |
| Data-TimeEnvSampling    | 0.912          |
| Iteration               | 4              |
| ItrTime                 | 14.7           |
| LossAfter               | -0.004503286   |
| LossBefore              | -1.3433862e-05 |
| Model-TimeModelFit      | 11             |
| ModelSampler-n_times... | 200000         |
| Policy-AverageAbsPol... | 0.8749532      |
| Policy-AverageDiscou... | 305            |
| Policy-AveragePolicyStd | 0.9289382      |
| Policy-AverageReturn    | 1.23e+03       |
| Policy-MaxReturn        | 1.62e+03       |
| Policy-MinReturn        | -249           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 503            |
| Policy-TimeAlgoOpt      | 0.664          |
| Policy-TimeSampleProc   | 0.412          |
| Policy-TimeSampling     | 1.71           |
| Policy-TimeStep         | 2.81           |
| Time                    | 55.3           |
| n_timesteps             | 5000           |
--------------------------------------------

 ---------------- Iteration 5 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 50 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 51 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 52 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 53 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 54 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 55 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 56 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 57 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 58 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 59 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.352         |
| Data-EnvSampler-Poli... | 0.658         |
| Data-EnvTrajs-Averag... | 29            |
| Data-EnvTrajs-MaxReturn | 31.2          |
| Data-EnvTrajs-MinReturn | 27            |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.63          |
| Data-TimeEnvSampleProc  | 0.000584      |
| Data-TimeEnvSampling    | 1.04          |
| Iteration               | 5             |
| ItrTime                 | 16.5          |
| LossAfter               | -0.0030518589 |
| LossBefore              | -1.331454e-05 |
| Model-TimeModelFit      | 12.6          |
| ModelSampler-n_times... | 240000        |
| Policy-AverageAbsPol... | 0.52237386    |
| Policy-AverageDiscou... | -186          |
| Policy-AveragePolicyStd | 0.91685414    |
| Policy-AverageReturn    | -1.18e+03     |
| Policy-MaxReturn        | 96.6          |
| Policy-MinReturn        | -5.8e+03      |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.87e+03      |
| Policy-TimeAlgoOpt      | 0.599         |
| Policy-TimeSampleProc   | 0.586         |
| Policy-TimeSampling     | 1.64          |
| Policy-TimeStep         | 2.85          |
| Time                    | 71.8          |
| n_timesteps             | 6000          |
-------------------------------------------

 ---------------- Iteration 6 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 60 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 61 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 62 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 63 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 64 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 65 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 66 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 67 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 68 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 69 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.352          |
| Data-EnvSampler-Poli... | 0.71           |
| Data-EnvTrajs-Averag... | 26.1           |
| Data-EnvTrajs-MaxReturn | 28.7           |
| Data-EnvTrajs-MinReturn | 23.9           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.76           |
| Data-TimeEnvSampleProc  | 0.000572       |
| Data-TimeEnvSampling    | 1.09           |
| Iteration               | 6              |
| ItrTime                 | 18.3           |
| LossAfter               | -0.0032914784  |
| LossBefore              | -1.3293859e-05 |
| Model-TimeModelFit      | 14.6           |
| ModelSampler-n_times... | 280000         |
| Policy-AverageAbsPol... | 0.71653175     |
| Policy-AverageDiscou... | 2.23           |
| Policy-AveragePolicyStd | 0.9133467      |
| Policy-AverageReturn    | -85.9          |
| Policy-MaxReturn        | 125            |
| Policy-MinReturn        | -1.52e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 384            |
| Policy-TimeAlgoOpt      | 0.524          |
| Policy-TimeSampleProc   | 0.444          |
| Policy-TimeSampling     | 1.58           |
| Policy-TimeStep         | 2.58           |
| Time                    | 90.1           |
| n_timesteps             | 7000           |
--------------------------------------------

 ---------------- Iteration 7 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 70 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 71 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 72 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 73 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 74 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 75 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 76 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 77 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 78 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 79 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Data-EnvSampler-EnvE... | 0.342        |
| Data-EnvSampler-Poli... | 0.847        |
| Data-EnvTrajs-Averag... | 25.7         |
| Data-EnvTrajs-MaxReturn | 31           |
| Data-EnvTrajs-MinReturn | 19.6         |
| Data-EnvTrajs-NumTrajs  | 5            |
| Data-EnvTrajs-StdReturn | 4.04         |
| Data-TimeEnvSampleProc  | 0.000808     |
| Data-TimeEnvSampling    | 1.22         |
| Iteration               | 7            |
| ItrTime                 | 20.8         |
| LossAfter               | -0.003280662 |
| LossBefore              | -1.30667e-05 |
| Model-TimeModelFit      | 16.7         |
| ModelSampler-n_times... | 320000       |
| Policy-AverageAbsPol... | 1.0159185    |
| Policy-AverageDiscou... | 20.5         |
| Policy-AveragePolicyStd | 0.8943772    |
| Policy-AverageReturn    | 31.3         |
| Policy-MaxReturn        | 48.4         |
| Policy-MinReturn        | -10.5        |
| Policy-NumTrajs         | 20           |
| Policy-StdReturn        | 12.6         |
| Policy-TimeAlgoOpt      | 0.679        |
| Policy-TimeSampleProc   | 0.387        |
| Policy-TimeSampling     | 1.76         |
| Policy-TimeStep         | 2.84         |
| Time                    | 111          |
| n_timesteps             | 8000         |
------------------------------------------

 ---------------- Iteration 8 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 80 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 81 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 82 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 83 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 84 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 85 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 86 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 87 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 88 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 89 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.396          |
| Data-EnvSampler-Poli... | 0.905          |
| Data-EnvTrajs-Averag... | 28.2           |
| Data-EnvTrajs-MaxReturn | 32.7           |
| Data-EnvTrajs-MinReturn | 24.4           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 3.23           |
| Data-TimeEnvSampleProc  | 0.0007         |
| Data-TimeEnvSampling    | 1.33           |
| Iteration               | 8              |
| ItrTime                 | 23.1           |
| LossAfter               | -0.0012805861  |
| LossBefore              | -1.2892712e-05 |
| Model-TimeModelFit      | 18.8           |
| ModelSampler-n_times... | 360000         |
| Policy-AverageAbsPol... | 0.9597107      |
| Policy-AverageDiscou... | 44.3           |
| Policy-AveragePolicyStd | 0.87871313     |
| Policy-AverageReturn    | 123            |
| Policy-MaxReturn        | 173            |
| Policy-MinReturn        | 64.7           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 28.8           |
| Policy-TimeAlgoOpt      | 0.583          |
| Policy-TimeSampleProc   | 0.481          |
| Policy-TimeSampling     | 1.84           |
| Policy-TimeStep         | 2.94           |
| Time                    | 134            |
| n_timesteps             | 9000           |
--------------------------------------------

 ---------------- Iteration 9 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 90 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 91 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 92 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 93 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 94 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 95 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 96 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 97 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 98 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 99 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.448           |
| Data-EnvSampler-Poli... | 0.955           |
| Data-EnvTrajs-Averag... | 29.6            |
| Data-EnvTrajs-MaxReturn | 32.3            |
| Data-EnvTrajs-MinReturn | 26.7            |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 2.02            |
| Data-TimeEnvSampleProc  | 0.00062         |
| Data-TimeEnvSampling    | 1.44            |
| Iteration               | 9               |
| ItrTime                 | 25.4            |
| LossAfter               | -0.0018601177   |
| LossBefore              | -1.27049225e-05 |
| Model-TimeModelFit      | 21.2            |
| ModelSampler-n_times... | 400000          |
| Policy-AverageAbsPol... | 1.1990093       |
| Policy-AverageDiscou... | 0.495           |
| Policy-AveragePolicyStd | 0.8627523       |
| Policy-AverageReturn    | -53.6           |
| Policy-MaxReturn        | 118             |
| Policy-MinReturn        | -2.45e+03       |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 550             |
| Policy-TimeAlgoOpt      | 0.6             |
| Policy-TimeSampleProc   | 0.41            |
| Policy-TimeSampling     | 1.67            |
| Policy-TimeStep         | 2.71            |
| Time                    | 159             |
| n_timesteps             | 10000           |
---------------------------------------------

 ---------------- Iteration 10 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 100 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 101 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 102 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 103 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 104 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 105 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 106 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 107 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 108 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 109 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.428          |
| Data-EnvSampler-Poli... | 0.92           |
| Data-EnvTrajs-Averag... | 30             |
| Data-EnvTrajs-MaxReturn | 31.9           |
| Data-EnvTrajs-MinReturn | 27.4           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.61           |
| Data-TimeEnvSampleProc  | 0.000723       |
| Data-TimeEnvSampling    | 1.38           |
| Iteration               | 10             |
| ItrTime                 | 28.8           |
| LossAfter               | -0.0020257565  |
| LossBefore              | -1.2415766e-05 |
| Model-TimeModelFit      | 24.4           |
| ModelSampler-n_times... | 440000         |
| Policy-AverageAbsPol... | 1.2188057      |
| Policy-AverageDiscou... | 40.1           |
| Policy-AveragePolicyStd | 0.8371501      |
| Policy-AverageReturn    | 64.9           |
| Policy-MaxReturn        | 93.4           |
| Policy-MinReturn        | 14.2           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 19             |
| Policy-TimeAlgoOpt      | 0.596          |
| Policy-TimeSampleProc   | 0.584          |
| Policy-TimeSampling     | 1.83           |
| Policy-TimeStep         | 3.06           |
| Time                    | 188            |
| n_timesteps             | 11000          |
--------------------------------------------

 ---------------- Iteration 11 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 110 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 111 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 112 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 113 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 114 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 115 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 116 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 117 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 118 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 119 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.453          |
| Data-EnvSampler-Poli... | 0.934          |
| Data-EnvTrajs-Averag... | 28.5           |
| Data-EnvTrajs-MaxReturn | 29.5           |
| Data-EnvTrajs-MinReturn | 27.2           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 0.784          |
| Data-TimeEnvSampleProc  | 0.00103        |
| Data-TimeEnvSampling    | 1.43           |
| Iteration               | 11             |
| ItrTime                 | 30.9           |
| LossAfter               | -0.0027365761  |
| LossBefore              | -1.2183793e-05 |
| Model-TimeModelFit      | 26.4           |
| ModelSampler-n_times... | 480000         |
| Policy-AverageAbsPol... | 1.4374714      |
| Policy-AverageDiscou... | 34.9           |
| Policy-AveragePolicyStd | 0.82136697     |
| Policy-AverageReturn    | 54.6           |
| Policy-MaxReturn        | 145            |
| Policy-MinReturn        | -583           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 148            |
| Policy-TimeAlgoOpt      | 0.65           |
| Policy-TimeSampleProc   | 0.392          |
| Policy-TimeSampling     | 1.97           |
| Policy-TimeStep         | 3.06           |
| Time                    | 219            |
| n_timesteps             | 12000          |
--------------------------------------------

 ---------------- Iteration 12 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 120 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 121 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 122 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 123 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 124 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 125 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 126 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 127 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 128 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 129 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.535          |
| Data-EnvSampler-Poli... | 1.22           |
| Data-EnvTrajs-Averag... | 27.7           |
| Data-EnvTrajs-MaxReturn | 30.7           |
| Data-EnvTrajs-MinReturn | 26.1           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.6            |
| Data-TimeEnvSampleProc  | 0.00332        |
| Data-TimeEnvSampling    | 1.8            |
| Iteration               | 12             |
| ItrTime                 | 31.7           |
| LossAfter               | -0.0025107933  |
| LossBefore              | -1.2042666e-05 |
| Model-TimeModelFit      | 27.3           |
| ModelSampler-n_times... | 520000         |
| Policy-AverageAbsPol... | 1.3025677      |
| Policy-AverageDiscou... | 15.7           |
| Policy-AveragePolicyStd | 0.80945396     |
| Policy-AverageReturn    | 25.9           |
| Policy-MaxReturn        | 69.5           |
| Policy-MinReturn        | -274           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 69.5           |
| Policy-TimeAlgoOpt      | 0.582          |
| Policy-TimeSampleProc   | 0.434          |
| Policy-TimeSampling     | 1.58           |
| Policy-TimeStep         | 2.63           |
| Time                    | 251            |
| n_timesteps             | 13000          |
--------------------------------------------

 ---------------- Iteration 13 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 130 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 131 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 132 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 133 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 134 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 135 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 136 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 137 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 138 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 139 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.396          |
| Data-EnvSampler-Poli... | 0.904          |
| Data-EnvTrajs-Averag... | 28.1           |
| Data-EnvTrajs-MaxReturn | 31.6           |
| Data-EnvTrajs-MinReturn | 22.8           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.98           |
| Data-TimeEnvSampleProc  | 0.000906       |
| Data-TimeEnvSampling    | 1.34           |
| Iteration               | 13             |
| ItrTime                 | 31.6           |
| LossAfter               | -0.003512678   |
| LossBefore              | -1.2010575e-05 |
| Model-TimeModelFit      | 27.8           |
| ModelSampler-n_times... | 560000         |
| Policy-AverageAbsPol... | 1.5796714      |
| Policy-AverageDiscou... | 32.6           |
| Policy-AveragePolicyStd | 0.80560946     |
| Policy-AverageReturn    | 58.9           |
| Policy-MaxReturn        | 110            |
| Policy-MinReturn        | -199           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 66.2           |
| Policy-TimeAlgoOpt      | 0.586          |
| Policy-TimeSampleProc   | 0.377          |
| Policy-TimeSampling     | 1.51           |
| Policy-TimeStep         | 2.51           |
| Time                    | 282            |
| n_timesteps             | 14000          |
--------------------------------------------

 ---------------- Iteration 14 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 140 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 141 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 142 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 143 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 144 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 145 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 146 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 147 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 148 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 149 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.398          |
| Data-EnvSampler-Poli... | 0.893          |
| Data-EnvTrajs-Averag... | 29.6           |
| Data-EnvTrajs-MaxReturn | 30.7           |
| Data-EnvTrajs-MinReturn | 26.9           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.45           |
| Data-TimeEnvSampleProc  | 0.000885       |
| Data-TimeEnvSampling    | 1.33           |
| Iteration               | 14             |
| ItrTime                 | 32.1           |
| LossAfter               | -0.005093095   |
| LossBefore              | -1.1869428e-05 |
| Model-TimeModelFit      | 27.9           |
| ModelSampler-n_times... | 600000         |
| Policy-AverageAbsPol... | 1.1936878      |
| Policy-AverageDiscou... | -697           |
| Policy-AveragePolicyStd | 0.7960272      |
| Policy-AverageReturn    | -3.48e+03      |
| Policy-MaxReturn        | 77.7           |
| Policy-MinReturn        | -9.67e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 3.83e+03       |
| Policy-TimeAlgoOpt      | 0.572          |
| Policy-TimeSampleProc   | 0.528          |
| Policy-TimeSampling     | 1.73           |
| Policy-TimeStep         | 2.89           |
| Time                    | 315            |
| n_timesteps             | 15000          |
--------------------------------------------

 ---------------- Iteration 15 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 150 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 151 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 152 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 153 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 154 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 155 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 156 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 157 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 158 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 159 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.426          |
| Data-EnvSampler-Poli... | 1.07           |
| Data-EnvTrajs-Averag... | 28.5           |
| Data-EnvTrajs-MaxReturn | 30             |
| Data-EnvTrajs-MinReturn | 25.2           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.76           |
| Data-TimeEnvSampleProc  | 0.000995       |
| Data-TimeEnvSampling    | 1.53           |
| Iteration               | 15             |
| ItrTime                 | 31.5           |
| LossAfter               | -0.0024539514  |
| LossBefore              | -1.1754009e-05 |
| Model-TimeModelFit      | 27.2           |
| ModelSampler-n_times... | 640000         |
| Policy-AverageAbsPol... | 1.1020867      |
| Policy-AverageDiscou... | -6.85          |
| Policy-AveragePolicyStd | 0.7856895      |
| Policy-AverageReturn    | -147           |
| Policy-MaxReturn        | 51.1           |
| Policy-MinReturn        | -2.27e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 569            |
| Policy-TimeAlgoOpt      | 0.673          |
| Policy-TimeSampleProc   | 0.397          |
| Policy-TimeSampling     | 1.68           |
| Policy-TimeStep         | 2.8            |
| Time                    | 346            |
| n_timesteps             | 16000          |
--------------------------------------------

 ---------------- Iteration 16 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 160 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 161 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 162 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 163 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 164 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 165 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 166 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 167 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 168 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 169 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.466          |
| Data-EnvSampler-Poli... | 1.05           |
| Data-EnvTrajs-Averag... | 30             |
| Data-EnvTrajs-MaxReturn | 32.4           |
| Data-EnvTrajs-MinReturn | 24.5           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.85           |
| Data-TimeEnvSampleProc  | 0.00103        |
| Data-TimeEnvSampling    | 1.56           |
| Iteration               | 16             |
| ItrTime                 | 33.1           |
| LossAfter               | -0.001707636   |
| LossBefore              | -1.1484937e-05 |
| Model-TimeModelFit      | 28.6           |
| ModelSampler-n_times... | 680000         |
| Policy-AverageAbsPol... | 1.1183621      |
| Policy-AverageDiscou... | 5.7            |
| Policy-AveragePolicyStd | 0.77044654     |
| Policy-AverageReturn    | -29            |
| Policy-MaxReturn        | 28.9           |
| Policy-MinReturn        | -893           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 198            |
| Policy-TimeAlgoOpt      | 0.629          |
| Policy-TimeSampleProc   | 0.487          |
| Policy-TimeSampling     | 1.73           |
| Policy-TimeStep         | 2.89           |
| Time                    | 379            |
| n_timesteps             | 17000          |
--------------------------------------------

 ---------------- Iteration 17 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 170 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 171 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 172 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 173 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 174 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 175 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 176 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 177 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 178 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 179 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.383          |
| Data-EnvSampler-Poli... | 0.897          |
| Data-EnvTrajs-Averag... | 21.9           |
| Data-EnvTrajs-MaxReturn | 24.2           |
| Data-EnvTrajs-MinReturn | 19.2           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.94           |
| Data-TimeEnvSampleProc  | 0.000911       |
| Data-TimeEnvSampling    | 1.32           |
| Iteration               | 17             |
| ItrTime                 | 32.9           |
| LossAfter               | -0.003959877   |
| LossBefore              | -1.1230835e-05 |
| Model-TimeModelFit      | 28.8           |
| ModelSampler-n_times... | 720000         |
| Policy-AverageAbsPol... | 0.87410635     |
| Policy-AverageDiscou... | 14.5           |
| Policy-AveragePolicyStd | 0.7520347      |
| Policy-AverageReturn    | 6.29           |
| Policy-MaxReturn        | 20             |
| Policy-MinReturn        | -6.31          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 7.88           |
| Policy-TimeAlgoOpt      | 0.568          |
| Policy-TimeSampleProc   | 0.512          |
| Policy-TimeSampling     | 1.62           |
| Policy-TimeStep         | 2.76           |
| Time                    | 412            |
| n_timesteps             | 18000          |
--------------------------------------------

 ---------------- Iteration 18 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...
Stopping DynamicsEnsemble Training since valid_loss_rolling_average decreased

 ---------------- Grad-Step 180 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 181 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 182 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 183 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 184 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 185 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 186 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 187 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 188 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 189 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.428           |
| Data-EnvSampler-Poli... | 1.01            |
| Data-EnvTrajs-Averag... | 20.3            |
| Data-EnvTrajs-MaxReturn | 24.7            |
| Data-EnvTrajs-MinReturn | 15              |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 3.23            |
| Data-TimeEnvSampleProc  | 0.000947        |
| Data-TimeEnvSampling    | 1.48            |
| Iteration               | 18              |
| ItrTime                 | 16.8            |
| LossAfter               | -0.0031471376   |
| LossBefore              | -1.10319115e-05 |
| Model-TimeModelFit      | 12.4            |
| ModelSampler-n_times... | 760000          |
| Policy-AverageAbsPol... | 0.93111306      |
| Policy-AverageDiscou... | 23.1            |
| Policy-AveragePolicyStd | 0.73793924      |
| Policy-AverageReturn    | 50.9            |
| Policy-MaxReturn        | 72              |
| Policy-MinReturn        | 38.1            |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 8.6             |
| Policy-TimeAlgoOpt      | 0.574           |
| Policy-TimeSampleProc   | 0.518           |
| Policy-TimeSampling     | 1.7             |
| Policy-TimeStep         | 2.83            |
| Time                    | 429             |
| n_timesteps             | 19000           |
---------------------------------------------

 ---------------- Iteration 19 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...
Stopping DynamicsEnsemble Training since valid_loss_rolling_average decreased

 ---------------- Grad-Step 190 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 191 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 192 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 193 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 194 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 195 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 196 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 197 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 198 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 199 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.407          |
| Data-EnvSampler-Poli... | 0.987          |
| Data-EnvTrajs-Averag... | 28             |
| Data-EnvTrajs-MaxReturn | 32.7           |
| Data-EnvTrajs-MinReturn | 23.3           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.98           |
| Data-TimeEnvSampleProc  | 0.00104        |
| Data-TimeEnvSampling    | 1.43           |
| Iteration               | 19             |
| ItrTime                 | 11.8           |
| LossAfter               | -0.0037087651  |
| LossBefore              | -1.0848557e-05 |
| Model-TimeModelFit      | 7.77           |
| ModelSampler-n_times... | 800000         |
| Policy-AverageAbsPol... | 0.9569669      |
| Policy-AverageDiscou... | -138           |
| Policy-AveragePolicyStd | 0.72497535     |
| Policy-AverageReturn    | -570           |
| Policy-MaxReturn        | 28.7           |
| Policy-MinReturn        | -1.16e+04      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.53e+03       |
| Policy-TimeAlgoOpt      | 0.555          |
| Policy-TimeSampleProc   | 0.431          |
| Policy-TimeSampling     | 1.54           |
| Policy-TimeStep         | 2.56           |
| Time                    | 441            |
| n_timesteps             | 20000          |
--------------------------------------------

 ---------------- Iteration 20 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...
Stopping DynamicsEnsemble Training since valid_loss_rolling_average decreased

 ---------------- Grad-Step 200 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 201 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 202 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 203 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 204 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 205 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 206 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 207 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 208 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 209 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.409          |
| Data-EnvSampler-Poli... | 0.883          |
| Data-EnvTrajs-Averag... | 29             |
| Data-EnvTrajs-MaxReturn | 32.2           |
| Data-EnvTrajs-MinReturn | 26.3           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.02           |
| Data-TimeEnvSampleProc  | 0.000991       |
| Data-TimeEnvSampling    | 1.33           |
| Iteration               | 20             |
| ItrTime                 | 29             |
| LossAfter               | -0.001790377   |
| LossBefore              | -1.0701374e-05 |
| Model-TimeModelFit      | 25.1           |
| ModelSampler-n_times... | 840000         |
| Policy-AverageAbsPol... | 0.82590383     |
| Policy-AverageDiscou... | 32.3           |
| Policy-AveragePolicyStd | 0.7173788      |
| Policy-AverageReturn    | 81.6           |
| Policy-MaxReturn        | 158            |
| Policy-MinReturn        | 38.9           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 28.3           |
| Policy-TimeAlgoOpt      | 0.568          |
| Policy-TimeSampleProc   | 0.371          |
| Policy-TimeSampling     | 1.58           |
| Policy-TimeStep         | 2.55           |
| Time                    | 470            |
| n_timesteps             | 21000          |
--------------------------------------------

 ---------------- Iteration 21 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 210 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 211 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 212 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 213 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 214 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 215 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 216 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 217 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 218 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 219 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.377         |
| Data-EnvSampler-Poli... | 0.818         |
| Data-EnvTrajs-Averag... | 27.8          |
| Data-EnvTrajs-MaxReturn | 31.1          |
| Data-EnvTrajs-MinReturn | 25.4          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 2.66          |
| Data-TimeEnvSampleProc  | 0.000673      |
| Data-TimeEnvSampling    | 1.24          |
| Iteration               | 21            |
| ItrTime                 | 33.1          |
| LossAfter               | -0.0038155974 |
| LossBefore              | -1.049602e-05 |
| Model-TimeModelFit      | 29.2          |
| ModelSampler-n_times... | 880000        |
| Policy-AverageAbsPol... | 0.854259      |
| Policy-AverageDiscou... | 31.4          |
| Policy-AveragePolicyStd | 0.7025967     |
| Policy-AverageReturn    | 79.4          |
| Policy-MaxReturn        | 109           |
| Policy-MinReturn        | 45.8          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 16            |
| Policy-TimeAlgoOpt      | 0.61          |
| Policy-TimeSampleProc   | 0.389         |
| Policy-TimeSampling     | 1.63          |
| Policy-TimeStep         | 2.66          |
| Time                    | 503           |
| n_timesteps             | 22000         |
-------------------------------------------

 ---------------- Iteration 22 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 220 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 221 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 222 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 223 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 224 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 225 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 226 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 227 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 228 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 229 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.393          |
| Data-EnvSampler-Poli... | 0.881          |
| Data-EnvTrajs-Averag... | 28.6           |
| Data-EnvTrajs-MaxReturn | 34.3           |
| Data-EnvTrajs-MinReturn | 25.2           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 3.41           |
| Data-TimeEnvSampleProc  | 0.00103        |
| Data-TimeEnvSampling    | 1.31           |
| Iteration               | 22             |
| ItrTime                 | 33.8           |
| LossAfter               | -0.0011831395  |
| LossBefore              | -1.0345728e-05 |
| Model-TimeModelFit      | 29.2           |
| ModelSampler-n_times... | 920000         |
| Policy-AverageAbsPol... | 0.71695286     |
| Policy-AverageDiscou... | -172           |
| Policy-AveragePolicyStd | 0.6914405      |
| Policy-AverageReturn    | -793           |
| Policy-MaxReturn        | 65.4           |
| Policy-MinReturn        | -1.2e+04       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.77e+03       |
| Policy-TimeAlgoOpt      | 0.619          |
| Policy-TimeSampleProc   | 0.603          |
| Policy-TimeSampling     | 1.99           |
| Policy-TimeStep         | 3.25           |
| Time                    | 537            |
| n_timesteps             | 23000          |
--------------------------------------------

 ---------------- Iteration 23 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 230 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 231 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 232 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 233 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 234 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 235 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 236 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 237 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 238 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 239 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.374          |
| Data-EnvSampler-Poli... | 0.957          |
| Data-EnvTrajs-Averag... | 27.3           |
| Data-EnvTrajs-MaxReturn | 29.4           |
| Data-EnvTrajs-MinReturn | 24.2           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.81           |
| Data-TimeEnvSampleProc  | 0.000977       |
| Data-TimeEnvSampling    | 1.37           |
| Iteration               | 23             |
| ItrTime                 | 32.4           |
| LossAfter               | -0.0058922893  |
| LossBefore              | -1.0286142e-05 |
| Model-TimeModelFit      | 28.7           |
| ModelSampler-n_times... | 960000         |
| Policy-AverageAbsPol... | 0.8122943      |
| Policy-AverageDiscou... | 27.1           |
| Policy-AveragePolicyStd | 0.68795353     |
| Policy-AverageReturn    | 37.3           |
| Policy-MaxReturn        | 45.9           |
| Policy-MinReturn        | 28.6           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 4.96           |
| Policy-TimeAlgoOpt      | 0.566          |
| Policy-TimeSampleProc   | 0.276          |
| Policy-TimeSampling     | 1.49           |
| Policy-TimeStep         | 2.37           |
| Time                    | 569            |
| n_timesteps             | 24000          |
--------------------------------------------

 ---------------- Iteration 24 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 240 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 241 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 242 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 243 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 244 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 245 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 246 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 247 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 248 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 249 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.384           |
| Data-EnvSampler-Poli... | 0.835           |
| Data-EnvTrajs-Averag... | 28.9            |
| Data-EnvTrajs-MaxReturn | 31.1            |
| Data-EnvTrajs-MinReturn | 27.4            |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 1.71            |
| Data-TimeEnvSampleProc  | 0.000992        |
| Data-TimeEnvSampling    | 1.26            |
| Iteration               | 24              |
| ItrTime                 | 33.8            |
| LossAfter               | -0.002294389    |
| LossBefore              | -1.01603855e-05 |
| Model-TimeModelFit      | 30.1            |
| ModelSampler-n_times... | 1000000         |
| Policy-AverageAbsPol... | 1.1114116       |
| Policy-AverageDiscou... | 31.1            |
| Policy-AveragePolicyStd | 0.680445        |
| Policy-AverageReturn    | 66.1            |
| Policy-MaxReturn        | 87.2            |
| Policy-MinReturn        | 55.4            |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 7.57            |
| Policy-TimeAlgoOpt      | 0.534           |
| Policy-TimeSampleProc   | 0.33            |
| Policy-TimeSampling     | 1.51            |
| Policy-TimeStep         | 2.42            |
| Time                    | 603             |
| n_timesteps             | 25000           |
---------------------------------------------

 ---------------- Iteration 25 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 250 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 251 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 252 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 253 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 254 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 255 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 256 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 257 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 258 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 259 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.392          |
| Data-EnvSampler-Poli... | 0.849          |
| Data-EnvTrajs-Averag... | 30             |
| Data-EnvTrajs-MaxReturn | 32.2           |
| Data-EnvTrajs-MinReturn | 26.1           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.15           |
| Data-TimeEnvSampleProc  | 0.00106        |
| Data-TimeEnvSampling    | 1.28           |
| Iteration               | 25             |
| ItrTime                 | 33             |
| LossAfter               | -0.0022012587  |
| LossBefore              | -1.0188278e-05 |
| Model-TimeModelFit      | 29.3           |
| ModelSampler-n_times... | 1040000        |
| Policy-AverageAbsPol... | 1.5382963      |
| Policy-AverageDiscou... | -6.78          |
| Policy-AveragePolicyStd | 0.68180984     |
| Policy-AverageReturn    | -231           |
| Policy-MaxReturn        | 224            |
| Policy-MinReturn        | -6.52e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.44e+03       |
| Policy-TimeAlgoOpt      | 0.53           |
| Policy-TimeSampleProc   | 0.383          |
| Policy-TimeSampling     | 1.49           |
| Policy-TimeStep         | 2.44           |
| Time                    | 636            |
| n_timesteps             | 26000          |
--------------------------------------------

 ---------------- Iteration 26 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 260 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 261 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 262 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 263 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 264 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 265 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 266 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 267 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 268 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 269 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.368          |
| Data-EnvSampler-Poli... | 0.83           |
| Data-EnvTrajs-Averag... | 28.6           |
| Data-EnvTrajs-MaxReturn | 32.5           |
| Data-EnvTrajs-MinReturn | 25.4           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.8            |
| Data-TimeEnvSampleProc  | 0.000888       |
| Data-TimeEnvSampling    | 1.23           |
| Iteration               | 26             |
| ItrTime                 | 33.6           |
| LossAfter               | -0.0040427493  |
| LossBefore              | -1.0065904e-05 |
| Model-TimeModelFit      | 29.5           |
| ModelSampler-n_times... | 1080000        |
| Policy-AverageAbsPol... | 1.154862       |
| Policy-AverageDiscou... | 8.73           |
| Policy-AveragePolicyStd | 0.671153       |
| Policy-AverageReturn    | -113           |
| Policy-MaxReturn        | 104            |
| Policy-MinReturn        | -3.04e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 672            |
| Policy-TimeAlgoOpt      | 0.602          |
| Policy-TimeSampleProc   | 0.363          |
| Policy-TimeSampling     | 1.86           |
| Policy-TimeStep         | 2.85           |
| Time                    | 669            |
| n_timesteps             | 27000          |
--------------------------------------------

 ---------------- Iteration 27 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 270 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 271 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 272 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 273 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 274 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 275 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 276 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 277 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 278 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 279 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.383         |
| Data-EnvSampler-Poli... | 0.916         |
| Data-EnvTrajs-Averag... | 5.57          |
| Data-EnvTrajs-MaxReturn | 30.5          |
| Data-EnvTrajs-MinReturn | -14.6         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 19            |
| Data-TimeEnvSampleProc  | 0.00108       |
| Data-TimeEnvSampling    | 1.34          |
| Iteration               | 27            |
| ItrTime                 | 33.6          |
| LossAfter               | -0.003244574  |
| LossBefore              | -9.831572e-06 |
| Model-TimeModelFit      | 29.8          |
| ModelSampler-n_times... | 1120000       |
| Policy-AverageAbsPol... | 1.2631584     |
| Policy-AverageDiscou... | 36.8          |
| Policy-AveragePolicyStd | 0.6551584     |
| Policy-AverageReturn    | 67.6          |
| Policy-MaxReturn        | 77.7          |
| Policy-MinReturn        | 56.5          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 6.12          |
| Policy-TimeAlgoOpt      | 0.561         |
| Policy-TimeSampleProc   | 0.363         |
| Policy-TimeSampling     | 1.47          |
| Policy-TimeStep         | 2.44          |
| Time                    | 703           |
| n_timesteps             | 28000         |
-------------------------------------------

 ---------------- Iteration 28 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...
Stopping DynamicsEnsemble Training since valid_loss_rolling_average decreased

 ---------------- Grad-Step 280 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 281 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 282 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 283 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 284 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 285 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 286 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 287 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 288 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 289 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.375         |
| Data-EnvSampler-Poli... | 0.858         |
| Data-EnvTrajs-Averag... | 30.3          |
| Data-EnvTrajs-MaxReturn | 31.7          |
| Data-EnvTrajs-MinReturn | 28.5          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.19          |
| Data-TimeEnvSampleProc  | 0.00121       |
| Data-TimeEnvSampling    | 1.27          |
| Iteration               | 28            |
| ItrTime                 | 32.1          |
| LossAfter               | -0.0028282017 |
| LossBefore              | -9.540681e-06 |
| Model-TimeModelFit      | 28            |
| ModelSampler-n_times... | 1160000       |
| Policy-AverageAbsPol... | 1.0699667     |
| Policy-AverageDiscou... | 21.8          |
| Policy-AveragePolicyStd | 0.63787097    |
| Policy-AverageReturn    | 31.5          |
| Policy-MaxReturn        | 40.9          |
| Policy-MinReturn        | 20.9          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 5.99          |
| Policy-TimeAlgoOpt      | 0.586         |
| Policy-TimeSampleProc   | 0.468         |
| Policy-TimeSampling     | 1.72          |
| Policy-TimeStep         | 2.81          |
| Time                    | 735           |
| n_timesteps             | 29000         |
-------------------------------------------

 ---------------- Iteration 29 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 290 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 291 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 292 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 293 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 294 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 295 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 296 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 297 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 298 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 299 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.519         |
| Data-EnvSampler-Poli... | 1.32          |
| Data-EnvTrajs-Averag... | 32.6          |
| Data-EnvTrajs-MaxReturn | 34.5          |
| Data-EnvTrajs-MinReturn | 31.6          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.11          |
| Data-TimeEnvSampleProc  | 0.00106       |
| Data-TimeEnvSampling    | 1.89          |
| Iteration               | 29            |
| ItrTime                 | 34.9          |
| LossAfter               | -0.0024643035 |
| LossBefore              | -9.082892e-06 |
| Model-TimeModelFit      | 30.7          |
| ModelSampler-n_times... | 1200000       |
| Policy-AverageAbsPol... | 1.5644951     |
| Policy-AverageDiscou... | 38            |
| Policy-AveragePolicyStd | 0.6121101     |
| Policy-AverageReturn    | 77.5          |
| Policy-MaxReturn        | 92.7          |
| Policy-MinReturn        | 53.9          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 11.5          |
| Policy-TimeAlgoOpt      | 0.543         |
| Policy-TimeSampleProc   | 0.341         |
| Policy-TimeSampling     | 1.43          |
| Policy-TimeStep         | 2.35          |
| Time                    | 770           |
| n_timesteps             | 30000         |
-------------------------------------------

 ---------------- Iteration 30 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 300 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 301 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 302 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 303 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 304 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 305 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 306 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 307 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 308 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 309 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.362         |
| Data-EnvSampler-Poli... | 0.842         |
| Data-EnvTrajs-Averag... | 31.1          |
| Data-EnvTrajs-MaxReturn | 32            |
| Data-EnvTrajs-MinReturn | 30.5          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 0.505         |
| Data-TimeEnvSampleProc  | 0.000987      |
| Data-TimeEnvSampling    | 1.24          |
| Iteration               | 30            |
| ItrTime                 | 34.6          |
| LossAfter               | -0.0015641861 |
| LossBefore              | -8.893054e-06 |
| Model-TimeModelFit      | 30.8          |
| ModelSampler-n_times... | 1240000       |
| Policy-AverageAbsPol... | 1.2805823     |
| Policy-AverageDiscou... | 19.4          |
| Policy-AveragePolicyStd | 0.60104954    |
| Policy-AverageReturn    | 22            |
| Policy-MaxReturn        | 29.2          |
| Policy-MinReturn        | 15.6          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 2.86          |
| Policy-TimeAlgoOpt      | 0.588         |
| Policy-TimeSampleProc   | 0.333         |
| Policy-TimeSampling     | 1.56          |
| Policy-TimeStep         | 2.51          |
| Time                    | 805           |
| n_timesteps             | 31000         |
-------------------------------------------

 ---------------- Iteration 31 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 310 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 311 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 312 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 313 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 314 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 315 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 316 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 317 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 318 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 319 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.416         |
| Data-EnvSampler-Poli... | 1.13          |
| Data-EnvTrajs-Averag... | 31.2          |
| Data-EnvTrajs-MaxReturn | 33.2          |
| Data-EnvTrajs-MinReturn | 29            |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.54          |
| Data-TimeEnvSampleProc  | 0.00101       |
| Data-TimeEnvSampling    | 1.6           |
| Iteration               | 31            |
| ItrTime                 | 34.6          |
| LossAfter               | -0.0018309182 |
| LossBefore              | -8.634206e-06 |
| Model-TimeModelFit      | 30.5          |
| ModelSampler-n_times... | 1280000       |
| Policy-AverageAbsPol... | 1.5898494     |
| Policy-AverageDiscou... | 34.4          |
| Policy-AveragePolicyStd | 0.5887324     |
| Policy-AverageReturn    | 72.9          |
| Policy-MaxReturn        | 85.5          |
| Policy-MinReturn        | 49.5          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 8.6           |
| Policy-TimeAlgoOpt      | 0.578         |
| Policy-TimeSampleProc   | 0.338         |
| Policy-TimeSampling     | 1.54          |
| Policy-TimeStep         | 2.48          |
| Time                    | 839           |
| n_timesteps             | 32000         |
-------------------------------------------

 ---------------- Iteration 32 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 320 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 321 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 322 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 323 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 324 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 325 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 326 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 327 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 328 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 329 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.432         |
| Data-EnvSampler-Poli... | 0.95          |
| Data-EnvTrajs-Averag... | 28.1          |
| Data-EnvTrajs-MaxReturn | 29.3          |
| Data-EnvTrajs-MinReturn | 27.2          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 0.745         |
| Data-TimeEnvSampleProc  | 0.00113       |
| Data-TimeEnvSampling    | 1.42          |
| Iteration               | 32            |
| ItrTime                 | 35            |
| LossAfter               | -0.0012537176 |
| LossBefore              | -8.307281e-06 |
| Model-TimeModelFit      | 31.1          |
| ModelSampler-n_times... | 1320000       |
| Policy-AverageAbsPol... | 1.2199169     |
| Policy-AverageDiscou... | 24.3          |
| Policy-AveragePolicyStd | 0.56922793    |
| Policy-AverageReturn    | 34.2          |
| Policy-MaxReturn        | 37.6          |
| Policy-MinReturn        | 31.5          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.41          |
| Policy-TimeAlgoOpt      | 0.554         |
| Policy-TimeSampleProc   | 0.421         |
| Policy-TimeSampling     | 1.54          |
| Policy-TimeStep         | 2.54          |
| Time                    | 874           |
| n_timesteps             | 33000         |
-------------------------------------------

 ---------------- Iteration 33 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 330 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 331 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 332 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 333 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 334 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 335 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 336 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 337 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 338 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 339 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.415          |
| Data-EnvSampler-Poli... | 0.948          |
| Data-EnvTrajs-Averag... | 31.5           |
| Data-EnvTrajs-MaxReturn | 33.1           |
| Data-EnvTrajs-MinReturn | 29.3           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.47           |
| Data-TimeEnvSampleProc  | 0.00121        |
| Data-TimeEnvSampling    | 1.4            |
| Iteration               | 33             |
| ItrTime                 | 35.3           |
| LossAfter               | -0.0014281335  |
| LossBefore              | -8.0798645e-06 |
| Model-TimeModelFit      | 31             |
| ModelSampler-n_times... | 1360000        |
| Policy-AverageAbsPol... | 1.1750989      |
| Policy-AverageDiscou... | 24.4           |
| Policy-AveragePolicyStd | 0.5565404      |
| Policy-AverageReturn    | 31.5           |
| Policy-MaxReturn        | 34.9           |
| Policy-MinReturn        | 27.7           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.01           |
| Policy-TimeAlgoOpt      | 0.589          |
| Policy-TimeSampleProc   | 0.56           |
| Policy-TimeSampling     | 1.79           |
| Policy-TimeStep         | 2.98           |
| Time                    | 910            |
| n_timesteps             | 34000          |
--------------------------------------------

 ---------------- Iteration 34 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 340 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 341 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 342 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 343 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 344 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 345 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 346 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 347 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 348 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 349 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.404         |
| Data-EnvSampler-Poli... | 0.964         |
| Data-EnvTrajs-Averag... | 32.6          |
| Data-EnvTrajs-MaxReturn | 34.5          |
| Data-EnvTrajs-MinReturn | 31.3          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.26          |
| Data-TimeEnvSampleProc  | 0.00094       |
| Data-TimeEnvSampling    | 1.41          |
| Iteration               | 34            |
| ItrTime                 | 35.3          |
| LossAfter               | -0.0013188887 |
| LossBefore              | -7.851466e-06 |
| Model-TimeModelFit      | 31.2          |
| ModelSampler-n_times... | 1400000       |
| Policy-AverageAbsPol... | 1.4436196     |
| Policy-AverageDiscou... | 32.8          |
| Policy-AveragePolicyStd | 0.54596394    |
| Policy-AverageReturn    | 62.9          |
| Policy-MaxReturn        | 84.8          |
| Policy-MinReturn        | 48.1          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 11.5          |
| Policy-TimeAlgoOpt      | 0.561         |
| Policy-TimeSampleProc   | 0.423         |
| Policy-TimeSampling     | 1.7           |
| Policy-TimeStep         | 2.7           |
| Time                    | 945           |
| n_timesteps             | 35000         |
-------------------------------------------

 ---------------- Iteration 35 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 350 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 351 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 352 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 353 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 354 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 355 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 356 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 357 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 358 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 359 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.39           |
| Data-EnvSampler-Poli... | 0.876          |
| Data-EnvTrajs-Averag... | 31.3           |
| Data-EnvTrajs-MaxReturn | 33.5           |
| Data-EnvTrajs-MinReturn | 30.2           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.18           |
| Data-TimeEnvSampleProc  | 0.000983       |
| Data-TimeEnvSampling    | 1.3            |
| Iteration               | 35             |
| ItrTime                 | 35.7           |
| LossAfter               | -0.0032262665  |
| LossBefore              | -7.4859354e-06 |
| Model-TimeModelFit      | 31.9           |
| ModelSampler-n_times... | 1440000        |
| Policy-AverageAbsPol... | 1.1810715      |
| Policy-AverageDiscou... | 27.4           |
| Policy-AveragePolicyStd | 0.5267705      |
| Policy-AverageReturn    | 47.1           |
| Policy-MaxReturn        | 59.7           |
| Policy-MinReturn        | 38.3           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 5.27           |
| Policy-TimeAlgoOpt      | 0.545          |
| Policy-TimeSampleProc   | 0.329          |
| Policy-TimeSampling     | 1.56           |
| Policy-TimeStep         | 2.47           |
| Time                    | 981            |
| n_timesteps             | 36000          |
--------------------------------------------

 ---------------- Iteration 36 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 360 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 361 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 362 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 363 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 364 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 365 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 366 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 367 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 368 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 369 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.36           |
| Data-EnvSampler-Poli... | 0.808          |
| Data-EnvTrajs-Averag... | 31.6           |
| Data-EnvTrajs-MaxReturn | 32             |
| Data-EnvTrajs-MinReturn | 30.5           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 0.543          |
| Data-TimeEnvSampleProc  | 0.000973       |
| Data-TimeEnvSampling    | 1.2            |
| Iteration               | 36             |
| ItrTime                 | 35.4           |
| LossAfter               | -0.0017309079  |
| LossBefore              | -6.9975335e-06 |
| Model-TimeModelFit      | 31.3           |
| ModelSampler-n_times... | 1480000        |
| Policy-AverageAbsPol... | 1.128721       |
| Policy-AverageDiscou... | 23.9           |
| Policy-AveragePolicyStd | 0.5008571      |
| Policy-AverageReturn    | 32.1           |
| Policy-MaxReturn        | 35.4           |
| Policy-MinReturn        | 28.7           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.44           |
| Policy-TimeAlgoOpt      | 0.655          |
| Policy-TimeSampleProc   | 0.427          |
| Policy-TimeSampling     | 1.76           |
| Policy-TimeStep         | 2.87           |
| Time                    | 1.02e+03       |
| n_timesteps             | 37000          |
--------------------------------------------

 ---------------- Iteration 37 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 370 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 371 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 372 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 373 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 374 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 375 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 376 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 377 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 378 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 379 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.491          |
| Data-EnvSampler-Poli... | 1.23           |
| Data-EnvTrajs-Averag... | 32             |
| Data-EnvTrajs-MaxReturn | 33.6           |
| Data-EnvTrajs-MinReturn | 30.3           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.21           |
| Data-TimeEnvSampleProc  | 0.00103        |
| Data-TimeEnvSampling    | 1.77           |
| Iteration               | 37             |
| ItrTime                 | 35.8           |
| LossAfter               | -0.0014110121  |
| LossBefore              | -6.7761466e-06 |
| Model-TimeModelFit      | 31.1           |
| ModelSampler-n_times... | 1520000        |
| Policy-AverageAbsPol... | 1.275529       |
| Policy-AverageDiscou... | 31.3           |
| Policy-AveragePolicyStd | 0.48745197     |
| Policy-AverageReturn    | 57.3           |
| Policy-MaxReturn        | 79.7           |
| Policy-MinReturn        | 41.3           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 9.03           |
| Policy-TimeAlgoOpt      | 0.594          |
| Policy-TimeSampleProc   | 0.535          |
| Policy-TimeSampling     | 1.71           |
| Policy-TimeStep         | 2.88           |
| Time                    | 1.05e+03       |
| n_timesteps             | 38000          |
--------------------------------------------

 ---------------- Iteration 38 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 380 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 381 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 382 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 383 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 384 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 385 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 386 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 387 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 388 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 389 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.432          |
| Data-EnvSampler-Poli... | 1.25           |
| Data-EnvTrajs-Averag... | 7.64           |
| Data-EnvTrajs-MaxReturn | 30.4           |
| Data-EnvTrajs-MinReturn | -13.8          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 16.6           |
| Data-TimeEnvSampleProc  | 0.0013         |
| Data-TimeEnvSampling    | 1.76           |
| Iteration               | 38             |
| ItrTime                 | 35.7           |
| LossAfter               | -0.0037817224  |
| LossBefore              | -6.5349805e-06 |
| Model-TimeModelFit      | 31.3           |
| ModelSampler-n_times... | 1560000        |
| Policy-AverageAbsPol... | 1.2160115      |
| Policy-AverageDiscou... | 25.2           |
| Policy-AveragePolicyStd | 0.47596583     |
| Policy-AverageReturn    | 30.9           |
| Policy-MaxReturn        | 33.7           |
| Policy-MinReturn        | 25.9           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.6            |
| Policy-TimeAlgoOpt      | 0.599          |
| Policy-TimeSampleProc   | 0.429          |
| Policy-TimeSampling     | 1.52           |
| Policy-TimeStep         | 2.57           |
| Time                    | 1.09e+03       |
| n_timesteps             | 39000          |
--------------------------------------------

 ---------------- Iteration 39 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...
Stopping DynamicsEnsemble Training since valid_loss_rolling_average decreased

 ---------------- Grad-Step 390 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 391 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 392 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 393 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 394 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 395 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 396 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 397 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 398 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 399 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.419         |
| Data-EnvSampler-Poli... | 0.955         |
| Data-EnvTrajs-Averag... | 31.9          |
| Data-EnvTrajs-MaxReturn | 33.7          |
| Data-EnvTrajs-MinReturn | 30.2          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.21          |
| Data-TimeEnvSampleProc  | 0.0011        |
| Data-TimeEnvSampling    | 1.41          |
| Iteration               | 39            |
| ItrTime                 | 24.2          |
| LossAfter               | -0.0014403369 |
| LossBefore              | -6.330776e-06 |
| Model-TimeModelFit      | 20.1          |
| ModelSampler-n_times... | 1600000       |
| Policy-AverageAbsPol... | 1.1791892     |
| Policy-AverageDiscou... | 36.4          |
| Policy-AveragePolicyStd | 0.46938574    |
| Policy-AverageReturn    | 62.8          |
| Policy-MaxReturn        | 87.7          |
| Policy-MinReturn        | 38.3          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 14.2          |
| Policy-TimeAlgoOpt      | 0.517         |
| Policy-TimeSampleProc   | 0.497         |
| Policy-TimeSampling     | 1.69          |
| Policy-TimeStep         | 2.74          |
| Time                    | 1.11e+03      |
| n_timesteps             | 40000         |
-------------------------------------------

 ---------------- Iteration 40 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 400 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 401 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 402 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 403 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 404 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 405 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 406 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 407 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 408 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 409 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.399          |
| Data-EnvSampler-Poli... | 0.864          |
| Data-EnvTrajs-Averag... | 31.6           |
| Data-EnvTrajs-MaxReturn | 33.8           |
| Data-EnvTrajs-MinReturn | 29.1           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.53           |
| Data-TimeEnvSampleProc  | 0.000925       |
| Data-TimeEnvSampling    | 1.3            |
| Iteration               | 40             |
| ItrTime                 | 35.4           |
| LossAfter               | -0.0012578311  |
| LossBefore              | -6.1636233e-06 |
| Model-TimeModelFit      | 31.5           |
| ModelSampler-n_times... | 1640000        |
| Policy-AverageAbsPol... | 1.5699221      |
| Policy-AverageDiscou... | 28.2           |
| Policy-AveragePolicyStd | 0.46102917     |
| Policy-AverageReturn    | 44.1           |
| Policy-MaxReturn        | 86.4           |
| Policy-MinReturn        | -291           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 80.3           |
| Policy-TimeAlgoOpt      | 0.553          |
| Policy-TimeSampleProc   | 0.457          |
| Policy-TimeSampling     | 1.63           |
| Policy-TimeStep         | 2.67           |
| Time                    | 1.15e+03       |
| n_timesteps             | 41000          |
--------------------------------------------

 ---------------- Iteration 41 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...
Stopping DynamicsEnsemble Training since valid_loss_rolling_average decreased

 ---------------- Grad-Step 410 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 411 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 412 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 413 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 414 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 415 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 416 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 417 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 418 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 419 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.431          |
| Data-EnvSampler-Poli... | 0.924          |
| Data-EnvTrajs-Averag... | 29.8           |
| Data-EnvTrajs-MaxReturn | 31.2           |
| Data-EnvTrajs-MinReturn | 28.3           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.08           |
| Data-TimeEnvSampleProc  | 0.00111        |
| Data-TimeEnvSampling    | 1.39           |
| Iteration               | 41             |
| ItrTime                 | 34.1           |
| LossAfter               | -0.0028226317  |
| LossBefore              | -5.9670006e-06 |
| Model-TimeModelFit      | 29.9           |
| ModelSampler-n_times... | 1680000        |
| Policy-AverageAbsPol... | 1.2635571      |
| Policy-AverageDiscou... | 0.254          |
| Policy-AveragePolicyStd | 0.45185772     |
| Policy-AverageReturn    | -45            |
| Policy-MaxReturn        | 13.3           |
| Policy-MinReturn        | -415           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 109            |
| Policy-TimeAlgoOpt      | 0.637          |
| Policy-TimeSampleProc   | 0.347          |
| Policy-TimeSampling     | 1.82           |
| Policy-TimeStep         | 2.82           |
| Time                    | 1.18e+03       |
| n_timesteps             | 42000          |
--------------------------------------------

 ---------------- Iteration 42 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 420 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 421 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 422 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 423 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 424 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 425 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 426 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 427 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 428 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 429 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.347         |
| Data-EnvSampler-Poli... | 0.763         |
| Data-EnvTrajs-Averag... | 33.1          |
| Data-EnvTrajs-MaxReturn | 35.6          |
| Data-EnvTrajs-MinReturn | 31.2          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.42          |
| Data-TimeEnvSampleProc  | 0.00105       |
| Data-TimeEnvSampling    | 1.15          |
| Iteration               | 42            |
| ItrTime                 | 35.8          |
| LossAfter               | -0.0011023171 |
| LossBefore              | -5.777026e-06 |
| Model-TimeModelFit      | 32            |
| ModelSampler-n_times... | 1720000       |
| Policy-AverageAbsPol... | 1.3871287     |
| Policy-AverageDiscou... | 26.4          |
| Policy-AveragePolicyStd | 0.44118682    |
| Policy-AverageReturn    | 37.9          |
| Policy-MaxReturn        | 41.4          |
| Policy-MinReturn        | 32.9          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 2.12          |
| Policy-TimeAlgoOpt      | 0.593         |
| Policy-TimeSampleProc   | 0.284         |
| Policy-TimeSampling     | 1.69          |
| Policy-TimeStep         | 2.64          |
| Time                    | 1.22e+03      |
| n_timesteps             | 43000         |
-------------------------------------------

 ---------------- Iteration 43 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 430 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 431 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 432 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 433 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 434 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 435 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 436 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 437 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 438 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 439 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.354          |
| Data-EnvSampler-Poli... | 0.733          |
| Data-EnvTrajs-Averag... | 30.5           |
| Data-EnvTrajs-MaxReturn | 33.1           |
| Data-EnvTrajs-MinReturn | 28.2           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.93           |
| Data-TimeEnvSampleProc  | 0.00114        |
| Data-TimeEnvSampling    | 1.12           |
| Iteration               | 43             |
| ItrTime                 | 36.9           |
| LossAfter               | -0.0042100223  |
| LossBefore              | -5.6978083e-06 |
| Model-TimeModelFit      | 32.5           |
| ModelSampler-n_times... | 1760000        |
| Policy-AverageAbsPol... | 1.2409955      |
| Policy-AverageDiscou... | 23.8           |
| Policy-AveragePolicyStd | 0.4383792      |
| Policy-AverageReturn    | 37.4           |
| Policy-MaxReturn        | 48.9           |
| Policy-MinReturn        | 28.9           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 6.45           |
| Policy-TimeAlgoOpt      | 0.587          |
| Policy-TimeSampleProc   | 0.689          |
| Policy-TimeSampling     | 1.96           |
| Policy-TimeStep         | 3.32           |
| Time                    | 1.25e+03       |
| n_timesteps             | 44000          |
--------------------------------------------

 ---------------- Iteration 44 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 440 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 441 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 442 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 443 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 444 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 445 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 446 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 447 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 448 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 449 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.329         |
| Data-EnvSampler-Poli... | 0.619         |
| Data-EnvTrajs-Averag... | 28.5          |
| Data-EnvTrajs-MaxReturn | 30.1          |
| Data-EnvTrajs-MinReturn | 27.8          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 0.848         |
| Data-TimeEnvSampleProc  | 0.000894      |
| Data-TimeEnvSampling    | 0.976         |
| Iteration               | 44            |
| ItrTime                 | 36.2          |
| LossAfter               | -0.003772634  |
| LossBefore              | -5.602329e-06 |
| Model-TimeModelFit      | 32.6          |
| ModelSampler-n_times... | 1800000       |
| Policy-AverageAbsPol... | 1.6997727     |
| Policy-AverageDiscou... | 19.8          |
| Policy-AveragePolicyStd | 0.43507427    |
| Policy-AverageReturn    | 22.3          |
| Policy-MaxReturn        | 37.8          |
| Policy-MinReturn        | -13.3         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 13.3          |
| Policy-TimeAlgoOpt      | 0.529         |
| Policy-TimeSampleProc   | 0.421         |
| Policy-TimeSampling     | 1.65          |
| Policy-TimeStep         | 2.62          |
| Time                    | 1.29e+03      |
| n_timesteps             | 45000         |
-------------------------------------------

 ---------------- Iteration 45 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 450 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 451 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 452 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 453 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 454 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 455 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 456 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 457 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 458 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 459 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.38          |
| Data-EnvSampler-Poli... | 0.758         |
| Data-EnvTrajs-Averag... | 27.1          |
| Data-EnvTrajs-MaxReturn | 28.4          |
| Data-EnvTrajs-MinReturn | 25.2          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.04          |
| Data-TimeEnvSampleProc  | 0.00135       |
| Data-TimeEnvSampling    | 1.17          |
| Iteration               | 45            |
| ItrTime                 | 38.7          |
| LossAfter               | -0.0035528694 |
| LossBefore              | -5.421207e-06 |
| Model-TimeModelFit      | 34.8          |
| ModelSampler-n_times... | 1840000       |
| Policy-AverageAbsPol... | 1.2630597     |
| Policy-AverageDiscou... | 24.7          |
| Policy-AveragePolicyStd | 0.42653516    |
| Policy-AverageReturn    | 28.1          |
| Policy-MaxReturn        | 35.2          |
| Policy-MinReturn        | 20.8          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 3.49          |
| Policy-TimeAlgoOpt      | 0.559         |
| Policy-TimeSampleProc   | 0.482         |
| Policy-TimeSampling     | 1.58          |
| Policy-TimeStep         | 2.66          |
| Time                    | 1.33e+03      |
| n_timesteps             | 46000         |
-------------------------------------------

 ---------------- Iteration 46 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 460 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 461 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 462 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 463 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 464 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 465 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 466 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 467 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 468 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 469 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.366          |
| Data-EnvSampler-Poli... | 0.773          |
| Data-EnvTrajs-Averag... | 31.2           |
| Data-EnvTrajs-MaxReturn | 34             |
| Data-EnvTrajs-MinReturn | 30.1           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.44           |
| Data-TimeEnvSampleProc  | 0.00118        |
| Data-TimeEnvSampling    | 1.17           |
| Iteration               | 46             |
| ItrTime                 | 37.8           |
| LossAfter               | -0.0015711242  |
| LossBefore              | -5.1042684e-06 |
| Model-TimeModelFit      | 33.7           |
| ModelSampler-n_times... | 1880000        |
| Policy-AverageAbsPol... | 1.1706507      |
| Policy-AverageDiscou... | 20.2           |
| Policy-AveragePolicyStd | 0.41428235     |
| Policy-AverageReturn    | 9.24           |
| Policy-MaxReturn        | 40.1           |
| Policy-MinReturn        | -20.4          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 18             |
| Policy-TimeAlgoOpt      | 0.511          |
| Policy-TimeSampleProc   | 0.484          |
| Policy-TimeSampling     | 1.79           |
| Policy-TimeStep         | 2.86           |
| Time                    | 1.37e+03       |
| n_timesteps             | 47000          |
--------------------------------------------

 ---------------- Iteration 47 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 470 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 471 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 472 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 473 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 474 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 475 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 476 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 477 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 478 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 479 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.383         |
| Data-EnvSampler-Poli... | 0.919         |
| Data-EnvTrajs-Averag... | 30.6          |
| Data-EnvTrajs-MaxReturn | 31            |
| Data-EnvTrajs-MinReturn | 30.1          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 0.321         |
| Data-TimeEnvSampleProc  | 0.00102       |
| Data-TimeEnvSampling    | 1.34          |
| Iteration               | 47            |
| ItrTime                 | 36.5          |
| LossAfter               | -0.0038253225 |
| LossBefore              | -4.973194e-06 |
| Model-TimeModelFit      | 32.9          |
| ModelSampler-n_times... | 1920000       |
| Policy-AverageAbsPol... | 1.3112159     |
| Policy-AverageDiscou... | 28.7          |
| Policy-AveragePolicyStd | 0.4089285     |
| Policy-AverageReturn    | 46.7          |
| Policy-MaxReturn        | 73.5          |
| Policy-MinReturn        | 36.7          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 9.23          |
| Policy-TimeAlgoOpt      | 0.522         |
| Policy-TimeSampleProc   | 0.386         |
| Policy-TimeSampling     | 1.36          |
| Policy-TimeStep         | 2.29          |
| Time                    | 1.4e+03       |
| n_timesteps             | 48000         |
-------------------------------------------

 ---------------- Iteration 48 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 480 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 481 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 482 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 483 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 484 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 485 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 486 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 487 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 488 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 489 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.341          |
| Data-EnvSampler-Poli... | 0.78           |
| Data-EnvTrajs-Averag... | 31             |
| Data-EnvTrajs-MaxReturn | 33.7           |
| Data-EnvTrajs-MinReturn | 29.3           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.64           |
| Data-TimeEnvSampleProc  | 0.000982       |
| Data-TimeEnvSampling    | 1.15           |
| Iteration               | 48             |
| ItrTime                 | 37.9           |
| LossAfter               | -0.0020048697  |
| LossBefore              | -5.0195654e-06 |
| Model-TimeModelFit      | 34.3           |
| ModelSampler-n_times... | 1960000        |
| Policy-AverageAbsPol... | 1.2337561      |
| Policy-AverageDiscou... | 27.1           |
| Policy-AveragePolicyStd | 0.41184        |
| Policy-AverageReturn    | 41.1           |
| Policy-MaxReturn        | 59.5           |
| Policy-MinReturn        | 31.5           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 7.36           |
| Policy-TimeAlgoOpt      | 0.548          |
| Policy-TimeSampleProc   | 0.376          |
| Policy-TimeSampling     | 1.4            |
| Policy-TimeStep         | 2.4            |
| Time                    | 1.44e+03       |
| n_timesteps             | 49000          |
--------------------------------------------

 ---------------- Iteration 49 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 490 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 491 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 492 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 493 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 494 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 495 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 496 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 497 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 498 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 499 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.403         |
| Data-EnvSampler-Poli... | 0.902         |
| Data-EnvTrajs-Averag... | 30.3          |
| Data-EnvTrajs-MaxReturn | 32.6          |
| Data-EnvTrajs-MinReturn | 26.7          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 2.16          |
| Data-TimeEnvSampleProc  | 0.00119       |
| Data-TimeEnvSampling    | 1.35          |
| Iteration               | 49            |
| ItrTime                 | 38.5          |
| LossAfter               | -0.004304026  |
| LossBefore              | -5.021938e-06 |
| Model-TimeModelFit      | 34.6          |
| ModelSampler-n_times... | 2000000       |
| Policy-AverageAbsPol... | 1.1201528     |
| Policy-AverageDiscou... | 26.1          |
| Policy-AveragePolicyStd | 0.4109635     |
| Policy-AverageReturn    | 42            |
| Policy-MaxReturn        | 51.4          |
| Policy-MinReturn        | 34.3          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 4.93          |
| Policy-TimeAlgoOpt      | 0.59          |
| Policy-TimeSampleProc   | 0.401         |
| Policy-TimeSampling     | 1.57          |
| Policy-TimeStep         | 2.59          |
| Time                    | 1.48e+03      |
| n_timesteps             | 50000         |
-------------------------------------------

 ---------------- Iteration 50 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 500 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 501 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 502 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 503 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 504 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 505 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 506 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 507 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 508 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 509 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.382          |
| Data-EnvSampler-Poli... | 0.874          |
| Data-EnvTrajs-Averag... | 31.5           |
| Data-EnvTrajs-MaxReturn | 32.6           |
| Data-EnvTrajs-MinReturn | 30.7           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 0.726          |
| Data-TimeEnvSampleProc  | 0.00104        |
| Data-TimeEnvSampling    | 1.3            |
| Iteration               | 50             |
| ItrTime                 | 36.7           |
| LossAfter               | -0.00063670747 |
| LossBefore              | -4.958648e-06  |
| Model-TimeModelFit      | 33.6           |
| ModelSampler-n_times... | 2040000        |
| Policy-AverageAbsPol... | 1.1890147      |
| Policy-AverageDiscou... | 30             |
| Policy-AveragePolicyStd | 0.40648395     |
| Policy-AverageReturn    | 51.3           |
| Policy-MaxReturn        | 60.8           |
| Policy-MinReturn        | 43.4           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 4.65           |
| Policy-TimeAlgoOpt      | 0.476          |
| Policy-TimeSampleProc   | 0.159          |
| Policy-TimeSampling     | 1.17           |
| Policy-TimeStep         | 1.81           |
| Time                    | 1.52e+03       |
| n_timesteps             | 51000          |
--------------------------------------------
Training finished
