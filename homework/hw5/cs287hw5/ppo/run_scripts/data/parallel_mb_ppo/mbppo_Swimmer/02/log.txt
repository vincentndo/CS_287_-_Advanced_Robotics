Logging to /home/vincent/workplace/CS_287_-_Advanced_Robotics/homework/hw5/cs287hw5/ppo/run_scripts/data/parallel_mb_ppo/mbppo_Swimmer//02

 ---------------- Iteration 0 ----------------
Obtaining random samples from the environment...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 0 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 1 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 2 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 3 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 4 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 5 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 6 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 7 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 8 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 9 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.139          |
| Data-EnvSampler-Poli... | 0.0427         |
| Data-EnvTrajs-Averag... | -1.28          |
| Data-EnvTrajs-MaxReturn | 4.39           |
| Data-EnvTrajs-MinReturn | -6.13          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 3.51           |
| Data-TimeEnvSampleProc  | 0.000521       |
| Data-TimeEnvSampling    | 0.193          |
| Iteration               | 0              |
| ItrTime                 | 9.85           |
| LossAfter               | -0.0038160675  |
| LossBefore              | -1.4081729e-05 |
| Model-TimeModelFit      | 3.34           |
| ModelSampler-n_times... | 40000          |
| Policy-AverageAbsPol... | 0.8659278      |
| Policy-AverageDiscou... | -354           |
| Policy-AveragePolicyStd | 0.9900629      |
| Policy-AverageReturn    | -1.35e+03      |
| Policy-MaxReturn        | -269           |
| Policy-MinReturn        | -3.01e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 868            |
| Policy-TimeAlgoOpt      | 1.14           |
| Policy-TimeSampleProc   | 0.57           |
| Policy-TimeSampling     | 4.55           |
| Policy-TimeStep         | 6.31           |
| Time                    | 9.85           |
| n_timesteps             | 1000           |
--------------------------------------------

 ---------------- Iteration 1 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 10 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 11 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 12 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 13 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 14 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 15 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 16 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 17 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 18 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 19 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.23           |
| Data-EnvSampler-Poli... | 0.522          |
| Data-EnvTrajs-Averag... | 3.84           |
| Data-EnvTrajs-MaxReturn | 24.9           |
| Data-EnvTrajs-MinReturn | -4.84          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 11.1           |
| Data-TimeEnvSampleProc  | 0.000791       |
| Data-TimeEnvSampling    | 0.774          |
| Iteration               | 1              |
| ItrTime                 | 8.1            |
| LossAfter               | -0.0055657155  |
| LossBefore              | -1.3968507e-05 |
| Model-TimeModelFit      | 4.69           |
| ModelSampler-n_times... | 80000          |
| Policy-AverageAbsPol... | 1.3801773      |
| Policy-AverageDiscou... | 4.97e+03       |
| Policy-AveragePolicyStd | 0.97808826     |
| Policy-AverageReturn    | 1.54e+04       |
| Policy-MaxReturn        | 1.59e+04       |
| Policy-MinReturn        | 1.36e+04       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 531            |
| Policy-TimeAlgoOpt      | 0.524          |
| Policy-TimeSampleProc   | 0.499          |
| Policy-TimeSampling     | 1.57           |
| Policy-TimeStep         | 2.63           |
| Time                    | 18.1           |
| n_timesteps             | 2000           |
--------------------------------------------

 ---------------- Iteration 2 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 20 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 21 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 22 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 23 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 24 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 25 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 26 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 27 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 28 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 29 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.245          |
| Data-EnvSampler-Poli... | 0.445          |
| Data-EnvTrajs-Averag... | -10.1          |
| Data-EnvTrajs-MaxReturn | -1.37          |
| Data-EnvTrajs-MinReturn | -15.8          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 4.88           |
| Data-TimeEnvSampleProc  | 0.000648       |
| Data-TimeEnvSampling    | 0.713          |
| Iteration               | 2              |
| ItrTime                 | 10.7           |
| LossAfter               | -0.00215999    |
| LossBefore              | -1.3790278e-05 |
| Model-TimeModelFit      | 7.31           |
| ModelSampler-n_times... | 120000         |
| Policy-AverageAbsPol... | 1.8331969      |
| Policy-AverageDiscou... | 2.93e+03       |
| Policy-AveragePolicyStd | 0.9610122      |
| Policy-AverageReturn    | 7.93e+03       |
| Policy-MaxReturn        | 8.11e+03       |
| Policy-MinReturn        | 7.69e+03       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 107            |
| Policy-TimeAlgoOpt      | 0.597          |
| Policy-TimeSampleProc   | 0.486          |
| Policy-TimeSampling     | 1.52           |
| Policy-TimeStep         | 2.63           |
| Time                    | 28.7           |
| n_timesteps             | 3000           |
--------------------------------------------

 ---------------- Iteration 3 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 30 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 31 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 32 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 33 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 34 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 35 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 36 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 37 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 38 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 39 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.242         |
| Data-EnvSampler-Poli... | 0.436         |
| Data-EnvTrajs-Averag... | -10.4         |
| Data-EnvTrajs-MaxReturn | -6.49         |
| Data-EnvTrajs-MinReturn | -16           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 3.91          |
| Data-TimeEnvSampleProc  | 0.000857      |
| Data-TimeEnvSampling    | 0.7           |
| Iteration               | 3             |
| ItrTime                 | 12.1          |
| LossAfter               | -0.006041211  |
| LossBefore              | -1.377705e-05 |
| Model-TimeModelFit      | 8.53          |
| ModelSampler-n_times... | 160000        |
| Policy-AverageAbsPol... | 1.9846543     |
| Policy-AverageDiscou... | 4.91e+03      |
| Policy-AveragePolicyStd | 0.9595048     |
| Policy-AverageReturn    | 1.53e+04      |
| Policy-MaxReturn        | 1.56e+04      |
| Policy-MinReturn        | 1.51e+04      |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 150           |
| Policy-TimeAlgoOpt      | 0.554         |
| Policy-TimeSampleProc   | 0.534         |
| Policy-TimeSampling     | 1.79          |
| Policy-TimeStep         | 2.92          |
| Time                    | 40.9          |
| n_timesteps             | 4000          |
-------------------------------------------

 ---------------- Iteration 4 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 40 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 41 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 42 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 43 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 44 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 45 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 46 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 47 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 48 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 49 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.255          |
| Data-EnvSampler-Poli... | 0.425          |
| Data-EnvTrajs-Averag... | -5.9           |
| Data-EnvTrajs-MaxReturn | 17             |
| Data-EnvTrajs-MinReturn | -12.4          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 11.5           |
| Data-TimeEnvSampleProc  | 0.000583       |
| Data-TimeEnvSampling    | 0.702          |
| Iteration               | 4              |
| ItrTime                 | 14.9           |
| LossAfter               | -0.004859538   |
| LossBefore              | -1.3752391e-05 |
| Model-TimeModelFit      | 11.6           |
| ModelSampler-n_times... | 200000         |
| Policy-AverageAbsPol... | 2.3518379      |
| Policy-AverageDiscou... | 4.89e+03       |
| Policy-AveragePolicyStd | 0.95710087     |
| Policy-AverageReturn    | 1.53e+04       |
| Policy-MaxReturn        | 1.57e+04       |
| Policy-MinReturn        | 1.47e+04       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 245            |
| Policy-TimeAlgoOpt      | 0.564          |
| Policy-TimeSampleProc   | 0.443          |
| Policy-TimeSampling     | 1.64           |
| Policy-TimeStep         | 2.67           |
| Time                    | 55.8           |
| n_timesteps             | 5000           |
--------------------------------------------

 ---------------- Iteration 5 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 50 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 51 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 52 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 53 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 54 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 55 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 56 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 57 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 58 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 59 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.268          |
| Data-EnvSampler-Poli... | 0.469          |
| Data-EnvTrajs-Averag... | -9.01          |
| Data-EnvTrajs-MaxReturn | -2.19          |
| Data-EnvTrajs-MinReturn | -13.2          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 4.01           |
| Data-TimeEnvSampleProc  | 0.000991       |
| Data-TimeEnvSampling    | 0.761          |
| Iteration               | 5              |
| ItrTime                 | 16.6           |
| LossAfter               | -0.0055413004  |
| LossBefore              | -1.3551381e-05 |
| Model-TimeModelFit      | 13.1           |
| ModelSampler-n_times... | 240000         |
| Policy-AverageAbsPol... | 2.5381005      |
| Policy-AverageDiscou... | 5.84e+03       |
| Policy-AveragePolicyStd | 0.94092363     |
| Policy-AverageReturn    | 1.67e+04       |
| Policy-MaxReturn        | 1.7e+04        |
| Policy-MinReturn        | 1.64e+04       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 131            |
| Policy-TimeAlgoOpt      | 0.57           |
| Policy-TimeSampleProc   | 0.472          |
| Policy-TimeSampling     | 1.64           |
| Policy-TimeStep         | 2.74           |
| Time                    | 72.5           |
| n_timesteps             | 6000           |
--------------------------------------------

 ---------------- Iteration 6 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 60 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 61 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 62 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 63 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 64 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 65 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 66 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 67 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 68 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 69 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.317          |
| Data-EnvSampler-Poli... | 0.565          |
| Data-EnvTrajs-Averag... | -9.56          |
| Data-EnvTrajs-MaxReturn | -5.85          |
| Data-EnvTrajs-MinReturn | -12.3          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.63           |
| Data-TimeEnvSampleProc  | 0.00105        |
| Data-TimeEnvSampling    | 0.91           |
| Iteration               | 6              |
| ItrTime                 | 18.5           |
| LossAfter               | -0.0035103804  |
| LossBefore              | -1.3550923e-05 |
| Model-TimeModelFit      | 15.1           |
| ModelSampler-n_times... | 280000         |
| Policy-AverageAbsPol... | 2.7376297      |
| Policy-AverageDiscou... | 5.34e+03       |
| Policy-AveragePolicyStd | 0.9415201      |
| Policy-AverageReturn    | 1.6e+04        |
| Policy-MaxReturn        | 1.63e+04       |
| Policy-MinReturn        | 1.56e+04       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 163            |
| Policy-TimeAlgoOpt      | 0.612          |
| Policy-TimeSampleProc   | 0.321          |
| Policy-TimeSampling     | 1.6            |
| Policy-TimeStep         | 2.54           |
| Time                    | 91             |
| n_timesteps             | 7000           |
--------------------------------------------

 ---------------- Iteration 7 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 70 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 71 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 72 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 73 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 74 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 75 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 76 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 77 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 78 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 79 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.321          |
| Data-EnvSampler-Poli... | 0.667          |
| Data-EnvTrajs-Averag... | -6.82          |
| Data-EnvTrajs-MaxReturn | -6.12          |
| Data-EnvTrajs-MinReturn | -7.3           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 0.507          |
| Data-TimeEnvSampleProc  | 0.000817       |
| Data-TimeEnvSampling    | 1.02           |
| Iteration               | 7              |
| ItrTime                 | 21.2           |
| LossAfter               | -0.0038374483  |
| LossBefore              | -1.3581904e-05 |
| Model-TimeModelFit      | 17.8           |
| ModelSampler-n_times... | 320000         |
| Policy-AverageAbsPol... | 3.1191394      |
| Policy-AverageDiscou... | 1.48e+03       |
| Policy-AveragePolicyStd | 0.9444241      |
| Policy-AverageReturn    | 6.57e+03       |
| Policy-MaxReturn        | 1.54e+04       |
| Policy-MinReturn        | -49.6          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 3.99e+03       |
| Policy-TimeAlgoOpt      | 0.471          |
| Policy-TimeSampleProc   | 0.554          |
| Policy-TimeSampling     | 1.34           |
| Policy-TimeStep         | 2.4            |
| Time                    | 112            |
| n_timesteps             | 8000           |
--------------------------------------------

 ---------------- Iteration 8 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 80 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 81 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 82 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 83 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 84 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 85 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 86 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 87 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 88 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 89 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.364          |
| Data-EnvSampler-Poli... | 0.712          |
| Data-EnvTrajs-Averag... | -6.61          |
| Data-EnvTrajs-MaxReturn | -5.52          |
| Data-EnvTrajs-MinReturn | -8.1           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.11           |
| Data-TimeEnvSampleProc  | 0.00109        |
| Data-TimeEnvSampling    | 1.11           |
| Iteration               | 8              |
| ItrTime                 | 23.7           |
| LossAfter               | -0.0053743566  |
| LossBefore              | -1.3553972e-05 |
| Model-TimeModelFit      | 20             |
| ModelSampler-n_times... | 360000         |
| Policy-AverageAbsPol... | 2.6452794      |
| Policy-AverageDiscou... | 5.07e+03       |
| Policy-AveragePolicyStd | 0.9463075      |
| Policy-AverageReturn    | 1.56e+04       |
| Policy-MaxReturn        | 1.58e+04       |
| Policy-MinReturn        | 1.53e+04       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 114            |
| Policy-TimeAlgoOpt      | 0.543          |
| Policy-TimeSampleProc   | 0.411          |
| Policy-TimeSampling     | 1.64           |
| Policy-TimeStep         | 2.63           |
| Time                    | 136            |
| n_timesteps             | 9000           |
--------------------------------------------

 ---------------- Iteration 9 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 90 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 91 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 92 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 93 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 94 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 95 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 96 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 97 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 98 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 99 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.391          |
| Data-EnvSampler-Poli... | 0.773          |
| Data-EnvTrajs-Averag... | -5.86          |
| Data-EnvTrajs-MaxReturn | -4.95          |
| Data-EnvTrajs-MinReturn | -6.83          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 0.817          |
| Data-TimeEnvSampleProc  | 0.00102        |
| Data-TimeEnvSampling    | 1.2            |
| Iteration               | 9              |
| ItrTime                 | 25.7           |
| LossAfter               | -0.0055637835  |
| LossBefore              | -1.3486063e-05 |
| Model-TimeModelFit      | 21.9           |
| ModelSampler-n_times... | 400000         |
| Policy-AverageAbsPol... | 2.879611       |
| Policy-AverageDiscou... | 5.24e+03       |
| Policy-AveragePolicyStd | 0.9391775      |
| Policy-AverageReturn    | 1.58e+04       |
| Policy-MaxReturn        | 1.6e+04        |
| Policy-MinReturn        | 1.56e+04       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 94.8           |
| Policy-TimeAlgoOpt      | 0.592          |
| Policy-TimeSampleProc   | 0.351          |
| Policy-TimeSampling     | 1.59           |
| Policy-TimeStep         | 2.57           |
| Time                    | 162            |
| n_timesteps             | 10000          |
--------------------------------------------

 ---------------- Iteration 10 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...
Stopping DynamicsEnsemble Training since valid_loss_rolling_average decreased

 ---------------- Grad-Step 100 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 101 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 102 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 103 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 104 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 105 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 106 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 107 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 108 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 109 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.339          |
| Data-EnvSampler-Poli... | 0.68           |
| Data-EnvTrajs-Averag... | -5.89          |
| Data-EnvTrajs-MaxReturn | -4.27          |
| Data-EnvTrajs-MinReturn | -7.67          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.36           |
| Data-TimeEnvSampleProc  | 0.000973       |
| Data-TimeEnvSampling    | 1.05           |
| Iteration               | 10             |
| ItrTime                 | 6.35           |
| LossAfter               | -0.0061617065  |
| LossBefore              | -1.3256708e-05 |
| Model-TimeModelFit      | 2.66           |
| ModelSampler-n_times... | 440000         |
| Policy-AverageAbsPol... | 2.7364714      |
| Policy-AverageDiscou... | 6.07e+03       |
| Policy-AveragePolicyStd | 0.9159333      |
| Policy-AverageReturn    | 1.7e+04        |
| Policy-MaxReturn        | 1.72e+04       |
| Policy-MinReturn        | 1.69e+04       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 73             |
| Policy-TimeAlgoOpt      | 0.636          |
| Policy-TimeSampleProc   | 0.311          |
| Policy-TimeSampling     | 1.67           |
| Policy-TimeStep         | 2.64           |
| Time                    | 168            |
| n_timesteps             | 11000          |
--------------------------------------------

 ---------------- Iteration 11 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 110 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 111 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 112 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 113 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 114 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 115 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 116 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 117 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 118 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 119 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.38           |
| Data-EnvSampler-Poli... | 0.86           |
| Data-EnvTrajs-Averag... | -5.24          |
| Data-EnvTrajs-MaxReturn | -3.84          |
| Data-EnvTrajs-MinReturn | -6.74          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 0.991          |
| Data-TimeEnvSampleProc  | 0.000866       |
| Data-TimeEnvSampling    | 1.28           |
| Iteration               | 11             |
| ItrTime                 | 31             |
| LossAfter               | -0.0044855326  |
| LossBefore              | -1.3105159e-05 |
| Model-TimeModelFit      | 27.1           |
| ModelSampler-n_times... | 480000         |
| Policy-AverageAbsPol... | 3.0455518      |
| Policy-AverageDiscou... | 4.65e+03       |
| Policy-AveragePolicyStd | 0.90128577     |
| Policy-AverageReturn    | 1.49e+04       |
| Policy-MaxReturn        | 1.54e+04       |
| Policy-MinReturn        | 1.35e+04       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 592            |
| Policy-TimeAlgoOpt      | 0.602          |
| Policy-TimeSampleProc   | 0.379          |
| Policy-TimeSampling     | 1.67           |
| Policy-TimeStep         | 2.68           |
| Time                    | 199            |
| n_timesteps             | 12000          |
--------------------------------------------

 ---------------- Iteration 12 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 120 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 121 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 122 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 123 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 124 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 125 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 126 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 127 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 128 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 129 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.415          |
| Data-EnvSampler-Poli... | 0.888          |
| Data-EnvTrajs-Averag... | -6.05          |
| Data-EnvTrajs-MaxReturn | -4             |
| Data-EnvTrajs-MinReturn | -7.53          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.17           |
| Data-TimeEnvSampleProc  | 0.00123        |
| Data-TimeEnvSampling    | 1.34           |
| Iteration               | 12             |
| ItrTime                 | 31.4           |
| LossAfter               | -0.0061295005  |
| LossBefore              | -1.2925286e-05 |
| Model-TimeModelFit      | 27.8           |
| ModelSampler-n_times... | 520000         |
| Policy-AverageAbsPol... | 3.219782       |
| Policy-AverageDiscou... | 5.4e+03        |
| Policy-AveragePolicyStd | 0.887218       |
| Policy-AverageReturn    | 1.61e+04       |
| Policy-MaxReturn        | 1.63e+04       |
| Policy-MinReturn        | 1.57e+04       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 136            |
| Policy-TimeAlgoOpt      | 0.513          |
| Policy-TimeSampleProc   | 0.254          |
| Policy-TimeSampling     | 1.47           |
| Policy-TimeStep         | 2.26           |
| Time                    | 231            |
| n_timesteps             | 13000          |
--------------------------------------------

 ---------------- Iteration 13 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 130 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 131 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 132 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 133 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 134 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 135 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 136 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 137 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 138 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 139 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.421          |
| Data-EnvSampler-Poli... | 0.894          |
| Data-EnvTrajs-Averag... | -6             |
| Data-EnvTrajs-MaxReturn | -5.4           |
| Data-EnvTrajs-MinReturn | -6.42          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 0.343          |
| Data-TimeEnvSampleProc  | 0.000659       |
| Data-TimeEnvSampling    | 1.36           |
| Iteration               | 13             |
| ItrTime                 | 31.3           |
| LossAfter               | -0.0060799513  |
| LossBefore              | -1.2751758e-05 |
| Model-TimeModelFit      | 27.5           |
| ModelSampler-n_times... | 560000         |
| Policy-AverageAbsPol... | 2.6017187      |
| Policy-AverageDiscou... | 3.49e+03       |
| Policy-AveragePolicyStd | 0.8708833      |
| Policy-AverageReturn    | 1.28e+04       |
| Policy-MaxReturn        | 1.34e+04       |
| Policy-MinReturn        | 1.25e+04       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 172            |
| Policy-TimeAlgoOpt      | 0.569          |
| Policy-TimeSampleProc   | 0.298          |
| Policy-TimeSampling     | 1.52           |
| Policy-TimeStep         | 2.4            |
| Time                    | 262            |
| n_timesteps             | 14000          |
--------------------------------------------

 ---------------- Iteration 14 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 140 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 141 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 142 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 143 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 144 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 145 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 146 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 147 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 148 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 149 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.412          |
| Data-EnvSampler-Poli... | 0.928          |
| Data-EnvTrajs-Averag... | -5.51          |
| Data-EnvTrajs-MaxReturn | -4.5           |
| Data-EnvTrajs-MinReturn | -5.95          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 0.534          |
| Data-TimeEnvSampleProc  | 0.00125        |
| Data-TimeEnvSampling    | 1.39           |
| Iteration               | 14             |
| ItrTime                 | 32.4           |
| LossAfter               | -0.0034956506  |
| LossBefore              | -1.2691574e-05 |
| Model-TimeModelFit      | 28.7           |
| ModelSampler-n_times... | 600000         |
| Policy-AverageAbsPol... | 3.17455        |
| Policy-AverageDiscou... | 728            |
| Policy-AveragePolicyStd | 0.86534727     |
| Policy-AverageReturn    | 3.06e+03       |
| Policy-MaxReturn        | 7.41e+03       |
| Policy-MinReturn        | -540           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 3.02e+03       |
| Policy-TimeAlgoOpt      | 0.53           |
| Policy-TimeSampleProc   | 0.383          |
| Policy-TimeSampling     | 1.46           |
| Policy-TimeStep         | 2.39           |
| Time                    | 294            |
| n_timesteps             | 15000          |
--------------------------------------------

 ---------------- Iteration 15 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 150 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 151 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 152 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 153 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 154 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 155 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 156 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 157 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 158 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 159 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.478          |
| Data-EnvSampler-Poli... | 1.08           |
| Data-EnvTrajs-Averag... | -5.48          |
| Data-EnvTrajs-MaxReturn | -5.08          |
| Data-EnvTrajs-MinReturn | -6.01          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 0.371          |
| Data-TimeEnvSampleProc  | 0.000593       |
| Data-TimeEnvSampling    | 1.6            |
| Iteration               | 15             |
| ItrTime                 | 32.9           |
| LossAfter               | -0.008959254   |
| LossBefore              | -1.2648418e-05 |
| Model-TimeModelFit      | 28.8           |
| ModelSampler-n_times... | 640000         |
| Policy-AverageAbsPol... | 5.008696       |
| Policy-AverageDiscou... | 3.57e+03       |
| Policy-AveragePolicyStd | 0.85982513     |
| Policy-AverageReturn    | 1.07e+04       |
| Policy-MaxReturn        | 1.13e+04       |
| Policy-MinReturn        | 1.03e+04       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 247            |
| Policy-TimeAlgoOpt      | 0.575          |
| Policy-TimeSampleProc   | 0.444          |
| Policy-TimeSampling     | 1.52           |
| Policy-TimeStep         | 2.56           |
| Time                    | 327            |
| n_timesteps             | 16000          |
--------------------------------------------

 ---------------- Iteration 16 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 160 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 161 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 162 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 163 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 164 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 165 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 166 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 167 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 168 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 169 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.43           |
| Data-EnvSampler-Poli... | 0.923          |
| Data-EnvTrajs-Averag... | -5.41          |
| Data-EnvTrajs-MaxReturn | -4.87          |
| Data-EnvTrajs-MinReturn | -6.41          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 0.583          |
| Data-TimeEnvSampleProc  | 0.000992       |
| Data-TimeEnvSampling    | 1.39           |
| Iteration               | 16             |
| ItrTime                 | 32.1           |
| LossAfter               | -0.0031057717  |
| LossBefore              | -1.2578875e-05 |
| Model-TimeModelFit      | 28.3           |
| ModelSampler-n_times... | 680000         |
| Policy-AverageAbsPol... | 4.393862       |
| Policy-AverageDiscou... | 4.99e+03       |
| Policy-AveragePolicyStd | 0.85479504     |
| Policy-AverageReturn    | 1.54e+04       |
| Policy-MaxReturn        | 1.69e+04       |
| Policy-MinReturn        | 1.37e+04       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 937            |
| Policy-TimeAlgoOpt      | 0.523          |
| Policy-TimeSampleProc   | 0.392          |
| Policy-TimeSampling     | 1.44           |
| Policy-TimeStep         | 2.43           |
| Time                    | 359            |
| n_timesteps             | 17000          |
--------------------------------------------

 ---------------- Iteration 17 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 170 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 171 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 172 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 173 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 174 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 175 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 176 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 177 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 178 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 179 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.461          |
| Data-EnvSampler-Poli... | 1.01           |
| Data-EnvTrajs-Averag... | -5.23          |
| Data-EnvTrajs-MaxReturn | -4.59          |
| Data-EnvTrajs-MinReturn | -5.73          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 0.38           |
| Data-TimeEnvSampleProc  | 0.000684       |
| Data-TimeEnvSampling    | 1.52           |
| Iteration               | 17             |
| ItrTime                 | 33.1           |
| LossAfter               | -0.0053957487  |
| LossBefore              | -1.2501747e-05 |
| Model-TimeModelFit      | 28.8           |
| ModelSampler-n_times... | 720000         |
| Policy-AverageAbsPol... | 3.720701       |
| Policy-AverageDiscou... | 3.33e+03       |
| Policy-AveragePolicyStd | 0.84749025     |
| Policy-AverageReturn    | 1.23e+04       |
| Policy-MaxReturn        | 1.39e+04       |
| Policy-MinReturn        | 9.2e+03        |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.3e+03        |
| Policy-TimeAlgoOpt      | 0.565          |
| Policy-TimeSampleProc   | 0.528          |
| Policy-TimeSampling     | 1.64           |
| Policy-TimeStep         | 2.77           |
| Time                    | 392            |
| n_timesteps             | 18000          |
--------------------------------------------

 ---------------- Iteration 18 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 180 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 181 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 182 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 183 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 184 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 185 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 186 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 187 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 188 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 189 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.448          |
| Data-EnvSampler-Poli... | 1.07           |
| Data-EnvTrajs-Averag... | -5.26          |
| Data-EnvTrajs-MaxReturn | -4.65          |
| Data-EnvTrajs-MinReturn | -5.81          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 0.421          |
| Data-TimeEnvSampleProc  | 0.00104        |
| Data-TimeEnvSampling    | 1.57           |
| Iteration               | 18             |
| ItrTime                 | 32.7           |
| LossAfter               | -0.0030825436  |
| LossBefore              | -1.2543629e-05 |
| Model-TimeModelFit      | 28.3           |
| ModelSampler-n_times... | 760000         |
| Policy-AverageAbsPol... | 2.2801034      |
| Policy-AverageDiscou... | 4.27e+03       |
| Policy-AveragePolicyStd | 0.85019535     |
| Policy-AverageReturn    | 1.41e+04       |
| Policy-MaxReturn        | 1.53e+04       |
| Policy-MinReturn        | 8.79e+03       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.91e+03       |
| Policy-TimeAlgoOpt      | 0.598          |
| Policy-TimeSampleProc   | 0.41           |
| Policy-TimeSampling     | 1.73           |
| Policy-TimeStep         | 2.8            |
| Time                    | 425            |
| n_timesteps             | 19000          |
--------------------------------------------

 ---------------- Iteration 19 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...
Stopping DynamicsEnsemble Training since valid_loss_rolling_average decreased

 ---------------- Grad-Step 190 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 191 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 192 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 193 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 194 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 195 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 196 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 197 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 198 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 199 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.475          |
| Data-EnvSampler-Poli... | 1.04           |
| Data-EnvTrajs-Averag... | -6.16          |
| Data-EnvTrajs-MaxReturn | -4.83          |
| Data-EnvTrajs-MinReturn | -8.02          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.1            |
| Data-TimeEnvSampleProc  | 0.00114        |
| Data-TimeEnvSampling    | 1.56           |
| Iteration               | 19             |
| ItrTime                 | 25.7           |
| LossAfter               | -0.0055731684  |
| LossBefore              | -1.2311058e-05 |
| Model-TimeModelFit      | 21.8           |
| ModelSampler-n_times... | 800000         |
| Policy-AverageAbsPol... | 2.6123888      |
| Policy-AverageDiscou... | 4.2e+03        |
| Policy-AveragePolicyStd | 0.8299756      |
| Policy-AverageReturn    | 1.37e+04       |
| Policy-MaxReturn        | 1.42e+04       |
| Policy-MinReturn        | 1.26e+04       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 337            |
| Policy-TimeAlgoOpt      | 0.553          |
| Policy-TimeSampleProc   | 0.317          |
| Policy-TimeSampling     | 1.44           |
| Policy-TimeStep         | 2.34           |
| Time                    | 451            |
| n_timesteps             | 20000          |
--------------------------------------------

 ---------------- Iteration 20 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...
Stopping DynamicsEnsemble Training since valid_loss_rolling_average decreased

 ---------------- Grad-Step 200 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 201 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 202 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 203 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 204 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 205 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 206 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 207 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 208 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 209 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.455          |
| Data-EnvSampler-Poli... | 0.973          |
| Data-EnvTrajs-Averag... | -5.16          |
| Data-EnvTrajs-MaxReturn | -3.56          |
| Data-EnvTrajs-MinReturn | -7.62          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.42           |
| Data-TimeEnvSampleProc  | 0.00126        |
| Data-TimeEnvSampling    | 1.5            |
| Iteration               | 20             |
| ItrTime                 | 27.9           |
| LossAfter               | -0.010675461   |
| LossBefore              | -1.2308794e-05 |
| Model-TimeModelFit      | 23.9           |
| ModelSampler-n_times... | 840000         |
| Policy-AverageAbsPol... | 2.5183427      |
| Policy-AverageDiscou... | 4.54e+03       |
| Policy-AveragePolicyStd | 0.83092743     |
| Policy-AverageReturn    | 1.43e+04       |
| Policy-MaxReturn        | 1.45e+04       |
| Policy-MinReturn        | 1.39e+04       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 196            |
| Policy-TimeAlgoOpt      | 0.553          |
| Policy-TimeSampleProc   | 0.388          |
| Policy-TimeSampling     | 1.5            |
| Policy-TimeStep         | 2.48           |
| Time                    | 479            |
| n_timesteps             | 21000          |
--------------------------------------------

 ---------------- Iteration 21 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 210 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 211 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 212 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 213 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 214 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 215 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 216 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 217 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 218 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 219 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.404           |
| Data-EnvSampler-Poli... | 0.95            |
| Data-EnvTrajs-Averag... | -6.61           |
| Data-EnvTrajs-MaxReturn | -4.45           |
| Data-EnvTrajs-MinReturn | -7.95           |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 1.24            |
| Data-TimeEnvSampleProc  | 0.000958        |
| Data-TimeEnvSampling    | 1.39            |
| Iteration               | 21              |
| ItrTime                 | 33.2            |
| LossAfter               | -0.0069948495   |
| LossBefore              | -1.22090105e-05 |
| Model-TimeModelFit      | 29.1            |
| ModelSampler-n_times... | 880000          |
| Policy-AverageAbsPol... | 3.264516        |
| Policy-AverageDiscou... | 4.84e+03        |
| Policy-AveragePolicyStd | 0.8213698       |
| Policy-AverageReturn    | 1.51e+04        |
| Policy-MaxReturn        | 1.54e+04        |
| Policy-MinReturn        | 1.48e+04        |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 160             |
| Policy-TimeAlgoOpt      | 0.608           |
| Policy-TimeSampleProc   | 0.407           |
| Policy-TimeSampling     | 1.65            |
| Policy-TimeStep         | 2.7             |
| Time                    | 512             |
| n_timesteps             | 22000           |
---------------------------------------------

 ---------------- Iteration 22 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 220 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 221 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 222 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 223 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 224 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 225 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 226 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 227 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 228 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 229 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.435          |
| Data-EnvSampler-Poli... | 1.03           |
| Data-EnvTrajs-Averag... | -12.4          |
| Data-EnvTrajs-MaxReturn | -6.74          |
| Data-EnvTrajs-MinReturn | -19.9          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 4.61           |
| Data-TimeEnvSampleProc  | 0.00107        |
| Data-TimeEnvSampling    | 1.51           |
| Iteration               | 22             |
| ItrTime                 | 33.9           |
| LossAfter               | -0.0073170466  |
| LossBefore              | -1.2122448e-05 |
| Model-TimeModelFit      | 29.7           |
| ModelSampler-n_times... | 920000         |
| Policy-AverageAbsPol... | 2.6781294      |
| Policy-AverageDiscou... | 5.8e+03        |
| Policy-AveragePolicyStd | 0.81568605     |
| Policy-AverageReturn    | 1.65e+04       |
| Policy-MaxReturn        | 1.82e+04       |
| Policy-MinReturn        | 1.47e+04       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.41e+03       |
| Policy-TimeAlgoOpt      | 0.574          |
| Policy-TimeSampleProc   | 0.446          |
| Policy-TimeSampling     | 1.62           |
| Policy-TimeStep         | 2.67           |
| Time                    | 546            |
| n_timesteps             | 23000          |
--------------------------------------------

 ---------------- Iteration 23 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 230 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 231 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 232 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 233 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 234 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 235 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 236 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 237 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 238 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 239 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.408          |
| Data-EnvSampler-Poli... | 0.88           |
| Data-EnvTrajs-Averag... | -3.31          |
| Data-EnvTrajs-MaxReturn | 15.9           |
| Data-EnvTrajs-MinReturn | -23.1          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 14.5           |
| Data-TimeEnvSampleProc  | 0.000991       |
| Data-TimeEnvSampling    | 1.32           |
| Iteration               | 23             |
| ItrTime                 | 32.4           |
| LossAfter               | -0.004956863   |
| LossBefore              | -1.2061103e-05 |
| Model-TimeModelFit      | 28.2           |
| ModelSampler-n_times... | 960000         |
| Policy-AverageAbsPol... | 3.8345547      |
| Policy-AverageDiscou... | 3.67e+03       |
| Policy-AveragePolicyStd | 0.81076086     |
| Policy-AverageReturn    | 1.22e+04       |
| Policy-MaxReturn        | 1.41e+04       |
| Policy-MinReturn        | 8.36e+03       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.46e+03       |
| Policy-TimeAlgoOpt      | 0.614          |
| Policy-TimeSampleProc   | 0.496          |
| Policy-TimeSampling     | 1.7            |
| Policy-TimeStep         | 2.86           |
| Time                    | 578            |
| n_timesteps             | 24000          |
--------------------------------------------

 ---------------- Iteration 24 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 240 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 241 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 242 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 243 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 244 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 245 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 246 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 247 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 248 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 249 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.435          |
| Data-EnvSampler-Poli... | 0.909          |
| Data-EnvTrajs-Averag... | -11.4          |
| Data-EnvTrajs-MaxReturn | 23.6           |
| Data-EnvTrajs-MinReturn | -21.8          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 17.5           |
| Data-TimeEnvSampleProc  | 0.00055        |
| Data-TimeEnvSampling    | 1.38           |
| Iteration               | 24             |
| ItrTime                 | 34             |
| LossAfter               | -0.0066095716  |
| LossBefore              | -1.1944995e-05 |
| Model-TimeModelFit      | 29.9           |
| ModelSampler-n_times... | 1000000        |
| Policy-AverageAbsPol... | 3.8011482      |
| Policy-AverageDiscou... | 1.99e+03       |
| Policy-AveragePolicyStd | 0.80373526     |
| Policy-AverageReturn    | 7.19e+03       |
| Policy-MaxReturn        | 9.49e+03       |
| Policy-MinReturn        | 1.07e+03       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.87e+03       |
| Policy-TimeAlgoOpt      | 0.534          |
| Policy-TimeSampleProc   | 0.55           |
| Policy-TimeSampling     | 1.56           |
| Policy-TimeStep         | 2.7            |
| Time                    | 612            |
| n_timesteps             | 25000          |
--------------------------------------------

 ---------------- Iteration 25 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 250 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 251 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 252 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 253 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 254 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 255 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 256 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 257 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 258 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 259 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.448           |
| Data-EnvSampler-Poli... | 1.01            |
| Data-EnvTrajs-Averag... | 5.51            |
| Data-EnvTrajs-MaxReturn | 16.4            |
| Data-EnvTrajs-MinReturn | -21.3           |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 13.7            |
| Data-TimeEnvSampleProc  | 0.000636        |
| Data-TimeEnvSampling    | 1.5             |
| Iteration               | 25              |
| ItrTime                 | 33.3            |
| LossAfter               | -0.006624313    |
| LossBefore              | -1.17217205e-05 |
| Model-TimeModelFit      | 29              |
| ModelSampler-n_times... | 1040000         |
| Policy-AverageAbsPol... | 4.4394064       |
| Policy-AverageDiscou... | 1.68e+03        |
| Policy-AveragePolicyStd | 0.78475803      |
| Policy-AverageReturn    | 5.03e+03        |
| Policy-MaxReturn        | 7.43e+03        |
| Policy-MinReturn        | 1.73e+03        |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 1.33e+03        |
| Policy-TimeAlgoOpt      | 0.583           |
| Policy-TimeSampleProc   | 0.449           |
| Policy-TimeSampling     | 1.67            |
| Policy-TimeStep         | 2.76            |
| Time                    | 645             |
| n_timesteps             | 26000           |
---------------------------------------------

 ---------------- Iteration 26 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 260 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 261 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 262 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 263 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 264 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 265 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 266 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 267 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 268 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 269 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.433         |
| Data-EnvSampler-Poli... | 0.93          |
| Data-EnvTrajs-Averag... | -8.32         |
| Data-EnvTrajs-MaxReturn | 7.92          |
| Data-EnvTrajs-MinReturn | -19.5         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 11.6          |
| Data-TimeEnvSampleProc  | 0.00112       |
| Data-TimeEnvSampling    | 1.41          |
| Iteration               | 26            |
| ItrTime                 | 34.4          |
| LossAfter               | -0.004896721  |
| LossBefore              | -1.164458e-05 |
| Model-TimeModelFit      | 30            |
| ModelSampler-n_times... | 1080000       |
| Policy-AverageAbsPol... | 2.8549695     |
| Policy-AverageDiscou... | 4.94e+03      |
| Policy-AveragePolicyStd | 0.7786875     |
| Policy-AverageReturn    | 1.5e+04       |
| Policy-MaxReturn        | 1.63e+04      |
| Policy-MinReturn        | 9.77e+03      |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.48e+03      |
| Policy-TimeAlgoOpt      | 0.635         |
| Policy-TimeSampleProc   | 0.424         |
| Policy-TimeSampling     | 1.84          |
| Policy-TimeStep         | 2.93          |
| Time                    | 680           |
| n_timesteps             | 27000         |
-------------------------------------------

 ---------------- Iteration 27 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 270 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 271 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 272 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 273 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 274 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 275 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 276 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 277 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 278 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 279 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.451          |
| Data-EnvSampler-Poli... | 1.06           |
| Data-EnvTrajs-Averag... | 5.77           |
| Data-EnvTrajs-MaxReturn | 16.2           |
| Data-EnvTrajs-MinReturn | -20.9          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 13.6           |
| Data-TimeEnvSampleProc  | 0.000923       |
| Data-TimeEnvSampling    | 1.54           |
| Iteration               | 27             |
| ItrTime                 | 33.3           |
| LossAfter               | -0.0049713366  |
| LossBefore              | -1.1593651e-05 |
| Model-TimeModelFit      | 29.1           |
| ModelSampler-n_times... | 1120000        |
| Policy-AverageAbsPol... | 4.6769238      |
| Policy-AverageDiscou... | 5.03e+03       |
| Policy-AveragePolicyStd | 0.7762893      |
| Policy-AverageReturn    | 1.46e+04       |
| Policy-MaxReturn        | 1.53e+04       |
| Policy-MinReturn        | 1.01e+04       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.09e+03       |
| Policy-TimeAlgoOpt      | 0.583          |
| Policy-TimeSampleProc   | 0.413          |
| Policy-TimeSampling     | 1.58           |
| Policy-TimeStep         | 2.61           |
| Time                    | 713            |
| n_timesteps             | 28000          |
--------------------------------------------

 ---------------- Iteration 28 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 280 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 281 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 282 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 283 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 284 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 285 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 286 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 287 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 288 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 289 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.414           |
| Data-EnvSampler-Poli... | 0.937           |
| Data-EnvTrajs-Averag... | 15.6            |
| Data-EnvTrajs-MaxReturn | 23.6            |
| Data-EnvTrajs-MinReturn | 7.45            |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 6.72            |
| Data-TimeEnvSampleProc  | 0.00104         |
| Data-TimeEnvSampling    | 1.39            |
| Iteration               | 28              |
| ItrTime                 | 34.2            |
| LossAfter               | -0.0038148172   |
| LossBefore              | -1.15106395e-05 |
| Model-TimeModelFit      | 30.3            |
| ModelSampler-n_times... | 1160000         |
| Policy-AverageAbsPol... | 4.699301        |
| Policy-AverageDiscou... | 4.05e+03        |
| Policy-AveragePolicyStd | 0.77132505      |
| Policy-AverageReturn    | 1.32e+04        |
| Policy-MaxReturn        | 1.52e+04        |
| Policy-MinReturn        | 1.08e+04        |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 1.84e+03        |
| Policy-TimeAlgoOpt      | 0.582           |
| Policy-TimeSampleProc   | 0.419           |
| Policy-TimeSampling     | 1.52            |
| Policy-TimeStep         | 2.54            |
| Time                    | 747             |
| n_timesteps             | 29000           |
---------------------------------------------

 ---------------- Iteration 29 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 290 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 291 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 292 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 293 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 294 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 295 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 296 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 297 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 298 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 299 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.37          |
| Data-EnvSampler-Poli... | 0.84          |
| Data-EnvTrajs-Averag... | 11.1          |
| Data-EnvTrajs-MaxReturn | 13.4          |
| Data-EnvTrajs-MinReturn | 4.02          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 3.54          |
| Data-TimeEnvSampleProc  | 0.000618      |
| Data-TimeEnvSampling    | 1.25          |
| Iteration               | 29            |
| ItrTime                 | 34.4          |
| LossAfter               | -0.0053461804 |
| LossBefore              | -1.138977e-05 |
| Model-TimeModelFit      | 30.1          |
| ModelSampler-n_times... | 1200000       |
| Policy-AverageAbsPol... | 5.0260696     |
| Policy-AverageDiscou... | 5.68e+03      |
| Policy-AveragePolicyStd | 0.76423216    |
| Policy-AverageReturn    | 1.65e+04      |
| Policy-MaxReturn        | 1.69e+04      |
| Policy-MinReturn        | 1.59e+04      |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 251           |
| Policy-TimeAlgoOpt      | 0.602         |
| Policy-TimeSampleProc   | 0.534         |
| Policy-TimeSampling     | 1.89          |
| Policy-TimeStep         | 3.07          |
| Time                    | 782           |
| n_timesteps             | 30000         |
-------------------------------------------

 ---------------- Iteration 30 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 300 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 301 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 302 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 303 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 304 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 305 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 306 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 307 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 308 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 309 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.439          |
| Data-EnvSampler-Poli... | 0.99           |
| Data-EnvTrajs-Averag... | 11.2           |
| Data-EnvTrajs-MaxReturn | 13.9           |
| Data-EnvTrajs-MinReturn | 7.19           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.79           |
| Data-TimeEnvSampleProc  | 0.00107        |
| Data-TimeEnvSampling    | 1.46           |
| Iteration               | 30             |
| ItrTime                 | 34.6           |
| LossAfter               | -0.004538068   |
| LossBefore              | -1.1299193e-05 |
| Model-TimeModelFit      | 30.7           |
| ModelSampler-n_times... | 1240000        |
| Policy-AverageAbsPol... | 5.221624       |
| Policy-AverageDiscou... | 4.07e+03       |
| Policy-AveragePolicyStd | 0.7564817      |
| Policy-AverageReturn    | 1.31e+04       |
| Policy-MaxReturn        | 1.55e+04       |
| Policy-MinReturn        | 308            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 3.48e+03       |
| Policy-TimeAlgoOpt      | 0.556          |
| Policy-TimeSampleProc   | 0.352          |
| Policy-TimeSampling     | 1.53           |
| Policy-TimeStep         | 2.46           |
| Time                    | 816            |
| n_timesteps             | 31000          |
--------------------------------------------

 ---------------- Iteration 31 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 310 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 311 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 312 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 313 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 314 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 315 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 316 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 317 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 318 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 319 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.431          |
| Data-EnvSampler-Poli... | 0.89           |
| Data-EnvTrajs-Averag... | 14.7           |
| Data-EnvTrajs-MaxReturn | 17.7           |
| Data-EnvTrajs-MinReturn | 10.8           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.66           |
| Data-TimeEnvSampleProc  | 0.0011         |
| Data-TimeEnvSampling    | 1.37           |
| Iteration               | 31             |
| ItrTime                 | 34.1           |
| LossAfter               | -0.0049999948  |
| LossBefore              | -1.1270258e-05 |
| Model-TimeModelFit      | 30.2           |
| ModelSampler-n_times... | 1280000        |
| Policy-AverageAbsPol... | 5.1138797      |
| Policy-AverageDiscou... | 6.32e+03       |
| Policy-AveragePolicyStd | 0.7527207      |
| Policy-AverageReturn    | 1.73e+04       |
| Policy-MaxReturn        | 1.75e+04       |
| Policy-MinReturn        | 1.72e+04       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 73.8           |
| Policy-TimeAlgoOpt      | 0.562          |
| Policy-TimeSampleProc   | 0.336          |
| Policy-TimeSampling     | 1.61           |
| Policy-TimeStep         | 2.54           |
| Time                    | 851            |
| n_timesteps             | 32000          |
--------------------------------------------

 ---------------- Iteration 32 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 320 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 321 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 322 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 323 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 324 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 325 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 326 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 327 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 328 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 329 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.388          |
| Data-EnvSampler-Poli... | 0.899          |
| Data-EnvTrajs-Averag... | 17.6           |
| Data-EnvTrajs-MaxReturn | 20.6           |
| Data-EnvTrajs-MinReturn | 14.7           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.05           |
| Data-TimeEnvSampleProc  | 0.000994       |
| Data-TimeEnvSampling    | 1.32           |
| Iteration               | 32             |
| ItrTime                 | 35.1           |
| LossAfter               | -0.0025060587  |
| LossBefore              | -1.0969946e-05 |
| Model-TimeModelFit      | 31.4           |
| ModelSampler-n_times... | 1320000        |
| Policy-AverageAbsPol... | 6.9396944      |
| Policy-AverageDiscou... | 193            |
| Policy-AveragePolicyStd | 0.7312183      |
| Policy-AverageReturn    | 670            |
| Policy-MaxReturn        | 6.94e+03       |
| Policy-MinReturn        | 323            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.44e+03       |
| Policy-TimeAlgoOpt      | 0.546          |
| Policy-TimeSampleProc   | 0.383          |
| Policy-TimeSampling     | 1.5            |
| Policy-TimeStep         | 2.46           |
| Time                    | 886            |
| n_timesteps             | 33000          |
--------------------------------------------

 ---------------- Iteration 33 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 330 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 331 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 332 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 333 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 334 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 335 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 336 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 337 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 338 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 339 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.404          |
| Data-EnvSampler-Poli... | 0.956          |
| Data-EnvTrajs-Averag... | 15.6           |
| Data-EnvTrajs-MaxReturn | 16.6           |
| Data-EnvTrajs-MinReturn | 14.4           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 0.835          |
| Data-TimeEnvSampleProc  | 0.000908       |
| Data-TimeEnvSampling    | 1.4            |
| Iteration               | 33             |
| ItrTime                 | 35.6           |
| LossAfter               | -0.0022718434  |
| LossBefore              | -1.0754773e-05 |
| Model-TimeModelFit      | 31.3           |
| ModelSampler-n_times... | 1360000        |
| Policy-AverageAbsPol... | 3.2575445      |
| Policy-AverageDiscou... | 6.28e+03       |
| Policy-AveragePolicyStd | 0.71550465     |
| Policy-AverageReturn    | 1.73e+04       |
| Policy-MaxReturn        | 1.74e+04       |
| Policy-MinReturn        | 1.71e+04       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 82.1           |
| Policy-TimeAlgoOpt      | 0.556          |
| Policy-TimeSampleProc   | 0.56           |
| Policy-TimeSampling     | 1.75           |
| Policy-TimeStep         | 2.92           |
| Time                    | 921            |
| n_timesteps             | 34000          |
--------------------------------------------

 ---------------- Iteration 34 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 340 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 341 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 342 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 343 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 344 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 345 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 346 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 347 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 348 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 349 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.385          |
| Data-EnvSampler-Poli... | 0.85           |
| Data-EnvTrajs-Averag... | 14.2           |
| Data-EnvTrajs-MaxReturn | 21.8           |
| Data-EnvTrajs-MinReturn | 6.64           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 5.18           |
| Data-TimeEnvSampleProc  | 0.000952       |
| Data-TimeEnvSampling    | 1.27           |
| Iteration               | 34             |
| ItrTime                 | 34.8           |
| LossAfter               | -0.00469926    |
| LossBefore              | -1.0581564e-05 |
| Model-TimeModelFit      | 30.8           |
| ModelSampler-n_times... | 1400000        |
| Policy-AverageAbsPol... | 2.4109035      |
| Policy-AverageDiscou... | 6.42e+03       |
| Policy-AveragePolicyStd | 0.7040814      |
| Policy-AverageReturn    | 1.75e+04       |
| Policy-MaxReturn        | 1.77e+04       |
| Policy-MinReturn        | 1.72e+04       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 105            |
| Policy-TimeAlgoOpt      | 0.567          |
| Policy-TimeSampleProc   | 0.469          |
| Policy-TimeSampling     | 1.66           |
| Policy-TimeStep         | 2.72           |
| Time                    | 956            |
| n_timesteps             | 35000          |
--------------------------------------------

 ---------------- Iteration 35 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 350 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 351 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 352 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 353 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 354 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 355 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 356 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 357 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 358 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 359 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.414          |
| Data-EnvSampler-Poli... | 0.999          |
| Data-EnvTrajs-Averag... | 11.9           |
| Data-EnvTrajs-MaxReturn | 19.4           |
| Data-EnvTrajs-MinReturn | 5.76           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 5.82           |
| Data-TimeEnvSampleProc  | 0.00125        |
| Data-TimeEnvSampling    | 1.45           |
| Iteration               | 35             |
| ItrTime                 | 35.4           |
| LossAfter               | -0.0018557752  |
| LossBefore              | -1.0424593e-05 |
| Model-TimeModelFit      | 31.1           |
| ModelSampler-n_times... | 1440000        |
| Policy-AverageAbsPol... | 7.6012897      |
| Policy-AverageDiscou... | 115            |
| Policy-AveragePolicyStd | 0.6941525      |
| Policy-AverageReturn    | 306            |
| Policy-MaxReturn        | 332            |
| Policy-MinReturn        | 280            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 13.1           |
| Policy-TimeAlgoOpt      | 0.612          |
| Policy-TimeSampleProc   | 0.413          |
| Policy-TimeSampling     | 1.75           |
| Policy-TimeStep         | 2.81           |
| Time                    | 991            |
| n_timesteps             | 36000          |
--------------------------------------------

 ---------------- Iteration 36 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 360 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 361 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 362 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 363 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 364 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 365 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 366 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 367 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 368 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 369 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.42           |
| Data-EnvSampler-Poli... | 0.935          |
| Data-EnvTrajs-Averag... | 16.1           |
| Data-EnvTrajs-MaxReturn | 19.3           |
| Data-EnvTrajs-MinReturn | 10.2           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 3.06           |
| Data-TimeEnvSampleProc  | 0.00104        |
| Data-TimeEnvSampling    | 1.39           |
| Iteration               | 36             |
| ItrTime                 | 35.8           |
| LossAfter               | -0.0018980554  |
| LossBefore              | -1.0322559e-05 |
| Model-TimeModelFit      | 31.7           |
| ModelSampler-n_times... | 1480000        |
| Policy-AverageAbsPol... | 6.045235       |
| Policy-AverageDiscou... | 2e+03          |
| Policy-AveragePolicyStd | 0.6864613      |
| Policy-AverageReturn    | 5.99e+03       |
| Policy-MaxReturn        | 1.73e+04       |
| Policy-MinReturn        | 226            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 7.45e+03       |
| Policy-TimeAlgoOpt      | 0.579          |
| Policy-TimeSampleProc   | 0.418          |
| Policy-TimeSampling     | 1.61           |
| Policy-TimeStep         | 2.63           |
| Time                    | 1.03e+03       |
| n_timesteps             | 37000          |
--------------------------------------------

 ---------------- Iteration 37 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 370 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 371 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 372 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 373 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 374 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 375 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 376 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 377 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 378 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 379 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.404          |
| Data-EnvSampler-Poli... | 0.859          |
| Data-EnvTrajs-Averag... | 15.9           |
| Data-EnvTrajs-MaxReturn | 19.1           |
| Data-EnvTrajs-MinReturn | 14             |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.94           |
| Data-TimeEnvSampleProc  | 0.00106        |
| Data-TimeEnvSampling    | 1.3            |
| Iteration               | 37             |
| ItrTime                 | 35.2           |
| LossAfter               | -0.0014926259  |
| LossBefore              | -1.0435645e-05 |
| Model-TimeModelFit      | 31.2           |
| ModelSampler-n_times... | 1520000        |
| Policy-AverageAbsPol... | 3.614899       |
| Policy-AverageDiscou... | 4.48e+03       |
| Policy-AveragePolicyStd | 0.69609857     |
| Policy-AverageReturn    | 1.31e+04       |
| Policy-MaxReturn        | 1.71e+04       |
| Policy-MinReturn        | 192            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 6.52e+03       |
| Policy-TimeAlgoOpt      | 0.57           |
| Policy-TimeSampleProc   | 0.371          |
| Policy-TimeSampling     | 1.74           |
| Policy-TimeStep         | 2.72           |
| Time                    | 1.06e+03       |
| n_timesteps             | 38000          |
--------------------------------------------

 ---------------- Iteration 38 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 380 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 381 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 382 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 383 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 384 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 385 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 386 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 387 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 388 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 389 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.452          |
| Data-EnvSampler-Poli... | 0.989          |
| Data-EnvTrajs-Averag... | 14.4           |
| Data-EnvTrajs-MaxReturn | 20.6           |
| Data-EnvTrajs-MinReturn | 10.3           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 3.72           |
| Data-TimeEnvSampleProc  | 0.00167        |
| Data-TimeEnvSampling    | 1.48           |
| Iteration               | 38             |
| ItrTime                 | 35.6           |
| LossAfter               | -0.0034060995  |
| LossBefore              | -1.0371273e-05 |
| Model-TimeModelFit      | 30.8           |
| ModelSampler-n_times... | 1560000        |
| Policy-AverageAbsPol... | 6.6348114      |
| Policy-AverageDiscou... | 733            |
| Policy-AveragePolicyStd | 0.69273657     |
| Policy-AverageReturn    | 2.31e+03       |
| Policy-MaxReturn        | 1.68e+04       |
| Policy-MinReturn        | 115            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 5.17e+03       |
| Policy-TimeAlgoOpt      | 0.621          |
| Policy-TimeSampleProc   | 0.649          |
| Policy-TimeSampling     | 1.96           |
| Policy-TimeStep         | 3.29           |
| Time                    | 1.1e+03        |
| n_timesteps             | 39000          |
--------------------------------------------

 ---------------- Iteration 39 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...
Stopping DynamicsEnsemble Training since valid_loss_rolling_average decreased

 ---------------- Grad-Step 390 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 391 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 392 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 393 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 394 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 395 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 396 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 397 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 398 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 399 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.431          |
| Data-EnvSampler-Poli... | 0.964          |
| Data-EnvTrajs-Averag... | 15             |
| Data-EnvTrajs-MaxReturn | 21             |
| Data-EnvTrajs-MinReturn | 9.95           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 4.14           |
| Data-TimeEnvSampleProc  | 0.00105        |
| Data-TimeEnvSampling    | 1.43           |
| Iteration               | 39             |
| ItrTime                 | 31.3           |
| LossAfter               | -0.0019225614  |
| LossBefore              | -1.0235714e-05 |
| Model-TimeModelFit      | 27.2           |
| ModelSampler-n_times... | 1600000        |
| Policy-AverageAbsPol... | 6.5250254      |
| Policy-AverageDiscou... | 668            |
| Policy-AveragePolicyStd | 0.68089        |
| Policy-AverageReturn    | 2.77e+03       |
| Policy-MaxReturn        | 1.37e+04       |
| Policy-MinReturn        | 158            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 4.13e+03       |
| Policy-TimeAlgoOpt      | 0.548          |
| Policy-TimeSampleProc   | 0.47           |
| Policy-TimeSampling     | 1.61           |
| Policy-TimeStep         | 2.66           |
| Time                    | 1.13e+03       |
| n_timesteps             | 40000          |
--------------------------------------------

 ---------------- Iteration 40 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 400 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 401 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 402 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 403 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 404 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 405 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 406 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 407 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 408 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 409 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.452          |
| Data-EnvSampler-Poli... | 0.991          |
| Data-EnvTrajs-Averag... | 12.1           |
| Data-EnvTrajs-MaxReturn | 16.2           |
| Data-EnvTrajs-MinReturn | 9.48           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.58           |
| Data-TimeEnvSampleProc  | 0.00105        |
| Data-TimeEnvSampling    | 1.49           |
| Iteration               | 40             |
| ItrTime                 | 36.5           |
| LossAfter               | -0.001517796   |
| LossBefore              | -1.0230793e-05 |
| Model-TimeModelFit      | 32.5           |
| ModelSampler-n_times... | 1640000        |
| Policy-AverageAbsPol... | 6.1589026      |
| Policy-AverageDiscou... | -1.4e+03       |
| Policy-AveragePolicyStd | 0.6823297      |
| Policy-AverageReturn    | -4.02e+03      |
| Policy-MaxReturn        | 204            |
| Policy-MinReturn        | -1.73e+04      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 7.28e+03       |
| Policy-TimeAlgoOpt      | 0.577          |
| Policy-TimeSampleProc   | 0.341          |
| Policy-TimeSampling     | 1.58           |
| Policy-TimeStep         | 2.51           |
| Time                    | 1.17e+03       |
| n_timesteps             | 41000          |
--------------------------------------------

 ---------------- Iteration 41 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 410 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 411 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 412 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 413 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 414 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 415 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 416 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 417 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 418 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 419 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.445         |
| Data-EnvSampler-Poli... | 1.05          |
| Data-EnvTrajs-Averag... | 16            |
| Data-EnvTrajs-MaxReturn | 21.4          |
| Data-EnvTrajs-MinReturn | 11.2          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 3.33          |
| Data-TimeEnvSampleProc  | 0.000664      |
| Data-TimeEnvSampling    | 1.54          |
| Iteration               | 41            |
| ItrTime                 | 35            |
| LossAfter               | -0.0029415665 |
| LossBefore              | -1.003508e-05 |
| Model-TimeModelFit      | 30.7          |
| ModelSampler-n_times... | 1680000       |
| Policy-AverageAbsPol... | 7.377638      |
| Policy-AverageDiscou... | 72.9          |
| Policy-AveragePolicyStd | 0.6710291     |
| Policy-AverageReturn    | 172           |
| Policy-MaxReturn        | 271           |
| Policy-MinReturn        | 151           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 34.6          |
| Policy-TimeAlgoOpt      | 0.593         |
| Policy-TimeSampleProc   | 0.368         |
| Policy-TimeSampling     | 1.82          |
| Policy-TimeStep         | 2.81          |
| Time                    | 1.2e+03       |
| n_timesteps             | 42000         |
-------------------------------------------

 ---------------- Iteration 42 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...
Stopping DynamicsEnsemble Training since valid_loss_rolling_average decreased

 ---------------- Grad-Step 420 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 421 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 422 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 423 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 424 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 425 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 426 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 427 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 428 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 429 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.396         |
| Data-EnvSampler-Poli... | 0.914         |
| Data-EnvTrajs-Averag... | 13.1          |
| Data-EnvTrajs-MaxReturn | 17.8          |
| Data-EnvTrajs-MinReturn | 5.82          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 3.95          |
| Data-TimeEnvSampleProc  | 0.000845      |
| Data-TimeEnvSampling    | 1.34          |
| Iteration               | 42            |
| ItrTime                 | 28.8          |
| LossAfter               | -0.0016805565 |
| LossBefore              | -9.802427e-06 |
| Model-TimeModelFit      | 25            |
| ModelSampler-n_times... | 1720000       |
| Policy-AverageAbsPol... | 3.5837648     |
| Policy-AverageDiscou... | -5.25e+03     |
| Policy-AveragePolicyStd | 0.65542334    |
| Policy-AverageReturn    | -1.46e+04     |
| Policy-MaxReturn        | 144           |
| Policy-MinReturn        | -1.75e+04     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 6.18e+03      |
| Policy-TimeAlgoOpt      | 0.567         |
| Policy-TimeSampleProc   | 0.322         |
| Policy-TimeSampling     | 1.54          |
| Policy-TimeStep         | 2.46          |
| Time                    | 1.23e+03      |
| n_timesteps             | 43000         |
-------------------------------------------

 ---------------- Iteration 43 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...
Stopping DynamicsEnsemble Training since valid_loss_rolling_average decreased

 ---------------- Grad-Step 430 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 431 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 432 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 433 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 434 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 435 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 436 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 437 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 438 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 439 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.4            |
| Data-EnvSampler-Poli... | 0.92           |
| Data-EnvTrajs-Averag... | 17.1           |
| Data-EnvTrajs-MaxReturn | 23.6           |
| Data-EnvTrajs-MinReturn | 11.2           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 4.53           |
| Data-TimeEnvSampleProc  | 0.000751       |
| Data-TimeEnvSampling    | 1.36           |
| Iteration               | 43             |
| ItrTime                 | 28.1           |
| LossAfter               | -0.0013955693  |
| LossBefore              | -9.7438415e-06 |
| Model-TimeModelFit      | 24.1           |
| ModelSampler-n_times... | 1760000        |
| Policy-AverageAbsPol... | 5.4201217      |
| Policy-AverageDiscou... | -2.51e+03      |
| Policy-AveragePolicyStd | 0.6530193      |
| Policy-AverageReturn    | -7.63e+03      |
| Policy-MaxReturn        | 239            |
| Policy-MinReturn        | -1.72e+04      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 7.85e+03       |
| Policy-TimeAlgoOpt      | 0.601          |
| Policy-TimeSampleProc   | 0.39           |
| Policy-TimeSampling     | 1.62           |
| Policy-TimeStep         | 2.63           |
| Time                    | 1.26e+03       |
| n_timesteps             | 44000          |
--------------------------------------------

 ---------------- Iteration 44 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 440 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 441 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 442 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 443 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 444 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 445 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 446 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 447 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 448 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 449 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.432         |
| Data-EnvSampler-Poli... | 0.925         |
| Data-EnvTrajs-Averag... | 13.3          |
| Data-EnvTrajs-MaxReturn | 18.1          |
| Data-EnvTrajs-MinReturn | 8.49          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 3.98          |
| Data-TimeEnvSampleProc  | 0.00104       |
| Data-TimeEnvSampling    | 1.39          |
| Iteration               | 44            |
| ItrTime                 | 37            |
| LossAfter               | -0.0010933293 |
| LossBefore              | -9.512969e-06 |
| Model-TimeModelFit      | 32.4          |
| ModelSampler-n_times... | 1800000       |
| Policy-AverageAbsPol... | 5.6689696     |
| Policy-AverageDiscou... | -2.18e+03     |
| Policy-AveragePolicyStd | 0.6387655     |
| Policy-AverageReturn    | -6.48e+03     |
| Policy-MaxReturn        | 215           |
| Policy-MinReturn        | -1.72e+04     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 7.9e+03       |
| Policy-TimeAlgoOpt      | 0.604         |
| Policy-TimeSampleProc   | 0.634         |
| Policy-TimeSampling     | 1.96          |
| Policy-TimeStep         | 3.23          |
| Time                    | 1.29e+03      |
| n_timesteps             | 45000         |
-------------------------------------------

 ---------------- Iteration 45 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 450 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 451 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 452 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 453 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 454 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 455 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 456 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 457 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 458 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 459 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.469         |
| Data-EnvSampler-Poli... | 1.13          |
| Data-EnvTrajs-Averag... | 14.1          |
| Data-EnvTrajs-MaxReturn | 18.2          |
| Data-EnvTrajs-MinReturn | 9.03          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 3.41          |
| Data-TimeEnvSampleProc  | 0.00105       |
| Data-TimeEnvSampling    | 1.64          |
| Iteration               | 45            |
| ItrTime                 | 37.8          |
| LossAfter               | -0.0032689383 |
| LossBefore              | -9.505126e-06 |
| Model-TimeModelFit      | 33.3          |
| ModelSampler-n_times... | 1840000       |
| Policy-AverageAbsPol... | 3.168677      |
| Policy-AverageDiscou... | -5.79e+03     |
| Policy-AveragePolicyStd | 0.6376697     |
| Policy-AverageReturn    | -1.64e+04     |
| Policy-MaxReturn        | -6.78e+03     |
| Policy-MinReturn        | -1.74e+04     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 2.33e+03      |
| Policy-TimeAlgoOpt      | 0.564         |
| Policy-TimeSampleProc   | 0.561         |
| Policy-TimeSampling     | 1.66          |
| Policy-TimeStep         | 2.81          |
| Time                    | 1.33e+03      |
| n_timesteps             | 46000         |
-------------------------------------------

 ---------------- Iteration 46 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...
Stopping DynamicsEnsemble Training since valid_loss_rolling_average decreased

 ---------------- Grad-Step 460 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 461 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 462 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 463 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 464 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 465 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 466 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 467 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 468 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 469 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.404         |
| Data-EnvSampler-Poli... | 0.889         |
| Data-EnvTrajs-Averag... | 11.6          |
| Data-EnvTrajs-MaxReturn | 14.5          |
| Data-EnvTrajs-MinReturn | 4.9           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 3.5           |
| Data-TimeEnvSampleProc  | 0.00103       |
| Data-TimeEnvSampling    | 1.34          |
| Iteration               | 46            |
| ItrTime                 | 32.5          |
| LossAfter               | -0.0027899293 |
| LossBefore              | -9.490034e-06 |
| Model-TimeModelFit      | 27.5          |
| ModelSampler-n_times... | 1880000       |
| Policy-AverageAbsPol... | 5.945669      |
| Policy-AverageDiscou... | -1.96e+03     |
| Policy-AveragePolicyStd | 0.6413418     |
| Policy-AverageReturn    | -6.23e+03     |
| Policy-MaxReturn        | 196           |
| Policy-MinReturn        | -1.71e+04     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 7.45e+03      |
| Policy-TimeAlgoOpt      | 0.722         |
| Policy-TimeSampleProc   | 0.737         |
| Policy-TimeSampling     | 2.17          |
| Policy-TimeStep         | 3.7           |
| Time                    | 1.37e+03      |
| n_timesteps             | 47000         |
-------------------------------------------

 ---------------- Iteration 47 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 470 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 471 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 472 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 473 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 474 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 475 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 476 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 477 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 478 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 479 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.521          |
| Data-EnvSampler-Poli... | 1.05           |
| Data-EnvTrajs-Averag... | 9.65           |
| Data-EnvTrajs-MaxReturn | 12.5           |
| Data-EnvTrajs-MinReturn | 8.16           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.65           |
| Data-TimeEnvSampleProc  | 0.00124        |
| Data-TimeEnvSampling    | 1.61           |
| Iteration               | 47             |
| ItrTime                 | 37.2           |
| LossAfter               | -0.0005127514  |
| LossBefore              | -9.5594605e-06 |
| Model-TimeModelFit      | 32.8           |
| ModelSampler-n_times... | 1920000        |
| Policy-AverageAbsPol... | 3.6057026      |
| Policy-AverageDiscou... | -5.28e+03      |
| Policy-AveragePolicyStd | 0.64536643     |
| Policy-AverageReturn    | -1.48e+04      |
| Policy-MaxReturn        | 101            |
| Policy-MinReturn        | -1.74e+04      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 5.8e+03        |
| Policy-TimeAlgoOpt      | 0.569          |
| Policy-TimeSampleProc   | 0.635          |
| Policy-TimeSampling     | 1.58           |
| Policy-TimeStep         | 2.83           |
| Time                    | 1.4e+03        |
| n_timesteps             | 48000          |
--------------------------------------------

 ---------------- Iteration 48 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 480 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 481 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 482 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 483 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 484 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 485 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 486 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 487 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 488 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 489 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.32          |
| Data-EnvSampler-Poli... | 0.617         |
| Data-EnvTrajs-Averag... | 12.5          |
| Data-EnvTrajs-MaxReturn | 18            |
| Data-EnvTrajs-MinReturn | 5.54          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 4.46          |
| Data-TimeEnvSampleProc  | 0.000866      |
| Data-TimeEnvSampling    | 0.963         |
| Iteration               | 48            |
| ItrTime                 | 37.7          |
| LossAfter               | -0.0016667785 |
| LossBefore              | -9.406695e-06 |
| Model-TimeModelFit      | 33.9          |
| ModelSampler-n_times... | 1960000       |
| Policy-AverageAbsPol... | 3.4465473     |
| Policy-AverageDiscou... | -5.06e+03     |
| Policy-AveragePolicyStd | 0.6358577     |
| Policy-AverageReturn    | -1.53e+04     |
| Policy-MaxReturn        | -9.62e+03     |
| Policy-MinReturn        | -1.72e+04     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 2.23e+03      |
| Policy-TimeAlgoOpt      | 0.583         |
| Policy-TimeSampleProc   | 0.462         |
| Policy-TimeSampling     | 1.73          |
| Policy-TimeStep         | 2.84          |
| Time                    | 1.44e+03      |
| n_timesteps             | 49000         |
-------------------------------------------

 ---------------- Iteration 49 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...
Stopping DynamicsEnsemble Training since valid_loss_rolling_average decreased

 ---------------- Grad-Step 490 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 491 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 492 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 493 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 494 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 495 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 496 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 497 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 498 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 499 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.399         |
| Data-EnvSampler-Poli... | 0.802         |
| Data-EnvTrajs-Averag... | 17.8          |
| Data-EnvTrajs-MaxReturn | 19.9          |
| Data-EnvTrajs-MinReturn | 14.9          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 2.13          |
| Data-TimeEnvSampleProc  | 0.0011        |
| Data-TimeEnvSampling    | 1.24          |
| Iteration               | 49            |
| ItrTime                 | 34.7          |
| LossAfter               | -0.0015267472 |
| LossBefore              | -9.302253e-06 |
| Model-TimeModelFit      | 30.5          |
| ModelSampler-n_times... | 2000000       |
| Policy-AverageAbsPol... | 3.104939      |
| Policy-AverageDiscou... | -5.86e+03     |
| Policy-AveragePolicyStd | 0.63113064    |
| Policy-AverageReturn    | -1.66e+04     |
| Policy-MaxReturn        | -8.38e+03     |
| Policy-MinReturn        | -1.73e+04     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.9e+03       |
| Policy-TimeAlgoOpt      | 0.573         |
| Policy-TimeSampleProc   | 0.623         |
| Policy-TimeSampling     | 1.78          |
| Policy-TimeStep         | 3.01          |
| Time                    | 1.47e+03      |
| n_timesteps             | 50000         |
-------------------------------------------

 ---------------- Iteration 50 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 500 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 501 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 502 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 503 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 504 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 505 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 506 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 507 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 508 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 509 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.456         |
| Data-EnvSampler-Poli... | 0.966         |
| Data-EnvTrajs-Averag... | 13.7          |
| Data-EnvTrajs-MaxReturn | 18            |
| Data-EnvTrajs-MinReturn | 6.49          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 4.04          |
| Data-TimeEnvSampleProc  | 0.00107       |
| Data-TimeEnvSampling    | 1.47          |
| Iteration               | 50            |
| ItrTime                 | 38            |
| LossAfter               | -0.0030135673 |
| LossBefore              | -9.18391e-06  |
| Model-TimeModelFit      | 33.9          |
| ModelSampler-n_times... | 2040000       |
| Policy-AverageAbsPol... | 4.4227214     |
| Policy-AverageDiscou... | -3.71e+03     |
| Policy-AveragePolicyStd | 0.62409854    |
| Policy-AverageReturn    | -1.12e+04     |
| Policy-MaxReturn        | 90            |
| Policy-MinReturn        | -1.73e+04     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 7.07e+03      |
| Policy-TimeAlgoOpt      | 0.567         |
| Policy-TimeSampleProc   | 0.453         |
| Policy-TimeSampling     | 1.56          |
| Policy-TimeStep         | 2.62          |
| Time                    | 1.51e+03      |
| n_timesteps             | 51000         |
-------------------------------------------
Training finished
