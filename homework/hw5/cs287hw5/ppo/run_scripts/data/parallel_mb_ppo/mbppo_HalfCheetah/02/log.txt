Logging to /home/vincent/workplace/CS_287_-_Advanced_Robotics/homework/hw5/cs287hw5/ppo/run_scripts/data/parallel_mb_ppo/mbppo_HalfCheetah//02

 ---------------- Iteration 0 ----------------
Obtaining random samples from the environment...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 0 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 1 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 2 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 3 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 4 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 5 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 6 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 7 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 8 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 9 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.122          |
| Data-EnvSampler-Poli... | 0.0372         |
| Data-EnvTrajs-Averag... | -71            |
| Data-EnvTrajs-MaxReturn | -46.2          |
| Data-EnvTrajs-MinReturn | -112           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 23.5           |
| Data-TimeEnvSampleProc  | 0.000505       |
| Data-TimeEnvSampling    | 0.17           |
| Iteration               | 0              |
| ItrTime                 | 8.41           |
| LossAfter               | -0.015101434   |
| LossBefore              | -1.3962102e-05 |
| Model-TimeModelFit      | 2.79           |
| ModelSampler-n_times... | 40000          |
| Policy-AverageAbsPol... | 0.63610184     |
| Policy-AverageDiscou... | -183           |
| Policy-AveragePolicyStd | 0.97893        |
| Policy-AverageReturn    | -447           |
| Policy-MaxReturn        | -362           |
| Policy-MinReturn        | -724           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 75.5           |
| Policy-TimeAlgoOpt      | 0.959          |
| Policy-TimeSampleProc   | 0.358          |
| Policy-TimeSampling     | 4.07           |
| Policy-TimeStep         | 5.44           |
| Time                    | 8.41           |
| n_timesteps             | 1000           |
--------------------------------------------

 ---------------- Iteration 1 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 10 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 11 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 12 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 13 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 14 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 15 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 16 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 17 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 18 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 19 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.223          |
| Data-EnvSampler-Poli... | 0.595          |
| Data-EnvTrajs-Averag... | -62.9          |
| Data-EnvTrajs-MaxReturn | 52.2           |
| Data-EnvTrajs-MinReturn | -135           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 64             |
| Data-TimeEnvSampleProc  | 0.000744       |
| Data-TimeEnvSampling    | 0.842          |
| Iteration               | 1              |
| ItrTime                 | 8.06           |
| LossAfter               | -0.013846304   |
| LossBefore              | -1.3675004e-05 |
| Model-TimeModelFit      | 4.23           |
| ModelSampler-n_times... | 80000          |
| Policy-AverageAbsPol... | 0.5290202      |
| Policy-AverageDiscou... | -68.2          |
| Policy-AveragePolicyStd | 0.9500433      |
| Policy-AverageReturn    | -171           |
| Policy-MaxReturn        | -125           |
| Policy-MinReturn        | -302           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 47.8           |
| Policy-TimeAlgoOpt      | 0.637          |
| Policy-TimeSampleProc   | 0.537          |
| Policy-TimeSampling     | 1.75           |
| Policy-TimeStep         | 2.99           |
| Time                    | 16.6           |
| n_timesteps             | 2000           |
--------------------------------------------

 ---------------- Iteration 2 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 20 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 21 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 22 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 23 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 24 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 25 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 26 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 27 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 28 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 29 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.275          |
| Data-EnvSampler-Poli... | 0.539          |
| Data-EnvTrajs-Averag... | -61.3          |
| Data-EnvTrajs-MaxReturn | -38.8          |
| Data-EnvTrajs-MinReturn | -95            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 21.4           |
| Data-TimeEnvSampleProc  | 0.00107        |
| Data-TimeEnvSampling    | 0.838          |
| Iteration               | 2              |
| ItrTime                 | 10.3           |
| LossAfter               | -0.0152259255  |
| LossBefore              | -1.3194066e-05 |
| Model-TimeModelFit      | 6.55           |
| ModelSampler-n_times... | 120000         |
| Policy-AverageAbsPol... | 0.48268783     |
| Policy-AverageDiscou... | -87.2          |
| Policy-AveragePolicyStd | 0.9054484      |
| Policy-AverageReturn    | -205           |
| Policy-MaxReturn        | -160           |
| Policy-MinReturn        | -244           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 24.5           |
| Policy-TimeAlgoOpt      | 0.687          |
| Policy-TimeSampleProc   | 0.388          |
| Policy-TimeSampling     | 1.74           |
| Policy-TimeStep         | 2.86           |
| Time                    | 26.9           |
| n_timesteps             | 3000           |
--------------------------------------------

 ---------------- Iteration 3 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 30 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 31 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 32 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 33 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 34 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 35 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 36 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 37 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 38 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 39 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.268          |
| Data-EnvSampler-Poli... | 0.539          |
| Data-EnvTrajs-Averag... | -59.3          |
| Data-EnvTrajs-MaxReturn | -20.9          |
| Data-EnvTrajs-MinReturn | -128           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 38.8           |
| Data-TimeEnvSampleProc  | 0.000743       |
| Data-TimeEnvSampling    | 0.834          |
| Iteration               | 3              |
| ItrTime                 | 12.8           |
| LossAfter               | -0.014313027   |
| LossBefore              | -1.2774855e-05 |
| Model-TimeModelFit      | 8.99           |
| ModelSampler-n_times... | 160000         |
| Policy-AverageAbsPol... | 0.41520894     |
| Policy-AverageDiscou... | 30.6           |
| Policy-AveragePolicyStd | 0.86841327     |
| Policy-AverageReturn    | 75.5           |
| Policy-MaxReturn        | 112            |
| Policy-MinReturn        | 50.1           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 15.3           |
| Policy-TimeAlgoOpt      | 0.618          |
| Policy-TimeSampleProc   | 0.518          |
| Policy-TimeSampling     | 1.82           |
| Policy-TimeStep         | 3              |
| Time                    | 39.7           |
| n_timesteps             | 4000           |
--------------------------------------------

 ---------------- Iteration 4 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 40 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 41 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 42 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 43 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 44 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 45 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 46 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 47 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 48 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 49 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.262         |
| Data-EnvSampler-Poli... | 0.507         |
| Data-EnvTrajs-Averag... | -13.5         |
| Data-EnvTrajs-MaxReturn | 61.3          |
| Data-EnvTrajs-MinReturn | -82.2         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 52.5          |
| Data-TimeEnvSampleProc  | 0.000965      |
| Data-TimeEnvSampling    | 0.796         |
| Iteration               | 4             |
| ItrTime                 | 14.5          |
| LossAfter               | -0.015702989  |
| LossBefore              | -1.246428e-05 |
| Model-TimeModelFit      | 11            |
| ModelSampler-n_times... | 200000        |
| Policy-AverageAbsPol... | 0.49351802    |
| Policy-AverageDiscou... | 91.6          |
| Policy-AveragePolicyStd | 0.8425336     |
| Policy-AverageReturn    | 230           |
| Policy-MaxReturn        | 290           |
| Policy-MinReturn        | 167           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 27.5          |
| Policy-TimeAlgoOpt      | 0.671         |
| Policy-TimeSampleProc   | 0.404         |
| Policy-TimeSampling     | 1.54          |
| Policy-TimeStep         | 2.65          |
| Time                    | 54.2          |
| n_timesteps             | 5000          |
-------------------------------------------

 ---------------- Iteration 5 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 50 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 51 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 52 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 53 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 54 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 55 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 56 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 57 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 58 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 59 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.282          |
| Data-EnvSampler-Poli... | 0.576          |
| Data-EnvTrajs-Averag... | -92            |
| Data-EnvTrajs-MaxReturn | -37.9          |
| Data-EnvTrajs-MinReturn | -154           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 44.4           |
| Data-TimeEnvSampleProc  | 0.00067        |
| Data-TimeEnvSampling    | 0.89           |
| Iteration               | 5              |
| ItrTime                 | 16.5           |
| LossAfter               | -0.015016433   |
| LossBefore              | -1.2185355e-05 |
| Model-TimeModelFit      | 13.2           |
| ModelSampler-n_times... | 240000         |
| Policy-AverageAbsPol... | 0.5005744      |
| Policy-AverageDiscou... | 33             |
| Policy-AveragePolicyStd | 0.81805503     |
| Policy-AverageReturn    | 86.4           |
| Policy-MaxReturn        | 138            |
| Policy-MinReturn        | 12.4           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 29.7           |
| Policy-TimeAlgoOpt      | 0.565          |
| Policy-TimeSampleProc   | 0.343          |
| Policy-TimeSampling     | 1.54           |
| Policy-TimeStep         | 2.48           |
| Time                    | 70.7           |
| n_timesteps             | 6000           |
--------------------------------------------

 ---------------- Iteration 6 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 60 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 61 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 62 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 63 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 64 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 65 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 66 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 67 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 68 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 69 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.292          |
| Data-EnvSampler-Poli... | 0.627          |
| Data-EnvTrajs-Averag... | -53.7          |
| Data-EnvTrajs-MaxReturn | -2.99          |
| Data-EnvTrajs-MinReturn | -89.8          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 28.2           |
| Data-TimeEnvSampleProc  | 0.000759       |
| Data-TimeEnvSampling    | 0.95           |
| Iteration               | 6              |
| ItrTime                 | 19.5           |
| LossAfter               | -0.014618357   |
| LossBefore              | -1.1886876e-05 |
| Model-TimeModelFit      | 15.9           |
| ModelSampler-n_times... | 280000         |
| Policy-AverageAbsPol... | 0.47240332     |
| Policy-AverageDiscou... | 10.2           |
| Policy-AveragePolicyStd | 0.7947209      |
| Policy-AverageReturn    | 33.4           |
| Policy-MaxReturn        | 79.1           |
| Policy-MinReturn        | -22.5          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 28.9           |
| Policy-TimeAlgoOpt      | 0.57           |
| Policy-TimeSampleProc   | 0.61           |
| Policy-TimeSampling     | 1.37           |
| Policy-TimeStep         | 2.58           |
| Time                    | 90.2           |
| n_timesteps             | 7000           |
--------------------------------------------

 ---------------- Iteration 7 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 70 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 71 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 72 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 73 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 74 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 75 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 76 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 77 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 78 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 79 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.41           |
| Data-EnvSampler-Poli... | 0.922          |
| Data-EnvTrajs-Averag... | -53.7          |
| Data-EnvTrajs-MaxReturn | -22.3          |
| Data-EnvTrajs-MinReturn | -107           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 34.8           |
| Data-TimeEnvSampleProc  | 0.000908       |
| Data-TimeEnvSampling    | 1.38           |
| Iteration               | 7              |
| ItrTime                 | 21.8           |
| LossAfter               | -0.016119177   |
| LossBefore              | -1.1586938e-05 |
| Model-TimeModelFit      | 17.7           |
| ModelSampler-n_times... | 320000         |
| Policy-AverageAbsPol... | 0.46809623     |
| Policy-AverageDiscou... | -37.9          |
| Policy-AveragePolicyStd | 0.76969564     |
| Policy-AverageReturn    | -84.6          |
| Policy-MaxReturn        | -6.47          |
| Policy-MinReturn        | -186           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 39.7           |
| Policy-TimeAlgoOpt      | 0.573          |
| Policy-TimeSampleProc   | 0.528          |
| Policy-TimeSampling     | 1.53           |
| Policy-TimeStep         | 2.67           |
| Time                    | 112            |
| n_timesteps             | 8000           |
--------------------------------------------

 ---------------- Iteration 8 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 80 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 81 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 82 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 83 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 84 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 85 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 86 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 87 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 88 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 89 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.323          |
| Data-EnvSampler-Poli... | 0.818          |
| Data-EnvTrajs-Averag... | -42            |
| Data-EnvTrajs-MaxReturn | -23.9          |
| Data-EnvTrajs-MinReturn | -57.2          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 11.6           |
| Data-TimeEnvSampleProc  | 0.000837       |
| Data-TimeEnvSampling    | 1.17           |
| Iteration               | 8              |
| ItrTime                 | 24.9           |
| LossAfter               | -0.016704535   |
| LossBefore              | -1.1341637e-05 |
| Model-TimeModelFit      | 21.1           |
| ModelSampler-n_times... | 360000         |
| Policy-AverageAbsPol... | 0.45708403     |
| Policy-AverageDiscou... | 5.54           |
| Policy-AveragePolicyStd | 0.75349253     |
| Policy-AverageReturn    | 10.6           |
| Policy-MaxReturn        | 66.3           |
| Policy-MinReturn        | -38.5          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 25.6           |
| Policy-TimeAlgoOpt      | 0.577          |
| Policy-TimeSampleProc   | 0.433          |
| Policy-TimeSampling     | 1.52           |
| Policy-TimeStep         | 2.58           |
| Time                    | 137            |
| n_timesteps             | 9000           |
--------------------------------------------

 ---------------- Iteration 9 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 90 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 91 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 92 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 93 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 94 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 95 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 96 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 97 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 98 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 99 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.377          |
| Data-EnvSampler-Poli... | 0.995          |
| Data-EnvTrajs-Averag... | -41.8          |
| Data-EnvTrajs-MaxReturn | 15.3           |
| Data-EnvTrajs-MinReturn | -112           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 46             |
| Data-TimeEnvSampleProc  | 0.000951       |
| Data-TimeEnvSampling    | 1.41           |
| Iteration               | 9              |
| ItrTime                 | 26.6           |
| LossAfter               | -0.015649296   |
| LossBefore              | -1.1154614e-05 |
| Model-TimeModelFit      | 22.6           |
| ModelSampler-n_times... | 400000         |
| Policy-AverageAbsPol... | 0.49549723     |
| Policy-AverageDiscou... | -92.5          |
| Policy-AveragePolicyStd | 0.7381411      |
| Policy-AverageReturn    | -212           |
| Policy-MaxReturn        | -152           |
| Policy-MinReturn        | -309           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 38.4           |
| Policy-TimeAlgoOpt      | 0.599          |
| Policy-TimeSampleProc   | 0.504          |
| Policy-TimeSampling     | 1.42           |
| Policy-TimeStep         | 2.57           |
| Time                    | 163            |
| n_timesteps             | 10000          |
--------------------------------------------

 ---------------- Iteration 10 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 100 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 101 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 102 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 103 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 104 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 105 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 106 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 107 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 108 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 109 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.291          |
| Data-EnvSampler-Poli... | 0.604          |
| Data-EnvTrajs-Averag... | -41.3          |
| Data-EnvTrajs-MaxReturn | -2.8           |
| Data-EnvTrajs-MinReturn | -99.9          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 34.5           |
| Data-TimeEnvSampleProc  | 0.00106        |
| Data-TimeEnvSampling    | 0.924          |
| Iteration               | 10             |
| ItrTime                 | 29.5           |
| LossAfter               | -0.015754012   |
| LossBefore              | -1.1009143e-05 |
| Model-TimeModelFit      | 25.7           |
| ModelSampler-n_times... | 440000         |
| Policy-AverageAbsPol... | 0.483243       |
| Policy-AverageDiscou... | -63.8          |
| Policy-AveragePolicyStd | 0.727276       |
| Policy-AverageReturn    | -143           |
| Policy-MaxReturn        | 4.59           |
| Policy-MinReturn        | -291           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 82.6           |
| Policy-TimeAlgoOpt      | 0.599          |
| Policy-TimeSampleProc   | 0.561          |
| Policy-TimeSampling     | 1.71           |
| Policy-TimeStep         | 2.92           |
| Time                    | 193            |
| n_timesteps             | 11000          |
--------------------------------------------

 ---------------- Iteration 11 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 110 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 111 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 112 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 113 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 114 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 115 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 116 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 117 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 118 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 119 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.356          |
| Data-EnvSampler-Poli... | 0.951          |
| Data-EnvTrajs-Averag... | -36            |
| Data-EnvTrajs-MaxReturn | 10.7           |
| Data-EnvTrajs-MinReturn | -89.4          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 33.3           |
| Data-TimeEnvSampleProc  | 0.000938       |
| Data-TimeEnvSampling    | 1.34           |
| Iteration               | 11             |
| ItrTime                 | 30.4           |
| LossAfter               | -0.019893799   |
| LossBefore              | -1.0906001e-05 |
| Model-TimeModelFit      | 26.1           |
| ModelSampler-n_times... | 480000         |
| Policy-AverageAbsPol... | 0.5142355      |
| Policy-AverageDiscou... | -70.3          |
| Policy-AveragePolicyStd | 0.72109056     |
| Policy-AverageReturn    | -184           |
| Policy-MaxReturn        | -127           |
| Policy-MinReturn        | -267           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 36.3           |
| Policy-TimeAlgoOpt      | 0.644          |
| Policy-TimeSampleProc   | 0.472          |
| Policy-TimeSampling     | 1.81           |
| Policy-TimeStep         | 3              |
| Time                    | 223            |
| n_timesteps             | 12000          |
--------------------------------------------

 ---------------- Iteration 12 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 120 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 121 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 122 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 123 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 124 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 125 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 126 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 127 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 128 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 129 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.317          |
| Data-EnvSampler-Poli... | 0.789          |
| Data-EnvTrajs-Averag... | 3              |
| Data-EnvTrajs-MaxReturn | 51.6           |
| Data-EnvTrajs-MinReturn | -37.8          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 32             |
| Data-TimeEnvSampleProc  | 0.00166        |
| Data-TimeEnvSampling    | 1.14           |
| Iteration               | 12             |
| ItrTime                 | 33.5           |
| LossAfter               | -0.014600927   |
| LossBefore              | -1.0799807e-05 |
| Model-TimeModelFit      | 29             |
| ModelSampler-n_times... | 520000         |
| Policy-AverageAbsPol... | 0.48208553     |
| Policy-AverageDiscou... | -8.31          |
| Policy-AveragePolicyStd | 0.7126108      |
| Policy-AverageReturn    | -31.4          |
| Policy-MaxReturn        | 19.8           |
| Policy-MinReturn        | -82.6          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 23.6           |
| Policy-TimeAlgoOpt      | 0.635          |
| Policy-TimeSampleProc   | 0.716          |
| Policy-TimeSampling     | 1.97           |
| Policy-TimeStep         | 3.36           |
| Time                    | 257            |
| n_timesteps             | 13000          |
--------------------------------------------

 ---------------- Iteration 13 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 130 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 131 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 132 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 133 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 134 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 135 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 136 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 137 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 138 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 139 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.367           |
| Data-EnvSampler-Poli... | 0.927           |
| Data-EnvTrajs-Averag... | -24.4           |
| Data-EnvTrajs-MaxReturn | -2.18           |
| Data-EnvTrajs-MinReturn | -74.9           |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 26.8            |
| Data-TimeEnvSampleProc  | 0.00126         |
| Data-TimeEnvSampling    | 1.33            |
| Iteration               | 13              |
| ItrTime                 | 32.8            |
| LossAfter               | -0.017236631    |
| LossBefore              | -1.07233445e-05 |
| Model-TimeModelFit      | 28.4            |
| ModelSampler-n_times... | 560000          |
| Policy-AverageAbsPol... | 0.48856044      |
| Policy-AverageDiscou... | 105             |
| Policy-AveragePolicyStd | 0.7071748       |
| Policy-AverageReturn    | 258             |
| Policy-MaxReturn        | 344             |
| Policy-MinReturn        | 160             |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 49.1            |
| Policy-TimeAlgoOpt      | 0.607           |
| Policy-TimeSampleProc   | 0.563           |
| Policy-TimeSampling     | 1.87            |
| Policy-TimeStep         | 3.11            |
| Time                    | 290             |
| n_timesteps             | 14000           |
---------------------------------------------

 ---------------- Iteration 14 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 140 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 141 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 142 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 143 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 144 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 145 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 146 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 147 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 148 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 149 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.337          |
| Data-EnvSampler-Poli... | 0.735          |
| Data-EnvTrajs-Averag... | -33.7          |
| Data-EnvTrajs-MaxReturn | 15.7           |
| Data-EnvTrajs-MinReturn | -107           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 40.7           |
| Data-TimeEnvSampleProc  | 0.000638       |
| Data-TimeEnvSampling    | 1.11           |
| Iteration               | 14             |
| ItrTime                 | 35.4           |
| LossAfter               | -0.013929835   |
| LossBefore              | -1.0501675e-05 |
| Model-TimeModelFit      | 31.1           |
| ModelSampler-n_times... | 600000         |
| Policy-AverageAbsPol... | 0.5030615      |
| Policy-AverageDiscou... | -17.6          |
| Policy-AveragePolicyStd | 0.69263184     |
| Policy-AverageReturn    | -40.1          |
| Policy-MaxReturn        | -9.04          |
| Policy-MinReturn        | -108           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 21.5           |
| Policy-TimeAlgoOpt      | 0.668          |
| Policy-TimeSampleProc   | 0.659          |
| Policy-TimeSampling     | 1.8            |
| Policy-TimeStep         | 3.17           |
| Time                    | 325            |
| n_timesteps             | 15000          |
--------------------------------------------

 ---------------- Iteration 15 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 150 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 151 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 152 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 153 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 154 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 155 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 156 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 157 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 158 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 159 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.31            |
| Data-EnvSampler-Poli... | 0.642           |
| Data-EnvTrajs-Averag... | -44.9           |
| Data-EnvTrajs-MaxReturn | -5.58           |
| Data-EnvTrajs-MinReturn | -88.9           |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 31              |
| Data-TimeEnvSampleProc  | 0.000969        |
| Data-TimeEnvSampling    | 0.986           |
| Iteration               | 15              |
| ItrTime                 | 32              |
| LossAfter               | -0.015620768    |
| LossBefore              | -1.02704025e-05 |
| Model-TimeModelFit      | 28.1            |
| ModelSampler-n_times... | 640000          |
| Policy-AverageAbsPol... | 0.52317464      |
| Policy-AverageDiscou... | 35.2            |
| Policy-AveragePolicyStd | 0.6756556       |
| Policy-AverageReturn    | 103             |
| Policy-MaxReturn        | 186             |
| Policy-MinReturn        | 31.4            |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 39.5            |
| Policy-TimeAlgoOpt      | 0.616           |
| Policy-TimeSampleProc   | 0.569           |
| Policy-TimeSampling     | 1.7             |
| Policy-TimeStep         | 2.93            |
| Time                    | 357             |
| n_timesteps             | 16000           |
---------------------------------------------

 ---------------- Iteration 16 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 160 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 161 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 162 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 163 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 164 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 165 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 166 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 167 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 168 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 169 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.31           |
| Data-EnvSampler-Poli... | 0.666          |
| Data-EnvTrajs-Averag... | -8.17          |
| Data-EnvTrajs-MaxReturn | 44.3           |
| Data-EnvTrajs-MinReturn | -50.6          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 32.8           |
| Data-TimeEnvSampleProc  | 0.00105        |
| Data-TimeEnvSampling    | 1.01           |
| Iteration               | 16             |
| ItrTime                 | 33.3           |
| LossAfter               | -0.015893517   |
| LossBefore              | -1.0058989e-05 |
| Model-TimeModelFit      | 29             |
| ModelSampler-n_times... | 680000         |
| Policy-AverageAbsPol... | 0.5045695      |
| Policy-AverageDiscou... | -5.16          |
| Policy-AveragePolicyStd | 0.66277236     |
| Policy-AverageReturn    | -18.8          |
| Policy-MaxReturn        | 8.86           |
| Policy-MinReturn        | -43.4          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 12.9           |
| Policy-TimeAlgoOpt      | 0.621          |
| Policy-TimeSampleProc   | 0.56           |
| Policy-TimeSampling     | 2.04           |
| Policy-TimeStep         | 3.28           |
| Time                    | 390            |
| n_timesteps             | 17000          |
--------------------------------------------

 ---------------- Iteration 17 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 170 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 171 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 172 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 173 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 174 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 175 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 176 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 177 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 178 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 179 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.294         |
| Data-EnvSampler-Poli... | 0.603         |
| Data-EnvTrajs-Averag... | -14           |
| Data-EnvTrajs-MaxReturn | 12            |
| Data-EnvTrajs-MinReturn | -44.7         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 19.1          |
| Data-TimeEnvSampleProc  | 0.000654      |
| Data-TimeEnvSampling    | 0.927         |
| Iteration               | 17            |
| ItrTime                 | 30.4          |
| LossAfter               | -0.016526606  |
| LossBefore              | -9.836289e-06 |
| Model-TimeModelFit      | 26.5          |
| ModelSampler-n_times... | 720000        |
| Policy-AverageAbsPol... | 0.5834673     |
| Policy-AverageDiscou... | -26.6         |
| Policy-AveragePolicyStd | 0.648427      |
| Policy-AverageReturn    | -65.1         |
| Policy-MaxReturn        | -33.3         |
| Policy-MinReturn        | -92.6         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 18.9          |
| Policy-TimeAlgoOpt      | 0.698         |
| Policy-TimeSampleProc   | 0.49          |
| Policy-TimeSampling     | 1.77          |
| Policy-TimeStep         | 3             |
| Time                    | 421           |
| n_timesteps             | 18000         |
-------------------------------------------

 ---------------- Iteration 18 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 180 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 181 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 182 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 183 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 184 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 185 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 186 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 187 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 188 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 189 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.322         |
| Data-EnvSampler-Poli... | 0.634         |
| Data-EnvTrajs-Averag... | -20           |
| Data-EnvTrajs-MaxReturn | 3.14          |
| Data-EnvTrajs-MinReturn | -33.5         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 14            |
| Data-TimeEnvSampleProc  | 0.000628      |
| Data-TimeEnvSampling    | 0.988         |
| Iteration               | 18            |
| ItrTime                 | 33.2          |
| LossAfter               | -0.018140486  |
| LossBefore              | -9.636699e-06 |
| Model-TimeModelFit      | 29.3          |
| ModelSampler-n_times... | 760000        |
| Policy-AverageAbsPol... | 0.6105619     |
| Policy-AverageDiscou... | 14            |
| Policy-AveragePolicyStd | 0.6359581     |
| Policy-AverageReturn    | 41            |
| Policy-MaxReturn        | 109           |
| Policy-MinReturn        | -21.8         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 33.7          |
| Policy-TimeAlgoOpt      | 0.585         |
| Policy-TimeSampleProc   | 0.644         |
| Policy-TimeSampling     | 1.69          |
| Policy-TimeStep         | 2.94          |
| Time                    | 454           |
| n_timesteps             | 19000         |
-------------------------------------------

 ---------------- Iteration 19 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 190 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 191 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 192 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 193 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 194 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 195 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 196 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 197 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 198 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 199 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.347         |
| Data-EnvSampler-Poli... | 0.739         |
| Data-EnvTrajs-Averag... | -19.2         |
| Data-EnvTrajs-MaxReturn | -0.177        |
| Data-EnvTrajs-MinReturn | -62.2         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 22.5          |
| Data-TimeEnvSampleProc  | 0.000847      |
| Data-TimeEnvSampling    | 1.12          |
| Iteration               | 19            |
| ItrTime                 | 31.8          |
| LossAfter               | -0.01636607   |
| LossBefore              | -9.435871e-06 |
| Model-TimeModelFit      | 27.3          |
| ModelSampler-n_times... | 800000        |
| Policy-AverageAbsPol... | 0.6911097     |
| Policy-AverageDiscou... | -17.6         |
| Policy-AveragePolicyStd | 0.6252386     |
| Policy-AverageReturn    | -41.3         |
| Policy-MaxReturn        | -3.04         |
| Policy-MinReturn        | -85.4         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 23.7          |
| Policy-TimeAlgoOpt      | 0.627         |
| Policy-TimeSampleProc   | 0.856         |
| Policy-TimeSampling     | 1.83          |
| Policy-TimeStep         | 3.36          |
| Time                    | 486           |
| n_timesteps             | 20000         |
-------------------------------------------

 ---------------- Iteration 20 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 200 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 201 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 202 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 203 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 204 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 205 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 206 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 207 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 208 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 209 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.363         |
| Data-EnvSampler-Poli... | 0.851         |
| Data-EnvTrajs-Averag... | 1.05          |
| Data-EnvTrajs-MaxReturn | 42.9          |
| Data-EnvTrajs-MinReturn | -12.8         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 21.3          |
| Data-TimeEnvSampleProc  | 0.000947      |
| Data-TimeEnvSampling    | 1.25          |
| Iteration               | 20            |
| ItrTime                 | 33.4          |
| LossAfter               | -0.016742297  |
| LossBefore              | -9.259636e-06 |
| Model-TimeModelFit      | 29.3          |
| ModelSampler-n_times... | 840000        |
| Policy-AverageAbsPol... | 0.6614086     |
| Policy-AverageDiscou... | -18.6         |
| Policy-AveragePolicyStd | 0.6128058     |
| Policy-AverageReturn    | -41.9         |
| Policy-MaxReturn        | 38.6          |
| Policy-MinReturn        | -191          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 47.6          |
| Policy-TimeAlgoOpt      | 0.695         |
| Policy-TimeSampleProc   | 0.411         |
| Policy-TimeSampling     | 1.66          |
| Policy-TimeStep         | 2.8           |
| Time                    | 519           |
| n_timesteps             | 21000         |
-------------------------------------------

 ---------------- Iteration 21 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 210 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 211 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 212 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 213 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 214 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 215 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 216 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 217 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 218 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 219 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.339         |
| Data-EnvSampler-Poli... | 0.699         |
| Data-EnvTrajs-Averag... | 16.9          |
| Data-EnvTrajs-MaxReturn | 35.7          |
| Data-EnvTrajs-MinReturn | -5.72         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 16.4          |
| Data-TimeEnvSampleProc  | 0.000802      |
| Data-TimeEnvSampling    | 1.07          |
| Iteration               | 21            |
| ItrTime                 | 34            |
| LossAfter               | -0.0148883    |
| LossBefore              | -9.069924e-06 |
| Model-TimeModelFit      | 30.2          |
| ModelSampler-n_times... | 880000        |
| Policy-AverageAbsPol... | 0.6770657     |
| Policy-AverageDiscou... | -58.6         |
| Policy-AveragePolicyStd | 0.6010548     |
| Policy-AverageReturn    | -136          |
| Policy-MaxReturn        | -98.1         |
| Policy-MinReturn        | -185          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 20.4          |
| Policy-TimeAlgoOpt      | 0.544         |
| Policy-TimeSampleProc   | 0.586         |
| Policy-TimeSampling     | 1.55          |
| Policy-TimeStep         | 2.73          |
| Time                    | 553           |
| n_timesteps             | 22000         |
-------------------------------------------

 ---------------- Iteration 22 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 220 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 221 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 222 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 223 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 224 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 225 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 226 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 227 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 228 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 229 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.335         |
| Data-EnvSampler-Poli... | 0.684         |
| Data-EnvTrajs-Averag... | 2.5           |
| Data-EnvTrajs-MaxReturn | 31.5          |
| Data-EnvTrajs-MinReturn | -13.6         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 16.5          |
| Data-TimeEnvSampleProc  | 0.000709      |
| Data-TimeEnvSampling    | 1.05          |
| Iteration               | 22            |
| ItrTime                 | 35.4          |
| LossAfter               | -0.014816553  |
| LossBefore              | -8.826942e-06 |
| Model-TimeModelFit      | 30.4          |
| ModelSampler-n_times... | 920000        |
| Policy-AverageAbsPol... | 0.6321345     |
| Policy-AverageDiscou... | -49.2         |
| Policy-AveragePolicyStd | 0.58309984    |
| Policy-AverageReturn    | -123          |
| Policy-MaxReturn        | -85.2         |
| Policy-MinReturn        | -153          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 19.9          |
| Policy-TimeAlgoOpt      | 0.704         |
| Policy-TimeSampleProc   | 0.927         |
| Policy-TimeSampling     | 2.3           |
| Policy-TimeStep         | 4.01          |
| Time                    | 589           |
| n_timesteps             | 23000         |
-------------------------------------------

 ---------------- Iteration 23 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 230 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 231 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 232 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 233 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 234 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 235 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 236 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 237 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 238 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 239 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.514         |
| Data-EnvSampler-Poli... | 1.14          |
| Data-EnvTrajs-Averag... | 8.27          |
| Data-EnvTrajs-MaxReturn | 19.8          |
| Data-EnvTrajs-MinReturn | -2.7          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 8.61          |
| Data-TimeEnvSampleProc  | 0.00125       |
| Data-TimeEnvSampling    | 1.72          |
| Iteration               | 23            |
| ItrTime                 | 34.4          |
| LossAfter               | -0.015310232  |
| LossBefore              | -8.506144e-06 |
| Model-TimeModelFit      | 29.5          |
| ModelSampler-n_times... | 960000        |
| Policy-AverageAbsPol... | 0.615522      |
| Policy-AverageDiscou... | -29.8         |
| Policy-AveragePolicyStd | 0.5666637     |
| Policy-AverageReturn    | -68.1         |
| Policy-MaxReturn        | -11.7         |
| Policy-MinReturn        | -104          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 22.9          |
| Policy-TimeAlgoOpt      | 0.725         |
| Policy-TimeSampleProc   | 0.584         |
| Policy-TimeSampling     | 1.84          |
| Policy-TimeStep         | 3.21          |
| Time                    | 623           |
| n_timesteps             | 24000         |
-------------------------------------------

 ---------------- Iteration 24 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 240 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 241 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 242 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 243 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 244 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 245 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 246 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 247 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 248 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 249 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.398         |
| Data-EnvSampler-Poli... | 0.883         |
| Data-EnvTrajs-Averag... | 48            |
| Data-EnvTrajs-MaxReturn | 82.9          |
| Data-EnvTrajs-MinReturn | 31.7          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 19.2          |
| Data-TimeEnvSampleProc  | 0.000785      |
| Data-TimeEnvSampling    | 1.32          |
| Iteration               | 24            |
| ItrTime                 | 39.3          |
| LossAfter               | -0.017509736  |
| LossBefore              | -8.217627e-06 |
| Model-TimeModelFit      | 34.5          |
| ModelSampler-n_times... | 1000000       |
| Policy-AverageAbsPol... | 0.6099445     |
| Policy-AverageDiscou... | -25.6         |
| Policy-AveragePolicyStd | 0.5509346     |
| Policy-AverageReturn    | -61           |
| Policy-MaxReturn        | -5.57         |
| Policy-MinReturn        | -135          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 28.2          |
| Policy-TimeAlgoOpt      | 0.645         |
| Policy-TimeSampleProc   | 0.857         |
| Policy-TimeSampling     | 1.88          |
| Policy-TimeStep         | 3.45          |
| Time                    | 662           |
| n_timesteps             | 25000         |
-------------------------------------------

 ---------------- Iteration 25 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 250 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 251 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 252 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 253 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 254 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 255 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 256 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 257 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 258 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 259 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.362         |
| Data-EnvSampler-Poli... | 0.772         |
| Data-EnvTrajs-Averag... | 23.8          |
| Data-EnvTrajs-MaxReturn | 51.6          |
| Data-EnvTrajs-MinReturn | -6.6          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 23.8          |
| Data-TimeEnvSampleProc  | 0.000946      |
| Data-TimeEnvSampling    | 1.17          |
| Iteration               | 25            |
| ItrTime                 | 35.7          |
| LossAfter               | -0.019545816  |
| LossBefore              | -7.986654e-06 |
| Model-TimeModelFit      | 31.8          |
| ModelSampler-n_times... | 1040000       |
| Policy-AverageAbsPol... | 0.55421597    |
| Policy-AverageDiscou... | 25.3          |
| Policy-AveragePolicyStd | 0.53805524    |
| Policy-AverageReturn    | 57.6          |
| Policy-MaxReturn        | 87.5          |
| Policy-MinReturn        | 16.8          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 18.5          |
| Policy-TimeAlgoOpt      | 0.68          |
| Policy-TimeSampleProc   | 0.35          |
| Policy-TimeSampling     | 1.63          |
| Policy-TimeStep         | 2.68          |
| Time                    | 698           |
| n_timesteps             | 26000         |
-------------------------------------------

 ---------------- Iteration 26 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 260 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 261 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 262 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 263 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 264 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 265 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 266 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 267 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 268 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 269 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.277         |
| Data-EnvSampler-Poli... | 0.581         |
| Data-EnvTrajs-Averag... | 39            |
| Data-EnvTrajs-MaxReturn | 66.1          |
| Data-EnvTrajs-MinReturn | -9.86         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 25.8          |
| Data-TimeEnvSampleProc  | 0.000949      |
| Data-TimeEnvSampling    | 0.888         |
| Iteration               | 26            |
| ItrTime                 | 33.5          |
| LossAfter               | -0.016883591  |
| LossBefore              | -7.820847e-06 |
| Model-TimeModelFit      | 29.6          |
| ModelSampler-n_times... | 1080000       |
| Policy-AverageAbsPol... | 0.54726154    |
| Policy-AverageDiscou... | 19.3          |
| Policy-AveragePolicyStd | 0.52867746    |
| Policy-AverageReturn    | 45            |
| Policy-MaxReturn        | 79.5          |
| Policy-MinReturn        | 14.8          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 21.4          |
| Policy-TimeAlgoOpt      | 0.609         |
| Policy-TimeSampleProc   | 0.552         |
| Policy-TimeSampling     | 1.8           |
| Policy-TimeStep         | 3.04          |
| Time                    | 732           |
| n_timesteps             | 27000         |
-------------------------------------------

 ---------------- Iteration 27 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 270 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 271 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 272 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 273 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 274 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 275 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 276 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 277 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 278 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 279 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.285          |
| Data-EnvSampler-Poli... | 0.565          |
| Data-EnvTrajs-Averag... | 24             |
| Data-EnvTrajs-MaxReturn | 66.1           |
| Data-EnvTrajs-MinReturn | -34.3          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 42             |
| Data-TimeEnvSampleProc  | 0.00092        |
| Data-TimeEnvSampling    | 0.878          |
| Iteration               | 27             |
| ItrTime                 | 34.4           |
| LossAfter               | -0.015038834   |
| LossBefore              | -7.6014403e-06 |
| Model-TimeModelFit      | 30.8           |
| ModelSampler-n_times... | 1120000        |
| Policy-AverageAbsPol... | 0.55781525     |
| Policy-AverageDiscou... | 29.5           |
| Policy-AveragePolicyStd | 0.51810247     |
| Policy-AverageReturn    | 75.2           |
| Policy-MaxReturn        | 130            |
| Policy-MinReturn        | 2.55           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 34.9           |
| Policy-TimeAlgoOpt      | 0.54           |
| Policy-TimeSampleProc   | 0.596          |
| Policy-TimeSampling     | 1.5            |
| Policy-TimeStep         | 2.71           |
| Time                    | 766            |
| n_timesteps             | 28000          |
--------------------------------------------

 ---------------- Iteration 28 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 280 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 281 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 282 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 283 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 284 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 285 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 286 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 287 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 288 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 289 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.276         |
| Data-EnvSampler-Poli... | 0.577         |
| Data-EnvTrajs-Averag... | 37.6          |
| Data-EnvTrajs-MaxReturn | 89.1          |
| Data-EnvTrajs-MinReturn | -5.92         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 31.4          |
| Data-TimeEnvSampleProc  | 0.000712      |
| Data-TimeEnvSampling    | 0.882         |
| Iteration               | 28            |
| ItrTime                 | 33.5          |
| LossAfter               | -0.015241393  |
| LossBefore              | -7.406174e-06 |
| Model-TimeModelFit      | 29.8          |
| ModelSampler-n_times... | 1160000       |
| Policy-AverageAbsPol... | 0.5992715     |
| Policy-AverageDiscou... | -2.36         |
| Policy-AveragePolicyStd | 0.5094159     |
| Policy-AverageReturn    | 0.72          |
| Policy-MaxReturn        | 79.3          |
| Policy-MinReturn        | -43.1         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 34.3          |
| Policy-TimeAlgoOpt      | 0.59          |
| Policy-TimeSampleProc   | 0.512         |
| Policy-TimeSampling     | 1.68          |
| Policy-TimeStep         | 2.86          |
| Time                    | 800           |
| n_timesteps             | 29000         |
-------------------------------------------

 ---------------- Iteration 29 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 290 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 291 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 292 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 293 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 294 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 295 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 296 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 297 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 298 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 299 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.372          |
| Data-EnvSampler-Poli... | 0.725          |
| Data-EnvTrajs-Averag... | 65             |
| Data-EnvTrajs-MaxReturn | 83.9           |
| Data-EnvTrajs-MinReturn | 47.7           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 12.9           |
| Data-TimeEnvSampleProc  | 0.000999       |
| Data-TimeEnvSampling    | 1.13           |
| Iteration               | 29             |
| ItrTime                 | 34.2           |
| LossAfter               | -0.0160193     |
| LossBefore              | -7.1971776e-06 |
| Model-TimeModelFit      | 30.2           |
| ModelSampler-n_times... | 1200000        |
| Policy-AverageAbsPol... | 0.5401468      |
| Policy-AverageDiscou... | -3.67          |
| Policy-AveragePolicyStd | 0.4990192      |
| Policy-AverageReturn    | -15.9          |
| Policy-MaxReturn        | 52.4           |
| Policy-MinReturn        | -81.1          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 30.5           |
| Policy-TimeAlgoOpt      | 0.699          |
| Policy-TimeSampleProc   | 0.392          |
| Policy-TimeSampling     | 1.72           |
| Policy-TimeStep         | 2.84           |
| Time                    | 834            |
| n_timesteps             | 30000          |
--------------------------------------------

 ---------------- Iteration 30 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 300 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 301 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 302 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 303 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 304 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 305 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 306 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 307 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 308 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 309 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.314          |
| Data-EnvSampler-Poli... | 0.689          |
| Data-EnvTrajs-Averag... | 79.3           |
| Data-EnvTrajs-MaxReturn | 113            |
| Data-EnvTrajs-MinReturn | 52.5           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 20.9           |
| Data-TimeEnvSampleProc  | 0.000872       |
| Data-TimeEnvSampling    | 1.04           |
| Iteration               | 30             |
| ItrTime                 | 35.2           |
| LossAfter               | -0.0163963     |
| LossBefore              | -6.9336825e-06 |
| Model-TimeModelFit      | 31             |
| ModelSampler-n_times... | 1240000        |
| Policy-AverageAbsPol... | 0.57256407     |
| Policy-AverageDiscou... | 37.6           |
| Policy-AveragePolicyStd | 0.48434982     |
| Policy-AverageReturn    | 88.8           |
| Policy-MaxReturn        | 141            |
| Policy-MinReturn        | 16.5           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 33.5           |
| Policy-TimeAlgoOpt      | 0.708          |
| Policy-TimeSampleProc   | 0.437          |
| Policy-TimeSampling     | 1.97           |
| Policy-TimeStep         | 3.14           |
| Time                    | 869            |
| n_timesteps             | 31000          |
--------------------------------------------

 ---------------- Iteration 31 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 310 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 311 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 312 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 313 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 314 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 315 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 316 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 317 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 318 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 319 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.318          |
| Data-EnvSampler-Poli... | 0.727          |
| Data-EnvTrajs-Averag... | 76             |
| Data-EnvTrajs-MaxReturn | 115            |
| Data-EnvTrajs-MinReturn | 52.5           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 20.6           |
| Data-TimeEnvSampleProc  | 0.00087        |
| Data-TimeEnvSampling    | 1.08           |
| Iteration               | 31             |
| ItrTime                 | 34.5           |
| LossAfter               | -0.018321073   |
| LossBefore              | -6.6800785e-06 |
| Model-TimeModelFit      | 30.2           |
| ModelSampler-n_times... | 1280000        |
| Policy-AverageAbsPol... | 0.6192417      |
| Policy-AverageDiscou... | 77.3           |
| Policy-AveragePolicyStd | 0.47242284     |
| Policy-AverageReturn    | 201            |
| Policy-MaxReturn        | 247            |
| Policy-MinReturn        | 130            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 26.9           |
| Policy-TimeAlgoOpt      | 0.753          |
| Policy-TimeSampleProc   | 0.537          |
| Policy-TimeSampling     | 1.82           |
| Policy-TimeStep         | 3.16           |
| Time                    | 903            |
| n_timesteps             | 32000          |
--------------------------------------------

 ---------------- Iteration 32 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 320 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 321 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 322 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 323 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 324 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 325 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 326 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 327 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 328 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 329 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.348          |
| Data-EnvSampler-Poli... | 0.892          |
| Data-EnvTrajs-Averag... | 112            |
| Data-EnvTrajs-MaxReturn | 166            |
| Data-EnvTrajs-MinReturn | 87.6           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 28             |
| Data-TimeEnvSampleProc  | 0.000625       |
| Data-TimeEnvSampling    | 1.27           |
| Iteration               | 32             |
| ItrTime                 | 35.6           |
| LossAfter               | -0.016127182   |
| LossBefore              | -6.4918154e-06 |
| Model-TimeModelFit      | 31.2           |
| ModelSampler-n_times... | 1320000        |
| Policy-AverageAbsPol... | 0.62331843     |
| Policy-AverageDiscou... | 36.7           |
| Policy-AveragePolicyStd | 0.46332014     |
| Policy-AverageReturn    | 98.2           |
| Policy-MaxReturn        | 207            |
| Policy-MinReturn        | 40.9           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 43.8           |
| Policy-TimeAlgoOpt      | 0.656          |
| Policy-TimeSampleProc   | 0.541          |
| Policy-TimeSampling     | 1.81           |
| Policy-TimeStep         | 3.03           |
| Time                    | 939            |
| n_timesteps             | 33000          |
--------------------------------------------

 ---------------- Iteration 33 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 330 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 331 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 332 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 333 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 334 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 335 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 336 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 337 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 338 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 339 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.313          |
| Data-EnvSampler-Poli... | 0.669          |
| Data-EnvTrajs-Averag... | 139            |
| Data-EnvTrajs-MaxReturn | 180            |
| Data-EnvTrajs-MinReturn | 96.2           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 27.3           |
| Data-TimeEnvSampleProc  | 0.000588       |
| Data-TimeEnvSampling    | 1.01           |
| Iteration               | 33             |
| ItrTime                 | 35.2           |
| LossAfter               | -0.017508648   |
| LossBefore              | -6.2849826e-06 |
| Model-TimeModelFit      | 31.3           |
| ModelSampler-n_times... | 1360000        |
| Policy-AverageAbsPol... | 0.643221       |
| Policy-AverageDiscou... | 54.5           |
| Policy-AveragePolicyStd | 0.45383167     |
| Policy-AverageReturn    | 127            |
| Policy-MaxReturn        | 181            |
| Policy-MinReturn        | 77             |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 28             |
| Policy-TimeAlgoOpt      | 0.671          |
| Policy-TimeSampleProc   | 0.37           |
| Policy-TimeSampling     | 1.78           |
| Policy-TimeStep         | 2.88           |
| Time                    | 974            |
| n_timesteps             | 34000          |
--------------------------------------------

 ---------------- Iteration 34 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 340 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 341 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 342 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 343 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 344 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 345 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 346 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 347 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 348 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 349 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.323         |
| Data-EnvSampler-Poli... | 0.752         |
| Data-EnvTrajs-Averag... | 136           |
| Data-EnvTrajs-MaxReturn | 159           |
| Data-EnvTrajs-MinReturn | 96.6          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 21.6          |
| Data-TimeEnvSampleProc  | 0.000568      |
| Data-TimeEnvSampling    | 1.11          |
| Iteration               | 34            |
| ItrTime                 | 36.8          |
| LossAfter               | -0.017600372  |
| LossBefore              | -6.165265e-06 |
| Model-TimeModelFit      | 32.4          |
| ModelSampler-n_times... | 1400000       |
| Policy-AverageAbsPol... | 0.67021435    |
| Policy-AverageDiscou... | 49            |
| Policy-AveragePolicyStd | 0.44778407    |
| Policy-AverageReturn    | 134           |
| Policy-MaxReturn        | 218           |
| Policy-MinReturn        | 83.6          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 40.8          |
| Policy-TimeAlgoOpt      | 0.701         |
| Policy-TimeSampleProc   | 0.481         |
| Policy-TimeSampling     | 2.01          |
| Policy-TimeStep         | 3.25          |
| Time                    | 1.01e+03      |
| n_timesteps             | 35000         |
-------------------------------------------

 ---------------- Iteration 35 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 350 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 351 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 352 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 353 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 354 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 355 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 356 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 357 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 358 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 359 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.332          |
| Data-EnvSampler-Poli... | 0.793          |
| Data-EnvTrajs-Averag... | 111            |
| Data-EnvTrajs-MaxReturn | 151            |
| Data-EnvTrajs-MinReturn | 86.2           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 21.7           |
| Data-TimeEnvSampleProc  | 0.000618       |
| Data-TimeEnvSampling    | 1.16           |
| Iteration               | 35             |
| ItrTime                 | 37.2           |
| LossAfter               | -0.020559903   |
| LossBefore              | -6.0014004e-06 |
| Model-TimeModelFit      | 32.4           |
| ModelSampler-n_times... | 1440000        |
| Policy-AverageAbsPol... | 0.69282633     |
| Policy-AverageDiscou... | 391            |
| Policy-AveragePolicyStd | 0.44103354     |
| Policy-AverageReturn    | 1.75e+03       |
| Policy-MaxReturn        | 1.06e+04       |
| Policy-MinReturn        | 26.8           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.95e+03       |
| Policy-TimeAlgoOpt      | 0.657          |
| Policy-TimeSampleProc   | 0.757          |
| Policy-TimeSampling     | 2.19           |
| Policy-TimeStep         | 3.66           |
| Time                    | 1.05e+03       |
| n_timesteps             | 36000          |
--------------------------------------------

 ---------------- Iteration 36 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 360 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 361 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 362 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 363 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 364 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 365 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 366 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 367 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 368 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 369 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.339         |
| Data-EnvSampler-Poli... | 0.782         |
| Data-EnvTrajs-Averag... | 132           |
| Data-EnvTrajs-MaxReturn | 145           |
| Data-EnvTrajs-MinReturn | 113           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 11            |
| Data-TimeEnvSampleProc  | 0.00107       |
| Data-TimeEnvSampling    | 1.15          |
| Iteration               | 36            |
| ItrTime                 | 36.1          |
| LossAfter               | -0.017962333  |
| LossBefore              | -5.778654e-06 |
| Model-TimeModelFit      | 31.8          |
| ModelSampler-n_times... | 1480000       |
| Policy-AverageAbsPol... | 0.69768816    |
| Policy-AverageDiscou... | 43.9          |
| Policy-AveragePolicyStd | 0.43195271    |
| Policy-AverageReturn    | 128           |
| Policy-MaxReturn        | 209           |
| Policy-MinReturn        | 59.1          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 31.1          |
| Policy-TimeAlgoOpt      | 0.695         |
| Policy-TimeSampleProc   | 0.629         |
| Policy-TimeSampling     | 1.76          |
| Policy-TimeStep         | 3.11          |
| Time                    | 1.08e+03      |
| n_timesteps             | 37000         |
-------------------------------------------

 ---------------- Iteration 37 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 370 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 371 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 372 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 373 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 374 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 375 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 376 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 377 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 378 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 379 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.329         |
| Data-EnvSampler-Poli... | 0.72          |
| Data-EnvTrajs-Averag... | 189           |
| Data-EnvTrajs-MaxReturn | 249           |
| Data-EnvTrajs-MinReturn | 126           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 45.3          |
| Data-TimeEnvSampleProc  | 0.000803      |
| Data-TimeEnvSampling    | 1.08          |
| Iteration               | 37            |
| ItrTime                 | 36.2          |
| LossAfter               | -0.021639476  |
| LossBefore              | -5.642974e-06 |
| Model-TimeModelFit      | 32.1          |
| ModelSampler-n_times... | 1520000       |
| Policy-AverageAbsPol... | 0.7072944     |
| Policy-AverageDiscou... | 25.3          |
| Policy-AveragePolicyStd | 0.42496818    |
| Policy-AverageReturn    | 88.1          |
| Policy-MaxReturn        | 177           |
| Policy-MinReturn        | -15.1         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 44.2          |
| Policy-TimeAlgoOpt      | 0.596         |
| Policy-TimeSampleProc   | 0.614         |
| Policy-TimeSampling     | 1.8           |
| Policy-TimeStep         | 3.06          |
| Time                    | 1.12e+03      |
| n_timesteps             | 38000         |
-------------------------------------------

 ---------------- Iteration 38 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 380 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 381 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 382 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 383 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 384 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 385 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 386 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 387 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 388 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 389 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.309          |
| Data-EnvSampler-Poli... | 0.649          |
| Data-EnvTrajs-Averag... | 154            |
| Data-EnvTrajs-MaxReturn | 211            |
| Data-EnvTrajs-MinReturn | 109            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 36.7           |
| Data-TimeEnvSampleProc  | 0.000947       |
| Data-TimeEnvSampling    | 0.989          |
| Iteration               | 38             |
| ItrTime                 | 35.5           |
| LossAfter               | -0.016939336   |
| LossBefore              | -5.5528444e-06 |
| Model-TimeModelFit      | 31.5           |
| ModelSampler-n_times... | 1560000        |
| Policy-AverageAbsPol... | 0.7047108      |
| Policy-AverageDiscou... | 55             |
| Policy-AveragePolicyStd | 0.4210667      |
| Policy-AverageReturn    | 153            |
| Policy-MaxReturn        | 231            |
| Policy-MinReturn        | 16.3           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 51.7           |
| Policy-TimeAlgoOpt      | 0.586          |
| Policy-TimeSampleProc   | 0.686          |
| Policy-TimeSampling     | 1.7            |
| Policy-TimeStep         | 3.02           |
| Time                    | 1.16e+03       |
| n_timesteps             | 39000          |
--------------------------------------------

 ---------------- Iteration 39 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 390 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 391 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 392 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 393 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 394 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 395 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 396 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 397 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 398 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 399 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.318         |
| Data-EnvSampler-Poli... | 0.71          |
| Data-EnvTrajs-Averag... | 208           |
| Data-EnvTrajs-MaxReturn | 230           |
| Data-EnvTrajs-MinReturn | 155           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 27.1          |
| Data-TimeEnvSampleProc  | 0.00113       |
| Data-TimeEnvSampling    | 1.06          |
| Iteration               | 39            |
| ItrTime                 | 38.1          |
| LossAfter               | -0.017578362  |
| LossBefore              | -5.347901e-06 |
| Model-TimeModelFit      | 34.1          |
| ModelSampler-n_times... | 1600000       |
| Policy-AverageAbsPol... | 0.72058374    |
| Policy-AverageDiscou... | 87.6          |
| Policy-AveragePolicyStd | 0.4129355     |
| Policy-AverageReturn    | 236           |
| Policy-MaxReturn        | 328           |
| Policy-MinReturn        | 155           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 49            |
| Policy-TimeAlgoOpt      | 0.613         |
| Policy-TimeSampleProc   | 0.602         |
| Policy-TimeSampling     | 1.61          |
| Policy-TimeStep         | 2.91          |
| Time                    | 1.19e+03      |
| n_timesteps             | 40000         |
-------------------------------------------

 ---------------- Iteration 40 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 400 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 401 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 402 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 403 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 404 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 405 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 406 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 407 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 408 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 409 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.302         |
| Data-EnvSampler-Poli... | 0.638         |
| Data-EnvTrajs-Averag... | 175           |
| Data-EnvTrajs-MaxReturn | 240           |
| Data-EnvTrajs-MinReturn | 131           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 39.2          |
| Data-TimeEnvSampleProc  | 0.0011        |
| Data-TimeEnvSampling    | 0.971         |
| Iteration               | 40            |
| ItrTime                 | 37            |
| LossAfter               | -0.016722754  |
| LossBefore              | -5.164609e-06 |
| Model-TimeModelFit      | 33.1          |
| ModelSampler-n_times... | 1640000       |
| Policy-AverageAbsPol... | 0.72188723    |
| Policy-AverageDiscou... | 72.4          |
| Policy-AveragePolicyStd | 0.4058254     |
| Policy-AverageReturn    | 197           |
| Policy-MaxReturn        | 245           |
| Policy-MinReturn        | 118           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 37.6          |
| Policy-TimeAlgoOpt      | 0.575         |
| Policy-TimeSampleProc   | 0.625         |
| Policy-TimeSampling     | 1.72          |
| Policy-TimeStep         | 2.95          |
| Time                    | 1.23e+03      |
| n_timesteps             | 41000         |
-------------------------------------------

 ---------------- Iteration 41 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 410 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 411 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 412 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 413 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 414 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 415 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 416 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 417 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 418 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 419 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.33           |
| Data-EnvSampler-Poli... | 0.685          |
| Data-EnvTrajs-Averag... | 176            |
| Data-EnvTrajs-MaxReturn | 216            |
| Data-EnvTrajs-MinReturn | 125            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 36.1           |
| Data-TimeEnvSampleProc  | 0.000614       |
| Data-TimeEnvSampling    | 1.05           |
| Iteration               | 41             |
| ItrTime                 | 35.3           |
| LossAfter               | -0.018247625   |
| LossBefore              | -4.9945374e-06 |
| Model-TimeModelFit      | 31.3           |
| ModelSampler-n_times... | 1680000        |
| Policy-AverageAbsPol... | 0.7357313      |
| Policy-AverageDiscou... | 93.6           |
| Policy-AveragePolicyStd | 0.3989641      |
| Policy-AverageReturn    | 245            |
| Policy-MaxReturn        | 295            |
| Policy-MinReturn        | 147            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 35.1           |
| Policy-TimeAlgoOpt      | 0.607          |
| Policy-TimeSampleProc   | 0.618          |
| Policy-TimeSampling     | 1.64           |
| Policy-TimeStep         | 2.93           |
| Time                    | 1.27e+03       |
| n_timesteps             | 42000          |
--------------------------------------------

 ---------------- Iteration 42 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 420 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 421 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 422 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 423 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 424 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 425 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 426 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 427 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 428 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 429 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.311          |
| Data-EnvSampler-Poli... | 0.652          |
| Data-EnvTrajs-Averag... | 188            |
| Data-EnvTrajs-MaxReturn | 241            |
| Data-EnvTrajs-MinReturn | 115            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 48.5           |
| Data-TimeEnvSampleProc  | 0.000722       |
| Data-TimeEnvSampling    | 0.993          |
| Iteration               | 42             |
| ItrTime                 | 35.7           |
| LossAfter               | -0.016880333   |
| LossBefore              | -4.8219204e-06 |
| Model-TimeModelFit      | 31.7           |
| ModelSampler-n_times... | 1720000        |
| Policy-AverageAbsPol... | 0.72653985     |
| Policy-AverageDiscou... | 24.5           |
| Policy-AveragePolicyStd | 0.3918691      |
| Policy-AverageReturn    | 68.2           |
| Policy-MaxReturn        | 121            |
| Policy-MinReturn        | 9.52           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 25.6           |
| Policy-TimeAlgoOpt      | 0.701          |
| Policy-TimeSampleProc   | 0.575          |
| Policy-TimeSampling     | 1.72           |
| Policy-TimeStep         | 3.04           |
| Time                    | 1.3e+03        |
| n_timesteps             | 43000          |
--------------------------------------------

 ---------------- Iteration 43 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 430 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 431 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 432 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 433 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 434 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 435 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 436 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 437 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 438 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 439 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.288         |
| Data-EnvSampler-Poli... | 0.591         |
| Data-EnvTrajs-Averag... | 189           |
| Data-EnvTrajs-MaxReturn | 249           |
| Data-EnvTrajs-MinReturn | 105           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 51.3          |
| Data-TimeEnvSampleProc  | 0.000816      |
| Data-TimeEnvSampling    | 0.91          |
| Iteration               | 43            |
| ItrTime                 | 37.5          |
| LossAfter               | -0.014104622  |
| LossBefore              | -4.627801e-06 |
| Model-TimeModelFit      | 33.8          |
| ModelSampler-n_times... | 1760000       |
| Policy-AverageAbsPol... | 0.73814374    |
| Policy-AverageDiscou... | 83            |
| Policy-AveragePolicyStd | 0.38455734    |
| Policy-AverageReturn    | 207           |
| Policy-MaxReturn        | 297           |
| Policy-MinReturn        | 113           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 40            |
| Policy-TimeAlgoOpt      | 0.636         |
| Policy-TimeSampleProc   | 0.507         |
| Policy-TimeSampling     | 1.62          |
| Policy-TimeStep         | 2.8           |
| Time                    | 1.34e+03      |
| n_timesteps             | 44000         |
-------------------------------------------

 ---------------- Iteration 44 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 440 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 441 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 442 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 443 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 444 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 445 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 446 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 447 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 448 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 449 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.374          |
| Data-EnvSampler-Poli... | 0.709          |
| Data-EnvTrajs-Averag... | 159            |
| Data-EnvTrajs-MaxReturn | 193            |
| Data-EnvTrajs-MinReturn | 127            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 21.8           |
| Data-TimeEnvSampleProc  | 0.000699       |
| Data-TimeEnvSampling    | 1.12           |
| Iteration               | 44             |
| ItrTime                 | 38             |
| LossAfter               | -0.020023048   |
| LossBefore              | -4.3950836e-06 |
| Model-TimeModelFit      | 33.7           |
| ModelSampler-n_times... | 1800000        |
| Policy-AverageAbsPol... | 0.76321214     |
| Policy-AverageDiscou... | 79.7           |
| Policy-AveragePolicyStd | 0.37642854     |
| Policy-AverageReturn    | 209            |
| Policy-MaxReturn        | 251            |
| Policy-MinReturn        | 145            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 31.6           |
| Policy-TimeAlgoOpt      | 0.66           |
| Policy-TimeSampleProc   | 0.672          |
| Policy-TimeSampling     | 1.78           |
| Policy-TimeStep         | 3.17           |
| Time                    | 1.38e+03       |
| n_timesteps             | 45000          |
--------------------------------------------

 ---------------- Iteration 45 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 450 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 451 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 452 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 453 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 454 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 455 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 456 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 457 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 458 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 459 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Data-EnvSampler-EnvE... | 0.273        |
| Data-EnvSampler-Poli... | 0.603        |
| Data-EnvTrajs-Averag... | 221          |
| Data-EnvTrajs-MaxReturn | 245          |
| Data-EnvTrajs-MinReturn | 192          |
| Data-EnvTrajs-NumTrajs  | 5            |
| Data-EnvTrajs-StdReturn | 21.2         |
| Data-TimeEnvSampleProc  | 0.000864     |
| Data-TimeEnvSampling    | 0.904        |
| Iteration               | 45           |
| ItrTime                 | 36.5         |
| LossAfter               | -0.023774646 |
| LossBefore              | -4.30341e-06 |
| Model-TimeModelFit      | 32.3         |
| ModelSampler-n_times... | 1840000      |
| Policy-AverageAbsPol... | 0.75923395   |
| Policy-AverageDiscou... | 96.1         |
| Policy-AveragePolicyStd | 0.37290463   |
| Policy-AverageReturn    | 273          |
| Policy-MaxReturn        | 753          |
| Policy-MinReturn        | 167          |
| Policy-NumTrajs         | 20           |
| Policy-StdReturn        | 134          |
| Policy-TimeAlgoOpt      | 0.646        |
| Policy-TimeSampleProc   | 0.758        |
| Policy-TimeSampling     | 1.87         |
| Policy-TimeStep         | 3.35         |
| Time                    | 1.41e+03     |
| n_timesteps             | 46000        |
------------------------------------------

 ---------------- Iteration 46 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 460 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 461 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 462 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 463 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 464 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 465 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 466 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 467 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 468 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 469 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.302         |
| Data-EnvSampler-Poli... | 0.644         |
| Data-EnvTrajs-Averag... | 212           |
| Data-EnvTrajs-MaxReturn | 257           |
| Data-EnvTrajs-MinReturn | 192           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 23.6          |
| Data-TimeEnvSampleProc  | 0.000833      |
| Data-TimeEnvSampling    | 0.98          |
| Iteration               | 46            |
| ItrTime                 | 36.3          |
| LossAfter               | -0.016554832  |
| LossBefore              | -4.164857e-06 |
| Model-TimeModelFit      | 32.4          |
| ModelSampler-n_times... | 1880000       |
| Policy-AverageAbsPol... | 0.7484575     |
| Policy-AverageDiscou... | 95.7          |
| Policy-AveragePolicyStd | 0.36716446    |
| Policy-AverageReturn    | 259           |
| Policy-MaxReturn        | 341           |
| Policy-MinReturn        | 182           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 47            |
| Policy-TimeAlgoOpt      | 0.628         |
| Policy-TimeSampleProc   | 0.641         |
| Policy-TimeSampling     | 1.61          |
| Policy-TimeStep         | 2.94          |
| Time                    | 1.45e+03      |
| n_timesteps             | 47000         |
-------------------------------------------

 ---------------- Iteration 47 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 470 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 471 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 472 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 473 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 474 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 475 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 476 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 477 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 478 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 479 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.278         |
| Data-EnvSampler-Poli... | 0.571         |
| Data-EnvTrajs-Averag... | 271           |
| Data-EnvTrajs-MaxReturn | 332           |
| Data-EnvTrajs-MinReturn | 235           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 32.7          |
| Data-TimeEnvSampleProc  | 0.000633      |
| Data-TimeEnvSampling    | 0.876         |
| Iteration               | 47            |
| ItrTime                 | 35.6          |
| LossAfter               | -0.01593947   |
| LossBefore              | -4.051244e-06 |
| Model-TimeModelFit      | 31.8          |
| ModelSampler-n_times... | 1920000       |
| Policy-AverageAbsPol... | 0.75912875    |
| Policy-AverageDiscou... | 71.8          |
| Policy-AveragePolicyStd | 0.36267138    |
| Policy-AverageReturn    | 188           |
| Policy-MaxReturn        | 295           |
| Policy-MinReturn        | 60.9          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 47.4          |
| Policy-TimeAlgoOpt      | 0.642         |
| Policy-TimeSampleProc   | 0.583         |
| Policy-TimeSampling     | 1.56          |
| Policy-TimeStep         | 2.84          |
| Time                    | 1.49e+03      |
| n_timesteps             | 48000         |
-------------------------------------------

 ---------------- Iteration 48 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 480 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 481 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 482 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 483 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 484 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 485 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 486 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 487 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 488 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 489 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.282         |
| Data-EnvSampler-Poli... | 0.612         |
| Data-EnvTrajs-Averag... | 267           |
| Data-EnvTrajs-MaxReturn | 315           |
| Data-EnvTrajs-MinReturn | 191           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 41.4          |
| Data-TimeEnvSampleProc  | 0.00112       |
| Data-TimeEnvSampling    | 0.924         |
| Iteration               | 48            |
| ItrTime                 | 36.6          |
| LossAfter               | -0.01565652   |
| LossBefore              | -3.932942e-06 |
| Model-TimeModelFit      | 33            |
| ModelSampler-n_times... | 1960000       |
| Policy-AverageAbsPol... | 0.730434      |
| Policy-AverageDiscou... | 114           |
| Policy-AveragePolicyStd | 0.35830376    |
| Policy-AverageReturn    | 298           |
| Policy-MaxReturn        | 376           |
| Policy-MinReturn        | 158           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 63            |
| Policy-TimeAlgoOpt      | 0.566         |
| Policy-TimeSampleProc   | 0.452         |
| Policy-TimeSampling     | 1.6           |
| Policy-TimeStep         | 2.66          |
| Time                    | 1.52e+03      |
| n_timesteps             | 49000         |
-------------------------------------------

 ---------------- Iteration 49 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 490 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 491 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 492 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 493 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 494 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 495 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 496 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 497 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 498 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 499 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.313          |
| Data-EnvSampler-Poli... | 0.676          |
| Data-EnvTrajs-Averag... | 281            |
| Data-EnvTrajs-MaxReturn | 330            |
| Data-EnvTrajs-MinReturn | 226            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 40.7           |
| Data-TimeEnvSampleProc  | 0.000617       |
| Data-TimeEnvSampling    | 1.02           |
| Iteration               | 49             |
| ItrTime                 | 36.1           |
| LossAfter               | -0.013308622   |
| LossBefore              | -3.7363604e-06 |
| Model-TimeModelFit      | 32.1           |
| ModelSampler-n_times... | 2000000        |
| Policy-AverageAbsPol... | 0.7508959      |
| Policy-AverageDiscou... | 96             |
| Policy-AveragePolicyStd | 0.35311466     |
| Policy-AverageReturn    | 244            |
| Policy-MaxReturn        | 330            |
| Policy-MinReturn        | 187            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 36.6           |
| Policy-TimeAlgoOpt      | 0.655          |
| Policy-TimeSampleProc   | 0.512          |
| Policy-TimeSampling     | 1.83           |
| Policy-TimeStep         | 3.03           |
| Time                    | 1.56e+03       |
| n_timesteps             | 50000          |
--------------------------------------------

 ---------------- Iteration 50 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 500 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 501 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 502 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 503 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 504 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 505 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 506 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 507 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 508 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 509 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.285         |
| Data-EnvSampler-Poli... | 0.628         |
| Data-EnvTrajs-Averag... | 273           |
| Data-EnvTrajs-MaxReturn | 331           |
| Data-EnvTrajs-MinReturn | 233           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 33            |
| Data-TimeEnvSampleProc  | 0.00104       |
| Data-TimeEnvSampling    | 0.943         |
| Iteration               | 50            |
| ItrTime                 | 31.2          |
| LossAfter               | -0.018825023  |
| LossBefore              | -3.652078e-06 |
| Model-TimeModelFit      | 28            |
| ModelSampler-n_times... | 2040000       |
| Policy-AverageAbsPol... | 0.7798513     |
| Policy-AverageDiscou... | 104           |
| Policy-AveragePolicyStd | 0.34918857    |
| Policy-AverageReturn    | 285           |
| Policy-MaxReturn        | 359           |
| Policy-MinReturn        | 221           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 35            |
| Policy-TimeAlgoOpt      | 0.554         |
| Policy-TimeSampleProc   | 0.222         |
| Policy-TimeSampling     | 1.54          |
| Policy-TimeStep         | 2.33          |
| Time                    | 1.59e+03      |
| n_timesteps             | 51000         |
-------------------------------------------
Training finished
