Logging to /home/vincent/workplace/CS_287_-_Advanced_Robotics/homework/hw5/cs287hw5/ppo/run_scripts/data/parallel_mb_ppo/mbppo_HalfCheetah//00

 ---------------- Iteration 0 ----------------
Obtaining random samples from the environment...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 0 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 1 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 2 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 3 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 4 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 5 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 6 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 7 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 8 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 9 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.123          |
| Data-EnvSampler-Poli... | 0.0384         |
| Data-EnvTrajs-Averag... | -60.2          |
| Data-EnvTrajs-MaxReturn | -18.6          |
| Data-EnvTrajs-MinReturn | -80.5          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 22             |
| Data-TimeEnvSampleProc  | 0.00048        |
| Data-TimeEnvSampling    | 0.171          |
| Iteration               | 0              |
| ItrTime                 | 8.53           |
| LossAfter               | -0.015726486   |
| LossBefore              | -1.4124934e-05 |
| Model-TimeModelFit      | 2.82           |
| ModelSampler-n_times... | 40000          |
| Policy-AverageAbsPol... | 0.86112255     |
| Policy-AverageDiscou... | 4.59e+03       |
| Policy-AveragePolicyStd | 0.99305356     |
| Policy-AverageReturn    | 1.33e+04       |
| Policy-MaxReturn        | 1.66e+04       |
| Policy-MinReturn        | 1.24e+03       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 5.9e+03        |
| Policy-TimeAlgoOpt      | 0.958          |
| Policy-TimeSampleProc   | 0.477          |
| Policy-TimeSampling     | 4.06           |
| Policy-TimeStep         | 5.53           |
| Time                    | 8.53           |
| n_timesteps             | 1000           |
--------------------------------------------

 ---------------- Iteration 1 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 10 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 11 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 12 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 13 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 14 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 15 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 16 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 17 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 18 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 19 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.228          |
| Data-EnvSampler-Poli... | 0.626          |
| Data-EnvTrajs-Averag... | -21.4          |
| Data-EnvTrajs-MaxReturn | 22.7           |
| Data-EnvTrajs-MinReturn | -66            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 37.1           |
| Data-TimeEnvSampleProc  | 0.000901       |
| Data-TimeEnvSampling    | 0.877          |
| Iteration               | 1              |
| ItrTime                 | 7.92           |
| LossAfter               | -0.013467725   |
| LossBefore              | -1.3953808e-05 |
| Model-TimeModelFit      | 4.15           |
| ModelSampler-n_times... | 80000          |
| Policy-AverageAbsPol... | 0.6865999      |
| Policy-AverageDiscou... | -99.2          |
| Policy-AveragePolicyStd | 0.97836816     |
| Policy-AverageReturn    | -293           |
| Policy-MaxReturn        | -114           |
| Policy-MinReturn        | -3e+03         |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 622            |
| Policy-TimeAlgoOpt      | 0.646          |
| Policy-TimeSampleProc   | 0.515          |
| Policy-TimeSampling     | 1.7            |
| Policy-TimeStep         | 2.89           |
| Time                    | 16.6           |
| n_timesteps             | 2000           |
--------------------------------------------

 ---------------- Iteration 2 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 20 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 21 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 22 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 23 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 24 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 25 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 26 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 27 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 28 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 29 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.258           |
| Data-EnvSampler-Poli... | 0.562           |
| Data-EnvTrajs-Averag... | -58.1           |
| Data-EnvTrajs-MaxReturn | -34.3           |
| Data-EnvTrajs-MinReturn | -91.1           |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 19.4            |
| Data-TimeEnvSampleProc  | 0.000935        |
| Data-TimeEnvSampling    | 0.846           |
| Iteration               | 2               |
| ItrTime                 | 10.3            |
| LossAfter               | -0.013548619    |
| LossBefore              | -1.35815435e-05 |
| Model-TimeModelFit      | 6.6             |
| ModelSampler-n_times... | 120000          |
| Policy-AverageAbsPol... | 0.55421865      |
| Policy-AverageDiscou... | -35.8           |
| Policy-AveragePolicyStd | 0.94093215      |
| Policy-AverageReturn    | -84.6           |
| Policy-MaxReturn        | -49.9           |
| Policy-MinReturn        | -127            |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 25.2            |
| Policy-TimeAlgoOpt      | 0.633           |
| Policy-TimeSampleProc   | 0.395           |
| Policy-TimeSampling     | 1.83            |
| Policy-TimeStep         | 2.88            |
| Time                    | 26.9            |
| n_timesteps             | 3000            |
---------------------------------------------

 ---------------- Iteration 3 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 30 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 31 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 32 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 33 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 34 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 35 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 36 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 37 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 38 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 39 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.276          |
| Data-EnvSampler-Poli... | 0.566          |
| Data-EnvTrajs-Averag... | -78.8          |
| Data-EnvTrajs-MaxReturn | -52.1          |
| Data-EnvTrajs-MinReturn | -108           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 20.9           |
| Data-TimeEnvSampleProc  | 0.000911       |
| Data-TimeEnvSampling    | 0.875          |
| Iteration               | 3              |
| ItrTime                 | 13.1           |
| LossAfter               | -0.015996922   |
| LossBefore              | -1.3266205e-05 |
| Model-TimeModelFit      | 9.13           |
| ModelSampler-n_times... | 160000         |
| Policy-AverageAbsPol... | 0.6403927      |
| Policy-AverageDiscou... | -369           |
| Policy-AveragePolicyStd | 0.9129274      |
| Policy-AverageReturn    | -1.54e+03      |
| Policy-MaxReturn        | -31.2          |
| Policy-MinReturn        | -4.25e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.4e+03        |
| Policy-TimeAlgoOpt      | 0.54           |
| Policy-TimeSampleProc   | 0.589          |
| Policy-TimeSampling     | 1.91           |
| Policy-TimeStep         | 3.08           |
| Time                    | 40             |
| n_timesteps             | 4000           |
--------------------------------------------

 ---------------- Iteration 4 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 40 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 41 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 42 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 43 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 44 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 45 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 46 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 47 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 48 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 49 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.273          |
| Data-EnvSampler-Poli... | 0.602          |
| Data-EnvTrajs-Averag... | -57.3          |
| Data-EnvTrajs-MaxReturn | 10.4           |
| Data-EnvTrajs-MinReturn | -135           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 59.4           |
| Data-TimeEnvSampleProc  | 0.000978       |
| Data-TimeEnvSampling    | 0.905          |
| Iteration               | 4              |
| ItrTime                 | 14.4           |
| LossAfter               | -0.015527888   |
| LossBefore              | -1.3165276e-05 |
| Model-TimeModelFit      | 11             |
| ModelSampler-n_times... | 200000         |
| Policy-AverageAbsPol... | 0.63981134     |
| Policy-AverageDiscou... | -205           |
| Policy-AveragePolicyStd | 0.904024       |
| Policy-AverageReturn    | -487           |
| Policy-MaxReturn        | -414           |
| Policy-MinReturn        | -576           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 39.2           |
| Policy-TimeAlgoOpt      | 0.602          |
| Policy-TimeSampleProc   | 0.381          |
| Policy-TimeSampling     | 1.43           |
| Policy-TimeStep         | 2.47           |
| Time                    | 54.4           |
| n_timesteps             | 5000           |
--------------------------------------------

 ---------------- Iteration 5 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 50 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 51 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 52 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 53 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 54 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 55 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 56 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 57 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 58 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 59 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.291           |
| Data-EnvSampler-Poli... | 0.598           |
| Data-EnvTrajs-Averag... | -58.4           |
| Data-EnvTrajs-MaxReturn | -1.38           |
| Data-EnvTrajs-MinReturn | -177            |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 65.6            |
| Data-TimeEnvSampleProc  | 0.00101         |
| Data-TimeEnvSampling    | 0.918           |
| Iteration               | 5               |
| ItrTime                 | 16.7            |
| LossAfter               | -0.017281       |
| LossBefore              | -1.31088755e-05 |
| Model-TimeModelFit      | 13.2            |
| ModelSampler-n_times... | 240000          |
| Policy-AverageAbsPol... | 0.7152017       |
| Policy-AverageDiscou... | -404            |
| Policy-AveragePolicyStd | 0.8990078       |
| Policy-AverageReturn    | -1.37e+03       |
| Policy-MaxReturn        | -459            |
| Policy-MinReturn        | -4.06e+03       |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 1.18e+03        |
| Policy-TimeAlgoOpt      | 0.589           |
| Policy-TimeSampleProc   | 0.411           |
| Policy-TimeSampling     | 1.55            |
| Policy-TimeStep         | 2.58            |
| Time                    | 71.2            |
| n_timesteps             | 6000            |
---------------------------------------------

 ---------------- Iteration 6 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 60 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 61 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 62 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 63 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 64 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 65 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 66 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 67 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 68 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 69 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.277          |
| Data-EnvSampler-Poli... | 0.618          |
| Data-EnvTrajs-Averag... | -46.9          |
| Data-EnvTrajs-MaxReturn | -33            |
| Data-EnvTrajs-MinReturn | -68.9          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 13             |
| Data-TimeEnvSampleProc  | 0.00254        |
| Data-TimeEnvSampling    | 0.925          |
| Iteration               | 6              |
| ItrTime                 | 19.4           |
| LossAfter               | -0.01651069    |
| LossBefore              | -1.3065055e-05 |
| Model-TimeModelFit      | 15.8           |
| ModelSampler-n_times... | 280000         |
| Policy-AverageAbsPol... | 0.6506951      |
| Policy-AverageDiscou... | -89.4          |
| Policy-AveragePolicyStd | 0.8936634      |
| Policy-AverageReturn    | -262           |
| Policy-MaxReturn        | -117           |
| Policy-MinReturn        | -2.47e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 507            |
| Policy-TimeAlgoOpt      | 0.669          |
| Policy-TimeSampleProc   | 0.446          |
| Policy-TimeSampling     | 1.51           |
| Policy-TimeStep         | 2.66           |
| Time                    | 90.6           |
| n_timesteps             | 7000           |
--------------------------------------------

 ---------------- Iteration 7 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 70 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 71 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 72 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 73 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 74 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 75 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 76 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 77 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 78 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 79 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.395          |
| Data-EnvSampler-Poli... | 0.932          |
| Data-EnvTrajs-Averag... | -60.7          |
| Data-EnvTrajs-MaxReturn | -48.7          |
| Data-EnvTrajs-MinReturn | -79.6          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 13.9           |
| Data-TimeEnvSampleProc  | 0.00144        |
| Data-TimeEnvSampling    | 1.37           |
| Iteration               | 7              |
| ItrTime                 | 21.7           |
| LossAfter               | -0.015358522   |
| LossBefore              | -1.2723018e-05 |
| Model-TimeModelFit      | 17.6           |
| ModelSampler-n_times... | 320000         |
| Policy-AverageAbsPol... | 0.6360144      |
| Policy-AverageDiscou... | -73.1          |
| Policy-AveragePolicyStd | 0.86487436     |
| Policy-AverageReturn    | -171           |
| Policy-MaxReturn        | -98.1          |
| Policy-MinReturn        | -204           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 23.9           |
| Policy-TimeAlgoOpt      | 0.612          |
| Policy-TimeSampleProc   | 0.349          |
| Policy-TimeSampling     | 1.72           |
| Policy-TimeStep         | 2.72           |
| Time                    | 112            |
| n_timesteps             | 8000           |
--------------------------------------------

 ---------------- Iteration 8 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 80 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 81 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 82 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 83 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 84 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 85 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 86 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 87 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 88 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 89 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.279          |
| Data-EnvSampler-Poli... | 0.677          |
| Data-EnvTrajs-Averag... | -29            |
| Data-EnvTrajs-MaxReturn | 4.27           |
| Data-EnvTrajs-MinReturn | -57.9          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 20.3           |
| Data-TimeEnvSampleProc  | 0.000905       |
| Data-TimeEnvSampling    | 0.987          |
| Iteration               | 8              |
| ItrTime                 | 24.4           |
| LossAfter               | -0.014152906   |
| LossBefore              | -1.2352832e-05 |
| Model-TimeModelFit      | 20.9           |
| ModelSampler-n_times... | 360000         |
| Policy-AverageAbsPol... | 0.57166857     |
| Policy-AverageDiscou... | 15.5           |
| Policy-AveragePolicyStd | 0.8320424      |
| Policy-AverageReturn    | 49.1           |
| Policy-MaxReturn        | 88.6           |
| Policy-MinReturn        | -8.27          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 22.2           |
| Policy-TimeAlgoOpt      | 0.549          |
| Policy-TimeSampleProc   | 0.43           |
| Policy-TimeSampling     | 1.48           |
| Policy-TimeStep         | 2.5            |
| Time                    | 137            |
| n_timesteps             | 9000           |
--------------------------------------------

 ---------------- Iteration 9 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 90 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 91 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 92 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 93 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 94 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 95 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 96 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 97 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 98 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 99 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.351         |
| Data-EnvSampler-Poli... | 0.967         |
| Data-EnvTrajs-Averag... | -51.2         |
| Data-EnvTrajs-MaxReturn | -23.6         |
| Data-EnvTrajs-MinReturn | -76.3         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 18.9          |
| Data-TimeEnvSampleProc  | 0.00109       |
| Data-TimeEnvSampling    | 1.36          |
| Iteration               | 9             |
| ItrTime                 | 26.7          |
| LossAfter               | -0.014608925  |
| LossBefore              | -1.208745e-05 |
| Model-TimeModelFit      | 22.8          |
| ModelSampler-n_times... | 400000        |
| Policy-AverageAbsPol... | 0.6049531     |
| Policy-AverageDiscou... | -51.3         |
| Policy-AveragePolicyStd | 0.8090925     |
| Policy-AverageReturn    | -114          |
| Policy-MaxReturn        | -66.4         |
| Policy-MinReturn        | -158          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 24.9          |
| Policy-TimeAlgoOpt      | 0.629         |
| Policy-TimeSampleProc   | 0.287         |
| Policy-TimeSampling     | 1.56          |
| Policy-TimeStep         | 2.49          |
| Time                    | 163           |
| n_timesteps             | 10000         |
-------------------------------------------

 ---------------- Iteration 10 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 100 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 101 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 102 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 103 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 104 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 105 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 106 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 107 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 108 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 109 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.296          |
| Data-EnvSampler-Poli... | 0.613          |
| Data-EnvTrajs-Averag... | 3.24           |
| Data-EnvTrajs-MaxReturn | 36.5           |
| Data-EnvTrajs-MinReturn | -44.9          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 30.6           |
| Data-TimeEnvSampleProc  | 0.000916       |
| Data-TimeEnvSampling    | 0.939          |
| Iteration               | 10             |
| ItrTime                 | 29.4           |
| LossAfter               | -0.016859898   |
| LossBefore              | -1.1859833e-05 |
| Model-TimeModelFit      | 25.5           |
| ModelSampler-n_times... | 440000         |
| Policy-AverageAbsPol... | 0.60366666     |
| Policy-AverageDiscou... | -53.4          |
| Policy-AveragePolicyStd | 0.79236615     |
| Policy-AverageReturn    | -125           |
| Policy-MaxReturn        | -58.1          |
| Policy-MinReturn        | -170           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 29.3           |
| Policy-TimeAlgoOpt      | 0.586          |
| Policy-TimeSampleProc   | 0.655          |
| Policy-TimeSampling     | 1.7            |
| Policy-TimeStep         | 3.01           |
| Time                    | 193            |
| n_timesteps             | 11000          |
--------------------------------------------

 ---------------- Iteration 11 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...
Stopping DynamicsEnsemble Training since valid_loss_rolling_average decreased

 ---------------- Grad-Step 110 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 111 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 112 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 113 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 114 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 115 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 116 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 117 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 118 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 119 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.367          |
| Data-EnvSampler-Poli... | 0.928          |
| Data-EnvTrajs-Averag... | -21.9          |
| Data-EnvTrajs-MaxReturn | -5.38          |
| Data-EnvTrajs-MinReturn | -44.6          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 15.2           |
| Data-TimeEnvSampleProc  | 0.00084        |
| Data-TimeEnvSampling    | 1.33           |
| Iteration               | 11             |
| ItrTime                 | 30.7           |
| LossAfter               | -0.021040577   |
| LossBefore              | -1.1772313e-05 |
| Model-TimeModelFit      | 26.3           |
| ModelSampler-n_times... | 480000         |
| Policy-AverageAbsPol... | 0.605701       |
| Policy-AverageDiscou... | 663            |
| Policy-AveragePolicyStd | 0.78495806     |
| Policy-AverageReturn    | 3.13e+03       |
| Policy-MaxReturn        | 4.7e+03        |
| Policy-MinReturn        | -437           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.08e+03       |
| Policy-TimeAlgoOpt      | 0.585          |
| Policy-TimeSampleProc   | 0.671          |
| Policy-TimeSampling     | 1.69           |
| Policy-TimeStep         | 3.04           |
| Time                    | 224            |
| n_timesteps             | 12000          |
--------------------------------------------

 ---------------- Iteration 12 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 120 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 121 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 122 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 123 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 124 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 125 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 126 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 127 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 128 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 129 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.328          |
| Data-EnvSampler-Poli... | 0.73           |
| Data-EnvTrajs-Averag... | -57.3          |
| Data-EnvTrajs-MaxReturn | -9.02          |
| Data-EnvTrajs-MinReturn | -92.6          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 32             |
| Data-TimeEnvSampleProc  | 0.00127        |
| Data-TimeEnvSampling    | 1.1            |
| Iteration               | 12             |
| ItrTime                 | 33.3           |
| LossAfter               | -0.01672019    |
| LossBefore              | -1.1508029e-05 |
| Model-TimeModelFit      | 28.9           |
| ModelSampler-n_times... | 520000         |
| Policy-AverageAbsPol... | 0.57508105     |
| Policy-AverageDiscou... | -17.7          |
| Policy-AveragePolicyStd | 0.7650342      |
| Policy-AverageReturn    | -42.5          |
| Policy-MaxReturn        | 15             |
| Policy-MinReturn        | -103           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 29.2           |
| Policy-TimeAlgoOpt      | 0.654          |
| Policy-TimeSampleProc   | 0.528          |
| Policy-TimeSampling     | 2.05           |
| Policy-TimeStep         | 3.34           |
| Time                    | 257            |
| n_timesteps             | 13000          |
--------------------------------------------

 ---------------- Iteration 13 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 130 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 131 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 132 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 133 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 134 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 135 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 136 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 137 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 138 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 139 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.373          |
| Data-EnvSampler-Poli... | 0.905          |
| Data-EnvTrajs-Averag... | -19.9          |
| Data-EnvTrajs-MaxReturn | 7.79           |
| Data-EnvTrajs-MinReturn | -46.6          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 19.9           |
| Data-TimeEnvSampleProc  | 0.00108        |
| Data-TimeEnvSampling    | 1.32           |
| Iteration               | 13             |
| ItrTime                 | 32.8           |
| LossAfter               | -0.014272634   |
| LossBefore              | -1.1156328e-05 |
| Model-TimeModelFit      | 28.3           |
| ModelSampler-n_times... | 560000         |
| Policy-AverageAbsPol... | 0.52950853     |
| Policy-AverageDiscou... | -23.3          |
| Policy-AveragePolicyStd | 0.73824024     |
| Policy-AverageReturn    | -67.2          |
| Policy-MaxReturn        | -32.5          |
| Policy-MinReturn        | -109           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 18.9           |
| Policy-TimeAlgoOpt      | 0.713          |
| Policy-TimeSampleProc   | 0.441          |
| Policy-TimeSampling     | 2.01           |
| Policy-TimeStep         | 3.22           |
| Time                    | 290            |
| n_timesteps             | 14000          |
--------------------------------------------

 ---------------- Iteration 14 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 140 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 141 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 142 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 143 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 144 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 145 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 146 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 147 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 148 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 149 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.334          |
| Data-EnvSampler-Poli... | 0.742          |
| Data-EnvTrajs-Averag... | -2.85          |
| Data-EnvTrajs-MaxReturn | 41.2           |
| Data-EnvTrajs-MinReturn | -36.9          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 28             |
| Data-TimeEnvSampleProc  | 0.000941       |
| Data-TimeEnvSampling    | 1.11           |
| Iteration               | 14             |
| ItrTime                 | 35.3           |
| LossAfter               | -0.016091608   |
| LossBefore              | -1.0929334e-05 |
| Model-TimeModelFit      | 31             |
| ModelSampler-n_times... | 600000         |
| Policy-AverageAbsPol... | 0.5489698      |
| Policy-AverageDiscou... | -26.8          |
| Policy-AveragePolicyStd | 0.7205454      |
| Policy-AverageReturn    | -65.1          |
| Policy-MaxReturn        | -30.9          |
| Policy-MinReturn        | -126           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 24.4           |
| Policy-TimeAlgoOpt      | 0.751          |
| Policy-TimeSampleProc   | 0.576          |
| Policy-TimeSampling     | 1.85           |
| Policy-TimeStep         | 3.23           |
| Time                    | 325            |
| n_timesteps             | 15000          |
--------------------------------------------

 ---------------- Iteration 15 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 150 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 151 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 152 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 153 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 154 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 155 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 156 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 157 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 158 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 159 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.319          |
| Data-EnvSampler-Poli... | 0.666          |
| Data-EnvTrajs-Averag... | 24.2           |
| Data-EnvTrajs-MaxReturn | 54.5           |
| Data-EnvTrajs-MinReturn | -8.78          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 22             |
| Data-TimeEnvSampleProc  | 0.001          |
| Data-TimeEnvSampling    | 1.02           |
| Iteration               | 15             |
| ItrTime                 | 32.1           |
| LossAfter               | -0.014193366   |
| LossBefore              | -1.0709341e-05 |
| Model-TimeModelFit      | 28.1           |
| ModelSampler-n_times... | 640000         |
| Policy-AverageAbsPol... | 0.5540557      |
| Policy-AverageDiscou... | -31.7          |
| Policy-AveragePolicyStd | 0.70562184     |
| Policy-AverageReturn    | -69            |
| Policy-MaxReturn        | -41.1          |
| Policy-MinReturn        | -113           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 17.9           |
| Policy-TimeAlgoOpt      | 0.535          |
| Policy-TimeSampleProc   | 0.716          |
| Policy-TimeSampling     | 1.69           |
| Policy-TimeStep         | 2.98           |
| Time                    | 357            |
| n_timesteps             | 16000          |
--------------------------------------------

 ---------------- Iteration 16 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 160 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 161 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 162 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 163 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 164 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 165 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 166 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 167 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 168 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 169 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.31           |
| Data-EnvSampler-Poli... | 0.612          |
| Data-EnvTrajs-Averag... | 5.25           |
| Data-EnvTrajs-MaxReturn | 34.9           |
| Data-EnvTrajs-MinReturn | -24.5          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 22.2           |
| Data-TimeEnvSampleProc  | 0.000642       |
| Data-TimeEnvSampling    | 0.953          |
| Iteration               | 16             |
| ItrTime                 | 32.7           |
| LossAfter               | -0.015730908   |
| LossBefore              | -1.0332094e-05 |
| Model-TimeModelFit      | 28.4           |
| ModelSampler-n_times... | 680000         |
| Policy-AverageAbsPol... | 0.5493111      |
| Policy-AverageDiscou... | 16.6           |
| Policy-AveragePolicyStd | 0.6804691      |
| Policy-AverageReturn    | 31.8           |
| Policy-MaxReturn        | 65.8           |
| Policy-MinReturn        | -11.5          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 24.1           |
| Policy-TimeAlgoOpt      | 0.75           |
| Policy-TimeSampleProc   | 0.516          |
| Policy-TimeSampling     | 2.04           |
| Policy-TimeStep         | 3.36           |
| Time                    | 390            |
| n_timesteps             | 17000          |
--------------------------------------------

 ---------------- Iteration 17 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 170 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 171 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 172 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 173 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 174 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 175 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 176 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 177 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 178 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 179 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.332          |
| Data-EnvSampler-Poli... | 0.693          |
| Data-EnvTrajs-Averag... | -8.26          |
| Data-EnvTrajs-MaxReturn | 26.6           |
| Data-EnvTrajs-MinReturn | -32.4          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 21.2           |
| Data-TimeEnvSampleProc  | 0.001          |
| Data-TimeEnvSampling    | 1.06           |
| Iteration               | 17             |
| ItrTime                 | 31             |
| LossAfter               | -0.016468126   |
| LossBefore              | -1.0059233e-05 |
| Model-TimeModelFit      | 26.9           |
| ModelSampler-n_times... | 720000         |
| Policy-AverageAbsPol... | 0.5587931      |
| Policy-AverageDiscou... | -42.6          |
| Policy-AveragePolicyStd | 0.66237134     |
| Policy-AverageReturn    | -94.8          |
| Policy-MaxReturn        | -24.8          |
| Policy-MinReturn        | -155           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 36.9           |
| Policy-TimeAlgoOpt      | 0.63           |
| Policy-TimeSampleProc   | 0.624          |
| Policy-TimeSampling     | 1.76           |
| Policy-TimeStep         | 3.06           |
| Time                    | 421            |
| n_timesteps             | 18000          |
--------------------------------------------

 ---------------- Iteration 18 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 180 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 181 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 182 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 183 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 184 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 185 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 186 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 187 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 188 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 189 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.322         |
| Data-EnvSampler-Poli... | 0.635         |
| Data-EnvTrajs-Averag... | 2.73          |
| Data-EnvTrajs-MaxReturn | 64            |
| Data-EnvTrajs-MinReturn | -75.3         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 47.7          |
| Data-TimeEnvSampleProc  | 0.00119       |
| Data-TimeEnvSampling    | 0.989         |
| Iteration               | 18            |
| ItrTime                 | 33.7          |
| LossAfter               | -0.016949145  |
| LossBefore              | -9.832829e-06 |
| Model-TimeModelFit      | 29.7          |
| ModelSampler-n_times... | 760000        |
| Policy-AverageAbsPol... | 0.52831054    |
| Policy-AverageDiscou... | -4.76         |
| Policy-AveragePolicyStd | 0.6441296     |
| Policy-AverageReturn    | -28.4         |
| Policy-MaxReturn        | 1.27          |
| Policy-MinReturn        | -67.5         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 18.3          |
| Policy-TimeAlgoOpt      | 0.66          |
| Policy-TimeSampleProc   | 0.408         |
| Policy-TimeSampling     | 1.78          |
| Policy-TimeStep         | 2.93          |
| Time                    | 455           |
| n_timesteps             | 19000         |
-------------------------------------------

 ---------------- Iteration 19 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 190 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 191 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 192 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 193 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 194 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 195 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 196 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 197 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 198 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 199 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.312         |
| Data-EnvSampler-Poli... | 0.667         |
| Data-EnvTrajs-Averag... | 16.8          |
| Data-EnvTrajs-MaxReturn | 71.1          |
| Data-EnvTrajs-MinReturn | -44.7         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 41.9          |
| Data-TimeEnvSampleProc  | 0.000962      |
| Data-TimeEnvSampling    | 1.01          |
| Iteration               | 19            |
| ItrTime                 | 31.9          |
| LossAfter               | -0.0170084    |
| LossBefore              | -9.574231e-06 |
| Model-TimeModelFit      | 27.5          |
| ModelSampler-n_times... | 800000        |
| Policy-AverageAbsPol... | 0.54616344    |
| Policy-AverageDiscou... | -0.627        |
| Policy-AveragePolicyStd | 0.630578      |
| Policy-AverageReturn    | 0.829         |
| Policy-MaxReturn        | 51            |
| Policy-MinReturn        | -46.5         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 23.4          |
| Policy-TimeAlgoOpt      | 0.644         |
| Policy-TimeSampleProc   | 0.834         |
| Policy-TimeSampling     | 1.94          |
| Policy-TimeStep         | 3.48          |
| Time                    | 487           |
| n_timesteps             | 20000         |
-------------------------------------------

 ---------------- Iteration 20 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 200 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 201 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 202 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 203 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 204 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 205 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 206 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 207 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 208 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 209 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.327         |
| Data-EnvSampler-Poli... | 0.722         |
| Data-EnvTrajs-Averag... | 52.6          |
| Data-EnvTrajs-MaxReturn | 106           |
| Data-EnvTrajs-MinReturn | -23           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 44.6          |
| Data-TimeEnvSampleProc  | 0.000527      |
| Data-TimeEnvSampling    | 1.08          |
| Iteration               | 20            |
| ItrTime                 | 33.3          |
| LossAfter               | -0.016033255  |
| LossBefore              | -9.316783e-06 |
| Model-TimeModelFit      | 29.4          |
| ModelSampler-n_times... | 840000        |
| Policy-AverageAbsPol... | 0.52944183    |
| Policy-AverageDiscou... | 1.9           |
| Policy-AveragePolicyStd | 0.6149578     |
| Policy-AverageReturn    | 2.89          |
| Policy-MaxReturn        | 58.8          |
| Policy-MinReturn        | -57.9         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 27.1          |
| Policy-TimeAlgoOpt      | 0.647         |
| Policy-TimeSampleProc   | 0.378         |
| Policy-TimeSampling     | 1.71          |
| Policy-TimeStep         | 2.78          |
| Time                    | 520           |
| n_timesteps             | 21000         |
-------------------------------------------

 ---------------- Iteration 21 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 210 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 211 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 212 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 213 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 214 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 215 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 216 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 217 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 218 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 219 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.292         |
| Data-EnvSampler-Poli... | 0.66          |
| Data-EnvTrajs-Averag... | 41            |
| Data-EnvTrajs-MaxReturn | 122           |
| Data-EnvTrajs-MinReturn | -8.63         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 45.5          |
| Data-TimeEnvSampleProc  | 0.000927      |
| Data-TimeEnvSampling    | 0.982         |
| Iteration               | 21            |
| ItrTime                 | 33.8          |
| LossAfter               | -0.014971563  |
| LossBefore              | -9.156556e-06 |
| Model-TimeModelFit      | 30.2          |
| ModelSampler-n_times... | 880000        |
| Policy-AverageAbsPol... | 0.5153568     |
| Policy-AverageDiscou... | -38.4         |
| Policy-AveragePolicyStd | 0.60502636    |
| Policy-AverageReturn    | -94.5         |
| Policy-MaxReturn        | -37.6         |
| Policy-MinReturn        | -149          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 25.8          |
| Policy-TimeAlgoOpt      | 0.626         |
| Policy-TimeSampleProc   | 0.389         |
| Policy-TimeSampling     | 1.54          |
| Policy-TimeStep         | 2.61          |
| Time                    | 554           |
| n_timesteps             | 22000         |
-------------------------------------------

 ---------------- Iteration 22 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 220 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 221 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 222 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 223 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 224 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 225 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 226 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 227 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 228 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 229 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.304         |
| Data-EnvSampler-Poli... | 0.64          |
| Data-EnvTrajs-Averag... | 44.2          |
| Data-EnvTrajs-MaxReturn | 68.9          |
| Data-EnvTrajs-MinReturn | 28.4          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 13.5          |
| Data-TimeEnvSampleProc  | 0.000963      |
| Data-TimeEnvSampling    | 0.973         |
| Iteration               | 22            |
| ItrTime                 | 35.6          |
| LossAfter               | -0.015697436  |
| LossBefore              | -8.896748e-06 |
| Model-TimeModelFit      | 30.8          |
| ModelSampler-n_times... | 920000        |
| Policy-AverageAbsPol... | 0.46888843    |
| Policy-AverageDiscou... | -5.82         |
| Policy-AveragePolicyStd | 0.589961      |
| Policy-AverageReturn    | -14.9         |
| Policy-MaxReturn        | 32.4          |
| Policy-MinReturn        | -77.5         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 24.1          |
| Policy-TimeAlgoOpt      | 0.656         |
| Policy-TimeSampleProc   | 0.677         |
| Policy-TimeSampling     | 2.37          |
| Policy-TimeStep         | 3.75          |
| Time                    | 589           |
| n_timesteps             | 23000         |
-------------------------------------------

 ---------------- Iteration 23 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 230 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 231 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 232 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 233 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 234 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 235 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 236 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 237 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 238 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 239 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.431         |
| Data-EnvSampler-Poli... | 1.17          |
| Data-EnvTrajs-Averag... | 20.1          |
| Data-EnvTrajs-MaxReturn | 55            |
| Data-EnvTrajs-MinReturn | -10.7         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 23.6          |
| Data-TimeEnvSampleProc  | 0.00109       |
| Data-TimeEnvSampling    | 1.65          |
| Iteration               | 23            |
| ItrTime                 | 34.2          |
| LossAfter               | -0.01792522   |
| LossBefore              | -8.598688e-06 |
| Model-TimeModelFit      | 29.4          |
| ModelSampler-n_times... | 960000        |
| Policy-AverageAbsPol... | 0.4940879     |
| Policy-AverageDiscou... | 24            |
| Policy-AveragePolicyStd | 0.5727555     |
| Policy-AverageReturn    | 63.1          |
| Policy-MaxReturn        | 121           |
| Policy-MinReturn        | -3.4          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 29            |
| Policy-TimeAlgoOpt      | 0.628         |
| Policy-TimeSampleProc   | 0.619         |
| Policy-TimeSampling     | 1.88          |
| Policy-TimeStep         | 3.18          |
| Time                    | 624           |
| n_timesteps             | 24000         |
-------------------------------------------

 ---------------- Iteration 24 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 240 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 241 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 242 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 243 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 244 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 245 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 246 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 247 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 248 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 249 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.418         |
| Data-EnvSampler-Poli... | 0.919         |
| Data-EnvTrajs-Averag... | 0.101         |
| Data-EnvTrajs-MaxReturn | 52.9          |
| Data-EnvTrajs-MinReturn | -76.8         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 48.6          |
| Data-TimeEnvSampleProc  | 0.0015        |
| Data-TimeEnvSampling    | 1.38          |
| Iteration               | 24            |
| ItrTime                 | 39.2          |
| LossAfter               | -0.017637327  |
| LossBefore              | -8.360765e-06 |
| Model-TimeModelFit      | 34.7          |
| ModelSampler-n_times... | 1000000       |
| Policy-AverageAbsPol... | 0.4770415     |
| Policy-AverageDiscou... | -16.4         |
| Policy-AveragePolicyStd | 0.5597223     |
| Policy-AverageReturn    | -64.3         |
| Policy-MaxReturn        | -34.2         |
| Policy-MinReturn        | -105          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 18.5          |
| Policy-TimeAlgoOpt      | 0.654         |
| Policy-TimeSampleProc   | 0.619         |
| Policy-TimeSampling     | 1.83          |
| Policy-TimeStep         | 3.15          |
| Time                    | 663           |
| n_timesteps             | 25000         |
-------------------------------------------

 ---------------- Iteration 25 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 250 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 251 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 252 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 253 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 254 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 255 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 256 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 257 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 258 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 259 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.353          |
| Data-EnvSampler-Poli... | 0.773          |
| Data-EnvTrajs-Averag... | 19             |
| Data-EnvTrajs-MaxReturn | 64             |
| Data-EnvTrajs-MinReturn | -20.6          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 26.9           |
| Data-TimeEnvSampleProc  | 0.00106        |
| Data-TimeEnvSampling    | 1.16           |
| Iteration               | 25             |
| ItrTime                 | 35.4           |
| LossAfter               | -0.013106871   |
| LossBefore              | -8.2220495e-06 |
| Model-TimeModelFit      | 31.6           |
| ModelSampler-n_times... | 1040000        |
| Policy-AverageAbsPol... | 0.51245713     |
| Policy-AverageDiscou... | -15.4          |
| Policy-AveragePolicyStd | 0.5523454      |
| Policy-AverageReturn    | -36.2          |
| Policy-MaxReturn        | 42.6           |
| Policy-MinReturn        | -109           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 37.9           |
| Policy-TimeAlgoOpt      | 0.615          |
| Policy-TimeSampleProc   | 0.398          |
| Policy-TimeSampling     | 1.56           |
| Policy-TimeStep         | 2.6            |
| Time                    | 698            |
| n_timesteps             | 26000          |
--------------------------------------------

 ---------------- Iteration 26 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 260 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 261 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 262 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 263 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 264 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 265 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 266 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 267 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 268 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 269 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.294         |
| Data-EnvSampler-Poli... | 0.596         |
| Data-EnvTrajs-Averag... | 57.7          |
| Data-EnvTrajs-MaxReturn | 92.9          |
| Data-EnvTrajs-MinReturn | 40.3          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 19.2          |
| Data-TimeEnvSampleProc  | 0.000856      |
| Data-TimeEnvSampling    | 0.921         |
| Iteration               | 26            |
| ItrTime                 | 33.6          |
| LossAfter               | -0.020188708  |
| LossBefore              | -8.040717e-06 |
| Model-TimeModelFit      | 29.7          |
| ModelSampler-n_times... | 1080000       |
| Policy-AverageAbsPol... | 0.507387      |
| Policy-AverageDiscou... | 18.8          |
| Policy-AveragePolicyStd | 0.5426653     |
| Policy-AverageReturn    | 45.7          |
| Policy-MaxReturn        | 132           |
| Policy-MinReturn        | -25.7         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 35.6          |
| Policy-TimeAlgoOpt      | 0.612         |
| Policy-TimeSampleProc   | 0.587         |
| Policy-TimeSampling     | 1.77          |
| Policy-TimeStep         | 3             |
| Time                    | 732           |
| n_timesteps             | 27000         |
-------------------------------------------

 ---------------- Iteration 27 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 270 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 271 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 272 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 273 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 274 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 275 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 276 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 277 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 278 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 279 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.281         |
| Data-EnvSampler-Poli... | 0.573         |
| Data-EnvTrajs-Averag... | 45.6          |
| Data-EnvTrajs-MaxReturn | 74.1          |
| Data-EnvTrajs-MinReturn | 35.9          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 14.4          |
| Data-TimeEnvSampleProc  | 0.00132       |
| Data-TimeEnvSampling    | 0.883         |
| Iteration               | 27            |
| ItrTime                 | 34.3          |
| LossAfter               | -0.017797137  |
| LossBefore              | -7.816975e-06 |
| Model-TimeModelFit      | 30.8          |
| ModelSampler-n_times... | 1120000       |
| Policy-AverageAbsPol... | 0.51060957    |
| Policy-AverageDiscou... | -11.1         |
| Policy-AveragePolicyStd | 0.5317736     |
| Policy-AverageReturn    | -28.8         |
| Policy-MaxReturn        | -2.17         |
| Policy-MinReturn        | -65.4         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 18.6          |
| Policy-TimeAlgoOpt      | 0.572         |
| Policy-TimeSampleProc   | 0.435         |
| Policy-TimeSampling     | 1.6           |
| Policy-TimeStep         | 2.63          |
| Time                    | 766           |
| n_timesteps             | 28000         |
-------------------------------------------

 ---------------- Iteration 28 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 280 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 281 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 282 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 283 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 284 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 285 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 286 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 287 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 288 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 289 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.294         |
| Data-EnvSampler-Poli... | 0.588         |
| Data-EnvTrajs-Averag... | 33.6          |
| Data-EnvTrajs-MaxReturn | 109           |
| Data-EnvTrajs-MinReturn | -7.54         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 41.6          |
| Data-TimeEnvSampleProc  | 0.000723      |
| Data-TimeEnvSampling    | 0.911         |
| Iteration               | 28            |
| ItrTime                 | 33.9          |
| LossAfter               | -0.017602606  |
| LossBefore              | -7.655398e-06 |
| Model-TimeModelFit      | 30.3          |
| ModelSampler-n_times... | 1160000       |
| Policy-AverageAbsPol... | 0.5375611     |
| Policy-AverageDiscou... | 36.4          |
| Policy-AveragePolicyStd | 0.52299553    |
| Policy-AverageReturn    | 95.7          |
| Policy-MaxReturn        | 145           |
| Policy-MinReturn        | 27.1          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 29.6          |
| Policy-TimeAlgoOpt      | 0.65          |
| Policy-TimeSampleProc   | 0.365         |
| Policy-TimeSampling     | 1.71          |
| Policy-TimeStep         | 2.77          |
| Time                    | 800           |
| n_timesteps             | 29000         |
-------------------------------------------

 ---------------- Iteration 29 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 290 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 291 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 292 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 293 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 294 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 295 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 296 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 297 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 298 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 299 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.333          |
| Data-EnvSampler-Poli... | 0.712          |
| Data-EnvTrajs-Averag... | 89.9           |
| Data-EnvTrajs-MaxReturn | 144            |
| Data-EnvTrajs-MinReturn | 43.3           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 38.8           |
| Data-TimeEnvSampleProc  | 0.00105        |
| Data-TimeEnvSampling    | 1.08           |
| Iteration               | 29             |
| ItrTime                 | 34.3           |
| LossAfter               | -0.016176233   |
| LossBefore              | -7.4206973e-06 |
| Model-TimeModelFit      | 30.5           |
| ModelSampler-n_times... | 1200000        |
| Policy-AverageAbsPol... | 0.5504092      |
| Policy-AverageDiscou... | 26.5           |
| Policy-AveragePolicyStd | 0.51183766     |
| Policy-AverageReturn    | 65.3           |
| Policy-MaxReturn        | 99.1           |
| Policy-MinReturn        | 6.6            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 24.3           |
| Policy-TimeAlgoOpt      | 0.627          |
| Policy-TimeSampleProc   | 0.461          |
| Policy-TimeSampling     | 1.59           |
| Policy-TimeStep         | 2.71           |
| Time                    | 834            |
| n_timesteps             | 30000          |
--------------------------------------------

 ---------------- Iteration 30 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 300 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 301 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 302 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 303 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 304 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 305 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 306 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 307 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 308 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 309 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.329          |
| Data-EnvSampler-Poli... | 0.705          |
| Data-EnvTrajs-Averag... | 111            |
| Data-EnvTrajs-MaxReturn | 156            |
| Data-EnvTrajs-MinReturn | 87.5           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 29             |
| Data-TimeEnvSampleProc  | 0.000606       |
| Data-TimeEnvSampling    | 1.07           |
| Iteration               | 30             |
| ItrTime                 | 35.2           |
| LossAfter               | -0.018271381   |
| LossBefore              | -7.2800476e-06 |
| Model-TimeModelFit      | 31.2           |
| ModelSampler-n_times... | 1240000        |
| Policy-AverageAbsPol... | 0.5695796      |
| Policy-AverageDiscou... | 28.2           |
| Policy-AveragePolicyStd | 0.5043599      |
| Policy-AverageReturn    | 75.9           |
| Policy-MaxReturn        | 117            |
| Policy-MinReturn        | -0.621         |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 29.7           |
| Policy-TimeAlgoOpt      | 0.617          |
| Policy-TimeSampleProc   | 0.583          |
| Policy-TimeSampling     | 1.73           |
| Policy-TimeStep         | 2.99           |
| Time                    | 870            |
| n_timesteps             | 31000          |
--------------------------------------------

 ---------------- Iteration 31 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 310 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 311 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 312 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 313 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 314 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 315 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 316 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 317 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 318 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 319 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.324          |
| Data-EnvSampler-Poli... | 0.733          |
| Data-EnvTrajs-Averag... | 109            |
| Data-EnvTrajs-MaxReturn | 135            |
| Data-EnvTrajs-MinReturn | 89.5           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 15.7           |
| Data-TimeEnvSampleProc  | 0.000796       |
| Data-TimeEnvSampling    | 1.09           |
| Iteration               | 31             |
| ItrTime                 | 34.5           |
| LossAfter               | -0.019314306   |
| LossBefore              | -7.1702307e-06 |
| Model-TimeModelFit      | 30.3           |
| ModelSampler-n_times... | 1280000        |
| Policy-AverageAbsPol... | 0.60479575     |
| Policy-AverageDiscou... | 21             |
| Policy-AveragePolicyStd | 0.4985623      |
| Policy-AverageReturn    | 51.5           |
| Policy-MaxReturn        | 140            |
| Policy-MinReturn        | -71.3          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 49.9           |
| Policy-TimeAlgoOpt      | 0.64           |
| Policy-TimeSampleProc   | 0.609          |
| Policy-TimeSampling     | 1.8            |
| Policy-TimeStep         | 3.07           |
| Time                    | 904            |
| n_timesteps             | 32000          |
--------------------------------------------

 ---------------- Iteration 32 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 320 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 321 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 322 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 323 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 324 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 325 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 326 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 327 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 328 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 329 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.336          |
| Data-EnvSampler-Poli... | 0.937          |
| Data-EnvTrajs-Averag... | 111            |
| Data-EnvTrajs-MaxReturn | 167            |
| Data-EnvTrajs-MinReturn | 88.3           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 29.2           |
| Data-TimeEnvSampleProc  | 0.00175        |
| Data-TimeEnvSampling    | 1.32           |
| Iteration               | 32             |
| ItrTime                 | 35.4           |
| LossAfter               | -0.01776706    |
| LossBefore              | -6.9660646e-06 |
| Model-TimeModelFit      | 31.3           |
| ModelSampler-n_times... | 1320000        |
| Policy-AverageAbsPol... | 0.65608686     |
| Policy-AverageDiscou... | 31.2           |
| Policy-AveragePolicyStd | 0.48988456     |
| Policy-AverageReturn    | 86.6           |
| Policy-MaxReturn        | 164            |
| Policy-MinReturn        | -44.2          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 49.8           |
| Policy-TimeAlgoOpt      | 0.704          |
| Policy-TimeSampleProc   | 0.438          |
| Policy-TimeSampling     | 1.58           |
| Policy-TimeStep         | 2.76           |
| Time                    | 940            |
| n_timesteps             | 33000          |
--------------------------------------------

 ---------------- Iteration 33 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 330 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 331 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 332 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 333 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 334 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 335 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 336 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 337 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 338 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 339 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.291         |
| Data-EnvSampler-Poli... | 0.659         |
| Data-EnvTrajs-Averag... | 149           |
| Data-EnvTrajs-MaxReturn | 214           |
| Data-EnvTrajs-MinReturn | 40.8          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 57.6          |
| Data-TimeEnvSampleProc  | 0.000947      |
| Data-TimeEnvSampling    | 0.981         |
| Iteration               | 33            |
| ItrTime                 | 35.3          |
| LossAfter               | -0.018625906  |
| LossBefore              | -6.786213e-06 |
| Model-TimeModelFit      | 31.6          |
| ModelSampler-n_times... | 1360000       |
| Policy-AverageAbsPol... | 0.6366495     |
| Policy-AverageDiscou... | 19.4          |
| Policy-AveragePolicyStd | 0.48237875    |
| Policy-AverageReturn    | 51.1          |
| Policy-MaxReturn        | 125           |
| Policy-MinReturn        | -19.6         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 37.8          |
| Policy-TimeAlgoOpt      | 0.634         |
| Policy-TimeSampleProc   | 0.508         |
| Policy-TimeSampling     | 1.57          |
| Policy-TimeStep         | 2.75          |
| Time                    | 975           |
| n_timesteps             | 34000         |
-------------------------------------------

 ---------------- Iteration 34 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 340 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 341 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 342 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 343 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 344 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 345 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 346 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 347 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 348 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 349 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.308          |
| Data-EnvSampler-Poli... | 0.704          |
| Data-EnvTrajs-Averag... | 162            |
| Data-EnvTrajs-MaxReturn | 222            |
| Data-EnvTrajs-MinReturn | 87.1           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 50.5           |
| Data-TimeEnvSampleProc  | 0.00135        |
| Data-TimeEnvSampling    | 1.04           |
| Iteration               | 34             |
| ItrTime                 | 36.9           |
| LossAfter               | -0.01702551    |
| LossBefore              | -6.5905497e-06 |
| Model-TimeModelFit      | 32.7           |
| ModelSampler-n_times... | 1400000        |
| Policy-AverageAbsPol... | 0.6336041      |
| Policy-AverageDiscou... | 85.7           |
| Policy-AveragePolicyStd | 0.47282445     |
| Policy-AverageReturn    | 221            |
| Policy-MaxReturn        | 282            |
| Policy-MinReturn        | 163            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 28.8           |
| Policy-TimeAlgoOpt      | 0.663          |
| Policy-TimeSampleProc   | 0.455          |
| Policy-TimeSampling     | 1.95           |
| Policy-TimeStep         | 3.11           |
| Time                    | 1.01e+03       |
| n_timesteps             | 35000          |
--------------------------------------------

 ---------------- Iteration 35 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 350 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 351 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 352 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 353 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 354 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 355 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 356 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 357 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 358 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 359 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.329          |
| Data-EnvSampler-Poli... | 0.758          |
| Data-EnvTrajs-Averag... | 127            |
| Data-EnvTrajs-MaxReturn | 158            |
| Data-EnvTrajs-MinReturn | 80.4           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 26             |
| Data-TimeEnvSampleProc  | 0.00103        |
| Data-TimeEnvSampling    | 1.12           |
| Iteration               | 35             |
| ItrTime                 | 37.1           |
| LossAfter               | -0.018402722   |
| LossBefore              | -6.4618507e-06 |
| Model-TimeModelFit      | 32.7           |
| ModelSampler-n_times... | 1440000        |
| Policy-AverageAbsPol... | 0.6296759      |
| Policy-AverageDiscou... | 4.34           |
| Policy-AveragePolicyStd | 0.46644652     |
| Policy-AverageReturn    | 13.6           |
| Policy-MaxReturn        | 69.8           |
| Policy-MinReturn        | -58.9          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 34.8           |
| Policy-TimeAlgoOpt      | 0.679          |
| Policy-TimeSampleProc   | 0.603          |
| Policy-TimeSampling     | 2              |
| Policy-TimeStep         | 3.33           |
| Time                    | 1.05e+03       |
| n_timesteps             | 36000          |
--------------------------------------------

 ---------------- Iteration 36 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 360 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 361 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 362 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 363 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 364 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 365 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 366 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 367 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 368 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 369 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.326          |
| Data-EnvSampler-Poli... | 0.692          |
| Data-EnvTrajs-Averag... | 127            |
| Data-EnvTrajs-MaxReturn | 157            |
| Data-EnvTrajs-MinReturn | 76.2           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 27.4           |
| Data-TimeEnvSampleProc  | 0.00112        |
| Data-TimeEnvSampling    | 1.05           |
| Iteration               | 36             |
| ItrTime                 | 35.9           |
| LossAfter               | -0.021626823   |
| LossBefore              | -6.2675886e-06 |
| Model-TimeModelFit      | 32.1           |
| ModelSampler-n_times... | 1480000        |
| Policy-AverageAbsPol... | 0.639823       |
| Policy-AverageDiscou... | 54.5           |
| Policy-AveragePolicyStd | 0.4574636      |
| Policy-AverageReturn    | 140            |
| Policy-MaxReturn        | 230            |
| Policy-MinReturn        | 24.8           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 50.4           |
| Policy-TimeAlgoOpt      | 0.642          |
| Policy-TimeSampleProc   | 0.343          |
| Policy-TimeSampling     | 1.79           |
| Policy-TimeStep         | 2.79           |
| Time                    | 1.08e+03       |
| n_timesteps             | 37000          |
--------------------------------------------

 ---------------- Iteration 37 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 370 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 371 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 372 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 373 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 374 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 375 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 376 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 377 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 378 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 379 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.353         |
| Data-EnvSampler-Poli... | 0.74          |
| Data-EnvTrajs-Averag... | 171           |
| Data-EnvTrajs-MaxReturn | 202           |
| Data-EnvTrajs-MinReturn | 134           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 26.4          |
| Data-TimeEnvSampleProc  | 0.00114       |
| Data-TimeEnvSampling    | 1.13          |
| Iteration               | 37            |
| ItrTime                 | 35.9          |
| LossAfter               | -0.019521406  |
| LossBefore              | -6.023929e-06 |
| Model-TimeModelFit      | 31.7          |
| ModelSampler-n_times... | 1520000       |
| Policy-AverageAbsPol... | 0.6715879     |
| Policy-AverageDiscou... | 46.1          |
| Policy-AveragePolicyStd | 0.4467179     |
| Policy-AverageReturn    | 118           |
| Policy-MaxReturn        | 181           |
| Policy-MinReturn        | 28.1          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 39            |
| Policy-TimeAlgoOpt      | 0.622         |
| Policy-TimeSampleProc   | 0.655         |
| Policy-TimeSampling     | 1.71          |
| Policy-TimeStep         | 3.03          |
| Time                    | 1.12e+03      |
| n_timesteps             | 38000         |
-------------------------------------------

 ---------------- Iteration 38 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 380 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 381 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 382 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 383 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 384 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 385 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 386 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 387 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 388 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 389 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.317         |
| Data-EnvSampler-Poli... | 0.675         |
| Data-EnvTrajs-Averag... | 183           |
| Data-EnvTrajs-MaxReturn | 226           |
| Data-EnvTrajs-MinReturn | 143           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 31.2          |
| Data-TimeEnvSampleProc  | 0.00113       |
| Data-TimeEnvSampling    | 1.02          |
| Iteration               | 38            |
| ItrTime                 | 35.4          |
| LossAfter               | -0.018633384  |
| LossBefore              | -5.826081e-06 |
| Model-TimeModelFit      | 31.5          |
| ModelSampler-n_times... | 1560000       |
| Policy-AverageAbsPol... | 0.65890354    |
| Policy-AverageDiscou... | 182           |
| Policy-AveragePolicyStd | 0.43811244    |
| Policy-AverageReturn    | 663           |
| Policy-MaxReturn        | 8.11e+03      |
| Policy-MinReturn        | 91.4          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.73e+03      |
| Policy-TimeAlgoOpt      | 0.585         |
| Policy-TimeSampleProc   | 0.584         |
| Policy-TimeSampling     | 1.71          |
| Policy-TimeStep         | 2.93          |
| Time                    | 1.16e+03      |
| n_timesteps             | 39000         |
-------------------------------------------

 ---------------- Iteration 39 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 390 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 391 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 392 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 393 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 394 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 395 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 396 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 397 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 398 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 399 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.321         |
| Data-EnvSampler-Poli... | 0.729         |
| Data-EnvTrajs-Averag... | 155           |
| Data-EnvTrajs-MaxReturn | 217           |
| Data-EnvTrajs-MinReturn | 111           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 38            |
| Data-TimeEnvSampleProc  | 0.000759      |
| Data-TimeEnvSampling    | 1.08          |
| Iteration               | 39            |
| ItrTime                 | 38.1          |
| LossAfter               | -0.01879905   |
| LossBefore              | -5.732708e-06 |
| Model-TimeModelFit      | 34.2          |
| ModelSampler-n_times... | 1600000       |
| Policy-AverageAbsPol... | 0.66738296    |
| Policy-AverageDiscou... | 12            |
| Policy-AveragePolicyStd | 0.43402344    |
| Policy-AverageReturn    | 44.4          |
| Policy-MaxReturn        | 127           |
| Policy-MinReturn        | -73.1         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 48.9          |
| Policy-TimeAlgoOpt      | 0.588         |
| Policy-TimeSampleProc   | 0.569         |
| Policy-TimeSampling     | 1.62          |
| Policy-TimeStep         | 2.83          |
| Time                    | 1.19e+03      |
| n_timesteps             | 40000         |
-------------------------------------------

 ---------------- Iteration 40 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 400 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 401 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 402 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 403 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 404 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 405 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 406 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 407 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 408 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 409 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.312          |
| Data-EnvSampler-Poli... | 0.647          |
| Data-EnvTrajs-Averag... | 183            |
| Data-EnvTrajs-MaxReturn | 228            |
| Data-EnvTrajs-MinReturn | 141            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 32.6           |
| Data-TimeEnvSampleProc  | 0.000973       |
| Data-TimeEnvSampling    | 0.99           |
| Iteration               | 40             |
| ItrTime                 | 37             |
| LossAfter               | -0.017517263   |
| LossBefore              | -5.6568065e-06 |
| Model-TimeModelFit      | 33.1           |
| ModelSampler-n_times... | 1640000        |
| Policy-AverageAbsPol... | 0.67760426     |
| Policy-AverageDiscou... | 61.6           |
| Policy-AveragePolicyStd | 0.4303754      |
| Policy-AverageReturn    | 166            |
| Policy-MaxReturn        | 267            |
| Policy-MinReturn        | 86.7           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 36.5           |
| Policy-TimeAlgoOpt      | 0.621          |
| Policy-TimeSampleProc   | 0.365          |
| Policy-TimeSampling     | 1.83           |
| Policy-TimeStep         | 2.85           |
| Time                    | 1.23e+03       |
| n_timesteps             | 41000          |
--------------------------------------------

 ---------------- Iteration 41 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 410 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 411 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 412 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 413 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 414 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 415 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 416 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 417 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 418 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 419 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.348          |
| Data-EnvSampler-Poli... | 0.716          |
| Data-EnvTrajs-Averag... | 170            |
| Data-EnvTrajs-MaxReturn | 234            |
| Data-EnvTrajs-MinReturn | 91.4           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 45.8           |
| Data-TimeEnvSampleProc  | 0.00142        |
| Data-TimeEnvSampling    | 1.1            |
| Iteration               | 41             |
| ItrTime                 | 35.3           |
| LossAfter               | -0.015910724   |
| LossBefore              | -5.5372298e-06 |
| Model-TimeModelFit      | 31.3           |
| ModelSampler-n_times... | 1680000        |
| Policy-AverageAbsPol... | 0.6964105      |
| Policy-AverageDiscou... | 57.6           |
| Policy-AveragePolicyStd | 0.42449772     |
| Policy-AverageReturn    | 158            |
| Policy-MaxReturn        | 282            |
| Policy-MinReturn        | 3.19           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 65.6           |
| Policy-TimeAlgoOpt      | 0.623          |
| Policy-TimeSampleProc   | 0.683          |
| Policy-TimeSampling     | 1.54           |
| Policy-TimeStep         | 2.9            |
| Time                    | 1.27e+03       |
| n_timesteps             | 42000          |
--------------------------------------------

 ---------------- Iteration 42 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 420 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 421 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 422 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 423 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 424 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 425 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 426 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 427 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 428 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 429 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.316          |
| Data-EnvSampler-Poli... | 0.683          |
| Data-EnvTrajs-Averag... | 194            |
| Data-EnvTrajs-MaxReturn | 247            |
| Data-EnvTrajs-MinReturn | 125            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 42.9           |
| Data-TimeEnvSampleProc  | 0.000809       |
| Data-TimeEnvSampling    | 1.03           |
| Iteration               | 42             |
| ItrTime                 | 35.8           |
| LossAfter               | -0.017929576   |
| LossBefore              | -5.4133293e-06 |
| Model-TimeModelFit      | 31.7           |
| ModelSampler-n_times... | 1720000        |
| Policy-AverageAbsPol... | 0.70297664     |
| Policy-AverageDiscou... | 51.9           |
| Policy-AveragePolicyStd | 0.41822493     |
| Policy-AverageReturn    | 150            |
| Policy-MaxReturn        | 259            |
| Policy-MinReturn        | -4.55          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 62.9           |
| Policy-TimeAlgoOpt      | 0.617          |
| Policy-TimeSampleProc   | 0.6            |
| Policy-TimeSampling     | 1.8            |
| Policy-TimeStep         | 3.07           |
| Time                    | 1.3e+03        |
| n_timesteps             | 43000          |
--------------------------------------------

 ---------------- Iteration 43 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 430 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 431 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 432 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 433 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 434 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 435 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 436 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 437 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 438 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 439 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.279         |
| Data-EnvSampler-Poli... | 0.602         |
| Data-EnvTrajs-Averag... | 200           |
| Data-EnvTrajs-MaxReturn | 282           |
| Data-EnvTrajs-MinReturn | 139           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 46.5          |
| Data-TimeEnvSampleProc  | 0.000944      |
| Data-TimeEnvSampling    | 0.909         |
| Iteration               | 43            |
| ItrTime                 | 37.7          |
| LossAfter               | -0.017374888  |
| LossBefore              | -5.230028e-06 |
| Model-TimeModelFit      | 33.7          |
| ModelSampler-n_times... | 1760000       |
| Policy-AverageAbsPol... | 0.6989181     |
| Policy-AverageDiscou... | 31.1          |
| Policy-AveragePolicyStd | 0.41138557    |
| Policy-AverageReturn    | 91.8          |
| Policy-MaxReturn        | 179           |
| Policy-MinReturn        | -53           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 59.9          |
| Policy-TimeAlgoOpt      | 0.634         |
| Policy-TimeSampleProc   | 0.546         |
| Policy-TimeSampling     | 1.76          |
| Policy-TimeStep         | 3.02          |
| Time                    | 1.34e+03      |
| n_timesteps             | 44000         |
-------------------------------------------

 ---------------- Iteration 44 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 440 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 441 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 442 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 443 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 444 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 445 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 446 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 447 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 448 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 449 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.332          |
| Data-EnvSampler-Poli... | 0.727          |
| Data-EnvTrajs-Averag... | 158            |
| Data-EnvTrajs-MaxReturn | 242            |
| Data-EnvTrajs-MinReturn | 47.3           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 73.3           |
| Data-TimeEnvSampleProc  | 0.00111        |
| Data-TimeEnvSampling    | 1.09           |
| Iteration               | 44             |
| ItrTime                 | 37.7           |
| LossAfter               | -0.020172901   |
| LossBefore              | -4.9873343e-06 |
| Model-TimeModelFit      | 33.6           |
| ModelSampler-n_times... | 1800000        |
| Policy-AverageAbsPol... | 0.6973494      |
| Policy-AverageDiscou... | 110            |
| Policy-AveragePolicyStd | 0.4017346      |
| Policy-AverageReturn    | 333            |
| Policy-MaxReturn        | 1.71e+03       |
| Policy-MinReturn        | 193            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 318            |
| Policy-TimeAlgoOpt      | 0.672          |
| Policy-TimeSampleProc   | 0.549          |
| Policy-TimeSampling     | 1.76           |
| Policy-TimeStep         | 3.02           |
| Time                    | 1.38e+03       |
| n_timesteps             | 45000          |
--------------------------------------------

 ---------------- Iteration 45 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 450 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 451 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 452 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 453 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 454 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 455 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 456 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 457 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 458 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 459 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.285          |
| Data-EnvSampler-Poli... | 0.599          |
| Data-EnvTrajs-Averag... | 250            |
| Data-EnvTrajs-MaxReturn | 289            |
| Data-EnvTrajs-MinReturn | 218            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 26.8           |
| Data-TimeEnvSampleProc  | 0.000987       |
| Data-TimeEnvSampling    | 0.918          |
| Iteration               | 45             |
| ItrTime                 | 36.5           |
| LossAfter               | -0.022078412   |
| LossBefore              | -4.8128086e-06 |
| Model-TimeModelFit      | 32.4           |
| ModelSampler-n_times... | 1840000        |
| Policy-AverageAbsPol... | 0.7172635      |
| Policy-AverageDiscou... | 85.9           |
| Policy-AveragePolicyStd | 0.3947979      |
| Policy-AverageReturn    | 316            |
| Policy-MaxReturn        | 3.57e+03       |
| Policy-MinReturn        | 13             |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 748            |
| Policy-TimeAlgoOpt      | 0.704          |
| Policy-TimeSampleProc   | 0.485          |
| Policy-TimeSampling     | 1.91           |
| Policy-TimeStep         | 3.15           |
| Time                    | 1.41e+03       |
| n_timesteps             | 46000          |
--------------------------------------------

 ---------------- Iteration 46 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 460 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 461 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 462 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 463 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 464 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 465 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 466 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 467 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 468 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 469 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.324         |
| Data-EnvSampler-Poli... | 0.735         |
| Data-EnvTrajs-Averag... | 185           |
| Data-EnvTrajs-MaxReturn | 249           |
| Data-EnvTrajs-MinReturn | 97.4          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 59.4          |
| Data-TimeEnvSampleProc  | 0.000571      |
| Data-TimeEnvSampling    | 1.09          |
| Iteration               | 46            |
| ItrTime                 | 36.4          |
| LossAfter               | -0.01909879   |
| LossBefore              | -4.728638e-06 |
| Model-TimeModelFit      | 32.4          |
| ModelSampler-n_times... | 1880000       |
| Policy-AverageAbsPol... | 0.7104595     |
| Policy-AverageDiscou... | 95.7          |
| Policy-AveragePolicyStd | 0.39287168    |
| Policy-AverageReturn    | 253           |
| Policy-MaxReturn        | 371           |
| Policy-MinReturn        | -112          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 103           |
| Policy-TimeAlgoOpt      | 0.639         |
| Policy-TimeSampleProc   | 0.47          |
| Policy-TimeSampling     | 1.71          |
| Policy-TimeStep         | 2.9           |
| Time                    | 1.45e+03      |
| n_timesteps             | 47000         |
-------------------------------------------

 ---------------- Iteration 47 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 470 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 471 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 472 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 473 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 474 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 475 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 476 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 477 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 478 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 479 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.279          |
| Data-EnvSampler-Poli... | 0.594          |
| Data-EnvTrajs-Averag... | 209            |
| Data-EnvTrajs-MaxReturn | 297            |
| Data-EnvTrajs-MinReturn | 158            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 46.8           |
| Data-TimeEnvSampleProc  | 0.000699       |
| Data-TimeEnvSampling    | 0.9            |
| Iteration               | 47             |
| ItrTime                 | 35.6           |
| LossAfter               | -0.02299022    |
| LossBefore              | -4.6612777e-06 |
| Model-TimeModelFit      | 31.8           |
| ModelSampler-n_times... | 1920000        |
| Policy-AverageAbsPol... | 0.7229572      |
| Policy-AverageDiscou... | 58.1           |
| Policy-AveragePolicyStd | 0.38797796     |
| Policy-AverageReturn    | 168            |
| Policy-MaxReturn        | 457            |
| Policy-MinReturn        | 27.9           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 91.7           |
| Policy-TimeAlgoOpt      | 0.627          |
| Policy-TimeSampleProc   | 0.507          |
| Policy-TimeSampling     | 1.68           |
| Policy-TimeStep         | 2.85           |
| Time                    | 1.49e+03       |
| n_timesteps             | 48000          |
--------------------------------------------

 ---------------- Iteration 48 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 480 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 481 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 482 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 483 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 484 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 485 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 486 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 487 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 488 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 489 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.279          |
| Data-EnvSampler-Poli... | 0.61           |
| Data-EnvTrajs-Averag... | 238            |
| Data-EnvTrajs-MaxReturn | 257            |
| Data-EnvTrajs-MinReturn | 190            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 25.6           |
| Data-TimeEnvSampleProc  | 0.000617       |
| Data-TimeEnvSampling    | 0.917          |
| Iteration               | 48             |
| ItrTime                 | 36.7           |
| LossAfter               | -0.019913543   |
| LossBefore              | -4.4651506e-06 |
| Model-TimeModelFit      | 33             |
| ModelSampler-n_times... | 1960000        |
| Policy-AverageAbsPol... | 0.74590886     |
| Policy-AverageDiscou... | 183            |
| Policy-AveragePolicyStd | 0.38067758     |
| Policy-AverageReturn    | 655            |
| Policy-MaxReturn        | 6.91e+03       |
| Policy-MinReturn        | 173            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.45e+03       |
| Policy-TimeAlgoOpt      | 0.627          |
| Policy-TimeSampleProc   | 0.519          |
| Policy-TimeSampling     | 1.59           |
| Policy-TimeStep         | 2.78           |
| Time                    | 1.52e+03       |
| n_timesteps             | 49000          |
--------------------------------------------

 ---------------- Iteration 49 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 490 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 491 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 492 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 493 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 494 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 495 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 496 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 497 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 498 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 499 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.288          |
| Data-EnvSampler-Poli... | 0.604          |
| Data-EnvTrajs-Averag... | 163            |
| Data-EnvTrajs-MaxReturn | 229            |
| Data-EnvTrajs-MinReturn | 84.7           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 49.4           |
| Data-TimeEnvSampleProc  | 0.000895       |
| Data-TimeEnvSampling    | 0.923          |
| Iteration               | 49             |
| ItrTime                 | 35.9           |
| LossAfter               | -0.019331973   |
| LossBefore              | -4.3940977e-06 |
| Model-TimeModelFit      | 32             |
| ModelSampler-n_times... | 2000000        |
| Policy-AverageAbsPol... | 0.7503959      |
| Policy-AverageDiscou... | 91.9           |
| Policy-AveragePolicyStd | 0.37913138     |
| Policy-AverageReturn    | 302            |
| Policy-MaxReturn        | 1.19e+03       |
| Policy-MinReturn        | 111            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 245            |
| Policy-TimeAlgoOpt      | 0.626          |
| Policy-TimeSampleProc   | 0.407          |
| Policy-TimeSampling     | 1.81           |
| Policy-TimeStep         | 2.92           |
| Time                    | 1.56e+03       |
| n_timesteps             | 50000          |
--------------------------------------------

 ---------------- Iteration 50 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 500 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 501 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 502 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 503 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 504 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 505 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 506 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 507 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 508 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 509 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.286          |
| Data-EnvSampler-Poli... | 0.638          |
| Data-EnvTrajs-Averag... | 191            |
| Data-EnvTrajs-MaxReturn | 263            |
| Data-EnvTrajs-MinReturn | 57.4           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 75.8           |
| Data-TimeEnvSampleProc  | 0.000946       |
| Data-TimeEnvSampling    | 0.956          |
| Iteration               | 50             |
| ItrTime                 | 31.1           |
| LossAfter               | -0.02482579    |
| LossBefore              | -4.2781985e-06 |
| Model-TimeModelFit      | 27.8           |
| ModelSampler-n_times... | 2040000        |
| Policy-AverageAbsPol... | 0.7643161      |
| Policy-AverageDiscou... | 186            |
| Policy-AveragePolicyStd | 0.3751644      |
| Policy-AverageReturn    | 928            |
| Policy-MaxReturn        | 6.33e+03       |
| Policy-MinReturn        | 43.9           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.76e+03       |
| Policy-TimeAlgoOpt      | 0.607          |
| Policy-TimeSampleProc   | 0.234          |
| Policy-TimeSampling     | 1.49           |
| Policy-TimeStep         | 2.35           |
| Time                    | 1.59e+03       |
| n_timesteps             | 51000          |
--------------------------------------------
Training finished
