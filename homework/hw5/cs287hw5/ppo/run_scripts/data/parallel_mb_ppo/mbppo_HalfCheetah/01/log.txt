Logging to /home/vincent/workplace/CS_287_-_Advanced_Robotics/homework/hw5/cs287hw5/ppo/run_scripts/data/parallel_mb_ppo/mbppo_HalfCheetah//01

 ---------------- Iteration 0 ----------------
Obtaining random samples from the environment...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 0 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 1 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 2 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 3 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 4 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 5 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 6 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 7 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 8 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 9 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.122         |
| Data-EnvSampler-Poli... | 0.0376        |
| Data-EnvTrajs-Averag... | -91.1         |
| Data-EnvTrajs-MaxReturn | -35.9         |
| Data-EnvTrajs-MinReturn | -134          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 38.8          |
| Data-TimeEnvSampleProc  | 0.000762      |
| Data-TimeEnvSampling    | 0.17          |
| Iteration               | 0             |
| ItrTime                 | 8.13          |
| LossAfter               | -0.012018676  |
| LossBefore              | -1.416922e-05 |
| Model-TimeModelFit      | 2.73          |
| ModelSampler-n_times... | 40000         |
| Policy-AverageAbsPol... | 0.6162491     |
| Policy-AverageDiscou... | 503           |
| Policy-AveragePolicyStd | 0.9970739     |
| Policy-AverageReturn    | 3.85e+03      |
| Policy-MaxReturn        | 4e+03         |
| Policy-MinReturn        | 3.7e+03       |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 75.5          |
| Policy-TimeAlgoOpt      | 0.901         |
| Policy-TimeSampleProc   | 0.449         |
| Policy-TimeSampling     | 3.81          |
| Policy-TimeStep         | 5.23          |
| Time                    | 8.13          |
| n_timesteps             | 1000          |
-------------------------------------------

 ---------------- Iteration 1 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 10 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 11 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 12 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 13 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 14 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 15 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 16 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 17 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 18 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 19 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.249          |
| Data-EnvSampler-Poli... | 0.809          |
| Data-EnvTrajs-Averag... | -29.1          |
| Data-EnvTrajs-MaxReturn | 30.3           |
| Data-EnvTrajs-MinReturn | -74.4          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 34.1           |
| Data-TimeEnvSampleProc  | 0.000801       |
| Data-TimeEnvSampling    | 1.08           |
| Iteration               | 1              |
| ItrTime                 | 7.85           |
| LossAfter               | -0.017795894   |
| LossBefore              | -1.3909596e-05 |
| Model-TimeModelFit      | 3.98           |
| ModelSampler-n_times... | 80000          |
| Policy-AverageAbsPol... | 0.6612897      |
| Policy-AverageDiscou... | -94.5          |
| Policy-AveragePolicyStd | 0.9725023      |
| Policy-AverageReturn    | -324           |
| Policy-MaxReturn        | -39.3          |
| Policy-MinReturn        | -1.67e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 494            |
| Policy-TimeAlgoOpt      | 0.612          |
| Policy-TimeSampleProc   | 0.51           |
| Policy-TimeSampling     | 1.63           |
| Policy-TimeStep         | 2.79           |
| Time                    | 16.2           |
| n_timesteps             | 2000           |
--------------------------------------------

 ---------------- Iteration 2 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 20 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 21 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 22 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 23 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 24 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 25 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 26 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 27 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 28 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 29 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.311          |
| Data-EnvSampler-Poli... | 0.568          |
| Data-EnvTrajs-Averag... | -44.5          |
| Data-EnvTrajs-MaxReturn | 9.77           |
| Data-EnvTrajs-MinReturn | -107           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 40.3           |
| Data-TimeEnvSampleProc  | 0.000535       |
| Data-TimeEnvSampling    | 0.906          |
| Iteration               | 2              |
| ItrTime                 | 10.2           |
| LossAfter               | -0.017237367   |
| LossBefore              | -1.3940114e-05 |
| Model-TimeModelFit      | 6.43           |
| ModelSampler-n_times... | 120000         |
| Policy-AverageAbsPol... | 0.65689313     |
| Policy-AverageDiscou... | 261            |
| Policy-AveragePolicyStd | 0.97498745     |
| Policy-AverageReturn    | 1.06e+03       |
| Policy-MaxReturn        | 1.28e+03       |
| Policy-MinReturn        | 727            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 154            |
| Policy-TimeAlgoOpt      | 0.536          |
| Policy-TimeSampleProc   | 0.651          |
| Policy-TimeSampling     | 1.65           |
| Policy-TimeStep         | 2.87           |
| Time                    | 26.4           |
| n_timesteps             | 3000           |
--------------------------------------------

 ---------------- Iteration 3 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 30 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 31 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 32 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 33 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 34 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 35 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 36 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 37 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 38 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 39 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.321           |
| Data-EnvSampler-Poli... | 0.669           |
| Data-EnvTrajs-Averag... | -80.7           |
| Data-EnvTrajs-MaxReturn | -19.4           |
| Data-EnvTrajs-MinReturn | -155            |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 45              |
| Data-TimeEnvSampleProc  | 0.00056         |
| Data-TimeEnvSampling    | 1.02            |
| Iteration               | 3               |
| ItrTime                 | 12.7            |
| LossAfter               | -0.015599417    |
| LossBefore              | -1.38826135e-05 |
| Model-TimeModelFit      | 8.88            |
| ModelSampler-n_times... | 160000          |
| Policy-AverageAbsPol... | 0.77125764      |
| Policy-AverageDiscou... | -59.1           |
| Policy-AveragePolicyStd | 0.96859556      |
| Policy-AverageReturn    | -191            |
| Policy-MaxReturn        | -63.6           |
| Policy-MinReturn        | -823            |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 202             |
| Policy-TimeAlgoOpt      | 0.62            |
| Policy-TimeSampleProc   | 0.382           |
| Policy-TimeSampling     | 1.75            |
| Policy-TimeStep         | 2.8             |
| Time                    | 39.1            |
| n_timesteps             | 4000            |
---------------------------------------------

 ---------------- Iteration 4 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 40 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 41 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 42 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 43 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 44 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 45 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 46 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 47 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 48 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 49 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.394          |
| Data-EnvSampler-Poli... | 0.728          |
| Data-EnvTrajs-Averag... | -47.5          |
| Data-EnvTrajs-MaxReturn | -16.5          |
| Data-EnvTrajs-MinReturn | -99.2          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 30.4           |
| Data-TimeEnvSampleProc  | 0.000666       |
| Data-TimeEnvSampling    | 1.15           |
| Iteration               | 4              |
| ItrTime                 | 14.3           |
| LossAfter               | -0.014756466   |
| LossBefore              | -1.3809927e-05 |
| Model-TimeModelFit      | 10.6           |
| ModelSampler-n_times... | 200000         |
| Policy-AverageAbsPol... | 0.7022561      |
| Policy-AverageDiscou... | -68.8          |
| Policy-AveragePolicyStd | 0.9612567      |
| Policy-AverageReturn    | -160           |
| Policy-MaxReturn        | -84.8          |
| Policy-MinReturn        | -412           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 67.4           |
| Policy-TimeAlgoOpt      | 0.602          |
| Policy-TimeSampleProc   | 0.361          |
| Policy-TimeSampling     | 1.55           |
| Policy-TimeStep         | 2.54           |
| Time                    | 53.4           |
| n_timesteps             | 5000           |
--------------------------------------------

 ---------------- Iteration 5 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 50 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 51 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 52 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 53 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 54 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 55 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 56 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 57 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 58 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 59 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.318          |
| Data-EnvSampler-Poli... | 0.843          |
| Data-EnvTrajs-Averag... | -50.8          |
| Data-EnvTrajs-MaxReturn | -16.8          |
| Data-EnvTrajs-MinReturn | -107           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 35.5           |
| Data-TimeEnvSampleProc  | 0.000651       |
| Data-TimeEnvSampling    | 1.19           |
| Iteration               | 5              |
| ItrTime                 | 16.3           |
| LossAfter               | -0.015496213   |
| LossBefore              | -1.3522659e-05 |
| Model-TimeModelFit      | 12.6           |
| ModelSampler-n_times... | 240000         |
| Policy-AverageAbsPol... | 0.6531143      |
| Policy-AverageDiscou... | -118           |
| Policy-AveragePolicyStd | 0.9357725      |
| Policy-AverageReturn    | -290           |
| Policy-MaxReturn        | -181           |
| Policy-MinReturn        | -558           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 77.6           |
| Policy-TimeAlgoOpt      | 0.552          |
| Policy-TimeSampleProc   | 0.405          |
| Policy-TimeSampling     | 1.49           |
| Policy-TimeStep         | 2.52           |
| Time                    | 69.6           |
| n_timesteps             | 6000           |
--------------------------------------------

 ---------------- Iteration 6 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 60 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 61 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 62 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 63 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 64 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 65 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 66 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 67 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 68 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 69 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.365          |
| Data-EnvSampler-Poli... | 0.92           |
| Data-EnvTrajs-Averag... | -40.6          |
| Data-EnvTrajs-MaxReturn | -12.2          |
| Data-EnvTrajs-MinReturn | -51.8          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 14.5           |
| Data-TimeEnvSampleProc  | 0.00099        |
| Data-TimeEnvSampling    | 1.32           |
| Iteration               | 6              |
| ItrTime                 | 18.9           |
| LossAfter               | -0.0149460705  |
| LossBefore              | -1.3156886e-05 |
| Model-TimeModelFit      | 15.1           |
| ModelSampler-n_times... | 280000         |
| Policy-AverageAbsPol... | 0.5733124      |
| Policy-AverageDiscou... | -40.7          |
| Policy-AveragePolicyStd | 0.9015128      |
| Policy-AverageReturn    | -99.2          |
| Policy-MaxReturn        | -57.1          |
| Policy-MinReturn        | -138           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 18.8           |
| Policy-TimeAlgoOpt      | 0.582          |
| Policy-TimeSampleProc   | 0.404          |
| Policy-TimeSampling     | 1.43           |
| Policy-TimeStep         | 2.47           |
| Time                    | 88.5           |
| n_timesteps             | 7000           |
--------------------------------------------

 ---------------- Iteration 7 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 70 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 71 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 72 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 73 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 74 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 75 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 76 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 77 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 78 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 79 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.323          |
| Data-EnvSampler-Poli... | 0.736          |
| Data-EnvTrajs-Averag... | -36.1          |
| Data-EnvTrajs-MaxReturn | -9.78          |
| Data-EnvTrajs-MinReturn | -67            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 18.9           |
| Data-TimeEnvSampleProc  | 0.000737       |
| Data-TimeEnvSampling    | 1.09           |
| Iteration               | 7              |
| ItrTime                 | 21.2           |
| LossAfter               | -0.015650695   |
| LossBefore              | -1.2777392e-05 |
| Model-TimeModelFit      | 17.6           |
| ModelSampler-n_times... | 320000         |
| Policy-AverageAbsPol... | 0.51862913     |
| Policy-AverageDiscou... | -6.26          |
| Policy-AveragePolicyStd | 0.86866385     |
| Policy-AverageReturn    | -16.2          |
| Policy-MaxReturn        | 13.5           |
| Policy-MinReturn        | -39.8          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 15.3           |
| Policy-TimeAlgoOpt      | 0.606          |
| Policy-TimeSampleProc   | 0.342          |
| Policy-TimeSampling     | 1.49           |
| Policy-TimeStep         | 2.47           |
| Time                    | 110            |
| n_timesteps             | 8000           |
--------------------------------------------

 ---------------- Iteration 8 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 80 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 81 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 82 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 83 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 84 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 85 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 86 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 87 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 88 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 89 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.422          |
| Data-EnvSampler-Poli... | 0.948          |
| Data-EnvTrajs-Averag... | -33.2          |
| Data-EnvTrajs-MaxReturn | -21.1          |
| Data-EnvTrajs-MinReturn | -49.5          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 10.6           |
| Data-TimeEnvSampleProc  | 0.000525       |
| Data-TimeEnvSampling    | 1.4            |
| Iteration               | 8              |
| ItrTime                 | 24.5           |
| LossAfter               | -0.015246914   |
| LossBefore              | -1.2514783e-05 |
| Model-TimeModelFit      | 20.4           |
| ModelSampler-n_times... | 360000         |
| Policy-AverageAbsPol... | 0.5396483      |
| Policy-AverageDiscou... | -6.21          |
| Policy-AveragePolicyStd | 0.8464064      |
| Policy-AverageReturn    | -1.52          |
| Policy-MaxReturn        | 45.8           |
| Policy-MinReturn        | -45.5          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 23.5           |
| Policy-TimeAlgoOpt      | 0.607          |
| Policy-TimeSampleProc   | 0.339          |
| Policy-TimeSampling     | 1.68           |
| Policy-TimeStep         | 2.66           |
| Time                    | 134            |
| n_timesteps             | 9000           |
--------------------------------------------

 ---------------- Iteration 9 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 90 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 91 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 92 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 93 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 94 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 95 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 96 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 97 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 98 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 99 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.379          |
| Data-EnvSampler-Poli... | 0.939          |
| Data-EnvTrajs-Averag... | -48.5          |
| Data-EnvTrajs-MaxReturn | -2.58          |
| Data-EnvTrajs-MinReturn | -98.7          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 39.7           |
| Data-TimeEnvSampleProc  | 0.001          |
| Data-TimeEnvSampling    | 1.35           |
| Iteration               | 9              |
| ItrTime                 | 26.4           |
| LossAfter               | -0.013670271   |
| LossBefore              | -1.2350498e-05 |
| Model-TimeModelFit      | 22.2           |
| ModelSampler-n_times... | 400000         |
| Policy-AverageAbsPol... | 0.5308004      |
| Policy-AverageDiscou... | -70.6          |
| Policy-AveragePolicyStd | 0.83241445     |
| Policy-AverageReturn    | -152           |
| Policy-MaxReturn        | -78.4          |
| Policy-MinReturn        | -363           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 79.9           |
| Policy-TimeAlgoOpt      | 0.588          |
| Policy-TimeSampleProc   | 0.429          |
| Policy-TimeSampling     | 1.78           |
| Policy-TimeStep         | 2.84           |
| Time                    | 161            |
| n_timesteps             | 10000          |
--------------------------------------------

 ---------------- Iteration 10 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 100 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 101 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 102 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 103 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 104 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 105 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 106 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 107 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 108 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 109 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.336           |
| Data-EnvSampler-Poli... | 0.832           |
| Data-EnvTrajs-Averag... | -38.3           |
| Data-EnvTrajs-MaxReturn | 19.5            |
| Data-EnvTrajs-MinReturn | -67.4           |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 31.5            |
| Data-TimeEnvSampleProc  | 0.000762        |
| Data-TimeEnvSampling    | 1.2             |
| Iteration               | 10              |
| ItrTime                 | 28.9            |
| LossAfter               | -0.01613739     |
| LossBefore              | -1.20840195e-05 |
| Model-TimeModelFit      | 25.3            |
| ModelSampler-n_times... | 440000          |
| Policy-AverageAbsPol... | 0.5418421       |
| Policy-AverageDiscou... | -70.3           |
| Policy-AveragePolicyStd | 0.8093573       |
| Policy-AverageReturn    | -169            |
| Policy-MaxReturn        | -130            |
| Policy-MinReturn        | -209            |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 22.8            |
| Policy-TimeAlgoOpt      | 0.57            |
| Policy-TimeSampleProc   | 0.343           |
| Policy-TimeSampling     | 1.45            |
| Policy-TimeStep         | 2.4             |
| Time                    | 189             |
| n_timesteps             | 11000           |
---------------------------------------------

 ---------------- Iteration 11 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 110 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 111 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 112 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 113 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 114 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 115 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 116 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 117 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 118 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 119 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.374          |
| Data-EnvSampler-Poli... | 0.872          |
| Data-EnvTrajs-Averag... | -57.9          |
| Data-EnvTrajs-MaxReturn | 33.9           |
| Data-EnvTrajs-MinReturn | -109           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 51.7           |
| Data-TimeEnvSampleProc  | 0.00126        |
| Data-TimeEnvSampling    | 1.28           |
| Iteration               | 11             |
| ItrTime                 | 30.2           |
| LossAfter               | -0.020738637   |
| LossBefore              | -1.1890271e-05 |
| Model-TimeModelFit      | 26             |
| ModelSampler-n_times... | 480000         |
| Policy-AverageAbsPol... | 0.6652238      |
| Policy-AverageDiscou... | 31.6           |
| Policy-AveragePolicyStd | 0.79522413     |
| Policy-AverageReturn    | 117            |
| Policy-MaxReturn        | 236            |
| Policy-MinReturn        | 18.4           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 64             |
| Policy-TimeAlgoOpt      | 0.582          |
| Policy-TimeSampleProc   | 0.558          |
| Policy-TimeSampling     | 1.68           |
| Policy-TimeStep         | 2.88           |
| Time                    | 220            |
| n_timesteps             | 12000          |
--------------------------------------------

 ---------------- Iteration 12 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 120 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 121 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 122 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 123 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 124 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 125 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 126 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 127 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 128 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 129 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.362          |
| Data-EnvSampler-Poli... | 0.934          |
| Data-EnvTrajs-Averag... | -77.1          |
| Data-EnvTrajs-MaxReturn | -35.7          |
| Data-EnvTrajs-MinReturn | -146           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 37.3           |
| Data-TimeEnvSampleProc  | 0.000986       |
| Data-TimeEnvSampling    | 1.34           |
| Iteration               | 12             |
| ItrTime                 | 32.5           |
| LossAfter               | -0.023410454   |
| LossBefore              | -1.1821513e-05 |
| Model-TimeModelFit      | 28.6           |
| ModelSampler-n_times... | 520000         |
| Policy-AverageAbsPol... | 0.6228802      |
| Policy-AverageDiscou... | -1.35          |
| Policy-AveragePolicyStd | 0.78827244     |
| Policy-AverageReturn    | 94.8           |
| Policy-MaxReturn        | 1.81e+03       |
| Policy-MinReturn        | -177           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 454            |
| Policy-TimeAlgoOpt      | 0.601          |
| Policy-TimeSampleProc   | 0.344          |
| Policy-TimeSampling     | 1.6            |
| Policy-TimeStep         | 2.59           |
| Time                    | 252            |
| n_timesteps             | 13000          |
--------------------------------------------

 ---------------- Iteration 13 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 130 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 131 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 132 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 133 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 134 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 135 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 136 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 137 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 138 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 139 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.319          |
| Data-EnvSampler-Poli... | 0.753          |
| Data-EnvTrajs-Averag... | -16.2          |
| Data-EnvTrajs-MaxReturn | 28.9           |
| Data-EnvTrajs-MinReturn | -53.8          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 27             |
| Data-TimeEnvSampleProc  | 0.000998       |
| Data-TimeEnvSampling    | 1.11           |
| Iteration               | 13             |
| ItrTime                 | 32.2           |
| LossAfter               | -0.015316343   |
| LossBefore              | -1.1660131e-05 |
| Model-TimeModelFit      | 28.3           |
| ModelSampler-n_times... | 560000         |
| Policy-AverageAbsPol... | 0.6037386      |
| Policy-AverageDiscou... | -11.6          |
| Policy-AveragePolicyStd | 0.77665275     |
| Policy-AverageReturn    | -23.9          |
| Policy-MaxReturn        | 40.3           |
| Policy-MinReturn        | -87.7          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 37.3           |
| Policy-TimeAlgoOpt      | 0.637          |
| Policy-TimeSampleProc   | 0.472          |
| Policy-TimeSampling     | 1.63           |
| Policy-TimeStep         | 2.78           |
| Time                    | 284            |
| n_timesteps             | 14000          |
--------------------------------------------

 ---------------- Iteration 14 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 140 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 141 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 142 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 143 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 144 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 145 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 146 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 147 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 148 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 149 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.421          |
| Data-EnvSampler-Poli... | 0.937          |
| Data-EnvTrajs-Averag... | -38.2          |
| Data-EnvTrajs-MaxReturn | 53.4           |
| Data-EnvTrajs-MinReturn | -96.9          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 49.7           |
| Data-TimeEnvSampleProc  | 0.000977       |
| Data-TimeEnvSampling    | 1.4            |
| Iteration               | 14             |
| ItrTime                 | 35.4           |
| LossAfter               | -0.015405117   |
| LossBefore              | -1.1519587e-05 |
| Model-TimeModelFit      | 31.4           |
| ModelSampler-n_times... | 600000         |
| Policy-AverageAbsPol... | 0.5957932      |
| Policy-AverageDiscou... | -65.6          |
| Policy-AveragePolicyStd | 0.7654777      |
| Policy-AverageReturn    | -165           |
| Policy-MaxReturn        | -68.7          |
| Policy-MinReturn        | -269           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 58.6           |
| Policy-TimeAlgoOpt      | 0.619          |
| Policy-TimeSampleProc   | 0.368          |
| Policy-TimeSampling     | 1.56           |
| Policy-TimeStep         | 2.6            |
| Time                    | 320            |
| n_timesteps             | 15000          |
--------------------------------------------

 ---------------- Iteration 15 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 150 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 151 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 152 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 153 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 154 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 155 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 156 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 157 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 158 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 159 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.391           |
| Data-EnvSampler-Poli... | 0.918           |
| Data-EnvTrajs-Averag... | -53.3           |
| Data-EnvTrajs-MaxReturn | -5.96           |
| Data-EnvTrajs-MinReturn | -141            |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 53.1            |
| Data-TimeEnvSampleProc  | 0.000679        |
| Data-TimeEnvSampling    | 1.35            |
| Iteration               | 15              |
| ItrTime                 | 31.3            |
| LossAfter               | -0.017032105    |
| LossBefore              | -1.13365395e-05 |
| Model-TimeModelFit      | 27.4            |
| ModelSampler-n_times... | 640000          |
| Policy-AverageAbsPol... | 0.58592284      |
| Policy-AverageDiscou... | -123            |
| Policy-AveragePolicyStd | 0.7519253       |
| Policy-AverageReturn    | -306            |
| Policy-MaxReturn        | -187            |
| Policy-MinReturn        | -393            |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 45.9            |
| Policy-TimeAlgoOpt      | 0.59            |
| Policy-TimeSampleProc   | 0.4             |
| Policy-TimeSampling     | 1.48            |
| Policy-TimeStep         | 2.49            |
| Time                    | 351             |
| n_timesteps             | 16000           |
---------------------------------------------

 ---------------- Iteration 16 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 160 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 161 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 162 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 163 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 164 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 165 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 166 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 167 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 168 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 169 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.426          |
| Data-EnvSampler-Poli... | 1.13           |
| Data-EnvTrajs-Averag... | -43.8          |
| Data-EnvTrajs-MaxReturn | -27.9          |
| Data-EnvTrajs-MinReturn | -64.6          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 15.7           |
| Data-TimeEnvSampleProc  | 0.00144        |
| Data-TimeEnvSampling    | 1.61           |
| Iteration               | 16             |
| ItrTime                 | 32.3           |
| LossAfter               | -0.014640995   |
| LossBefore              | -1.1221133e-05 |
| Model-TimeModelFit      | 28.1           |
| ModelSampler-n_times... | 680000         |
| Policy-AverageAbsPol... | 0.5764962      |
| Policy-AverageDiscou... | -43.9          |
| Policy-AveragePolicyStd | 0.74204075     |
| Policy-AverageReturn    | -114           |
| Policy-MaxReturn        | -41.5          |
| Policy-MinReturn        | -210           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 43.3           |
| Policy-TimeAlgoOpt      | 0.648          |
| Policy-TimeSampleProc   | 0.303          |
| Policy-TimeSampling     | 1.55           |
| Policy-TimeStep         | 2.53           |
| Time                    | 383            |
| n_timesteps             | 17000          |
--------------------------------------------

 ---------------- Iteration 17 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 170 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 171 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 172 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 173 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 174 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 175 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 176 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 177 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 178 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 179 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.4            |
| Data-EnvSampler-Poli... | 0.921          |
| Data-EnvTrajs-Averag... | -24.4          |
| Data-EnvTrajs-MaxReturn | 36.9           |
| Data-EnvTrajs-MinReturn | -98.7          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 46.9           |
| Data-TimeEnvSampleProc  | 0.00125        |
| Data-TimeEnvSampling    | 1.36           |
| Iteration               | 17             |
| ItrTime                 | 31.5           |
| LossAfter               | -0.015930125   |
| LossBefore              | -1.1138184e-05 |
| Model-TimeModelFit      | 27.6           |
| ModelSampler-n_times... | 720000         |
| Policy-AverageAbsPol... | 0.67827755     |
| Policy-AverageDiscou... | 508            |
| Policy-AveragePolicyStd | 0.73708415     |
| Policy-AverageReturn    | 2.23e+03       |
| Policy-MaxReturn        | 1.26e+04       |
| Policy-MinReturn        | -130           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 3.55e+03       |
| Policy-TimeAlgoOpt      | 0.614          |
| Policy-TimeSampleProc   | 0.402          |
| Policy-TimeSampling     | 1.43           |
| Policy-TimeStep         | 2.5            |
| Time                    | 415            |
| n_timesteps             | 18000          |
--------------------------------------------

 ---------------- Iteration 18 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 180 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 181 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 182 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 183 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 184 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 185 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 186 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 187 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 188 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 189 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.34           |
| Data-EnvSampler-Poli... | 0.795          |
| Data-EnvTrajs-Averag... | -2.76          |
| Data-EnvTrajs-MaxReturn | 23.6           |
| Data-EnvTrajs-MinReturn | -30.3          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 17.5           |
| Data-TimeEnvSampleProc  | 0.00106        |
| Data-TimeEnvSampling    | 1.17           |
| Iteration               | 18             |
| ItrTime                 | 32.5           |
| LossAfter               | -0.017609892   |
| LossBefore              | -1.0996994e-05 |
| Model-TimeModelFit      | 27.8           |
| ModelSampler-n_times... | 760000         |
| Policy-AverageAbsPol... | 0.59659445     |
| Policy-AverageDiscou... | -87.9          |
| Policy-AveragePolicyStd | 0.72712433     |
| Policy-AverageReturn    | -202           |
| Policy-MaxReturn        | -152           |
| Policy-MinReturn        | -355           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 53.2           |
| Policy-TimeAlgoOpt      | 0.658          |
| Policy-TimeSampleProc   | 0.565          |
| Policy-TimeSampling     | 2.21           |
| Policy-TimeStep         | 3.49           |
| Time                    | 447            |
| n_timesteps             | 19000          |
--------------------------------------------

 ---------------- Iteration 19 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 190 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 191 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 192 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 193 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 194 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 195 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 196 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 197 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 198 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 199 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.602          |
| Data-EnvSampler-Poli... | 1.47           |
| Data-EnvTrajs-Averag... | -42.6          |
| Data-EnvTrajs-MaxReturn | -17.4          |
| Data-EnvTrajs-MinReturn | -92.1          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 26.8           |
| Data-TimeEnvSampleProc  | 0.000668       |
| Data-TimeEnvSampling    | 2.13           |
| Iteration               | 19             |
| ItrTime                 | 31.8           |
| LossAfter               | -0.015790267   |
| LossBefore              | -1.0673673e-05 |
| Model-TimeModelFit      | 27.3           |
| ModelSampler-n_times... | 800000         |
| Policy-AverageAbsPol... | 0.5460658      |
| Policy-AverageDiscou... | -12.8          |
| Policy-AveragePolicyStd | 0.7039015      |
| Policy-AverageReturn    | -43.3          |
| Policy-MaxReturn        | -5.91          |
| Policy-MinReturn        | -95.2          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 20.3           |
| Policy-TimeAlgoOpt      | 0.59           |
| Policy-TimeSampleProc   | 0.329          |
| Policy-TimeSampling     | 1.43           |
| Policy-TimeStep         | 2.38           |
| Time                    | 479            |
| n_timesteps             | 20000          |
--------------------------------------------

 ---------------- Iteration 20 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 200 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 201 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 202 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 203 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 204 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 205 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 206 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 207 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 208 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 209 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.45           |
| Data-EnvSampler-Poli... | 1.01           |
| Data-EnvTrajs-Averag... | -45.3          |
| Data-EnvTrajs-MaxReturn | -32.4          |
| Data-EnvTrajs-MinReturn | -77.7          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 16.5           |
| Data-TimeEnvSampleProc  | 0.00098        |
| Data-TimeEnvSampling    | 1.51           |
| Iteration               | 20             |
| ItrTime                 | 33.8           |
| LossAfter               | -0.017424582   |
| LossBefore              | -1.0553637e-05 |
| Model-TimeModelFit      | 29.6           |
| ModelSampler-n_times... | 840000         |
| Policy-AverageAbsPol... | 0.54150164     |
| Policy-AverageDiscou... | -135           |
| Policy-AveragePolicyStd | 0.6947365      |
| Policy-AverageReturn    | -304           |
| Policy-MaxReturn        | -140           |
| Policy-MinReturn        | -496           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 112            |
| Policy-TimeAlgoOpt      | 0.66           |
| Policy-TimeSampleProc   | 0.365          |
| Policy-TimeSampling     | 1.63           |
| Policy-TimeStep         | 2.68           |
| Time                    | 513            |
| n_timesteps             | 21000          |
--------------------------------------------

 ---------------- Iteration 21 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 210 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 211 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 212 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 213 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 214 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 215 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 216 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 217 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 218 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 219 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.428           |
| Data-EnvSampler-Poli... | 1.11            |
| Data-EnvTrajs-Averag... | -31.7           |
| Data-EnvTrajs-MaxReturn | 7.86            |
| Data-EnvTrajs-MinReturn | -73.1           |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 25.7            |
| Data-TimeEnvSampleProc  | 0.000976        |
| Data-TimeEnvSampling    | 1.58            |
| Iteration               | 21              |
| ItrTime                 | 33.5            |
| LossAfter               | -0.015211488    |
| LossBefore              | -1.04122755e-05 |
| Model-TimeModelFit      | 28.7            |
| ModelSampler-n_times... | 880000          |
| Policy-AverageAbsPol... | 0.53685826      |
| Policy-AverageDiscou... | -84             |
| Policy-AveragePolicyStd | 0.6846226       |
| Policy-AverageReturn    | -194            |
| Policy-MaxReturn        | -144            |
| Policy-MinReturn        | -352            |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 60.1            |
| Policy-TimeAlgoOpt      | 0.666           |
| Policy-TimeSampleProc   | 0.665           |
| Policy-TimeSampling     | 1.85            |
| Policy-TimeStep         | 3.25            |
| Time                    | 546             |
| n_timesteps             | 22000           |
---------------------------------------------

 ---------------- Iteration 22 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 220 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 221 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 222 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 223 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 224 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 225 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 226 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 227 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 228 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 229 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.368          |
| Data-EnvSampler-Poli... | 0.966          |
| Data-EnvTrajs-Averag... | -35.1          |
| Data-EnvTrajs-MaxReturn | 19.7           |
| Data-EnvTrajs-MinReturn | -74.5          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 31.8           |
| Data-TimeEnvSampleProc  | 0.000997       |
| Data-TimeEnvSampling    | 1.37           |
| Iteration               | 22             |
| ItrTime                 | 32.9           |
| LossAfter               | -0.016794052   |
| LossBefore              | -1.0180839e-05 |
| Model-TimeModelFit      | 28.9           |
| ModelSampler-n_times... | 920000         |
| Policy-AverageAbsPol... | 0.5242933      |
| Policy-AverageDiscou... | 24             |
| Policy-AveragePolicyStd | 0.6704253      |
| Policy-AverageReturn    | 49.8           |
| Policy-MaxReturn        | 103            |
| Policy-MinReturn        | -19.9          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 35.4           |
| Policy-TimeAlgoOpt      | 0.662          |
| Policy-TimeSampleProc   | 0.342          |
| Policy-TimeSampling     | 1.64           |
| Policy-TimeStep         | 2.66           |
| Time                    | 579            |
| n_timesteps             | 23000          |
--------------------------------------------

 ---------------- Iteration 23 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 230 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 231 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 232 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 233 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 234 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 235 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 236 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 237 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 238 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 239 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Data-EnvSampler-EnvE... | 0.329        |
| Data-EnvSampler-Poli... | 0.779        |
| Data-EnvTrajs-Averag... | -39.9        |
| Data-EnvTrajs-MaxReturn | 39.6         |
| Data-EnvTrajs-MinReturn | -105         |
| Data-EnvTrajs-NumTrajs  | 5            |
| Data-EnvTrajs-StdReturn | 56.1         |
| Data-TimeEnvSampleProc  | 0.000624     |
| Data-TimeEnvSampling    | 1.14         |
| Iteration               | 23           |
| ItrTime                 | 35.3         |
| LossAfter               | -0.018432977 |
| LossBefore              | -9.92161e-06 |
| Model-TimeModelFit      | 31.5         |
| ModelSampler-n_times... | 960000       |
| Policy-AverageAbsPol... | 0.49340722   |
| Policy-AverageDiscou... | -3.74        |
| Policy-AveragePolicyStd | 0.65466934   |
| Policy-AverageReturn    | -17.8        |
| Policy-MaxReturn        | 14.8         |
| Policy-MinReturn        | -62          |
| Policy-NumTrajs         | 20           |
| Policy-StdReturn        | 22.3         |
| Policy-TimeAlgoOpt      | 0.644        |
| Policy-TimeSampleProc   | 0.479        |
| Policy-TimeSampling     | 1.52         |
| Policy-TimeStep         | 2.7          |
| Time                    | 615          |
| n_timesteps             | 24000        |
------------------------------------------

 ---------------- Iteration 24 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 240 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 241 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 242 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 243 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 244 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 245 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 246 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 247 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 248 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 249 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.346         |
| Data-EnvSampler-Poli... | 0.858         |
| Data-EnvTrajs-Averag... | -26.1         |
| Data-EnvTrajs-MaxReturn | 16.9          |
| Data-EnvTrajs-MinReturn | -69.4         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 32.8          |
| Data-TimeEnvSampleProc  | 0.000797      |
| Data-TimeEnvSampling    | 1.24          |
| Iteration               | 24            |
| ItrTime                 | 38.2          |
| LossAfter               | -0.017250344  |
| LossBefore              | -9.802767e-06 |
| Model-TimeModelFit      | 33.5          |
| ModelSampler-n_times... | 1000000       |
| Policy-AverageAbsPol... | 0.49055246    |
| Policy-AverageDiscou... | -64.1         |
| Policy-AveragePolicyStd | 0.6442418     |
| Policy-AverageReturn    | -160          |
| Policy-MaxReturn        | -99.1         |
| Policy-MinReturn        | -210          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 32.8          |
| Policy-TimeAlgoOpt      | 0.674         |
| Policy-TimeSampleProc   | 0.67          |
| Policy-TimeSampling     | 2.02          |
| Policy-TimeStep         | 3.45          |
| Time                    | 653           |
| n_timesteps             | 25000         |
-------------------------------------------

 ---------------- Iteration 25 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 250 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 251 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 252 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 253 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 254 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 255 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 256 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 257 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 258 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 259 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Data-EnvSampler-EnvE... | 0.484        |
| Data-EnvSampler-Poli... | 1.15         |
| Data-EnvTrajs-Averag... | -14.2        |
| Data-EnvTrajs-MaxReturn | 15.5         |
| Data-EnvTrajs-MinReturn | -37.9        |
| Data-EnvTrajs-NumTrajs  | 5            |
| Data-EnvTrajs-StdReturn | 17.8         |
| Data-TimeEnvSampleProc  | 0.00117      |
| Data-TimeEnvSampling    | 1.68         |
| Iteration               | 25           |
| ItrTime                 | 36.7         |
| LossAfter               | -0.017162615 |
| LossBefore              | -9.56819e-06 |
| Model-TimeModelFit      | 32.1         |
| ModelSampler-n_times... | 1040000      |
| Policy-AverageAbsPol... | 0.45809498   |
| Policy-AverageDiscou... | 0.757        |
| Policy-AveragePolicyStd | 0.63052356   |
| Policy-AverageReturn    | -8.66        |
| Policy-MaxReturn        | 40.1         |
| Policy-MinReturn        | -49.1        |
| Policy-NumTrajs         | 20           |
| Policy-StdReturn        | 29.1         |
| Policy-TimeAlgoOpt      | 0.694        |
| Policy-TimeSampleProc   | 0.443        |
| Policy-TimeSampling     | 1.73         |
| Policy-TimeStep         | 2.94         |
| Time                    | 690          |
| n_timesteps             | 26000        |
------------------------------------------

 ---------------- Iteration 26 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 260 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 261 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 262 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 263 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 264 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 265 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 266 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 267 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 268 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 269 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.399         |
| Data-EnvSampler-Poli... | 0.97          |
| Data-EnvTrajs-Averag... | 2.1           |
| Data-EnvTrajs-MaxReturn | 67.2          |
| Data-EnvTrajs-MinReturn | -50.1         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 42.2          |
| Data-TimeEnvSampleProc  | 0.00108       |
| Data-TimeEnvSampling    | 1.42          |
| Iteration               | 26            |
| ItrTime                 | 34.1          |
| LossAfter               | -0.014960918  |
| LossBefore              | -9.379127e-06 |
| Model-TimeModelFit      | 29.7          |
| ModelSampler-n_times... | 1080000       |
| Policy-AverageAbsPol... | 0.47452137    |
| Policy-AverageDiscou... | 5.99          |
| Policy-AveragePolicyStd | 0.61819595    |
| Policy-AverageReturn    | 6.89          |
| Policy-MaxReturn        | 56.4          |
| Policy-MinReturn        | -58.6         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 25.8          |
| Policy-TimeAlgoOpt      | 0.599         |
| Policy-TimeSampleProc   | 0.592         |
| Policy-TimeSampling     | 1.8           |
| Policy-TimeStep         | 3.05          |
| Time                    | 724           |
| n_timesteps             | 27000         |
-------------------------------------------

 ---------------- Iteration 27 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 270 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 271 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 272 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 273 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 274 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 275 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 276 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 277 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 278 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 279 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.338         |
| Data-EnvSampler-Poli... | 0.813         |
| Data-EnvTrajs-Averag... | -24           |
| Data-EnvTrajs-MaxReturn | 54.7          |
| Data-EnvTrajs-MinReturn | -73.3         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 44.7          |
| Data-TimeEnvSampleProc  | 0.00139       |
| Data-TimeEnvSampling    | 1.19          |
| Iteration               | 27            |
| ItrTime                 | 33.6          |
| LossAfter               | -0.017403318  |
| LossBefore              | -9.158824e-06 |
| Model-TimeModelFit      | 29.8          |
| ModelSampler-n_times... | 1120000       |
| Policy-AverageAbsPol... | 0.4764551     |
| Policy-AverageDiscou... | 32.1          |
| Policy-AveragePolicyStd | 0.6058274     |
| Policy-AverageReturn    | 83.8          |
| Policy-MaxReturn        | 126           |
| Policy-MinReturn        | 9.83          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 28.2          |
| Policy-TimeAlgoOpt      | 0.638         |
| Policy-TimeSampleProc   | 0.374         |
| Policy-TimeSampling     | 1.57          |
| Policy-TimeStep         | 2.61          |
| Time                    | 757           |
| n_timesteps             | 28000         |
-------------------------------------------

 ---------------- Iteration 28 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 280 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 281 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 282 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 283 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 284 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 285 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 286 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 287 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 288 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 289 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Data-EnvSampler-EnvE... | 0.355        |
| Data-EnvSampler-Poli... | 0.915        |
| Data-EnvTrajs-Averag... | -11.3        |
| Data-EnvTrajs-MaxReturn | 26.9         |
| Data-EnvTrajs-MinReturn | -44.7        |
| Data-EnvTrajs-NumTrajs  | 5            |
| Data-EnvTrajs-StdReturn | 23.6         |
| Data-TimeEnvSampleProc  | 0.000988     |
| Data-TimeEnvSampling    | 1.3          |
| Iteration               | 28           |
| ItrTime                 | 33.3         |
| LossAfter               | -0.018254261 |
| LossBefore              | -8.91566e-06 |
| Model-TimeModelFit      | 29.5         |
| ModelSampler-n_times... | 1160000      |
| Policy-AverageAbsPol... | 0.5050238    |
| Policy-AverageDiscou... | 49.8         |
| Policy-AveragePolicyStd | 0.59010047   |
| Policy-AverageReturn    | 130          |
| Policy-MaxReturn        | 192          |
| Policy-MinReturn        | 73.3         |
| Policy-NumTrajs         | 20           |
| Policy-StdReturn        | 31.6         |
| Policy-TimeAlgoOpt      | 0.602        |
| Policy-TimeSampleProc   | 0.325        |
| Policy-TimeSampling     | 1.54         |
| Policy-TimeStep         | 2.48         |
| Time                    | 791          |
| n_timesteps             | 29000        |
------------------------------------------

 ---------------- Iteration 29 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 290 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 291 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 292 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 293 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 294 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 295 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 296 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 297 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 298 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 299 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.39          |
| Data-EnvSampler-Poli... | 0.999         |
| Data-EnvTrajs-Averag... | 0.485         |
| Data-EnvTrajs-MaxReturn | 45.8          |
| Data-EnvTrajs-MinReturn | -32.5         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 27.8          |
| Data-TimeEnvSampleProc  | 0.000915      |
| Data-TimeEnvSampling    | 1.43          |
| Iteration               | 29            |
| ItrTime                 | 34.2          |
| LossAfter               | -0.017936401  |
| LossBefore              | -8.604996e-06 |
| Model-TimeModelFit      | 30            |
| ModelSampler-n_times... | 1200000       |
| Policy-AverageAbsPol... | 0.49410886    |
| Policy-AverageDiscou... | 27            |
| Policy-AveragePolicyStd | 0.5730361     |
| Policy-AverageReturn    | 64.6          |
| Policy-MaxReturn        | 134           |
| Policy-MinReturn        | -37.2         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 37            |
| Policy-TimeAlgoOpt      | 0.623         |
| Policy-TimeSampleProc   | 0.428         |
| Policy-TimeSampling     | 1.59          |
| Policy-TimeStep         | 2.69          |
| Time                    | 825           |
| n_timesteps             | 30000         |
-------------------------------------------

 ---------------- Iteration 30 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 300 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 301 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 302 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 303 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 304 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 305 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 306 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 307 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 308 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 309 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.342         |
| Data-EnvSampler-Poli... | 0.852         |
| Data-EnvTrajs-Averag... | -12.7         |
| Data-EnvTrajs-MaxReturn | 55            |
| Data-EnvTrajs-MinReturn | -116          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 59            |
| Data-TimeEnvSampleProc  | 0.000843      |
| Data-TimeEnvSampling    | 1.24          |
| Iteration               | 30            |
| ItrTime                 | 33.7          |
| LossAfter               | -0.018137991  |
| LossBefore              | -8.453143e-06 |
| Model-TimeModelFit      | 29.4          |
| ModelSampler-n_times... | 1240000       |
| Policy-AverageAbsPol... | 0.49137434    |
| Policy-AverageDiscou... | -9.07         |
| Policy-AveragePolicyStd | 0.5649757     |
| Policy-AverageReturn    | -14.6         |
| Policy-MaxReturn        | 61.1          |
| Policy-MinReturn        | -124          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 50.3          |
| Policy-TimeAlgoOpt      | 0.616         |
| Policy-TimeSampleProc   | 0.589         |
| Policy-TimeSampling     | 1.8           |
| Policy-TimeStep         | 3.06          |
| Time                    | 859           |
| n_timesteps             | 31000         |
-------------------------------------------

 ---------------- Iteration 31 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 310 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 311 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 312 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 313 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 314 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 315 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 316 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 317 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 318 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 319 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.423          |
| Data-EnvSampler-Poli... | 1.33           |
| Data-EnvTrajs-Averag... | 0.776          |
| Data-EnvTrajs-MaxReturn | 38.1           |
| Data-EnvTrajs-MinReturn | -69.2          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 42.2           |
| Data-TimeEnvSampleProc  | 0.000872       |
| Data-TimeEnvSampling    | 1.79           |
| Iteration               | 31             |
| ItrTime                 | 34.7           |
| LossAfter               | -0.01794023    |
| LossBefore              | -8.4424655e-06 |
| Model-TimeModelFit      | 30.2           |
| ModelSampler-n_times... | 1280000        |
| Policy-AverageAbsPol... | 0.49294144     |
| Policy-AverageDiscou... | -100           |
| Policy-AveragePolicyStd | 0.56260395     |
| Policy-AverageReturn    | -249           |
| Policy-MaxReturn        | -146           |
| Policy-MinReturn        | -304           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 45.7           |
| Policy-TimeAlgoOpt      | 0.713          |
| Policy-TimeSampleProc   | 0.375          |
| Policy-TimeSampling     | 1.6            |
| Policy-TimeStep         | 2.71           |
| Time                    | 893            |
| n_timesteps             | 32000          |
--------------------------------------------

 ---------------- Iteration 32 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 320 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 321 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 322 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 323 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 324 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 325 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 326 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 327 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 328 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 329 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.442         |
| Data-EnvSampler-Poli... | 1.29          |
| Data-EnvTrajs-Averag... | 45.4          |
| Data-EnvTrajs-MaxReturn | 70.1          |
| Data-EnvTrajs-MinReturn | -3.86         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 25.9          |
| Data-TimeEnvSampleProc  | 0.00127       |
| Data-TimeEnvSampling    | 1.78          |
| Iteration               | 32            |
| ItrTime                 | 34.6          |
| LossAfter               | -0.019141957  |
| LossBefore              | -8.199164e-06 |
| Model-TimeModelFit      | 30.1          |
| ModelSampler-n_times... | 1320000       |
| Policy-AverageAbsPol... | 0.5435198     |
| Policy-AverageDiscou... | 40.5          |
| Policy-AveragePolicyStd | 0.54881424    |
| Policy-AverageReturn    | 98.1          |
| Policy-MaxReturn        | 142           |
| Policy-MinReturn        | 44.3          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 30            |
| Policy-TimeAlgoOpt      | 0.644         |
| Policy-TimeSampleProc   | 0.428         |
| Policy-TimeSampling     | 1.57          |
| Policy-TimeStep         | 2.7           |
| Time                    | 928           |
| n_timesteps             | 33000         |
-------------------------------------------

 ---------------- Iteration 33 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 330 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 331 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 332 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 333 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 334 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 335 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 336 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 337 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 338 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 339 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.384         |
| Data-EnvSampler-Poli... | 0.933         |
| Data-EnvTrajs-Averag... | 27.4          |
| Data-EnvTrajs-MaxReturn | 121           |
| Data-EnvTrajs-MinReturn | -44.4         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 64.9          |
| Data-TimeEnvSampleProc  | 0.00409       |
| Data-TimeEnvSampling    | 1.36          |
| Iteration               | 33            |
| ItrTime                 | 35.7          |
| LossAfter               | -0.019364526  |
| LossBefore              | -7.964746e-06 |
| Model-TimeModelFit      | 31.6          |
| ModelSampler-n_times... | 1360000       |
| Policy-AverageAbsPol... | 0.51036465    |
| Policy-AverageDiscou... | 83.9          |
| Policy-AveragePolicyStd | 0.53650475    |
| Policy-AverageReturn    | 202           |
| Policy-MaxReturn        | 277           |
| Policy-MinReturn        | 127           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 45.7          |
| Policy-TimeAlgoOpt      | 0.622         |
| Policy-TimeSampleProc   | 0.423         |
| Policy-TimeSampling     | 1.58          |
| Policy-TimeStep         | 2.71          |
| Time                    | 964           |
| n_timesteps             | 34000         |
-------------------------------------------

 ---------------- Iteration 34 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 340 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 341 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 342 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 343 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 344 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 345 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 346 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 347 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 348 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 349 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.324         |
| Data-EnvSampler-Poli... | 0.858         |
| Data-EnvTrajs-Averag... | -7.69         |
| Data-EnvTrajs-MaxReturn | 64.3          |
| Data-EnvTrajs-MinReturn | -46.1         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 38.5          |
| Data-TimeEnvSampleProc  | 0.000811      |
| Data-TimeEnvSampling    | 1.22          |
| Iteration               | 34            |
| ItrTime                 | 36.1          |
| LossAfter               | -0.018107407  |
| LossBefore              | -7.802934e-06 |
| Model-TimeModelFit      | 31.5          |
| ModelSampler-n_times... | 1400000       |
| Policy-AverageAbsPol... | 0.49930355    |
| Policy-AverageDiscou... | 62.3          |
| Policy-AveragePolicyStd | 0.5284854     |
| Policy-AverageReturn    | 157           |
| Policy-MaxReturn        | 250           |
| Policy-MinReturn        | 17.5          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 55.6          |
| Policy-TimeAlgoOpt      | 0.675         |
| Policy-TimeSampleProc   | 0.617         |
| Policy-TimeSampling     | 2.09          |
| Policy-TimeStep         | 3.43          |
| Time                    | 1e+03         |
| n_timesteps             | 35000         |
-------------------------------------------

 ---------------- Iteration 35 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 350 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 351 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 352 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 353 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 354 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 355 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 356 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 357 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 358 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 359 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.331         |
| Data-EnvSampler-Poli... | 0.843         |
| Data-EnvTrajs-Averag... | 29.5          |
| Data-EnvTrajs-MaxReturn | 78.4          |
| Data-EnvTrajs-MinReturn | -62.7         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 48            |
| Data-TimeEnvSampleProc  | 0.00052       |
| Data-TimeEnvSampling    | 1.2           |
| Iteration               | 35            |
| ItrTime                 | 34.5          |
| LossAfter               | -0.018587522  |
| LossBefore              | -7.726301e-06 |
| Model-TimeModelFit      | 30.6          |
| ModelSampler-n_times... | 1440000       |
| Policy-AverageAbsPol... | 0.5256857     |
| Policy-AverageDiscou... | 101           |
| Policy-AveragePolicyStd | 0.52349347    |
| Policy-AverageReturn    | 343           |
| Policy-MaxReturn        | 2.8e+03       |
| Policy-MinReturn        | 133           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 565           |
| Policy-TimeAlgoOpt      | 0.613         |
| Policy-TimeSampleProc   | 0.4           |
| Policy-TimeSampling     | 1.59          |
| Policy-TimeStep         | 2.67          |
| Time                    | 1.03e+03      |
| n_timesteps             | 36000         |
-------------------------------------------

 ---------------- Iteration 36 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 360 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 361 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 362 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 363 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 364 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 365 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 366 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 367 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 368 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 369 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.338          |
| Data-EnvSampler-Poli... | 0.918          |
| Data-EnvTrajs-Averag... | 14.2           |
| Data-EnvTrajs-MaxReturn | 59.1           |
| Data-EnvTrajs-MinReturn | -47            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 34.6           |
| Data-TimeEnvSampleProc  | 0.00114        |
| Data-TimeEnvSampling    | 1.29           |
| Iteration               | 36             |
| ItrTime                 | 37.5           |
| LossAfter               | -0.019780047   |
| LossBefore              | -7.5461767e-06 |
| Model-TimeModelFit      | 33.3           |
| ModelSampler-n_times... | 1480000        |
| Policy-AverageAbsPol... | 0.50621974     |
| Policy-AverageDiscou... | -9.18          |
| Policy-AveragePolicyStd | 0.51580316     |
| Policy-AverageReturn    | -22.5          |
| Policy-MaxReturn        | 65.1           |
| Policy-MinReturn        | -142           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 48             |
| Policy-TimeAlgoOpt      | 0.669          |
| Policy-TimeSampleProc   | 0.566          |
| Policy-TimeSampling     | 1.61           |
| Policy-TimeStep         | 2.92           |
| Time                    | 1.07e+03       |
| n_timesteps             | 37000          |
--------------------------------------------

 ---------------- Iteration 37 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 370 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 371 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 372 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 373 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 374 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 375 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 376 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 377 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 378 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 379 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.366          |
| Data-EnvSampler-Poli... | 0.921          |
| Data-EnvTrajs-Averag... | 30.8           |
| Data-EnvTrajs-MaxReturn | 72.6           |
| Data-EnvTrajs-MinReturn | -27            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 34.3           |
| Data-TimeEnvSampleProc  | 0.00116        |
| Data-TimeEnvSampling    | 1.33           |
| Iteration               | 37             |
| ItrTime                 | 35.6           |
| LossAfter               | -0.021608645   |
| LossBefore              | -7.4012614e-06 |
| Model-TimeModelFit      | 31.7           |
| ModelSampler-n_times... | 1520000        |
| Policy-AverageAbsPol... | 0.5845464      |
| Policy-AverageDiscou... | 30.1           |
| Policy-AveragePolicyStd | 0.50776976     |
| Policy-AverageReturn    | 72.7           |
| Policy-MaxReturn        | 171            |
| Policy-MinReturn        | 4.13           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 51.4           |
| Policy-TimeAlgoOpt      | 0.577          |
| Policy-TimeSampleProc   | 0.429          |
| Policy-TimeSampling     | 1.52           |
| Policy-TimeStep         | 2.57           |
| Time                    | 1.11e+03       |
| n_timesteps             | 38000          |
--------------------------------------------

 ---------------- Iteration 38 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 380 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 381 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 382 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 383 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 384 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 385 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 386 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 387 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 388 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 389 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.353         |
| Data-EnvSampler-Poli... | 0.831         |
| Data-EnvTrajs-Averag... | 33.8          |
| Data-EnvTrajs-MaxReturn | 84.4          |
| Data-EnvTrajs-MinReturn | -84.8         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 60.7          |
| Data-TimeEnvSampleProc  | 0.000987      |
| Data-TimeEnvSampling    | 1.22          |
| Iteration               | 38            |
| ItrTime                 | 35.6          |
| LossAfter               | -0.019561598  |
| LossBefore              | -7.261951e-06 |
| Model-TimeModelFit      | 31.9          |
| ModelSampler-n_times... | 1560000       |
| Policy-AverageAbsPol... | 0.56987387    |
| Policy-AverageDiscou... | 105           |
| Policy-AveragePolicyStd | 0.500816      |
| Policy-AverageReturn    | 279           |
| Policy-MaxReturn        | 453           |
| Policy-MinReturn        | 211           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 53.9          |
| Policy-TimeAlgoOpt      | 0.586         |
| Policy-TimeSampleProc   | 0.393         |
| Policy-TimeSampling     | 1.48          |
| Policy-TimeStep         | 2.48          |
| Time                    | 1.14e+03      |
| n_timesteps             | 39000         |
-------------------------------------------

 ---------------- Iteration 39 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 390 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 391 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 392 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 393 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 394 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 395 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 396 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 397 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 398 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 399 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.33           |
| Data-EnvSampler-Poli... | 0.825          |
| Data-EnvTrajs-Averag... | 46             |
| Data-EnvTrajs-MaxReturn | 113            |
| Data-EnvTrajs-MinReturn | -25.9          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 49.1           |
| Data-TimeEnvSampleProc  | 0.000981       |
| Data-TimeEnvSampling    | 1.19           |
| Iteration               | 39             |
| ItrTime                 | 36.3           |
| LossAfter               | -0.027276421   |
| LossBefore              | -7.1856452e-06 |
| Model-TimeModelFit      | 32.4           |
| ModelSampler-n_times... | 1600000        |
| Policy-AverageAbsPol... | 0.6651504      |
| Policy-AverageDiscou... | 517            |
| Policy-AveragePolicyStd | 0.49725786     |
| Policy-AverageReturn    | 1.97e+03       |
| Policy-MaxReturn        | 6.43e+03       |
| Policy-MinReturn        | 93.6           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.89e+03       |
| Policy-TimeAlgoOpt      | 0.634          |
| Policy-TimeSampleProc   | 0.442          |
| Policy-TimeSampling     | 1.56           |
| Policy-TimeStep         | 2.67           |
| Time                    | 1.18e+03       |
| n_timesteps             | 40000          |
--------------------------------------------

 ---------------- Iteration 40 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 400 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 401 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 402 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 403 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 404 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 405 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 406 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 407 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 408 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 409 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.463          |
| Data-EnvSampler-Poli... | 1.27           |
| Data-EnvTrajs-Averag... | 2.94           |
| Data-EnvTrajs-MaxReturn | 81.5           |
| Data-EnvTrajs-MinReturn | -93.2          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 58.3           |
| Data-TimeEnvSampleProc  | 0.000546       |
| Data-TimeEnvSampling    | 1.78           |
| Iteration               | 40             |
| ItrTime                 | 37             |
| LossAfter               | -0.019416116   |
| LossBefore              | -7.1504383e-06 |
| Model-TimeModelFit      | 32.7           |
| ModelSampler-n_times... | 1640000        |
| Policy-AverageAbsPol... | 0.6001694      |
| Policy-AverageDiscou... | 24.4           |
| Policy-AveragePolicyStd | 0.49549484     |
| Policy-AverageReturn    | 67.6           |
| Policy-MaxReturn        | 145            |
| Policy-MinReturn        | -55.9          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 53.1           |
| Policy-TimeAlgoOpt      | 0.579          |
| Policy-TimeSampleProc   | 0.349          |
| Policy-TimeSampling     | 1.59           |
| Policy-TimeStep         | 2.56           |
| Time                    | 1.22e+03       |
| n_timesteps             | 41000          |
--------------------------------------------

 ---------------- Iteration 41 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 410 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 411 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 412 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 413 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 414 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 415 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 416 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 417 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 418 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 419 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.333         |
| Data-EnvSampler-Poli... | 0.819         |
| Data-EnvTrajs-Averag... | -3.99         |
| Data-EnvTrajs-MaxReturn | 32.4          |
| Data-EnvTrajs-MinReturn | -30.5         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 21.9          |
| Data-TimeEnvSampleProc  | 0.00108       |
| Data-TimeEnvSampling    | 1.19          |
| Iteration               | 41            |
| ItrTime                 | 36            |
| LossAfter               | -0.022547683  |
| LossBefore              | -7.088341e-06 |
| Model-TimeModelFit      | 32.2          |
| ModelSampler-n_times... | 1680000       |
| Policy-AverageAbsPol... | 0.6523897     |
| Policy-AverageDiscou... | 364           |
| Policy-AveragePolicyStd | 0.49208054    |
| Policy-AverageReturn    | 1.38e+03      |
| Policy-MaxReturn        | 1.34e+04      |
| Policy-MinReturn        | -144          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 2.89e+03      |
| Policy-TimeAlgoOpt      | 0.595         |
| Policy-TimeSampleProc   | 0.304         |
| Policy-TimeSampling     | 1.61          |
| Policy-TimeStep         | 2.54          |
| Time                    | 1.25e+03      |
| n_timesteps             | 42000         |
-------------------------------------------

 ---------------- Iteration 42 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 420 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 421 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 422 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 423 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 424 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 425 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 426 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 427 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 428 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 429 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.331          |
| Data-EnvSampler-Poli... | 0.819          |
| Data-EnvTrajs-Averag... | 48.2           |
| Data-EnvTrajs-MaxReturn | 137            |
| Data-EnvTrajs-MinReturn | 20.1           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 44.8           |
| Data-TimeEnvSampleProc  | 0.00079        |
| Data-TimeEnvSampling    | 1.19           |
| Iteration               | 42             |
| ItrTime                 | 35             |
| LossAfter               | -0.019050715   |
| LossBefore              | -7.0610768e-06 |
| Model-TimeModelFit      | 31             |
| ModelSampler-n_times... | 1720000        |
| Policy-AverageAbsPol... | 0.590195       |
| Policy-AverageDiscou... | 29.5           |
| Policy-AveragePolicyStd | 0.48902306     |
| Policy-AverageReturn    | 48.5           |
| Policy-MaxReturn        | 124            |
| Policy-MinReturn        | -21.2          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 43.9           |
| Policy-TimeAlgoOpt      | 0.596          |
| Policy-TimeSampleProc   | 0.466          |
| Policy-TimeSampling     | 1.66           |
| Policy-TimeStep         | 2.79           |
| Time                    | 1.29e+03       |
| n_timesteps             | 43000          |
--------------------------------------------

 ---------------- Iteration 43 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 430 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 431 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 432 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 433 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 434 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 435 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 436 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 437 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 438 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 439 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.354          |
| Data-EnvSampler-Poli... | 0.86           |
| Data-EnvTrajs-Averag... | 64.8           |
| Data-EnvTrajs-MaxReturn | 124            |
| Data-EnvTrajs-MinReturn | -26            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 52.4           |
| Data-TimeEnvSampleProc  | 0.000839       |
| Data-TimeEnvSampling    | 1.25           |
| Iteration               | 43             |
| ItrTime                 | 36.4           |
| LossAfter               | -0.021008844   |
| LossBefore              | -6.7505957e-06 |
| Model-TimeModelFit      | 31.7           |
| ModelSampler-n_times... | 1760000        |
| Policy-AverageAbsPol... | 0.5756456      |
| Policy-AverageDiscou... | 31.6           |
| Policy-AveragePolicyStd | 0.4761595      |
| Policy-AverageReturn    | 76.5           |
| Policy-MaxReturn        | 176            |
| Policy-MinReturn        | -74.6          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 65.1           |
| Policy-TimeAlgoOpt      | 0.64           |
| Policy-TimeSampleProc   | 0.622          |
| Policy-TimeSampling     | 2.16           |
| Policy-TimeStep         | 3.49           |
| Time                    | 1.32e+03       |
| n_timesteps             | 44000          |
--------------------------------------------

 ---------------- Iteration 44 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 440 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 441 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 442 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 443 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 444 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 445 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 446 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 447 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 448 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 449 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.383          |
| Data-EnvSampler-Poli... | 1.16           |
| Data-EnvTrajs-Averag... | 22.8           |
| Data-EnvTrajs-MaxReturn | 105            |
| Data-EnvTrajs-MinReturn | -58.5          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 63.5           |
| Data-TimeEnvSampleProc  | 0.00101        |
| Data-TimeEnvSampling    | 1.59           |
| Iteration               | 44             |
| ItrTime                 | 36.4           |
| LossAfter               | -0.018520731   |
| LossBefore              | -6.5943004e-06 |
| Model-TimeModelFit      | 32.2           |
| ModelSampler-n_times... | 1800000        |
| Policy-AverageAbsPol... | 0.5786845      |
| Policy-AverageDiscou... | -52.7          |
| Policy-AveragePolicyStd | 0.46804264     |
| Policy-AverageReturn    | -103           |
| Policy-MaxReturn        | 16.3           |
| Policy-MinReturn        | -175           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 48             |
| Policy-TimeAlgoOpt      | 0.616          |
| Policy-TimeSampleProc   | 0.377          |
| Policy-TimeSampling     | 1.55           |
| Policy-TimeStep         | 2.55           |
| Time                    | 1.36e+03       |
| n_timesteps             | 45000          |
--------------------------------------------

 ---------------- Iteration 45 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 450 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 451 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 452 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 453 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 454 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 455 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 456 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 457 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 458 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 459 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.335         |
| Data-EnvSampler-Poli... | 0.852         |
| Data-EnvTrajs-Averag... | 39.7          |
| Data-EnvTrajs-MaxReturn | 70.8          |
| Data-EnvTrajs-MinReturn | 16.6          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 17.8          |
| Data-TimeEnvSampleProc  | 0.00108       |
| Data-TimeEnvSampling    | 1.22          |
| Iteration               | 45            |
| ItrTime                 | 36.3          |
| LossAfter               | -0.019707488  |
| LossBefore              | -6.523682e-06 |
| Model-TimeModelFit      | 32.5          |
| ModelSampler-n_times... | 1840000       |
| Policy-AverageAbsPol... | 0.59450907    |
| Policy-AverageDiscou... | -45.5         |
| Policy-AveragePolicyStd | 0.46517864    |
| Policy-AverageReturn    | -85.1         |
| Policy-MaxReturn        | 26.6          |
| Policy-MinReturn        | -230          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 70.7          |
| Policy-TimeAlgoOpt      | 0.626         |
| Policy-TimeSampleProc   | 0.429         |
| Policy-TimeSampling     | 1.5           |
| Policy-TimeStep         | 2.58          |
| Time                    | 1.4e+03       |
| n_timesteps             | 46000         |
-------------------------------------------

 ---------------- Iteration 46 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 460 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 461 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 462 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 463 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 464 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 465 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 466 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 467 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 468 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 469 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.326          |
| Data-EnvSampler-Poli... | 0.884          |
| Data-EnvTrajs-Averag... | 22.1           |
| Data-EnvTrajs-MaxReturn | 47.3           |
| Data-EnvTrajs-MinReturn | 7.1            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 13.9           |
| Data-TimeEnvSampleProc  | 0.000847       |
| Data-TimeEnvSampling    | 1.25           |
| Iteration               | 46             |
| ItrTime                 | 36.6           |
| LossAfter               | -0.02140167    |
| LossBefore              | -6.4287337e-06 |
| Model-TimeModelFit      | 32.5           |
| ModelSampler-n_times... | 1880000        |
| Policy-AverageAbsPol... | 0.57316273     |
| Policy-AverageDiscou... | 9.52           |
| Policy-AveragePolicyStd | 0.4600966      |
| Policy-AverageReturn    | 34.7           |
| Policy-MaxReturn        | 115            |
| Policy-MinReturn        | -83.1          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 46.6           |
| Policy-TimeAlgoOpt      | 0.65           |
| Policy-TimeSampleProc   | 0.48           |
| Policy-TimeSampling     | 1.7            |
| Policy-TimeStep         | 2.88           |
| Time                    | 1.43e+03       |
| n_timesteps             | 47000          |
--------------------------------------------

 ---------------- Iteration 47 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 470 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 471 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 472 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 473 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 474 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 475 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 476 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 477 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 478 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 479 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.367          |
| Data-EnvSampler-Poli... | 0.936          |
| Data-EnvTrajs-Averag... | 50.8           |
| Data-EnvTrajs-MaxReturn | 152            |
| Data-EnvTrajs-MinReturn | -57.5          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 70.5           |
| Data-TimeEnvSampleProc  | 0.001          |
| Data-TimeEnvSampling    | 1.34           |
| Iteration               | 47             |
| ItrTime                 | 35.2           |
| LossAfter               | -0.021287043   |
| LossBefore              | -6.2602985e-06 |
| Model-TimeModelFit      | 31.2           |
| ModelSampler-n_times... | 1920000        |
| Policy-AverageAbsPol... | 0.56419325     |
| Policy-AverageDiscou... | -33.6          |
| Policy-AveragePolicyStd | 0.45321065     |
| Policy-AverageReturn    | -93            |
| Policy-MaxReturn        | 29.5           |
| Policy-MinReturn        | -309           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 72             |
| Policy-TimeAlgoOpt      | 0.65           |
| Policy-TimeSampleProc   | 0.385          |
| Policy-TimeSampling     | 1.53           |
| Policy-TimeStep         | 2.62           |
| Time                    | 1.47e+03       |
| n_timesteps             | 48000          |
--------------------------------------------

 ---------------- Iteration 48 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 480 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 481 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 482 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 483 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 484 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 485 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 486 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 487 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 488 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 489 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.323          |
| Data-EnvSampler-Poli... | 0.829          |
| Data-EnvTrajs-Averag... | 70             |
| Data-EnvTrajs-MaxReturn | 110            |
| Data-EnvTrajs-MinReturn | 8.05           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 45.8           |
| Data-TimeEnvSampleProc  | 0.00091        |
| Data-TimeEnvSampling    | 1.18           |
| Iteration               | 48             |
| ItrTime                 | 36.1           |
| LossAfter               | -0.022583451   |
| LossBefore              | -6.2350614e-06 |
| Model-TimeModelFit      | 31.9           |
| ModelSampler-n_times... | 1960000        |
| Policy-AverageAbsPol... | 0.57600415     |
| Policy-AverageDiscou... | -1.96          |
| Policy-AveragePolicyStd | 0.45214018     |
| Policy-AverageReturn    | 1.41           |
| Policy-MaxReturn        | 144            |
| Policy-MinReturn        | -74.6          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 53.6           |
| Policy-TimeAlgoOpt      | 0.703          |
| Policy-TimeSampleProc   | 0.45           |
| Policy-TimeSampling     | 1.78           |
| Policy-TimeStep         | 2.99           |
| Time                    | 1.5e+03        |
| n_timesteps             | 49000          |
--------------------------------------------

 ---------------- Iteration 49 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 490 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 491 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 492 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 493 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 494 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 495 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 496 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 497 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 498 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 499 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.358          |
| Data-EnvSampler-Poli... | 0.906          |
| Data-EnvTrajs-Averag... | 77.3           |
| Data-EnvTrajs-MaxReturn | 155            |
| Data-EnvTrajs-MinReturn | 13.2           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 52.3           |
| Data-TimeEnvSampleProc  | 0.0011         |
| Data-TimeEnvSampling    | 1.3            |
| Iteration               | 49             |
| ItrTime                 | 35.2           |
| LossAfter               | -0.022898266   |
| LossBefore              | -6.1739624e-06 |
| Model-TimeModelFit      | 31.4           |
| ModelSampler-n_times... | 2000000        |
| Policy-AverageAbsPol... | 0.5841059      |
| Policy-AverageDiscou... | 48             |
| Policy-AveragePolicyStd | 0.44979027     |
| Policy-AverageReturn    | 130            |
| Policy-MaxReturn        | 314            |
| Policy-MinReturn        | -15.5          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 80             |
| Policy-TimeAlgoOpt      | 0.569          |
| Policy-TimeSampleProc   | 0.395          |
| Policy-TimeSampling     | 1.52           |
| Policy-TimeStep         | 2.54           |
| Time                    | 1.54e+03       |
| n_timesteps             | 50000          |
--------------------------------------------

 ---------------- Iteration 50 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 500 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 501 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 502 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 503 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 504 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 505 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 506 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 507 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 508 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 509 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.358         |
| Data-EnvSampler-Poli... | 0.833         |
| Data-EnvTrajs-Averag... | 82            |
| Data-EnvTrajs-MaxReturn | 196           |
| Data-EnvTrajs-MinReturn | -7.14         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 74.8          |
| Data-TimeEnvSampleProc  | 0.000725      |
| Data-TimeEnvSampling    | 1.23          |
| Iteration               | 50            |
| ItrTime                 | 36.3          |
| LossAfter               | -0.019334128  |
| LossBefore              | -6.056839e-06 |
| Model-TimeModelFit      | 32.1          |
| ModelSampler-n_times... | 2040000       |
| Policy-AverageAbsPol... | 0.55256695    |
| Policy-AverageDiscou... | -12.8         |
| Policy-AveragePolicyStd | 0.44633365    |
| Policy-AverageReturn    | -35.7         |
| Policy-MaxReturn        | 103           |
| Policy-MinReturn        | -131          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 50.7          |
| Policy-TimeAlgoOpt      | 0.62          |
| Policy-TimeSampleProc   | 0.506         |
| Policy-TimeSampling     | 1.84          |
| Policy-TimeStep         | 3.01          |
| Time                    | 1.58e+03      |
| n_timesteps             | 51000         |
-------------------------------------------
Training finished
