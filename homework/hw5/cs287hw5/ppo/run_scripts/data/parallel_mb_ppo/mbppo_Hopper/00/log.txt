Logging to /home/vincent/workplace/CS_287_-_Advanced_Robotics/homework/hw5/cs287hw5/ppo/run_scripts/data/parallel_mb_ppo/mbppo_Hopper//00

 ---------------- Iteration 0 ----------------
Obtaining random samples from the environment...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 0 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 1 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 2 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 3 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 4 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 5 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 6 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 7 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 8 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 9 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.202          |
| Data-EnvSampler-Poli... | 0.0446         |
| Data-EnvTrajs-Averag... | -274           |
| Data-EnvTrajs-MaxReturn | -185           |
| Data-EnvTrajs-MinReturn | -332           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 52.4           |
| Data-TimeEnvSampleProc  | 0.00056        |
| Data-TimeEnvSampling    | 0.258          |
| Iteration               | 0              |
| ItrTime                 | 10.6           |
| LossAfter               | -0.006878032   |
| LossBefore              | -1.3757099e-05 |
| Model-TimeModelFit      | 3.61           |
| ModelSampler-n_times... | 40000          |
| Policy-AverageAbsPol... | 0.41917276     |
| Policy-AverageDiscou... | -2.05e+06      |
| Policy-AveragePolicyStd | 0.9582872      |
| Policy-AverageReturn    | -5.33e+06      |
| Policy-MaxReturn        | -5.21e+06      |
| Policy-MinReturn        | -5.44e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 6.03e+04       |
| Policy-TimeAlgoOpt      | 1.13           |
| Policy-TimeSampleProc   | 0.417          |
| Policy-TimeSampling     | 5.19           |
| Policy-TimeStep         | 6.77           |
| Time                    | 10.6           |
| n_timesteps             | 1000           |
--------------------------------------------

 ---------------- Iteration 1 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 10 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 11 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 12 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 13 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 14 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 15 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 16 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 17 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 18 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 19 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.294          |
| Data-EnvSampler-Poli... | 0.536          |
| Data-EnvTrajs-Averag... | 85.2           |
| Data-EnvTrajs-MaxReturn | 193            |
| Data-EnvTrajs-MinReturn | -88.6          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 99             |
| Data-TimeEnvSampleProc  | 0.000723       |
| Data-TimeEnvSampling    | 0.852          |
| Iteration               | 1              |
| ItrTime                 | 8.58           |
| LossAfter               | -0.0054692724  |
| LossBefore              | -1.3606636e-05 |
| Model-TimeModelFit      | 4.81           |
| ModelSampler-n_times... | 80000          |
| Policy-AverageAbsPol... | 0.23817529     |
| Policy-AverageDiscou... | -2.09e+06      |
| Policy-AveragePolicyStd | 0.9429554      |
| Policy-AverageReturn    | -5.34e+06      |
| Policy-MaxReturn        | -3.77e+06      |
| Policy-MinReturn        | -5.48e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 3.62e+05       |
| Policy-TimeAlgoOpt      | 0.66           |
| Policy-TimeSampleProc   | 0.412          |
| Policy-TimeSampling     | 1.83           |
| Policy-TimeStep         | 2.92           |
| Time                    | 19.4           |
| n_timesteps             | 2000           |
--------------------------------------------

 ---------------- Iteration 2 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 20 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 21 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 22 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 23 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 24 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 25 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 26 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 27 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 28 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 29 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.389          |
| Data-EnvSampler-Poli... | 0.56           |
| Data-EnvTrajs-Averag... | -109           |
| Data-EnvTrajs-MaxReturn | 119            |
| Data-EnvTrajs-MinReturn | -289           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 158            |
| Data-TimeEnvSampleProc  | 0.00097        |
| Data-TimeEnvSampling    | 0.977          |
| Iteration               | 2              |
| ItrTime                 | 11.6           |
| LossAfter               | -0.0027127983  |
| LossBefore              | -1.3488606e-05 |
| Model-TimeModelFit      | 7.52           |
| ModelSampler-n_times... | 120000         |
| Policy-AverageAbsPol... | 0.30206037     |
| Policy-AverageDiscou... | -2.12e+06      |
| Policy-AveragePolicyStd | 0.93283814     |
| Policy-AverageReturn    | -5.39e+06      |
| Policy-MaxReturn        | -5.34e+06      |
| Policy-MinReturn        | -5.43e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.56e+04       |
| Policy-TimeAlgoOpt      | 0.641          |
| Policy-TimeSampleProc   | 0.478          |
| Policy-TimeSampling     | 1.99           |
| Policy-TimeStep         | 3.15           |
| Time                    | 31             |
| n_timesteps             | 3000           |
--------------------------------------------

 ---------------- Iteration 3 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 30 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 31 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 32 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 33 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 34 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 35 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 36 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 37 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 38 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 39 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.367          |
| Data-EnvSampler-Poli... | 0.517          |
| Data-EnvTrajs-Averag... | 43.5           |
| Data-EnvTrajs-MaxReturn | 95.3           |
| Data-EnvTrajs-MinReturn | 19.5           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 26.6           |
| Data-TimeEnvSampleProc  | 0.000899       |
| Data-TimeEnvSampling    | 0.911          |
| Iteration               | 3              |
| ItrTime                 | 13.3           |
| LossAfter               | -0.0074445647  |
| LossBefore              | -1.3473781e-05 |
| Model-TimeModelFit      | 9.05           |
| ModelSampler-n_times... | 160000         |
| Policy-AverageAbsPol... | 0.6124454      |
| Policy-AverageDiscou... | -1.22e+06      |
| Policy-AveragePolicyStd | 0.9311673      |
| Policy-AverageReturn    | -4.06e+06      |
| Policy-MaxReturn        | -3.43e+06      |
| Policy-MinReturn        | -5.25e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 5.27e+05       |
| Policy-TimeAlgoOpt      | 0.641          |
| Policy-TimeSampleProc   | 0.515          |
| Policy-TimeSampling     | 2.15           |
| Policy-TimeStep         | 3.34           |
| Time                    | 44.4           |
| n_timesteps             | 4000           |
--------------------------------------------

 ---------------- Iteration 4 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 40 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 41 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 42 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 43 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 44 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 45 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 46 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 47 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 48 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 49 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.342          |
| Data-EnvSampler-Poli... | 0.484          |
| Data-EnvTrajs-Averag... | -166           |
| Data-EnvTrajs-MaxReturn | 136            |
| Data-EnvTrajs-MinReturn | -407           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 194            |
| Data-TimeEnvSampleProc  | 0.000618       |
| Data-TimeEnvSampling    | 0.851          |
| Iteration               | 4              |
| ItrTime                 | 14.6           |
| LossAfter               | -0.0031039058  |
| LossBefore              | -1.3425613e-05 |
| Model-TimeModelFit      | 10.9           |
| ModelSampler-n_times... | 200000         |
| Policy-AverageAbsPol... | 0.57226074     |
| Policy-AverageDiscou... | -1.77e+06      |
| Policy-AveragePolicyStd | 0.92641276     |
| Policy-AverageReturn    | -4.92e+06      |
| Policy-MaxReturn        | -3.73e+06      |
| Policy-MinReturn        | -5.26e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 5.13e+05       |
| Policy-TimeAlgoOpt      | 0.694          |
| Policy-TimeSampleProc   | 0.475          |
| Policy-TimeSampling     | 1.65           |
| Policy-TimeStep         | 2.86           |
| Time                    | 59             |
| n_timesteps             | 5000           |
--------------------------------------------

 ---------------- Iteration 5 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 50 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 51 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 52 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 53 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 54 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 55 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 56 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 57 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 58 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 59 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.297           |
| Data-EnvSampler-Poli... | 0.413           |
| Data-EnvTrajs-Averag... | -476            |
| Data-EnvTrajs-MaxReturn | -452            |
| Data-EnvTrajs-MinReturn | -504            |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 19.6            |
| Data-TimeEnvSampleProc  | 0.000787        |
| Data-TimeEnvSampling    | 0.732           |
| Iteration               | 5               |
| ItrTime                 | 16.3            |
| LossAfter               | -0.0057321507   |
| LossBefore              | -1.33359235e-05 |
| Model-TimeModelFit      | 12.6            |
| ModelSampler-n_times... | 240000          |
| Policy-AverageAbsPol... | 0.6908454       |
| Policy-AverageDiscou... | -1.9e+06        |
| Policy-AveragePolicyStd | 0.9192588       |
| Policy-AverageReturn    | -5.15e+06       |
| Policy-MaxReturn        | -5.12e+06       |
| Policy-MinReturn        | -5.18e+06       |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 1.81e+04        |
| Policy-TimeAlgoOpt      | 0.655           |
| Policy-TimeSampleProc   | 0.428           |
| Policy-TimeSampling     | 1.78            |
| Policy-TimeStep         | 2.89            |
| Time                    | 75.3            |
| n_timesteps             | 6000            |
---------------------------------------------

 ---------------- Iteration 6 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 60 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 61 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 62 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 63 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 64 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 65 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 66 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 67 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 68 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 69 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.45           |
| Data-EnvSampler-Poli... | 0.676          |
| Data-EnvTrajs-Averag... | -224           |
| Data-EnvTrajs-MaxReturn | -53.9          |
| Data-EnvTrajs-MinReturn | -498           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 201            |
| Data-TimeEnvSampleProc  | 0.00119        |
| Data-TimeEnvSampling    | 1.16           |
| Iteration               | 6              |
| ItrTime                 | 19.8           |
| LossAfter               | -0.0055688657  |
| LossBefore              | -1.3286094e-05 |
| Model-TimeModelFit      | 15.8           |
| ModelSampler-n_times... | 280000         |
| Policy-AverageAbsPol... | 0.73327434     |
| Policy-AverageDiscou... | -1.77e+06      |
| Policy-AveragePolicyStd | 0.91397566     |
| Policy-AverageReturn    | -4.98e+06      |
| Policy-MaxReturn        | -4.91e+06      |
| Policy-MinReturn        | -5.05e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 3.72e+04       |
| Policy-TimeAlgoOpt      | 0.623          |
| Policy-TimeSampleProc   | 0.546          |
| Policy-TimeSampling     | 1.57           |
| Policy-TimeStep         | 2.76           |
| Time                    | 95.1           |
| n_timesteps             | 7000           |
--------------------------------------------

 ---------------- Iteration 7 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 70 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 71 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 72 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 73 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 74 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 75 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 76 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 77 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 78 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 79 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.432          |
| Data-EnvSampler-Poli... | 0.642          |
| Data-EnvTrajs-Averag... | -300           |
| Data-EnvTrajs-MaxReturn | 159            |
| Data-EnvTrajs-MinReturn | -435           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 230            |
| Data-TimeEnvSampleProc  | 0.00114        |
| Data-TimeEnvSampling    | 1.11           |
| Iteration               | 7              |
| ItrTime                 | 21             |
| LossAfter               | -0.0048120827  |
| LossBefore              | -1.3156303e-05 |
| Model-TimeModelFit      | 17.4           |
| ModelSampler-n_times... | 320000         |
| Policy-AverageAbsPol... | 0.6990446      |
| Policy-AverageDiscou... | -1.88e+06      |
| Policy-AveragePolicyStd | 0.90294874     |
| Policy-AverageReturn    | -5.12e+06      |
| Policy-MaxReturn        | -5.07e+06      |
| Policy-MinReturn        | -5.14e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2e+04          |
| Policy-TimeAlgoOpt      | 0.583          |
| Policy-TimeSampleProc   | 0.349          |
| Policy-TimeSampling     | 1.52           |
| Policy-TimeStep         | 2.49           |
| Time                    | 116            |
| n_timesteps             | 8000           |
--------------------------------------------

 ---------------- Iteration 8 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 80 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 81 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 82 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 83 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 84 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 85 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 86 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 87 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 88 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 89 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.45           |
| Data-EnvSampler-Poli... | 0.855          |
| Data-EnvTrajs-Averag... | -396           |
| Data-EnvTrajs-MaxReturn | -374           |
| Data-EnvTrajs-MinReturn | -431           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 21.4           |
| Data-TimeEnvSampleProc  | 0.000879       |
| Data-TimeEnvSampling    | 1.34           |
| Iteration               | 8              |
| ItrTime                 | 23.6           |
| LossAfter               | -0.0046455176  |
| LossBefore              | -1.3142188e-05 |
| Model-TimeModelFit      | 19.5           |
| ModelSampler-n_times... | 360000         |
| Policy-AverageAbsPol... | 1.0506626      |
| Policy-AverageDiscou... | -1.36e+06      |
| Policy-AveragePolicyStd | 0.9013222      |
| Policy-AverageReturn    | -4.31e+06      |
| Policy-MaxReturn        | -2.85e+06      |
| Policy-MinReturn        | -4.84e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 6.42e+05       |
| Policy-TimeAlgoOpt      | 0.584          |
| Policy-TimeSampleProc   | 0.388          |
| Policy-TimeSampling     | 1.77           |
| Policy-TimeStep         | 2.78           |
| Time                    | 140            |
| n_timesteps             | 9000           |
--------------------------------------------

 ---------------- Iteration 9 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 90 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 91 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 92 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 93 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 94 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 95 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 96 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 97 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 98 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 99 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.489          |
| Data-EnvSampler-Poli... | 0.881          |
| Data-EnvTrajs-Averag... | -482           |
| Data-EnvTrajs-MaxReturn | -418           |
| Data-EnvTrajs-MinReturn | -526           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 36.2           |
| Data-TimeEnvSampleProc  | 0.00102        |
| Data-TimeEnvSampling    | 1.41           |
| Iteration               | 9              |
| ItrTime                 | 27.3           |
| LossAfter               | -0.0038811215  |
| LossBefore              | -1.2951349e-05 |
| Model-TimeModelFit      | 23             |
| ModelSampler-n_times... | 400000         |
| Policy-AverageAbsPol... | 1.0371364      |
| Policy-AverageDiscou... | -1.39e+06      |
| Policy-AveragePolicyStd | 0.88431585     |
| Policy-AverageReturn    | -4.4e+06       |
| Policy-MaxReturn        | -3.94e+06      |
| Policy-MinReturn        | -4.72e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.9e+05        |
| Policy-TimeAlgoOpt      | 0.591          |
| Policy-TimeSampleProc   | 0.528          |
| Policy-TimeSampling     | 1.69           |
| Policy-TimeStep         | 2.85           |
| Time                    | 167            |
| n_timesteps             | 10000          |
--------------------------------------------

 ---------------- Iteration 10 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 100 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 101 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 102 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 103 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 104 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 105 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 106 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 107 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 108 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 109 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.488           |
| Data-EnvSampler-Poli... | 0.911           |
| Data-EnvTrajs-Averag... | -404            |
| Data-EnvTrajs-MaxReturn | -400            |
| Data-EnvTrajs-MinReturn | -407            |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 2.44            |
| Data-TimeEnvSampleProc  | 0.000713        |
| Data-TimeEnvSampling    | 1.43            |
| Iteration               | 10              |
| ItrTime                 | 27.1            |
| LossAfter               | -0.0046386644   |
| LossBefore              | -1.29141035e-05 |
| Model-TimeModelFit      | 23.2            |
| ModelSampler-n_times... | 440000          |
| Policy-AverageAbsPol... | 1.0103816       |
| Policy-AverageDiscou... | -2.32e+05       |
| Policy-AveragePolicyStd | 0.88022137      |
| Policy-AverageReturn    | -7.99e+05       |
| Policy-MaxReturn        | -409            |
| Policy-MinReturn        | -4.24e+06       |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 1.6e+06         |
| Policy-TimeAlgoOpt      | 0.605           |
| Policy-TimeSampleProc   | 0.29            |
| Policy-TimeSampling     | 1.56            |
| Policy-TimeStep         | 2.47            |
| Time                    | 194             |
| n_timesteps             | 11000           |
---------------------------------------------

 ---------------- Iteration 11 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 110 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 111 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 112 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 113 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 114 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 115 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 116 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 117 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 118 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 119 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.478          |
| Data-EnvSampler-Poli... | 0.862          |
| Data-EnvTrajs-Averag... | -365           |
| Data-EnvTrajs-MaxReturn | -337           |
| Data-EnvTrajs-MinReturn | -380           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 15.4           |
| Data-TimeEnvSampleProc  | 0.00119        |
| Data-TimeEnvSampling    | 1.38           |
| Iteration               | 11             |
| ItrTime                 | 30.1           |
| LossAfter               | -0.006606431   |
| LossBefore              | -1.2850299e-05 |
| Model-TimeModelFit      | 26.1           |
| ModelSampler-n_times... | 480000         |
| Policy-AverageAbsPol... | 1.0525244      |
| Policy-AverageDiscou... | -6.61e+04      |
| Policy-AveragePolicyStd | 0.8737672      |
| Policy-AverageReturn    | -2.9e+05       |
| Policy-MaxReturn        | -307           |
| Policy-MinReturn        | -3.59e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 8.26e+05       |
| Policy-TimeAlgoOpt      | 0.592          |
| Policy-TimeSampleProc   | 0.446          |
| Policy-TimeSampling     | 1.54           |
| Policy-TimeStep         | 2.63           |
| Time                    | 224            |
| n_timesteps             | 12000          |
--------------------------------------------

 ---------------- Iteration 12 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 120 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 121 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 122 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 123 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 124 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 125 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 126 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 127 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 128 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 129 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.554           |
| Data-EnvSampler-Poli... | 0.965           |
| Data-EnvTrajs-Averag... | -364            |
| Data-EnvTrajs-MaxReturn | -345            |
| Data-EnvTrajs-MinReturn | -382            |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 14.1            |
| Data-TimeEnvSampleProc  | 0.00126         |
| Data-TimeEnvSampling    | 1.56            |
| Iteration               | 12              |
| ItrTime                 | 31.8            |
| LossAfter               | -0.0073292227   |
| LossBefore              | -1.26824325e-05 |
| Model-TimeModelFit      | 27.8            |
| ModelSampler-n_times... | 520000          |
| Policy-AverageAbsPol... | 1.0420823       |
| Policy-AverageDiscou... | -3.84e+03       |
| Policy-AveragePolicyStd | 0.8605383       |
| Policy-AverageReturn    | -2.63e+04       |
| Policy-MaxReturn        | -402            |
| Policy-MinReturn        | -2.64e+05       |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 7.39e+04        |
| Policy-TimeAlgoOpt      | 0.604           |
| Policy-TimeSampleProc   | 0.377           |
| Policy-TimeSampling     | 1.45            |
| Policy-TimeStep         | 2.47            |
| Time                    | 256             |
| n_timesteps             | 13000           |
---------------------------------------------

 ---------------- Iteration 13 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 130 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 131 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 132 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 133 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 134 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 135 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 136 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 137 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 138 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 139 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.479          |
| Data-EnvSampler-Poli... | 0.883          |
| Data-EnvTrajs-Averag... | -391           |
| Data-EnvTrajs-MaxReturn | -361           |
| Data-EnvTrajs-MinReturn | -443           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 28.7           |
| Data-TimeEnvSampleProc  | 0.000977       |
| Data-TimeEnvSampling    | 1.4            |
| Iteration               | 13             |
| ItrTime                 | 31.5           |
| LossAfter               | -0.0035630746  |
| LossBefore              | -1.2645128e-05 |
| Model-TimeModelFit      | 27.6           |
| ModelSampler-n_times... | 560000         |
| Policy-AverageAbsPol... | 1.0910412      |
| Policy-AverageDiscou... | -192           |
| Policy-AveragePolicyStd | 0.8565834      |
| Policy-AverageReturn    | -486           |
| Policy-MaxReturn        | -416           |
| Policy-MinReturn        | -551           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 34.7           |
| Policy-TimeAlgoOpt      | 0.555          |
| Policy-TimeSampleProc   | 0.386          |
| Policy-TimeSampling     | 1.5            |
| Policy-TimeStep         | 2.5            |
| Time                    | 288            |
| n_timesteps             | 14000          |
--------------------------------------------

 ---------------- Iteration 14 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 140 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 141 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 142 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 143 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 144 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 145 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 146 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 147 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 148 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 149 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.547          |
| Data-EnvSampler-Poli... | 0.994          |
| Data-EnvTrajs-Averag... | -380           |
| Data-EnvTrajs-MaxReturn | -368           |
| Data-EnvTrajs-MinReturn | -393           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 8.56           |
| Data-TimeEnvSampleProc  | 0.00083        |
| Data-TimeEnvSampling    | 1.58           |
| Iteration               | 14             |
| ItrTime                 | 32.2           |
| LossAfter               | -0.00478728    |
| LossBefore              | -1.2511567e-05 |
| Model-TimeModelFit      | 28             |
| ModelSampler-n_times... | 600000         |
| Policy-AverageAbsPol... | 0.9992435      |
| Policy-AverageDiscou... | -3.45e+05      |
| Policy-AveragePolicyStd | 0.8457022      |
| Policy-AverageReturn    | -1.59e+06      |
| Policy-MaxReturn        | -453           |
| Policy-MinReturn        | -2.96e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.23e+06       |
| Policy-TimeAlgoOpt      | 0.561          |
| Policy-TimeSampleProc   | 0.469          |
| Policy-TimeSampling     | 1.56           |
| Policy-TimeStep         | 2.64           |
| Time                    | 320            |
| n_timesteps             | 15000          |
--------------------------------------------

 ---------------- Iteration 15 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 150 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 151 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 152 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 153 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 154 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 155 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 156 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 157 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 158 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 159 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.554           |
| Data-EnvSampler-Poli... | 1.05            |
| Data-EnvTrajs-Averag... | -397            |
| Data-EnvTrajs-MaxReturn | -383            |
| Data-EnvTrajs-MinReturn | -419            |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 12.7            |
| Data-TimeEnvSampleProc  | 0.000899        |
| Data-TimeEnvSampling    | 1.65            |
| Iteration               | 15              |
| ItrTime                 | 32              |
| LossAfter               | -0.005455909    |
| LossBefore              | -1.23878945e-05 |
| Model-TimeModelFit      | 27.3            |
| ModelSampler-n_times... | 640000          |
| Policy-AverageAbsPol... | 1.0042977       |
| Policy-AverageDiscou... | -5.26e+05       |
| Policy-AveragePolicyStd | 0.8355949       |
| Policy-AverageReturn    | -2.28e+06       |
| Policy-MaxReturn        | -427            |
| Policy-MinReturn        | -3.14e+06       |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 1.16e+06        |
| Policy-TimeAlgoOpt      | 0.629           |
| Policy-TimeSampleProc   | 0.523           |
| Policy-TimeSampling     | 1.84            |
| Policy-TimeStep         | 3.04            |
| Time                    | 352             |
| n_timesteps             | 16000           |
---------------------------------------------

 ---------------- Iteration 16 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 160 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 161 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 162 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 163 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 164 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 165 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 166 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 167 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 168 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 169 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.601          |
| Data-EnvSampler-Poli... | 1.1            |
| Data-EnvTrajs-Averag... | -475           |
| Data-EnvTrajs-MaxReturn | -466           |
| Data-EnvTrajs-MinReturn | -484           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 7              |
| Data-TimeEnvSampleProc  | 0.00112        |
| Data-TimeEnvSampling    | 1.75           |
| Iteration               | 16             |
| ItrTime                 | 32.3           |
| LossAfter               | -0.003413454   |
| LossBefore              | -1.2373293e-05 |
| Model-TimeModelFit      | 28.1           |
| ModelSampler-n_times... | 680000         |
| Policy-AverageAbsPol... | 0.8571359      |
| Policy-AverageDiscou... | -2.27e+05      |
| Policy-AveragePolicyStd | 0.8356787      |
| Policy-AverageReturn    | -9.89e+05      |
| Policy-MaxReturn        | -424           |
| Policy-MinReturn        | -3.21e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.35e+06       |
| Policy-TimeAlgoOpt      | 0.566          |
| Policy-TimeSampleProc   | 0.346          |
| Policy-TimeSampling     | 1.45           |
| Policy-TimeStep         | 2.39           |
| Time                    | 384            |
| n_timesteps             | 17000          |
--------------------------------------------

 ---------------- Iteration 17 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 170 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 171 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 172 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 173 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 174 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 175 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 176 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 177 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 178 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 179 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.469          |
| Data-EnvSampler-Poli... | 0.912          |
| Data-EnvTrajs-Averag... | -487           |
| Data-EnvTrajs-MaxReturn | -445           |
| Data-EnvTrajs-MinReturn | -502           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 21.2           |
| Data-TimeEnvSampleProc  | 0.000994       |
| Data-TimeEnvSampling    | 1.42           |
| Iteration               | 17             |
| ItrTime                 | 34.1           |
| LossAfter               | -0.0037554577  |
| LossBefore              | -1.2330864e-05 |
| Model-TimeModelFit      | 29.9           |
| ModelSampler-n_times... | 720000         |
| Policy-AverageAbsPol... | 0.9338918      |
| Policy-AverageDiscou... | -4.27e+05      |
| Policy-AveragePolicyStd | 0.8323199      |
| Policy-AverageReturn    | -1.88e+06      |
| Policy-MaxReturn        | -430           |
| Policy-MinReturn        | -3.14e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.3e+06        |
| Policy-TimeAlgoOpt      | 0.616          |
| Policy-TimeSampleProc   | 0.374          |
| Policy-TimeSampling     | 1.72           |
| Policy-TimeStep         | 2.74           |
| Time                    | 418            |
| n_timesteps             | 18000          |
--------------------------------------------

 ---------------- Iteration 18 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 180 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 181 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 182 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 183 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 184 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 185 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 186 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 187 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 188 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 189 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.478          |
| Data-EnvSampler-Poli... | 0.838          |
| Data-EnvTrajs-Averag... | -490           |
| Data-EnvTrajs-MaxReturn | -456           |
| Data-EnvTrajs-MinReturn | -516           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 23.2           |
| Data-TimeEnvSampleProc  | 0.00091        |
| Data-TimeEnvSampling    | 1.35           |
| Iteration               | 18             |
| ItrTime                 | 32.4           |
| LossAfter               | -0.005094844   |
| LossBefore              | -1.2159136e-05 |
| Model-TimeModelFit      | 28.3           |
| ModelSampler-n_times... | 760000         |
| Policy-AverageAbsPol... | 0.83963346     |
| Policy-AverageDiscou... | -1.19e+05      |
| Policy-AveragePolicyStd | 0.81902784     |
| Policy-AverageReturn    | -5.34e+05      |
| Policy-MaxReturn        | -423           |
| Policy-MinReturn        | -3.05e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.08e+06       |
| Policy-TimeAlgoOpt      | 0.595          |
| Policy-TimeSampleProc   | 0.44           |
| Policy-TimeSampling     | 1.63           |
| Policy-TimeStep         | 2.7            |
| Time                    | 451            |
| n_timesteps             | 19000          |
--------------------------------------------

 ---------------- Iteration 19 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 190 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 191 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 192 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 193 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 194 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 195 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 196 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 197 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 198 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 199 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.468          |
| Data-EnvSampler-Poli... | 0.866          |
| Data-EnvTrajs-Averag... | -459           |
| Data-EnvTrajs-MaxReturn | -441           |
| Data-EnvTrajs-MinReturn | -484           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 16.1           |
| Data-TimeEnvSampleProc  | 0.00069        |
| Data-TimeEnvSampling    | 1.37           |
| Iteration               | 19             |
| ItrTime                 | 32.6           |
| LossAfter               | -0.0047907555  |
| LossBefore              | -1.2070263e-05 |
| Model-TimeModelFit      | 28.7           |
| ModelSampler-n_times... | 800000         |
| Policy-AverageAbsPol... | 0.9740861      |
| Policy-AverageDiscou... | -3.5e+05       |
| Policy-AveragePolicyStd | 0.8127285      |
| Policy-AverageReturn    | -1.4e+06       |
| Policy-MaxReturn        | -435           |
| Policy-MinReturn        | -3.51e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.61e+06       |
| Policy-TimeAlgoOpt      | 0.632          |
| Policy-TimeSampleProc   | 0.42           |
| Policy-TimeSampling     | 1.53           |
| Policy-TimeStep         | 2.6            |
| Time                    | 483            |
| n_timesteps             | 20000          |
--------------------------------------------

 ---------------- Iteration 20 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 200 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 201 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 202 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 203 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 204 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 205 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 206 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 207 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 208 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 209 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.464          |
| Data-EnvSampler-Poli... | 0.867          |
| Data-EnvTrajs-Averag... | -483           |
| Data-EnvTrajs-MaxReturn | -460           |
| Data-EnvTrajs-MinReturn | -498           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 13             |
| Data-TimeEnvSampleProc  | 0.000996       |
| Data-TimeEnvSampling    | 1.37           |
| Iteration               | 20             |
| ItrTime                 | 33.6           |
| LossAfter               | -0.007893316   |
| LossBefore              | -1.1984564e-05 |
| Model-TimeModelFit      | 29.4           |
| ModelSampler-n_times... | 840000         |
| Policy-AverageAbsPol... | 1.0830818      |
| Policy-AverageDiscou... | -3.33e+05      |
| Policy-AveragePolicyStd | 0.80446273     |
| Policy-AverageReturn    | -1.34e+06      |
| Policy-MaxReturn        | -188           |
| Policy-MinReturn        | -3.74e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.58e+06       |
| Policy-TimeAlgoOpt      | 0.611          |
| Policy-TimeSampleProc   | 0.521          |
| Policy-TimeSampling     | 1.7            |
| Policy-TimeStep         | 2.88           |
| Time                    | 517            |
| n_timesteps             | 21000          |
--------------------------------------------

 ---------------- Iteration 21 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 210 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 211 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 212 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 213 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 214 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 215 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 216 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 217 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 218 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 219 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.51            |
| Data-EnvSampler-Poli... | 0.909           |
| Data-EnvTrajs-Averag... | -497            |
| Data-EnvTrajs-MaxReturn | -485            |
| Data-EnvTrajs-MinReturn | -505            |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 7.5             |
| Data-TimeEnvSampleProc  | 0.000972        |
| Data-TimeEnvSampling    | 1.46            |
| Iteration               | 21              |
| ItrTime                 | 32.3            |
| LossAfter               | -0.0030144367   |
| LossBefore              | -1.18138805e-05 |
| Model-TimeModelFit      | 28.1            |
| ModelSampler-n_times... | 880000          |
| Policy-AverageAbsPol... | 1.0990475       |
| Policy-AverageDiscou... | -4.2e+04        |
| Policy-AveragePolicyStd | 0.79248554      |
| Policy-AverageReturn    | -2e+05          |
| Policy-MaxReturn        | -12.6           |
| Policy-MinReturn        | -2.81e+06       |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 6.53e+05        |
| Policy-TimeAlgoOpt      | 0.566           |
| Policy-TimeSampleProc   | 0.446           |
| Policy-TimeSampling     | 1.68            |
| Policy-TimeStep         | 2.72            |
| Time                    | 549             |
| n_timesteps             | 22000           |
---------------------------------------------

 ---------------- Iteration 22 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 220 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 221 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 222 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 223 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 224 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 225 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 226 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 227 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 228 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 229 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.479          |
| Data-EnvSampler-Poli... | 0.927          |
| Data-EnvTrajs-Averag... | -486           |
| Data-EnvTrajs-MaxReturn | -453           |
| Data-EnvTrajs-MinReturn | -504           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 19.5           |
| Data-TimeEnvSampleProc  | 0.000958       |
| Data-TimeEnvSampling    | 1.46           |
| Iteration               | 22             |
| ItrTime                 | 34.1           |
| LossAfter               | -0.006936399   |
| LossBefore              | -1.1704218e-05 |
| Model-TimeModelFit      | 30             |
| ModelSampler-n_times... | 920000         |
| Policy-AverageAbsPol... | 1.0180117      |
| Policy-AverageDiscou... | -114           |
| Policy-AveragePolicyStd | 0.7822374      |
| Policy-AverageReturn    | -345           |
| Policy-MaxReturn        | -205           |
| Policy-MinReturn        | -490           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 80.6           |
| Policy-TimeAlgoOpt      | 0.669          |
| Policy-TimeSampleProc   | 0.331          |
| Policy-TimeSampling     | 1.6            |
| Policy-TimeStep         | 2.62           |
| Time                    | 583            |
| n_timesteps             | 23000          |
--------------------------------------------

 ---------------- Iteration 23 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 230 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 231 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 232 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 233 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 234 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 235 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 236 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 237 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 238 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 239 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.478          |
| Data-EnvSampler-Poli... | 0.85           |
| Data-EnvTrajs-Averag... | -484           |
| Data-EnvTrajs-MaxReturn | -466           |
| Data-EnvTrajs-MinReturn | -495           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 10.6           |
| Data-TimeEnvSampleProc  | 0.00101        |
| Data-TimeEnvSampling    | 1.37           |
| Iteration               | 23             |
| ItrTime                 | 31.8           |
| LossAfter               | -0.00751582    |
| LossBefore              | -1.1719981e-05 |
| Model-TimeModelFit      | 27.9           |
| ModelSampler-n_times... | 960000         |
| Policy-AverageAbsPol... | 1.4722073      |
| Policy-AverageDiscou... | -7.55e+05      |
| Policy-AveragePolicyStd | 0.7844457      |
| Policy-AverageReturn    | -3.11e+06      |
| Policy-MaxReturn        | -2.48e+06      |
| Policy-MinReturn        | -3.5e+06       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.46e+05       |
| Policy-TimeAlgoOpt      | 0.559          |
| Policy-TimeSampleProc   | 0.395          |
| Policy-TimeSampling     | 1.5            |
| Policy-TimeStep         | 2.48           |
| Time                    | 615            |
| n_timesteps             | 24000          |
--------------------------------------------

 ---------------- Iteration 24 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 240 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 241 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 242 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 243 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 244 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 245 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 246 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 247 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 248 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 249 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.498          |
| Data-EnvSampler-Poli... | 0.906          |
| Data-EnvTrajs-Averag... | -495           |
| Data-EnvTrajs-MaxReturn | -475           |
| Data-EnvTrajs-MinReturn | -512           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 14.2           |
| Data-TimeEnvSampleProc  | 0.00177        |
| Data-TimeEnvSampling    | 1.44           |
| Iteration               | 24             |
| ItrTime                 | 32.6           |
| LossAfter               | -0.0047448482  |
| LossBefore              | -1.1678751e-05 |
| Model-TimeModelFit      | 28.7           |
| ModelSampler-n_times... | 1000000        |
| Policy-AverageAbsPol... | 1.2309331      |
| Policy-AverageDiscou... | -1.38e+05      |
| Policy-AveragePolicyStd | 0.7806134      |
| Policy-AverageReturn    | -5.88e+05      |
| Policy-MaxReturn        | -81.1          |
| Policy-MinReturn        | -3.12e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.18e+06       |
| Policy-TimeAlgoOpt      | 0.584          |
| Policy-TimeSampleProc   | 0.29           |
| Policy-TimeSampling     | 1.59           |
| Policy-TimeStep         | 2.47           |
| Time                    | 648            |
| n_timesteps             | 25000          |
--------------------------------------------

 ---------------- Iteration 25 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 250 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 251 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 252 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 253 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 254 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 255 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 256 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 257 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 258 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 259 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.533          |
| Data-EnvSampler-Poli... | 0.989          |
| Data-EnvTrajs-Averag... | -488           |
| Data-EnvTrajs-MaxReturn | -467           |
| Data-EnvTrajs-MinReturn | -516           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 17.4           |
| Data-TimeEnvSampleProc  | 0.00131        |
| Data-TimeEnvSampling    | 1.56           |
| Iteration               | 25             |
| ItrTime                 | 34.5           |
| LossAfter               | -0.0072844997  |
| LossBefore              | -1.1566524e-05 |
| Model-TimeModelFit      | 30.3           |
| ModelSampler-n_times... | 1040000        |
| Policy-AverageAbsPol... | 1.0343775      |
| Policy-AverageDiscou... | -8.9e+03       |
| Policy-AveragePolicyStd | 0.7706157      |
| Policy-AverageReturn    | -5.42e+04      |
| Policy-MaxReturn        | -92.6          |
| Policy-MinReturn        | -1.08e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.36e+05       |
| Policy-TimeAlgoOpt      | 0.608          |
| Policy-TimeSampleProc   | 0.334          |
| Policy-TimeSampling     | 1.7            |
| Policy-TimeStep         | 2.67           |
| Time                    | 682            |
| n_timesteps             | 26000          |
--------------------------------------------

 ---------------- Iteration 26 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 260 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 261 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 262 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 263 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 264 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 265 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 266 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 267 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 268 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 269 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.497          |
| Data-EnvSampler-Poli... | 0.911          |
| Data-EnvTrajs-Averag... | -451           |
| Data-EnvTrajs-MaxReturn | -432           |
| Data-EnvTrajs-MinReturn | -474           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 14.9           |
| Data-TimeEnvSampleProc  | 0.000631       |
| Data-TimeEnvSampling    | 1.45           |
| Iteration               | 26             |
| ItrTime                 | 33.6           |
| LossAfter               | -0.005472951   |
| LossBefore              | -1.1323425e-05 |
| Model-TimeModelFit      | 29.5           |
| ModelSampler-n_times... | 1080000        |
| Policy-AverageAbsPol... | 0.7193811      |
| Policy-AverageDiscou... | -241           |
| Policy-AveragePolicyStd | 0.75212646     |
| Policy-AverageReturn    | -939           |
| Policy-MaxReturn        | -472           |
| Policy-MinReturn        | -8.78e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.8e+03        |
| Policy-TimeAlgoOpt      | 0.594          |
| Policy-TimeSampleProc   | 0.376          |
| Policy-TimeSampling     | 1.69           |
| Policy-TimeStep         | 2.68           |
| Time                    | 716            |
| n_timesteps             | 27000          |
--------------------------------------------

 ---------------- Iteration 27 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 270 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 271 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 272 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 273 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 274 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 275 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 276 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 277 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 278 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 279 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.517          |
| Data-EnvSampler-Poli... | 1.01           |
| Data-EnvTrajs-Averag... | -470           |
| Data-EnvTrajs-MaxReturn | -461           |
| Data-EnvTrajs-MinReturn | -480           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 7.73           |
| Data-TimeEnvSampleProc  | 0.000616       |
| Data-TimeEnvSampling    | 1.57           |
| Iteration               | 27             |
| ItrTime                 | 33.9           |
| LossAfter               | -0.009108546   |
| LossBefore              | -1.1260073e-05 |
| Model-TimeModelFit      | 29.9           |
| ModelSampler-n_times... | 1120000        |
| Policy-AverageAbsPol... | 0.8155617      |
| Policy-AverageDiscou... | -4.66e+04      |
| Policy-AveragePolicyStd | 0.74856174     |
| Policy-AverageReturn    | -2.27e+05      |
| Policy-MaxReturn        | -454           |
| Policy-MinReturn        | -2.38e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 6.82e+05       |
| Policy-TimeAlgoOpt      | 0.548          |
| Policy-TimeSampleProc   | 0.378          |
| Policy-TimeSampling     | 1.47           |
| Policy-TimeStep         | 2.43           |
| Time                    | 750            |
| n_timesteps             | 28000          |
--------------------------------------------

 ---------------- Iteration 28 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 280 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 281 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 282 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 283 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 284 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 285 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 286 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 287 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 288 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 289 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.474          |
| Data-EnvSampler-Poli... | 0.868          |
| Data-EnvTrajs-Averag... | -433           |
| Data-EnvTrajs-MaxReturn | -412           |
| Data-EnvTrajs-MinReturn | -461           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 22.4           |
| Data-TimeEnvSampleProc  | 0.000623       |
| Data-TimeEnvSampling    | 1.38           |
| Iteration               | 28             |
| ItrTime                 | 35             |
| LossAfter               | -0.0037601935  |
| LossBefore              | -1.1244864e-05 |
| Model-TimeModelFit      | 30.9           |
| ModelSampler-n_times... | 1160000        |
| Policy-AverageAbsPol... | 0.7760752      |
| Policy-AverageDiscou... | -169           |
| Policy-AveragePolicyStd | 0.7469434      |
| Policy-AverageReturn    | -512           |
| Policy-MaxReturn        | -460           |
| Policy-MinReturn        | -561           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 23.5           |
| Policy-TimeAlgoOpt      | 0.537          |
| Policy-TimeSampleProc   | 0.493          |
| Policy-TimeSampling     | 1.65           |
| Policy-TimeStep         | 2.72           |
| Time                    | 785            |
| n_timesteps             | 29000          |
--------------------------------------------

 ---------------- Iteration 29 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 290 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 291 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 292 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 293 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 294 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 295 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 296 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 297 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 298 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 299 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.463          |
| Data-EnvSampler-Poli... | 0.92           |
| Data-EnvTrajs-Averag... | -473           |
| Data-EnvTrajs-MaxReturn | -460           |
| Data-EnvTrajs-MinReturn | -485           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 8.67           |
| Data-TimeEnvSampleProc  | 0.000789       |
| Data-TimeEnvSampling    | 1.42           |
| Iteration               | 29             |
| ItrTime                 | 35.4           |
| LossAfter               | -0.0056948494  |
| LossBefore              | -1.1157946e-05 |
| Model-TimeModelFit      | 31.2           |
| ModelSampler-n_times... | 1200000        |
| Policy-AverageAbsPol... | 0.8283903      |
| Policy-AverageDiscou... | -2.53e+04      |
| Policy-AveragePolicyStd | 0.738488       |
| Policy-AverageReturn    | -1.6e+05       |
| Policy-MaxReturn        | -91            |
| Policy-MinReturn        | -1.22e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 3.45e+05       |
| Policy-TimeAlgoOpt      | 0.66           |
| Policy-TimeSampleProc   | 0.398          |
| Policy-TimeSampling     | 1.71           |
| Policy-TimeStep         | 2.79           |
| Time                    | 820            |
| n_timesteps             | 30000          |
--------------------------------------------

 ---------------- Iteration 30 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 300 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 301 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 302 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 303 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 304 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 305 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 306 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 307 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 308 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 309 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.55           |
| Data-EnvSampler-Poli... | 1.08           |
| Data-EnvTrajs-Averag... | -446           |
| Data-EnvTrajs-MaxReturn | -373           |
| Data-EnvTrajs-MinReturn | -508           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 46.1           |
| Data-TimeEnvSampleProc  | 0.000639       |
| Data-TimeEnvSampling    | 1.67           |
| Iteration               | 30             |
| ItrTime                 | 34.6           |
| LossAfter               | -0.006345025   |
| LossBefore              | -1.1190984e-05 |
| Model-TimeModelFit      | 30.3           |
| ModelSampler-n_times... | 1240000        |
| Policy-AverageAbsPol... | 0.75518847     |
| Policy-AverageDiscou... | -2.38e+04      |
| Policy-AveragePolicyStd | 0.7410563      |
| Policy-AverageReturn    | -1.16e+05      |
| Policy-MaxReturn        | -345           |
| Policy-MinReturn        | -2.3e+06       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 5.01e+05       |
| Policy-TimeAlgoOpt      | 0.57           |
| Policy-TimeSampleProc   | 0.355          |
| Policy-TimeSampling     | 1.68           |
| Policy-TimeStep         | 2.63           |
| Time                    | 855            |
| n_timesteps             | 31000          |
--------------------------------------------

 ---------------- Iteration 31 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 310 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 311 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 312 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 313 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 314 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 315 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 316 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 317 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 318 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 319 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.562          |
| Data-EnvSampler-Poli... | 1.1            |
| Data-EnvTrajs-Averag... | -405           |
| Data-EnvTrajs-MaxReturn | -391           |
| Data-EnvTrajs-MinReturn | -412           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 7.68           |
| Data-TimeEnvSampleProc  | 0.00103        |
| Data-TimeEnvSampling    | 1.71           |
| Iteration               | 31             |
| ItrTime                 | 34.4           |
| LossAfter               | -0.0068602776  |
| LossBefore              | -1.1016113e-05 |
| Model-TimeModelFit      | 30.3           |
| ModelSampler-n_times... | 1280000        |
| Policy-AverageAbsPol... | 0.78573793     |
| Policy-AverageDiscou... | -2.6e+04       |
| Policy-AveragePolicyStd | 0.72875553     |
| Policy-AverageReturn    | -1.23e+05      |
| Policy-MaxReturn        | -476           |
| Policy-MinReturn        | -2.44e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 5.32e+05       |
| Policy-TimeAlgoOpt      | 0.574          |
| Policy-TimeSampleProc   | 0.266          |
| Policy-TimeSampling     | 1.52           |
| Policy-TimeStep         | 2.38           |
| Time                    | 889            |
| n_timesteps             | 32000          |
--------------------------------------------

 ---------------- Iteration 32 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 320 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 321 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 322 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 323 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 324 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 325 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 326 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 327 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 328 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 329 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.453         |
| Data-EnvSampler-Poli... | 0.808         |
| Data-EnvTrajs-Averag... | -393          |
| Data-EnvTrajs-MaxReturn | -357          |
| Data-EnvTrajs-MinReturn | -412          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 18.5          |
| Data-TimeEnvSampleProc  | 0.00103       |
| Data-TimeEnvSampling    | 1.3           |
| Iteration               | 32            |
| ItrTime                 | 35.7          |
| LossAfter               | -0.0048033227 |
| LossBefore              | -1.075307e-05 |
| Model-TimeModelFit      | 31.7          |
| ModelSampler-n_times... | 1320000       |
| Policy-AverageAbsPol... | 0.6670265     |
| Policy-AverageDiscou... | -161          |
| Policy-AveragePolicyStd | 0.70924425    |
| Policy-AverageReturn    | -474          |
| Policy-MaxReturn        | -428          |
| Policy-MinReturn        | -512          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 20.7          |
| Policy-TimeAlgoOpt      | 0.616         |
| Policy-TimeSampleProc   | 0.416         |
| Policy-TimeSampling     | 1.62          |
| Policy-TimeStep         | 2.67          |
| Time                    | 925           |
| n_timesteps             | 33000         |
-------------------------------------------

 ---------------- Iteration 33 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 330 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 331 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 332 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 333 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 334 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 335 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 336 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 337 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 338 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 339 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.513          |
| Data-EnvSampler-Poli... | 0.964          |
| Data-EnvTrajs-Averag... | -377           |
| Data-EnvTrajs-MaxReturn | -346           |
| Data-EnvTrajs-MinReturn | -450           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 37.3           |
| Data-TimeEnvSampleProc  | 0.00111        |
| Data-TimeEnvSampling    | 1.51           |
| Iteration               | 33             |
| ItrTime                 | 36.2           |
| LossAfter               | -0.0051507475  |
| LossBefore              | -1.0534712e-05 |
| Model-TimeModelFit      | 31.7           |
| ModelSampler-n_times... | 1360000        |
| Policy-AverageAbsPol... | 0.6313081      |
| Policy-AverageDiscou... | -125           |
| Policy-AveragePolicyStd | 0.69437355     |
| Policy-AverageReturn    | -327           |
| Policy-MaxReturn        | -272           |
| Policy-MinReturn        | -439           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 37.5           |
| Policy-TimeAlgoOpt      | 0.635          |
| Policy-TimeSampleProc   | 0.544          |
| Policy-TimeSampling     | 1.77           |
| Policy-TimeStep         | 2.99           |
| Time                    | 961            |
| n_timesteps             | 34000          |
--------------------------------------------

 ---------------- Iteration 34 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 340 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 341 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 342 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 343 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 344 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 345 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 346 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 347 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 348 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 349 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.562          |
| Data-EnvSampler-Poli... | 1.02           |
| Data-EnvTrajs-Averag... | -382           |
| Data-EnvTrajs-MaxReturn | -349           |
| Data-EnvTrajs-MinReturn | -455           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 40             |
| Data-TimeEnvSampleProc  | 0.0011         |
| Data-TimeEnvSampling    | 1.63           |
| Iteration               | 34             |
| ItrTime                 | 36.1           |
| LossAfter               | -0.006595574   |
| LossBefore              | -1.0363724e-05 |
| Model-TimeModelFit      | 31.6           |
| ModelSampler-n_times... | 1400000        |
| Policy-AverageAbsPol... | 0.6712283      |
| Policy-AverageDiscou... | -1.47e+04      |
| Policy-AveragePolicyStd | 0.6829327      |
| Policy-AverageReturn    | -9.19e+04      |
| Policy-MaxReturn        | -196           |
| Policy-MinReturn        | -1.16e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.75e+05       |
| Policy-TimeAlgoOpt      | 0.628          |
| Policy-TimeSampleProc   | 0.433          |
| Policy-TimeSampling     | 1.85           |
| Policy-TimeStep         | 2.94           |
| Time                    | 997            |
| n_timesteps             | 35000          |
--------------------------------------------

 ---------------- Iteration 35 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 350 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 351 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 352 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 353 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 354 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 355 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 356 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 357 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 358 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 359 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.437          |
| Data-EnvSampler-Poli... | 0.89           |
| Data-EnvTrajs-Averag... | -359           |
| Data-EnvTrajs-MaxReturn | -343           |
| Data-EnvTrajs-MinReturn | -377           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 12.6           |
| Data-TimeEnvSampleProc  | 0.000966       |
| Data-TimeEnvSampling    | 1.36           |
| Iteration               | 35             |
| ItrTime                 | 36.5           |
| LossAfter               | -0.005529186   |
| LossBefore              | -1.0157133e-05 |
| Model-TimeModelFit      | 32             |
| ModelSampler-n_times... | 1440000        |
| Policy-AverageAbsPol... | 0.542885       |
| Policy-AverageDiscou... | -106           |
| Policy-AveragePolicyStd | 0.6708731      |
| Policy-AverageReturn    | -308           |
| Policy-MaxReturn        | -267           |
| Policy-MinReturn        | -343           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 17.6           |
| Policy-TimeAlgoOpt      | 0.607          |
| Policy-TimeSampleProc   | 0.608          |
| Policy-TimeSampling     | 1.91           |
| Policy-TimeStep         | 3.18           |
| Time                    | 1.03e+03       |
| n_timesteps             | 36000          |
--------------------------------------------

 ---------------- Iteration 36 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 360 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 361 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 362 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 363 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 364 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 365 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 366 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 367 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 368 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 369 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.474         |
| Data-EnvSampler-Poli... | 0.929         |
| Data-EnvTrajs-Averag... | -380          |
| Data-EnvTrajs-MaxReturn | -343          |
| Data-EnvTrajs-MinReturn | -413          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 26.6          |
| Data-TimeEnvSampleProc  | 0.000689      |
| Data-TimeEnvSampling    | 1.44          |
| Iteration               | 36            |
| ItrTime                 | 35.4          |
| LossAfter               | -0.0052341106 |
| LossBefore              | -9.939851e-06 |
| Model-TimeModelFit      | 31.4          |
| ModelSampler-n_times... | 1480000       |
| Policy-AverageAbsPol... | 0.57369       |
| Policy-AverageDiscou... | -94.1         |
| Policy-AveragePolicyStd | 0.65503895    |
| Policy-AverageReturn    | -281          |
| Policy-MaxReturn        | -200          |
| Policy-MinReturn        | -346          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 39.2          |
| Policy-TimeAlgoOpt      | 0.565         |
| Policy-TimeSampleProc   | 0.427         |
| Policy-TimeSampling     | 1.5           |
| Policy-TimeStep         | 2.53          |
| Time                    | 1.07e+03      |
| n_timesteps             | 37000         |
-------------------------------------------

 ---------------- Iteration 37 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 370 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 371 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 372 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 373 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 374 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 375 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 376 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 377 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 378 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 379 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.559         |
| Data-EnvSampler-Poli... | 1.01          |
| Data-EnvTrajs-Averag... | -352          |
| Data-EnvTrajs-MaxReturn | -314          |
| Data-EnvTrajs-MinReturn | -387          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 27.3          |
| Data-TimeEnvSampleProc  | 0.000592      |
| Data-TimeEnvSampling    | 1.61          |
| Iteration               | 37            |
| ItrTime                 | 36.9          |
| LossAfter               | -0.0074870046 |
| LossBefore              | -9.798673e-06 |
| Model-TimeModelFit      | 32.3          |
| ModelSampler-n_times... | 1520000       |
| Policy-AverageAbsPol... | 0.49641398    |
| Policy-AverageDiscou... | -93.4         |
| Policy-AveragePolicyStd | 0.6458173     |
| Policy-AverageReturn    | -292          |
| Policy-MaxReturn        | -221          |
| Policy-MinReturn        | -355          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 40.3          |
| Policy-TimeAlgoOpt      | 0.653         |
| Policy-TimeSampleProc   | 0.606         |
| Policy-TimeSampling     | 1.75          |
| Policy-TimeStep         | 3.03          |
| Time                    | 1.11e+03      |
| n_timesteps             | 38000         |
-------------------------------------------

 ---------------- Iteration 38 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 380 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 381 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 382 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 383 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 384 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 385 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 386 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 387 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 388 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 389 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.549         |
| Data-EnvSampler-Poli... | 1.11          |
| Data-EnvTrajs-Averag... | -354          |
| Data-EnvTrajs-MaxReturn | -322          |
| Data-EnvTrajs-MinReturn | -400          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 31.8          |
| Data-TimeEnvSampleProc  | 0.000685      |
| Data-TimeEnvSampling    | 1.7           |
| Iteration               | 38            |
| ItrTime                 | 37            |
| LossAfter               | -0.006312585  |
| LossBefore              | -9.630488e-06 |
| Model-TimeModelFit      | 32.7          |
| ModelSampler-n_times... | 1560000       |
| Policy-AverageAbsPol... | 0.5014291     |
| Policy-AverageDiscou... | -71.9         |
| Policy-AveragePolicyStd | 0.6349983     |
| Policy-AverageReturn    | -219          |
| Policy-MaxReturn        | -61.2         |
| Policy-MinReturn        | -523          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 103           |
| Policy-TimeAlgoOpt      | 0.575         |
| Policy-TimeSampleProc   | 0.474         |
| Policy-TimeSampling     | 1.61          |
| Policy-TimeStep         | 2.7           |
| Time                    | 1.14e+03      |
| n_timesteps             | 39000         |
-------------------------------------------

 ---------------- Iteration 39 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 390 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 391 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 392 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 393 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 394 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 395 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 396 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 397 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 398 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 399 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.522         |
| Data-EnvSampler-Poli... | 0.919         |
| Data-EnvTrajs-Averag... | -271          |
| Data-EnvTrajs-MaxReturn | -165          |
| Data-EnvTrajs-MinReturn | -334          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 56.9          |
| Data-TimeEnvSampleProc  | 0.000865      |
| Data-TimeEnvSampling    | 1.48          |
| Iteration               | 39            |
| ItrTime                 | 36.7          |
| LossAfter               | -0.0058970847 |
| LossBefore              | -9.47516e-06  |
| Model-TimeModelFit      | 32.5          |
| ModelSampler-n_times... | 1600000       |
| Policy-AverageAbsPol... | 0.5138285     |
| Policy-AverageDiscou... | -102          |
| Policy-AveragePolicyStd | 0.6253435     |
| Policy-AverageReturn    | -375          |
| Policy-MaxReturn        | -245          |
| Policy-MinReturn        | -694          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 117           |
| Policy-TimeAlgoOpt      | 0.671         |
| Policy-TimeSampleProc   | 0.44          |
| Policy-TimeSampling     | 1.55          |
| Policy-TimeStep         | 2.69          |
| Time                    | 1.18e+03      |
| n_timesteps             | 40000         |
-------------------------------------------

 ---------------- Iteration 40 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 400 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 401 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 402 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 403 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 404 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 405 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 406 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 407 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 408 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 409 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.469         |
| Data-EnvSampler-Poli... | 0.943         |
| Data-EnvTrajs-Averag... | -329          |
| Data-EnvTrajs-MaxReturn | -286          |
| Data-EnvTrajs-MinReturn | -373          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 35.6          |
| Data-TimeEnvSampleProc  | 0.00101       |
| Data-TimeEnvSampling    | 1.45          |
| Iteration               | 40            |
| ItrTime                 | 37.3          |
| LossAfter               | -0.008045625  |
| LossBefore              | -9.343592e-06 |
| Model-TimeModelFit      | 33            |
| ModelSampler-n_times... | 1640000       |
| Policy-AverageAbsPol... | 0.4701225     |
| Policy-AverageDiscou... | -1.1e+03      |
| Policy-AveragePolicyStd | 0.6182848     |
| Policy-AverageReturn    | -7.24e+03     |
| Policy-MaxReturn        | -148          |
| Policy-MinReturn        | -1.4e+05      |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 3.04e+04      |
| Policy-TimeAlgoOpt      | 0.598         |
| Policy-TimeSampleProc   | 0.473         |
| Policy-TimeSampling     | 1.68          |
| Policy-TimeStep         | 2.81          |
| Time                    | 1.22e+03      |
| n_timesteps             | 41000         |
-------------------------------------------

 ---------------- Iteration 41 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 410 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 411 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 412 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 413 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 414 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 415 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 416 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 417 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 418 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 419 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.46          |
| Data-EnvSampler-Poli... | 0.908         |
| Data-EnvTrajs-Averag... | -332          |
| Data-EnvTrajs-MaxReturn | -319          |
| Data-EnvTrajs-MinReturn | -345          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 9.77          |
| Data-TimeEnvSampleProc  | 0.0012        |
| Data-TimeEnvSampling    | 1.4           |
| Iteration               | 41            |
| ItrTime                 | 37.2          |
| LossAfter               | -0.004272265  |
| LossBefore              | -9.326215e-06 |
| Model-TimeModelFit      | 32.9          |
| ModelSampler-n_times... | 1680000       |
| Policy-AverageAbsPol... | 0.4424346     |
| Policy-AverageDiscou... | -99.4         |
| Policy-AveragePolicyStd | 0.6159105     |
| Policy-AverageReturn    | -267          |
| Policy-MaxReturn        | -176          |
| Policy-MinReturn        | -803          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 132           |
| Policy-TimeAlgoOpt      | 0.635         |
| Policy-TimeSampleProc   | 0.449         |
| Policy-TimeSampling     | 1.79          |
| Policy-TimeStep         | 2.97          |
| Time                    | 1.25e+03      |
| n_timesteps             | 42000         |
-------------------------------------------

 ---------------- Iteration 42 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 420 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 421 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 422 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 423 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 424 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 425 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 426 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 427 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 428 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 429 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.554         |
| Data-EnvSampler-Poli... | 1.11          |
| Data-EnvTrajs-Averag... | -357          |
| Data-EnvTrajs-MaxReturn | -333          |
| Data-EnvTrajs-MinReturn | -392          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 20.1          |
| Data-TimeEnvSampleProc  | 0.000748      |
| Data-TimeEnvSampling    | 1.72          |
| Iteration               | 42            |
| ItrTime                 | 37.1          |
| LossAfter               | -0.006486816  |
| LossBefore              | -9.216249e-06 |
| Model-TimeModelFit      | 32.9          |
| ModelSampler-n_times... | 1720000       |
| Policy-AverageAbsPol... | 0.52955174    |
| Policy-AverageDiscou... | -183          |
| Policy-AveragePolicyStd | 0.6100034     |
| Policy-AverageReturn    | -984          |
| Policy-MaxReturn        | 53.7          |
| Policy-MinReturn        | -1.67e+04     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 3.61e+03      |
| Policy-TimeAlgoOpt      | 0.574         |
| Policy-TimeSampleProc   | 0.293         |
| Policy-TimeSampling     | 1.59          |
| Policy-TimeStep         | 2.48          |
| Time                    | 1.29e+03      |
| n_timesteps             | 43000         |
-------------------------------------------

 ---------------- Iteration 43 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 430 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 431 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 432 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 433 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 434 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 435 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 436 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 437 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 438 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 439 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Data-EnvSampler-EnvE... | 0.475        |
| Data-EnvSampler-Poli... | 0.941        |
| Data-EnvTrajs-Averag... | -326         |
| Data-EnvTrajs-MaxReturn | -312         |
| Data-EnvTrajs-MinReturn | -342         |
| Data-EnvTrajs-NumTrajs  | 5            |
| Data-EnvTrajs-StdReturn | 10.9         |
| Data-TimeEnvSampleProc  | 0.000949     |
| Data-TimeEnvSampling    | 1.46         |
| Iteration               | 43           |
| ItrTime                 | 37.3         |
| LossAfter               | -0.007749144 |
| LossBefore              | -9.1407e-06  |
| Model-TimeModelFit      | 33           |
| ModelSampler-n_times... | 1760000      |
| Policy-AverageAbsPol... | 0.44575408   |
| Policy-AverageDiscou... | -19.9        |
| Policy-AveragePolicyStd | 0.60380757   |
| Policy-AverageReturn    | 37.3         |
| Policy-MaxReturn        | 675          |
| Policy-MinReturn        | -227         |
| Policy-NumTrajs         | 20           |
| Policy-StdReturn        | 278          |
| Policy-TimeAlgoOpt      | 0.589        |
| Policy-TimeSampleProc   | 0.409        |
| Policy-TimeSampling     | 1.86         |
| Policy-TimeStep         | 2.89         |
| Time                    | 1.33e+03     |
| n_timesteps             | 44000        |
------------------------------------------

 ---------------- Iteration 44 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 440 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 441 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 442 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 443 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 444 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 445 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 446 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 447 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 448 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 449 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.552         |
| Data-EnvSampler-Poli... | 1.1           |
| Data-EnvTrajs-Averag... | -311          |
| Data-EnvTrajs-MaxReturn | -299          |
| Data-EnvTrajs-MinReturn | -328          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 10.4          |
| Data-TimeEnvSampleProc  | 0.00104       |
| Data-TimeEnvSampling    | 1.7           |
| Iteration               | 44            |
| ItrTime                 | 37.2          |
| LossAfter               | -0.0067196516 |
| LossBefore              | -8.997754e-06 |
| Model-TimeModelFit      | 33            |
| ModelSampler-n_times... | 1800000       |
| Policy-AverageAbsPol... | 0.56110203    |
| Policy-AverageDiscou... | -6.67         |
| Policy-AveragePolicyStd | 0.59524876    |
| Policy-AverageReturn    | 58            |
| Policy-MaxReturn        | 2.18e+03      |
| Policy-MinReturn        | -764          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 733           |
| Policy-TimeAlgoOpt      | 0.581         |
| Policy-TimeSampleProc   | 0.295         |
| Policy-TimeSampling     | 1.54          |
| Policy-TimeStep         | 2.46          |
| Time                    | 1.37e+03      |
| n_timesteps             | 45000         |
-------------------------------------------

 ---------------- Iteration 45 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 450 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 451 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 452 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 453 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 454 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 455 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 456 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 457 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 458 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 459 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Data-EnvSampler-EnvE... | 0.467        |
| Data-EnvSampler-Poli... | 0.905        |
| Data-EnvTrajs-Averag... | -307         |
| Data-EnvTrajs-MaxReturn | -295         |
| Data-EnvTrajs-MinReturn | -333         |
| Data-EnvTrajs-NumTrajs  | 5            |
| Data-EnvTrajs-StdReturn | 13.2         |
| Data-TimeEnvSampleProc  | 0.00101      |
| Data-TimeEnvSampling    | 1.42         |
| Iteration               | 45           |
| ItrTime                 | 37.9         |
| LossAfter               | -0.009021462 |
| LossBefore              | -8.76552e-06 |
| Model-TimeModelFit      | 33.8         |
| ModelSampler-n_times... | 1840000      |
| Policy-AverageAbsPol... | 0.44261917   |
| Policy-AverageDiscou... | -4.95e+03    |
| Policy-AveragePolicyStd | 0.5809024    |
| Policy-AverageReturn    | -3.39e+04    |
| Policy-MaxReturn        | 2.23e+03     |
| Policy-MinReturn        | -4.46e+05    |
| Policy-NumTrajs         | 20           |
| Policy-StdReturn        | 9.9e+04      |
| Policy-TimeAlgoOpt      | 0.624        |
| Policy-TimeSampleProc   | 0.465        |
| Policy-TimeSampling     | 1.53         |
| Policy-TimeStep         | 2.64         |
| Time                    | 1.4e+03      |
| n_timesteps             | 46000        |
------------------------------------------

 ---------------- Iteration 46 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 460 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 461 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 462 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 463 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 464 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 465 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 466 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 467 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 468 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 469 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Data-EnvSampler-EnvE... | 0.476        |
| Data-EnvSampler-Poli... | 0.932        |
| Data-EnvTrajs-Averag... | -300         |
| Data-EnvTrajs-MaxReturn | -224         |
| Data-EnvTrajs-MinReturn | -393         |
| Data-EnvTrajs-NumTrajs  | 5            |
| Data-EnvTrajs-StdReturn | 57.1         |
| Data-TimeEnvSampleProc  | 0.000985     |
| Data-TimeEnvSampling    | 1.45         |
| Iteration               | 46           |
| ItrTime                 | 37.8         |
| LossAfter               | -0.009907841 |
| LossBefore              | -8.53583e-06 |
| Model-TimeModelFit      | 33.8         |
| ModelSampler-n_times... | 1880000      |
| Policy-AverageAbsPol... | 0.6374951    |
| Policy-AverageDiscou... | -58.5        |
| Policy-AveragePolicyStd | 0.568797     |
| Policy-AverageReturn    | -708         |
| Policy-MaxReturn        | 2.73e+03     |
| Policy-MinReturn        | -1.21e+04    |
| Policy-NumTrajs         | 20           |
| Policy-StdReturn        | 3.2e+03      |
| Policy-TimeAlgoOpt      | 0.61         |
| Policy-TimeSampleProc   | 0.292        |
| Policy-TimeSampling     | 1.66         |
| Policy-TimeStep         | 2.59         |
| Time                    | 1.44e+03     |
| n_timesteps             | 47000        |
------------------------------------------

 ---------------- Iteration 47 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 470 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 471 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 472 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 473 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 474 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 475 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 476 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 477 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 478 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 479 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.465         |
| Data-EnvSampler-Poli... | 0.891         |
| Data-EnvTrajs-Averag... | -125          |
| Data-EnvTrajs-MaxReturn | -50.1         |
| Data-EnvTrajs-MinReturn | -238          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 67.4          |
| Data-TimeEnvSampleProc  | 0.00103       |
| Data-TimeEnvSampling    | 1.39          |
| Iteration               | 47            |
| ItrTime                 | 38            |
| LossAfter               | -0.01018681   |
| LossBefore              | -8.386297e-06 |
| Model-TimeModelFit      | 33.1          |
| ModelSampler-n_times... | 1920000       |
| Policy-AverageAbsPol... | 0.50671595    |
| Policy-AverageDiscou... | -19.5         |
| Policy-AveragePolicyStd | 0.56167287    |
| Policy-AverageReturn    | -320          |
| Policy-MaxReturn        | 1.17e+03      |
| Policy-MinReturn        | -2.29e+03     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 733           |
| Policy-TimeAlgoOpt      | 0.663         |
| Policy-TimeSampleProc   | 0.71          |
| Policy-TimeSampling     | 2.13          |
| Policy-TimeStep         | 3.54          |
| Time                    | 1.48e+03      |
| n_timesteps             | 48000         |
-------------------------------------------

 ---------------- Iteration 48 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 480 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 481 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 482 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 483 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 484 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 485 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 486 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 487 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 488 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 489 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.659         |
| Data-EnvSampler-Poli... | 1.39          |
| Data-EnvTrajs-Averag... | 14.1          |
| Data-EnvTrajs-MaxReturn | 59.3          |
| Data-EnvTrajs-MinReturn | -29.1         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 29.5          |
| Data-TimeEnvSampleProc  | 0.00124       |
| Data-TimeEnvSampling    | 2.1           |
| Iteration               | 48            |
| ItrTime                 | 39.2          |
| LossAfter               | -0.0062048314 |
| LossBefore              | -8.260533e-06 |
| Model-TimeModelFit      | 34.4          |
| ModelSampler-n_times... | 1960000       |
| Policy-AverageAbsPol... | 0.3768404     |
| Policy-AverageDiscou... | -27.3         |
| Policy-AveragePolicyStd | 0.55435467    |
| Policy-AverageReturn    | -152          |
| Policy-MaxReturn        | 207           |
| Policy-MinReturn        | -845          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 189           |
| Policy-TimeAlgoOpt      | 0.58          |
| Policy-TimeSampleProc   | 0.453         |
| Policy-TimeSampling     | 1.65          |
| Policy-TimeStep         | 2.72          |
| Time                    | 1.52e+03      |
| n_timesteps             | 49000         |
-------------------------------------------

 ---------------- Iteration 49 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 490 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 491 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 492 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 493 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 494 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 495 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 496 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 497 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 498 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 499 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.563         |
| Data-EnvSampler-Poli... | 0.99          |
| Data-EnvTrajs-Averag... | -37.9         |
| Data-EnvTrajs-MaxReturn | -19           |
| Data-EnvTrajs-MinReturn | -72.7         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 19.8          |
| Data-TimeEnvSampleProc  | 0.00103       |
| Data-TimeEnvSampling    | 1.6           |
| Iteration               | 49            |
| ItrTime                 | 35.6          |
| LossAfter               | -0.0085681975 |
| LossBefore              | -8.131794e-06 |
| Model-TimeModelFit      | 31.8          |
| ModelSampler-n_times... | 2000000       |
| Policy-AverageAbsPol... | 0.96292424    |
| Policy-AverageDiscou... | 246           |
| Policy-AveragePolicyStd | 0.547637      |
| Policy-AverageReturn    | 769           |
| Policy-MaxReturn        | 1.24e+03      |
| Policy-MinReturn        | 511           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 184           |
| Policy-TimeAlgoOpt      | 0.589         |
| Policy-TimeSampleProc   | 0.246         |
| Policy-TimeSampling     | 1.34          |
| Policy-TimeStep         | 2.2           |
| Time                    | 1.55e+03      |
| n_timesteps             | 50000         |
-------------------------------------------

 ---------------- Iteration 50 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 500 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 501 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 502 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 503 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 504 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 505 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 506 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 507 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 508 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 509 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.496         |
| Data-EnvSampler-Poli... | 0.734         |
| Data-EnvTrajs-Averag... | 18.5          |
| Data-EnvTrajs-MaxReturn | 88.6          |
| Data-EnvTrajs-MinReturn | -23.8         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 42.2          |
| Data-TimeEnvSampleProc  | 0.00102       |
| Data-TimeEnvSampling    | 1.27          |
| Iteration               | 50            |
| ItrTime                 | 23.4          |
| LossAfter               | -0.009872713  |
| LossBefore              | -8.023525e-06 |
| Model-TimeModelFit      | 20.4          |
| ModelSampler-n_times... | 2040000       |
| Policy-AverageAbsPol... | 0.7221094     |
| Policy-AverageDiscou... | -1.73e+03     |
| Policy-AveragePolicyStd | 0.5401474     |
| Policy-AverageReturn    | -1.25e+04     |
| Policy-MaxReturn        | 469           |
| Policy-MinReturn        | -7.83e+04     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 2.18e+04      |
| Policy-TimeAlgoOpt      | 0.518         |
| Policy-TimeSampleProc   | 0.209         |
| Policy-TimeSampling     | 1.04          |
| Policy-TimeStep         | 1.77          |
| Time                    | 1.58e+03      |
| n_timesteps             | 51000         |
-------------------------------------------
Training finished
