Logging to /home/vincent/workplace/CS_287_-_Advanced_Robotics/homework/hw5/cs287hw5/ppo/run_scripts/data/parallel_mb_ppo/mbppo_Hopper//02

 ---------------- Iteration 0 ----------------
Obtaining random samples from the environment...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 0 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 1 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 2 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 3 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 4 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 5 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 6 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 7 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 8 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 9 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.228         |
| Data-EnvSampler-Poli... | 0.0504        |
| Data-EnvTrajs-Averag... | -272          |
| Data-EnvTrajs-MaxReturn | -159          |
| Data-EnvTrajs-MinReturn | -340          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 63.8          |
| Data-TimeEnvSampleProc  | 0.000568      |
| Data-TimeEnvSampling    | 0.292         |
| Iteration               | 0             |
| ItrTime                 | 10.5          |
| LossAfter               | -0.0065089436 |
| LossBefore              | -1.376666e-05 |
| Model-TimeModelFit      | 3.41          |
| ModelSampler-n_times... | 40000         |
| Policy-AverageAbsPol... | 1.0401043     |
| Policy-AverageDiscou... | -1.98e+06     |
| Policy-AveragePolicyStd | 0.9588881     |
| Policy-AverageReturn    | -5.25e+06     |
| Policy-MaxReturn        | -4.98e+06     |
| Policy-MinReturn        | -5.41e+06     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.08e+05      |
| Policy-TimeAlgoOpt      | 1.06          |
| Policy-TimeSampleProc   | 0.484         |
| Policy-TimeSampling     | 5.2           |
| Policy-TimeStep         | 6.8           |
| Time                    | 10.5          |
| n_timesteps             | 1000          |
-------------------------------------------

 ---------------- Iteration 1 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 10 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 11 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 12 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 13 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 14 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 15 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 16 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 17 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 18 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 19 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.308          |
| Data-EnvSampler-Poli... | 0.611          |
| Data-EnvTrajs-Averag... | 103            |
| Data-EnvTrajs-MaxReturn | 267            |
| Data-EnvTrajs-MinReturn | -107           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 145            |
| Data-TimeEnvSampleProc  | 0.000609       |
| Data-TimeEnvSampling    | 0.94           |
| Iteration               | 1              |
| ItrTime                 | 8.47           |
| LossAfter               | -0.0026052021  |
| LossBefore              | -1.3552404e-05 |
| Model-TimeModelFit      | 4.25           |
| ModelSampler-n_times... | 80000          |
| Policy-AverageAbsPol... | 0.72919345     |
| Policy-AverageDiscou... | -2.15e+06      |
| Policy-AveragePolicyStd | 0.9395529      |
| Policy-AverageReturn    | -5.42e+06      |
| Policy-MaxReturn        | -5.4e+06       |
| Policy-MinReturn        | -5.46e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.41e+04       |
| Policy-TimeAlgoOpt      | 0.606          |
| Policy-TimeSampleProc   | 0.635          |
| Policy-TimeSampling     | 1.98           |
| Policy-TimeStep         | 3.28           |
| Time                    | 19.2           |
| n_timesteps             | 2000           |
--------------------------------------------

 ---------------- Iteration 2 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 20 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 21 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 22 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 23 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 24 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 25 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 26 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 27 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 28 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 29 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.438          |
| Data-EnvSampler-Poli... | 0.68           |
| Data-EnvTrajs-Averag... | -21            |
| Data-EnvTrajs-MaxReturn | 220            |
| Data-EnvTrajs-MinReturn | -298           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 174            |
| Data-TimeEnvSampleProc  | 0.000901       |
| Data-TimeEnvSampling    | 1.15           |
| Iteration               | 2              |
| ItrTime                 | 11.5           |
| LossAfter               | -0.0043106526  |
| LossBefore              | -1.3481964e-05 |
| Model-TimeModelFit      | 7.22           |
| ModelSampler-n_times... | 120000         |
| Policy-AverageAbsPol... | 1.0135015      |
| Policy-AverageDiscou... | -2.17e+06      |
| Policy-AveragePolicyStd | 0.9318808      |
| Policy-AverageReturn    | -5.45e+06      |
| Policy-MaxReturn        | -5.43e+06      |
| Policy-MinReturn        | -5.49e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.52e+04       |
| Policy-TimeAlgoOpt      | 0.71           |
| Policy-TimeSampleProc   | 0.429          |
| Policy-TimeSampling     | 1.92           |
| Policy-TimeStep         | 3.08           |
| Time                    | 30.7           |
| n_timesteps             | 3000           |
--------------------------------------------

 ---------------- Iteration 3 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 30 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 31 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 32 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 33 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 34 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 35 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 36 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 37 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 38 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 39 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.462          |
| Data-EnvSampler-Poli... | 0.741          |
| Data-EnvTrajs-Averag... | -497           |
| Data-EnvTrajs-MaxReturn | -471           |
| Data-EnvTrajs-MinReturn | -509           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 14.1           |
| Data-TimeEnvSampleProc  | 0.000552       |
| Data-TimeEnvSampling    | 1.24           |
| Iteration               | 3              |
| ItrTime                 | 13.5           |
| LossAfter               | -0.0042769127  |
| LossBefore              | -1.3334468e-05 |
| Model-TimeModelFit      | 8.67           |
| ModelSampler-n_times... | 160000         |
| Policy-AverageAbsPol... | 1.3204178      |
| Policy-AverageDiscou... | -1.65e+06      |
| Policy-AveragePolicyStd | 0.9178714      |
| Policy-AverageReturn    | -4.75e+06      |
| Policy-MaxReturn        | -3.78e+06      |
| Policy-MinReturn        | -5.3e+06       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 6.03e+05       |
| Policy-TimeAlgoOpt      | 0.673          |
| Policy-TimeSampleProc   | 0.853          |
| Policy-TimeSampling     | 2.02           |
| Policy-TimeStep         | 3.58           |
| Time                    | 44.2           |
| n_timesteps             | 4000           |
--------------------------------------------

 ---------------- Iteration 4 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 40 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 41 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 42 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 43 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 44 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 45 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 46 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 47 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 48 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 49 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.43           |
| Data-EnvSampler-Poli... | 0.576          |
| Data-EnvTrajs-Averag... | -463           |
| Data-EnvTrajs-MaxReturn | -432           |
| Data-EnvTrajs-MinReturn | -495           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 22             |
| Data-TimeEnvSampleProc  | 0.000891       |
| Data-TimeEnvSampling    | 1.04           |
| Iteration               | 4              |
| ItrTime                 | 14.6           |
| LossAfter               | -0.005500675   |
| LossBefore              | -1.3074568e-05 |
| Model-TimeModelFit      | 10.8           |
| ModelSampler-n_times... | 200000         |
| Policy-AverageAbsPol... | 0.95625293     |
| Policy-AverageDiscou... | -1.78e+06      |
| Policy-AveragePolicyStd | 0.89453954     |
| Policy-AverageReturn    | -4.97e+06      |
| Policy-MaxReturn        | -3.87e+06      |
| Policy-MinReturn        | -5.18e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.68e+05       |
| Policy-TimeAlgoOpt      | 0.694          |
| Policy-TimeSampleProc   | 0.387          |
| Policy-TimeSampling     | 1.69           |
| Policy-TimeStep         | 2.83           |
| Time                    | 58.8           |
| n_timesteps             | 5000           |
--------------------------------------------

 ---------------- Iteration 5 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...
Stopping DynamicsEnsemble Training since valid_loss_rolling_average decreased

 ---------------- Grad-Step 50 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 51 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 52 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 53 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 54 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 55 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 56 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 57 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 58 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 59 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.351          |
| Data-EnvSampler-Poli... | 0.563          |
| Data-EnvTrajs-Averag... | -455           |
| Data-EnvTrajs-MaxReturn | -438           |
| Data-EnvTrajs-MinReturn | -470           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 11.4           |
| Data-TimeEnvSampleProc  | 0.000565       |
| Data-TimeEnvSampling    | 0.94           |
| Iteration               | 5              |
| ItrTime                 | 3.61           |
| LossAfter               | -0.005268691   |
| LossBefore              | -1.2674607e-05 |
| Model-TimeModelFit      | 0.27           |
| ModelSampler-n_times... | 240000         |
| Policy-AverageAbsPol... | 1.630442       |
| Policy-AverageDiscou... | -2.06e+06      |
| Policy-AveragePolicyStd | 0.8589269      |
| Policy-AverageReturn    | -5.34e+06      |
| Policy-MaxReturn        | -5.31e+06      |
| Policy-MinReturn        | -5.38e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.91e+04       |
| Policy-TimeAlgoOpt      | 0.577          |
| Policy-TimeSampleProc   | 0.282          |
| Policy-TimeSampling     | 1.5            |
| Policy-TimeStep         | 2.4            |
| Time                    | 62.4           |
| n_timesteps             | 6000           |
--------------------------------------------

 ---------------- Iteration 6 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 60 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 61 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 62 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 63 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 64 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 65 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 66 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 67 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 68 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 69 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.46           |
| Data-EnvSampler-Poli... | 0.841          |
| Data-EnvTrajs-Averag... | -488           |
| Data-EnvTrajs-MaxReturn | -457           |
| Data-EnvTrajs-MinReturn | -511           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 19.7           |
| Data-TimeEnvSampleProc  | 0.00102        |
| Data-TimeEnvSampling    | 1.34           |
| Iteration               | 6              |
| ItrTime                 | 19.6           |
| LossAfter               | -0.004314443   |
| LossBefore              | -1.2288082e-05 |
| Model-TimeModelFit      | 15.2           |
| ModelSampler-n_times... | 280000         |
| Policy-AverageAbsPol... | 1.1932421      |
| Policy-AverageDiscou... | -1.16e+06      |
| Policy-AveragePolicyStd | 0.8268519      |
| Policy-AverageReturn    | -3.91e+06      |
| Policy-MaxReturn        | -2.98e+06      |
| Policy-MinReturn        | -4.9e+06       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 7.62e+05       |
| Policy-TimeAlgoOpt      | 0.717          |
| Policy-TimeSampleProc   | 0.413          |
| Policy-TimeSampling     | 1.89           |
| Policy-TimeStep         | 3.05           |
| Time                    | 82.1           |
| n_timesteps             | 7000           |
--------------------------------------------

 ---------------- Iteration 7 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 70 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 71 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 72 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 73 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 74 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 75 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 76 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 77 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 78 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 79 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.55           |
| Data-EnvSampler-Poli... | 1.01           |
| Data-EnvTrajs-Averag... | -428           |
| Data-EnvTrajs-MaxReturn | -414           |
| Data-EnvTrajs-MinReturn | -449           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 11.5           |
| Data-TimeEnvSampleProc  | 0.00103        |
| Data-TimeEnvSampling    | 1.6            |
| Iteration               | 7              |
| ItrTime                 | 21.5           |
| LossAfter               | -0.0043278094  |
| LossBefore              | -1.2211643e-05 |
| Model-TimeModelFit      | 17.5           |
| ModelSampler-n_times... | 320000         |
| Policy-AverageAbsPol... | 0.47674575     |
| Policy-AverageDiscou... | -1.22e+06      |
| Policy-AveragePolicyStd | 0.8205932      |
| Policy-AverageReturn    | -3.78e+06      |
| Policy-MaxReturn        | -3.84e+05      |
| Policy-MinReturn        | -4.92e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.62e+06       |
| Policy-TimeAlgoOpt      | 0.579          |
| Policy-TimeSampleProc   | 0.326          |
| Policy-TimeSampling     | 1.49           |
| Policy-TimeStep         | 2.42           |
| Time                    | 104            |
| n_timesteps             | 8000           |
--------------------------------------------

 ---------------- Iteration 8 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 80 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 81 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 82 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 83 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 84 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 85 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 86 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 87 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 88 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 89 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.498          |
| Data-EnvSampler-Poli... | 0.862          |
| Data-EnvTrajs-Averag... | -448           |
| Data-EnvTrajs-MaxReturn | -430           |
| Data-EnvTrajs-MinReturn | -462           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 12             |
| Data-TimeEnvSampleProc  | 0.00116        |
| Data-TimeEnvSampling    | 1.4            |
| Iteration               | 8              |
| ItrTime                 | 22.9           |
| LossAfter               | -0.004090018   |
| LossBefore              | -1.2105321e-05 |
| Model-TimeModelFit      | 19.1           |
| ModelSampler-n_times... | 360000         |
| Policy-AverageAbsPol... | 0.6909527      |
| Policy-AverageDiscou... | -4.99e+05      |
| Policy-AveragePolicyStd | 0.8131885      |
| Policy-AverageReturn    | -1.98e+06      |
| Policy-MaxReturn        | -3.36e+05      |
| Policy-MinReturn        | -4.78e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.46e+06       |
| Policy-TimeAlgoOpt      | 0.505          |
| Policy-TimeSampleProc   | 0.314          |
| Policy-TimeSampling     | 1.5            |
| Policy-TimeStep         | 2.35           |
| Time                    | 126            |
| n_timesteps             | 9000           |
--------------------------------------------

 ---------------- Iteration 9 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 90 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 91 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 92 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 93 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 94 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 95 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 96 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 97 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 98 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 99 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.487          |
| Data-EnvSampler-Poli... | 0.867          |
| Data-EnvTrajs-Averag... | -404           |
| Data-EnvTrajs-MaxReturn | -400           |
| Data-EnvTrajs-MinReturn | -411           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 3.65           |
| Data-TimeEnvSampleProc  | 0.00101        |
| Data-TimeEnvSampling    | 1.39           |
| Iteration               | 9              |
| ItrTime                 | 26.6           |
| LossAfter               | -0.0059956633  |
| LossBefore              | -1.1905602e-05 |
| Model-TimeModelFit      | 22.6           |
| ModelSampler-n_times... | 400000         |
| Policy-AverageAbsPol... | 0.60569525     |
| Policy-AverageDiscou... | -1.73e+06      |
| Policy-AveragePolicyStd | 0.7967806      |
| Policy-AverageReturn    | -4.92e+06      |
| Policy-MaxReturn        | -4.86e+06      |
| Policy-MinReturn        | -4.95e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.13e+04       |
| Policy-TimeAlgoOpt      | 0.582          |
| Policy-TimeSampleProc   | 0.397          |
| Policy-TimeSampling     | 1.61           |
| Policy-TimeStep         | 2.63           |
| Time                    | 153            |
| n_timesteps             | 10000          |
--------------------------------------------

 ---------------- Iteration 10 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 100 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 101 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 102 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 103 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 104 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 105 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 106 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 107 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 108 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 109 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.592          |
| Data-EnvSampler-Poli... | 1.07           |
| Data-EnvTrajs-Averag... | -391           |
| Data-EnvTrajs-MaxReturn | -386           |
| Data-EnvTrajs-MinReturn | -396           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 3.37           |
| Data-TimeEnvSampleProc  | 0.00117        |
| Data-TimeEnvSampling    | 1.7            |
| Iteration               | 10             |
| ItrTime                 | 28.9           |
| LossAfter               | -0.0053154537  |
| LossBefore              | -1.1834916e-05 |
| Model-TimeModelFit      | 24.8           |
| ModelSampler-n_times... | 440000         |
| Policy-AverageAbsPol... | 0.46411133     |
| Policy-AverageDiscou... | -9.14e+03      |
| Policy-AveragePolicyStd | 0.7913514      |
| Policy-AverageReturn    | -5.85e+04      |
| Policy-MaxReturn        | -756           |
| Policy-MinReturn        | -8.59e+05      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.94e+05       |
| Policy-TimeAlgoOpt      | 0.559          |
| Policy-TimeSampleProc   | 0.298          |
| Policy-TimeSampling     | 1.47           |
| Policy-TimeStep         | 2.36           |
| Time                    | 182            |
| n_timesteps             | 11000          |
--------------------------------------------

 ---------------- Iteration 11 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 110 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 111 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 112 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 113 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 114 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 115 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 116 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 117 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 118 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 119 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.471          |
| Data-EnvSampler-Poli... | 0.934          |
| Data-EnvTrajs-Averag... | -420           |
| Data-EnvTrajs-MaxReturn | -405           |
| Data-EnvTrajs-MinReturn | -436           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 10.4           |
| Data-TimeEnvSampleProc  | 0.000688       |
| Data-TimeEnvSampling    | 1.44           |
| Iteration               | 11             |
| ItrTime                 | 30.2           |
| LossAfter               | -0.0056493166  |
| LossBefore              | -1.1837829e-05 |
| Model-TimeModelFit      | 26.4           |
| ModelSampler-n_times... | 480000         |
| Policy-AverageAbsPol... | 0.90387255     |
| Policy-AverageDiscou... | -3.93e+05      |
| Policy-AveragePolicyStd | 0.7913623      |
| Policy-AverageReturn    | -1.28e+06      |
| Policy-MaxReturn        | -1.53e+03      |
| Policy-MinReturn        | -4.53e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.96e+06       |
| Policy-TimeAlgoOpt      | 0.609          |
| Policy-TimeSampleProc   | 0.277          |
| Policy-TimeSampling     | 1.52           |
| Policy-TimeStep         | 2.42           |
| Time                    | 212            |
| n_timesteps             | 12000          |
--------------------------------------------

 ---------------- Iteration 12 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 120 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 121 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 122 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 123 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 124 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 125 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 126 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 127 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 128 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 129 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.478          |
| Data-EnvSampler-Poli... | 0.88           |
| Data-EnvTrajs-Averag... | -441           |
| Data-EnvTrajs-MaxReturn | -434           |
| Data-EnvTrajs-MinReturn | -446           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 4.06           |
| Data-TimeEnvSampleProc  | 0.00104        |
| Data-TimeEnvSampling    | 1.4            |
| Iteration               | 12             |
| ItrTime                 | 31.6           |
| LossAfter               | -0.0034417654  |
| LossBefore              | -1.1607681e-05 |
| Model-TimeModelFit      | 27.5           |
| ModelSampler-n_times... | 520000         |
| Policy-AverageAbsPol... | 0.84249395     |
| Policy-AverageDiscou... | -1.56e+06      |
| Policy-AveragePolicyStd | 0.77418464     |
| Policy-AverageReturn    | -4.67e+06      |
| Policy-MaxReturn        | -4.62e+06      |
| Policy-MinReturn        | -4.71e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.54e+04       |
| Policy-TimeAlgoOpt      | 0.564          |
| Policy-TimeSampleProc   | 0.34           |
| Policy-TimeSampling     | 1.69           |
| Policy-TimeStep         | 2.63           |
| Time                    | 244            |
| n_timesteps             | 13000          |
--------------------------------------------

 ---------------- Iteration 13 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 130 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 131 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 132 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 133 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 134 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 135 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 136 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 137 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 138 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 139 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.489           |
| Data-EnvSampler-Poli... | 0.865           |
| Data-EnvTrajs-Averag... | -442            |
| Data-EnvTrajs-MaxReturn | -435            |
| Data-EnvTrajs-MinReturn | -446            |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 4.1             |
| Data-TimeEnvSampleProc  | 0.000926        |
| Data-TimeEnvSampling    | 1.39            |
| Iteration               | 13              |
| ItrTime                 | 31.2            |
| LossAfter               | -0.004664928    |
| LossBefore              | -1.14699515e-05 |
| Model-TimeModelFit      | 27.2            |
| ModelSampler-n_times... | 560000          |
| Policy-AverageAbsPol... | 1.3658692       |
| Policy-AverageDiscou... | -1.09e+06       |
| Policy-AveragePolicyStd | 0.762792        |
| Policy-AverageReturn    | -3.72e+06       |
| Policy-MaxReturn        | -428            |
| Policy-MinReturn        | -4.4e+06        |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 1.08e+06        |
| Policy-TimeAlgoOpt      | 0.573           |
| Policy-TimeSampleProc   | 0.346           |
| Policy-TimeSampling     | 1.67            |
| Policy-TimeStep         | 2.62            |
| Time                    | 275             |
| n_timesteps             | 14000           |
---------------------------------------------

 ---------------- Iteration 14 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 140 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 141 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 142 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 143 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 144 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 145 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 146 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 147 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 148 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 149 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.471          |
| Data-EnvSampler-Poli... | 0.894          |
| Data-EnvTrajs-Averag... | -444           |
| Data-EnvTrajs-MaxReturn | -393           |
| Data-EnvTrajs-MinReturn | -483           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 30.3           |
| Data-TimeEnvSampleProc  | 0.000991       |
| Data-TimeEnvSampling    | 1.4            |
| Iteration               | 14             |
| ItrTime                 | 32.3           |
| LossAfter               | -0.0062904293  |
| LossBefore              | -1.1328652e-05 |
| Model-TimeModelFit      | 27.8           |
| ModelSampler-n_times... | 600000         |
| Policy-AverageAbsPol... | 0.53293085     |
| Policy-AverageDiscou... | -6.36e+04      |
| Policy-AveragePolicyStd | 0.7525494      |
| Policy-AverageReturn    | -3.15e+05      |
| Policy-MaxReturn        | -481           |
| Policy-MinReturn        | -2.65e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 7.58e+05       |
| Policy-TimeAlgoOpt      | 0.7            |
| Policy-TimeSampleProc   | 0.552          |
| Policy-TimeSampling     | 1.77           |
| Policy-TimeStep         | 3.06           |
| Time                    | 307            |
| n_timesteps             | 15000          |
--------------------------------------------

 ---------------- Iteration 15 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 150 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 151 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 152 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 153 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 154 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 155 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 156 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 157 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 158 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 159 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.449         |
| Data-EnvSampler-Poli... | 0.832         |
| Data-EnvTrajs-Averag... | -421          |
| Data-EnvTrajs-MaxReturn | -391          |
| Data-EnvTrajs-MinReturn | -443          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 18.8          |
| Data-TimeEnvSampleProc  | 0.000865      |
| Data-TimeEnvSampling    | 1.32          |
| Iteration               | 15            |
| ItrTime                 | 31.8          |
| LossAfter               | -0.007830251  |
| LossBefore              | -1.124338e-05 |
| Model-TimeModelFit      | 27.9          |
| ModelSampler-n_times... | 640000        |
| Policy-AverageAbsPol... | 0.5201786     |
| Policy-AverageDiscou... | -1.07e+03     |
| Policy-AveragePolicyStd | 0.74510854    |
| Policy-AverageReturn    | -6.97e+03     |
| Policy-MaxReturn        | -460          |
| Policy-MinReturn        | -1.21e+05     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 2.61e+04      |
| Policy-TimeAlgoOpt      | 0.662         |
| Policy-TimeSampleProc   | 0.3           |
| Policy-TimeSampling     | 1.65          |
| Policy-TimeStep         | 2.64          |
| Time                    | 339           |
| n_timesteps             | 16000         |
-------------------------------------------

 ---------------- Iteration 16 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 160 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 161 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 162 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 163 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 164 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 165 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 166 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 167 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 168 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 169 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.484          |
| Data-EnvSampler-Poli... | 0.877          |
| Data-EnvTrajs-Averag... | -417           |
| Data-EnvTrajs-MaxReturn | -393           |
| Data-EnvTrajs-MinReturn | -440           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 15.4           |
| Data-TimeEnvSampleProc  | 0.00107        |
| Data-TimeEnvSampling    | 1.4            |
| Iteration               | 16             |
| ItrTime                 | 32.6           |
| LossAfter               | -0.0061253584  |
| LossBefore              | -1.1028866e-05 |
| Model-TimeModelFit      | 28.5           |
| ModelSampler-n_times... | 680000         |
| Policy-AverageAbsPol... | 0.481729       |
| Policy-AverageDiscou... | -232           |
| Policy-AveragePolicyStd | 0.72920245     |
| Policy-AverageReturn    | -894           |
| Policy-MaxReturn        | -442           |
| Policy-MinReturn        | -5.69e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.11e+03       |
| Policy-TimeAlgoOpt      | 0.558          |
| Policy-TimeSampleProc   | 0.482          |
| Policy-TimeSampling     | 1.58           |
| Policy-TimeStep         | 2.68           |
| Time                    | 372            |
| n_timesteps             | 17000          |
--------------------------------------------

 ---------------- Iteration 17 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 170 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 171 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 172 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 173 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 174 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 175 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 176 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 177 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 178 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 179 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.464          |
| Data-EnvSampler-Poli... | 0.854          |
| Data-EnvTrajs-Averag... | -410           |
| Data-EnvTrajs-MaxReturn | -406           |
| Data-EnvTrajs-MinReturn | -416           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 4.01           |
| Data-TimeEnvSampleProc  | 0.00096        |
| Data-TimeEnvSampling    | 1.35           |
| Iteration               | 17             |
| ItrTime                 | 33.1           |
| LossAfter               | -0.004827582   |
| LossBefore              | -1.0903314e-05 |
| Model-TimeModelFit      | 28.9           |
| ModelSampler-n_times... | 720000         |
| Policy-AverageAbsPol... | 0.46185124     |
| Policy-AverageDiscou... | -134           |
| Policy-AveragePolicyStd | 0.7196399      |
| Policy-AverageReturn    | -421           |
| Policy-MaxReturn        | -299           |
| Policy-MinReturn        | -596           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 66.4           |
| Policy-TimeAlgoOpt      | 0.642          |
| Policy-TimeSampleProc   | 0.381          |
| Policy-TimeSampling     | 1.79           |
| Policy-TimeStep         | 2.85           |
| Time                    | 405            |
| n_timesteps             | 18000          |
--------------------------------------------

 ---------------- Iteration 18 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 180 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 181 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 182 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 183 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 184 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 185 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 186 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 187 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 188 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 189 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.484          |
| Data-EnvSampler-Poli... | 0.874          |
| Data-EnvTrajs-Averag... | -364           |
| Data-EnvTrajs-MaxReturn | -342           |
| Data-EnvTrajs-MinReturn | -379           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 14.2           |
| Data-TimeEnvSampleProc  | 0.00106        |
| Data-TimeEnvSampling    | 1.4            |
| Iteration               | 18             |
| ItrTime                 | 33.8           |
| LossAfter               | -0.004306611   |
| LossBefore              | -1.0842661e-05 |
| Model-TimeModelFit      | 30             |
| ModelSampler-n_times... | 760000         |
| Policy-AverageAbsPol... | 0.44596106     |
| Policy-AverageDiscou... | -292           |
| Policy-AveragePolicyStd | 0.7157915      |
| Policy-AverageReturn    | -1.73e+03      |
| Policy-MaxReturn        | -181           |
| Policy-MinReturn        | -2.88e+04      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 6.21e+03       |
| Policy-TimeAlgoOpt      | 0.541          |
| Policy-TimeSampleProc   | 0.232          |
| Policy-TimeSampling     | 1.6            |
| Policy-TimeStep         | 2.41           |
| Time                    | 439            |
| n_timesteps             | 19000          |
--------------------------------------------

 ---------------- Iteration 19 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 190 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 191 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 192 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 193 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 194 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 195 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 196 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 197 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 198 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 199 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.476          |
| Data-EnvSampler-Poli... | 0.932          |
| Data-EnvTrajs-Averag... | -30.8          |
| Data-EnvTrajs-MaxReturn | 144            |
| Data-EnvTrajs-MinReturn | -174           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 128            |
| Data-TimeEnvSampleProc  | 0.000924       |
| Data-TimeEnvSampling    | 1.45           |
| Iteration               | 19             |
| ItrTime                 | 32.7           |
| LossAfter               | -0.005892641   |
| LossBefore              | -1.0826076e-05 |
| Model-TimeModelFit      | 28.8           |
| ModelSampler-n_times... | 800000         |
| Policy-AverageAbsPol... | 0.46808928     |
| Policy-AverageDiscou... | -252           |
| Policy-AveragePolicyStd | 0.71497065     |
| Policy-AverageReturn    | -1.66e+03      |
| Policy-MaxReturn        | 129            |
| Policy-MinReturn        | -2.65e+04      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 5.7e+03        |
| Policy-TimeAlgoOpt      | 0.556          |
| Policy-TimeSampleProc   | 0.293          |
| Policy-TimeSampling     | 1.63           |
| Policy-TimeStep         | 2.5            |
| Time                    | 472            |
| n_timesteps             | 20000          |
--------------------------------------------

 ---------------- Iteration 20 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 200 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 201 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 202 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 203 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 204 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 205 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 206 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 207 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 208 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 209 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.478          |
| Data-EnvSampler-Poli... | 0.815          |
| Data-EnvTrajs-Averag... | -391           |
| Data-EnvTrajs-MaxReturn | -364           |
| Data-EnvTrajs-MinReturn | -408           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 16.4           |
| Data-TimeEnvSampleProc  | 0.000887       |
| Data-TimeEnvSampling    | 1.33           |
| Iteration               | 20             |
| ItrTime                 | 32.4           |
| LossAfter               | -0.007449009   |
| LossBefore              | -1.0626829e-05 |
| Model-TimeModelFit      | 28.5           |
| ModelSampler-n_times... | 840000         |
| Policy-AverageAbsPol... | 0.41746435     |
| Policy-AverageDiscou... | -80.8          |
| Policy-AveragePolicyStd | 0.7015628      |
| Policy-AverageReturn    | -321           |
| Policy-MaxReturn        | -225           |
| Policy-MinReturn        | -478           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 59.5           |
| Policy-TimeAlgoOpt      | 0.577          |
| Policy-TimeSampleProc   | 0.374          |
| Policy-TimeSampling     | 1.59           |
| Policy-TimeStep         | 2.56           |
| Time                    | 504            |
| n_timesteps             | 21000          |
--------------------------------------------

 ---------------- Iteration 21 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 210 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 211 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 212 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 213 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 214 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 215 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 216 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 217 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 218 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 219 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.452          |
| Data-EnvSampler-Poli... | 0.881          |
| Data-EnvTrajs-Averag... | 82.1           |
| Data-EnvTrajs-MaxReturn | 173            |
| Data-EnvTrajs-MinReturn | -169           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 128            |
| Data-TimeEnvSampleProc  | 0.000575       |
| Data-TimeEnvSampling    | 1.37           |
| Iteration               | 21             |
| ItrTime                 | 31.9           |
| LossAfter               | -0.004081476   |
| LossBefore              | -1.0424623e-05 |
| Model-TimeModelFit      | 28.2           |
| ModelSampler-n_times... | 880000         |
| Policy-AverageAbsPol... | 0.44944626     |
| Policy-AverageDiscou... | -65.9          |
| Policy-AveragePolicyStd | 0.68706167     |
| Policy-AverageReturn    | -621           |
| Policy-MaxReturn        | 292            |
| Policy-MinReturn        | -1.23e+04      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.68e+03       |
| Policy-TimeAlgoOpt      | 0.564          |
| Policy-TimeSampleProc   | 0.237          |
| Policy-TimeSampling     | 1.49           |
| Policy-TimeStep         | 2.31           |
| Time                    | 536            |
| n_timesteps             | 22000          |
--------------------------------------------

 ---------------- Iteration 22 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 220 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 221 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 222 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 223 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 224 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 225 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 226 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 227 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 228 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 229 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.462          |
| Data-EnvSampler-Poli... | 0.833          |
| Data-EnvTrajs-Averag... | -5.7           |
| Data-EnvTrajs-MaxReturn | 153            |
| Data-EnvTrajs-MinReturn | -194           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 148            |
| Data-TimeEnvSampleProc  | 0.000954       |
| Data-TimeEnvSampling    | 1.33           |
| Iteration               | 22             |
| ItrTime                 | 33.1           |
| LossAfter               | -0.0056629423  |
| LossBefore              | -1.0412592e-05 |
| Model-TimeModelFit      | 29.3           |
| ModelSampler-n_times... | 920000         |
| Policy-AverageAbsPol... | 0.47968957     |
| Policy-AverageDiscou... | -4.7e+04       |
| Policy-AveragePolicyStd | 0.6852221      |
| Policy-AverageReturn    | -2.77e+05      |
| Policy-MaxReturn        | 53.6           |
| Policy-MinReturn        | -1.65e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 5.19e+05       |
| Policy-TimeAlgoOpt      | 0.546          |
| Policy-TimeSampleProc   | 0.39           |
| Policy-TimeSampling     | 1.46           |
| Policy-TimeStep         | 2.45           |
| Time                    | 569            |
| n_timesteps             | 23000          |
--------------------------------------------

 ---------------- Iteration 23 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 230 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 231 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 232 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 233 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 234 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 235 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 236 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 237 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 238 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 239 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.442          |
| Data-EnvSampler-Poli... | 0.833          |
| Data-EnvTrajs-Averag... | -377           |
| Data-EnvTrajs-MaxReturn | -326           |
| Data-EnvTrajs-MinReturn | -423           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 37.2           |
| Data-TimeEnvSampleProc  | 0.00101        |
| Data-TimeEnvSampling    | 1.32           |
| Iteration               | 23             |
| ItrTime                 | 32.8           |
| LossAfter               | -0.008264356   |
| LossBefore              | -1.0247184e-05 |
| Model-TimeModelFit      | 29             |
| ModelSampler-n_times... | 960000         |
| Policy-AverageAbsPol... | 0.40238208     |
| Policy-AverageDiscou... | -100           |
| Policy-AveragePolicyStd | 0.67463046     |
| Policy-AverageReturn    | -345           |
| Policy-MaxReturn        | -184           |
| Policy-MinReturn        | -471           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 84.3           |
| Policy-TimeAlgoOpt      | 0.577          |
| Policy-TimeSampleProc   | 0.325          |
| Policy-TimeSampling     | 1.53           |
| Policy-TimeStep         | 2.46           |
| Time                    | 602            |
| n_timesteps             | 24000          |
--------------------------------------------

 ---------------- Iteration 24 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 240 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 241 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 242 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 243 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 244 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 245 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 246 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 247 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 248 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 249 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.514          |
| Data-EnvSampler-Poli... | 1.01           |
| Data-EnvTrajs-Averag... | 97.5           |
| Data-EnvTrajs-MaxReturn | 161            |
| Data-EnvTrajs-MinReturn | -48.5          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 76.4           |
| Data-TimeEnvSampleProc  | 0.000988       |
| Data-TimeEnvSampling    | 1.56           |
| Iteration               | 24             |
| ItrTime                 | 32.6           |
| LossAfter               | -0.005149814   |
| LossBefore              | -1.0078701e-05 |
| Model-TimeModelFit      | 28.6           |
| ModelSampler-n_times... | 1000000        |
| Policy-AverageAbsPol... | 0.39943987     |
| Policy-AverageDiscou... | 61.8           |
| Policy-AveragePolicyStd | 0.6634123      |
| Policy-AverageReturn    | 76.4           |
| Policy-MaxReturn        | 579            |
| Policy-MinReturn        | -2.95e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 738            |
| Policy-TimeAlgoOpt      | 0.543          |
| Policy-TimeSampleProc   | 0.328          |
| Policy-TimeSampling     | 1.49           |
| Policy-TimeStep         | 2.4            |
| Time                    | 634            |
| n_timesteps             | 25000          |
--------------------------------------------

 ---------------- Iteration 25 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 250 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 251 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 252 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 253 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 254 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 255 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 256 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 257 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 258 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 259 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.462         |
| Data-EnvSampler-Poli... | 0.804         |
| Data-EnvTrajs-Averag... | 66.5          |
| Data-EnvTrajs-MaxReturn | 161           |
| Data-EnvTrajs-MinReturn | -46.1         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 82.7          |
| Data-TimeEnvSampleProc  | 0.000828      |
| Data-TimeEnvSampling    | 1.3           |
| Iteration               | 25            |
| ItrTime                 | 33.9          |
| LossAfter               | -0.004816107  |
| LossBefore              | -1.001982e-05 |
| Model-TimeModelFit      | 29.7          |
| ModelSampler-n_times... | 1040000       |
| Policy-AverageAbsPol... | 0.39063248    |
| Policy-AverageDiscou... | -32.9         |
| Policy-AveragePolicyStd | 0.6598674     |
| Policy-AverageReturn    | -218          |
| Policy-MaxReturn        | 20.1          |
| Policy-MinReturn        | -448          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 106           |
| Policy-TimeAlgoOpt      | 0.586         |
| Policy-TimeSampleProc   | 0.479         |
| Policy-TimeSampling     | 1.83          |
| Policy-TimeStep         | 2.96          |
| Time                    | 668           |
| n_timesteps             | 26000         |
-------------------------------------------

 ---------------- Iteration 26 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 260 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 261 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 262 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 263 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 264 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 265 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 266 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 267 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 268 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 269 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.493          |
| Data-EnvSampler-Poli... | 0.812          |
| Data-EnvTrajs-Averag... | 104            |
| Data-EnvTrajs-MaxReturn | 147            |
| Data-EnvTrajs-MinReturn | 22.5           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 43.3           |
| Data-TimeEnvSampleProc  | 0.000679       |
| Data-TimeEnvSampling    | 1.34           |
| Iteration               | 26             |
| ItrTime                 | 32.8           |
| LossAfter               | -0.006362666   |
| LossBefore              | -1.0067336e-05 |
| Model-TimeModelFit      | 28.9           |
| ModelSampler-n_times... | 1080000        |
| Policy-AverageAbsPol... | 0.837096       |
| Policy-AverageDiscou... | -5.59e+05      |
| Policy-AveragePolicyStd | 0.66409373     |
| Policy-AverageReturn    | -2.57e+06      |
| Policy-MaxReturn        | -2.17e+06      |
| Policy-MinReturn        | -2.84e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.62e+05       |
| Policy-TimeAlgoOpt      | 0.635          |
| Policy-TimeSampleProc   | 0.317          |
| Policy-TimeSampling     | 1.56           |
| Policy-TimeStep         | 2.54           |
| Time                    | 701            |
| n_timesteps             | 27000          |
--------------------------------------------

 ---------------- Iteration 27 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 270 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 271 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 272 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 273 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 274 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 275 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 276 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 277 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 278 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 279 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.48           |
| Data-EnvSampler-Poli... | 0.876          |
| Data-EnvTrajs-Averag... | -34.6          |
| Data-EnvTrajs-MaxReturn | 87.5           |
| Data-EnvTrajs-MinReturn | -286           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 134            |
| Data-TimeEnvSampleProc  | 0.00064        |
| Data-TimeEnvSampling    | 1.39           |
| Iteration               | 27             |
| ItrTime                 | 33.9           |
| LossAfter               | -0.0041684126  |
| LossBefore              | -1.0050862e-05 |
| Model-TimeModelFit      | 29.8           |
| ModelSampler-n_times... | 1120000        |
| Policy-AverageAbsPol... | 0.42657036     |
| Policy-AverageDiscou... | -4.7e+03       |
| Policy-AveragePolicyStd | 0.66144294     |
| Policy-AverageReturn    | -3.08e+04      |
| Policy-MaxReturn        | -252           |
| Policy-MinReturn        | -6.1e+05       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.33e+05       |
| Policy-TimeAlgoOpt      | 0.594          |
| Policy-TimeSampleProc   | 0.352          |
| Policy-TimeSampling     | 1.69           |
| Policy-TimeStep         | 2.67           |
| Time                    | 735            |
| n_timesteps             | 28000          |
--------------------------------------------

 ---------------- Iteration 28 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 280 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 281 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 282 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 283 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 284 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 285 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 286 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 287 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 288 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 289 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.487          |
| Data-EnvSampler-Poli... | 0.908          |
| Data-EnvTrajs-Averag... | -229           |
| Data-EnvTrajs-MaxReturn | -64            |
| Data-EnvTrajs-MinReturn | -349           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 94.9           |
| Data-TimeEnvSampleProc  | 0.000857       |
| Data-TimeEnvSampling    | 1.44           |
| Iteration               | 28             |
| ItrTime                 | 34.6           |
| LossAfter               | -0.0073575233  |
| LossBefore              | -1.0027365e-05 |
| Model-TimeModelFit      | 29.9           |
| ModelSampler-n_times... | 1160000        |
| Policy-AverageAbsPol... | 0.44340706     |
| Policy-AverageDiscou... | -2.9e+03       |
| Policy-AveragePolicyStd | 0.6604458      |
| Policy-AverageReturn    | -1.98e+04      |
| Policy-MaxReturn        | -180           |
| Policy-MinReturn        | -3.91e+05      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 8.51e+04       |
| Policy-TimeAlgoOpt      | 0.69           |
| Policy-TimeSampleProc   | 0.632          |
| Policy-TimeSampling     | 1.83           |
| Policy-TimeStep         | 3.26           |
| Time                    | 770            |
| n_timesteps             | 29000          |
--------------------------------------------

 ---------------- Iteration 29 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 290 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 291 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 292 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 293 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 294 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 295 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 296 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 297 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 298 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 299 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.485         |
| Data-EnvSampler-Poli... | 0.883         |
| Data-EnvTrajs-Averag... | -237          |
| Data-EnvTrajs-MaxReturn | 17.9          |
| Data-EnvTrajs-MinReturn | -326          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 128           |
| Data-TimeEnvSampleProc  | 0.000853      |
| Data-TimeEnvSampling    | 1.4           |
| Iteration               | 29            |
| ItrTime                 | 34.3          |
| LossAfter               | -0.0036713153 |
| LossBefore              | -9.946087e-06 |
| Model-TimeModelFit      | 29.8          |
| ModelSampler-n_times... | 1200000       |
| Policy-AverageAbsPol... | 0.4312136     |
| Policy-AverageDiscou... | -95.8         |
| Policy-AveragePolicyStd | 0.6552642     |
| Policy-AverageReturn    | -331          |
| Policy-MaxReturn        | -265          |
| Policy-MinReturn        | -592          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 73.3          |
| Policy-TimeAlgoOpt      | 0.565         |
| Policy-TimeSampleProc   | 0.652         |
| Policy-TimeSampling     | 1.88          |
| Policy-TimeStep         | 3.17          |
| Time                    | 804           |
| n_timesteps             | 30000         |
-------------------------------------------

 ---------------- Iteration 30 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 300 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 301 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 302 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 303 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 304 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 305 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 306 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 307 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 308 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 309 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.443         |
| Data-EnvSampler-Poli... | 0.832         |
| Data-EnvTrajs-Averag... | 162           |
| Data-EnvTrajs-MaxReturn | 192           |
| Data-EnvTrajs-MinReturn | 134           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 20.4          |
| Data-TimeEnvSampleProc  | 0.000999      |
| Data-TimeEnvSampling    | 1.31          |
| Iteration               | 30            |
| ItrTime                 | 34.6          |
| LossAfter               | -0.008791645  |
| LossBefore              | -9.924257e-06 |
| Model-TimeModelFit      | 30.7          |
| ModelSampler-n_times... | 1240000       |
| Policy-AverageAbsPol... | 0.57682735    |
| Policy-AverageDiscou... | -3.78e+03     |
| Policy-AveragePolicyStd | 0.6543235     |
| Policy-AverageReturn    | -2.53e+04     |
| Policy-MaxReturn        | -199          |
| Policy-MinReturn        | -4.93e+05     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.07e+05      |
| Policy-TimeAlgoOpt      | 0.564         |
| Policy-TimeSampleProc   | 0.387         |
| Policy-TimeSampling     | 1.56          |
| Policy-TimeStep         | 2.54          |
| Time                    | 838           |
| n_timesteps             | 31000         |
-------------------------------------------

 ---------------- Iteration 31 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 310 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 311 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 312 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 313 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 314 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 315 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 316 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 317 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 318 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 319 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.471         |
| Data-EnvSampler-Poli... | 0.927         |
| Data-EnvTrajs-Averag... | -124          |
| Data-EnvTrajs-MaxReturn | 48.7          |
| Data-EnvTrajs-MinReturn | -269          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 109           |
| Data-TimeEnvSampleProc  | 0.00145       |
| Data-TimeEnvSampling    | 1.44          |
| Iteration               | 31            |
| ItrTime                 | 35.2          |
| LossAfter               | -0.0048063397 |
| LossBefore              | -9.839927e-06 |
| Model-TimeModelFit      | 30.8          |
| ModelSampler-n_times... | 1280000       |
| Policy-AverageAbsPol... | 0.39655653    |
| Policy-AverageDiscou... | -83           |
| Policy-AveragePolicyStd | 0.6482766     |
| Policy-AverageReturn    | -313          |
| Policy-MaxReturn        | -226          |
| Policy-MinReturn        | -444          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 57.9          |
| Policy-TimeAlgoOpt      | 0.608         |
| Policy-TimeSampleProc   | 0.444         |
| Policy-TimeSampling     | 1.82          |
| Policy-TimeStep         | 2.9           |
| Time                    | 874           |
| n_timesteps             | 32000         |
-------------------------------------------

 ---------------- Iteration 32 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 320 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 321 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 322 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 323 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 324 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 325 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 326 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 327 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 328 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 329 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.503         |
| Data-EnvSampler-Poli... | 1.01          |
| Data-EnvTrajs-Averag... | -347          |
| Data-EnvTrajs-MaxReturn | -309          |
| Data-EnvTrajs-MinReturn | -385          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 24.3          |
| Data-TimeEnvSampleProc  | 0.000854      |
| Data-TimeEnvSampling    | 1.55          |
| Iteration               | 32            |
| ItrTime                 | 35.2          |
| LossAfter               | -0.004132993  |
| LossBefore              | -9.663868e-06 |
| Model-TimeModelFit      | 30.7          |
| ModelSampler-n_times... | 1320000       |
| Policy-AverageAbsPol... | 0.4856329     |
| Policy-AverageDiscou... | -1.56e+04     |
| Policy-AveragePolicyStd | 0.6365345     |
| Policy-AverageReturn    | -9.2e+04      |
| Policy-MaxReturn        | -326          |
| Policy-MinReturn        | -1.46e+06     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 3.23e+05      |
| Policy-TimeAlgoOpt      | 0.627         |
| Policy-TimeSampleProc   | 0.522         |
| Policy-TimeSampling     | 1.68          |
| Policy-TimeStep         | 2.89          |
| Time                    | 909           |
| n_timesteps             | 33000         |
-------------------------------------------

 ---------------- Iteration 33 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 330 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 331 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 332 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 333 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 334 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 335 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 336 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 337 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 338 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 339 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.469         |
| Data-EnvSampler-Poli... | 0.86          |
| Data-EnvTrajs-Averag... | -332          |
| Data-EnvTrajs-MaxReturn | -296          |
| Data-EnvTrajs-MinReturn | -378          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 29.4          |
| Data-TimeEnvSampleProc  | 0.000961      |
| Data-TimeEnvSampling    | 1.37          |
| Iteration               | 33            |
| ItrTime                 | 36.1          |
| LossAfter               | -0.00480351   |
| LossBefore              | -9.496307e-06 |
| Model-TimeModelFit      | 31.8          |
| ModelSampler-n_times... | 1360000       |
| Policy-AverageAbsPol... | 0.5589494     |
| Policy-AverageDiscou... | -73.9         |
| Policy-AveragePolicyStd | 0.6258058     |
| Policy-AverageReturn    | -231          |
| Policy-MaxReturn        | -87.3         |
| Policy-MinReturn        | -308          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 54.6          |
| Policy-TimeAlgoOpt      | 0.677         |
| Policy-TimeSampleProc   | 0.494         |
| Policy-TimeSampling     | 1.77          |
| Policy-TimeStep         | 2.98          |
| Time                    | 945           |
| n_timesteps             | 34000         |
-------------------------------------------

 ---------------- Iteration 34 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 340 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 341 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 342 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 343 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 344 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 345 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 346 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 347 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 348 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 349 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.698         |
| Data-EnvSampler-Poli... | 1.38          |
| Data-EnvTrajs-Averag... | -190          |
| Data-EnvTrajs-MaxReturn | -38.7         |
| Data-EnvTrajs-MinReturn | -236          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 75.7          |
| Data-TimeEnvSampleProc  | 0.000757      |
| Data-TimeEnvSampling    | 2.13          |
| Iteration               | 34            |
| ItrTime                 | 36.6          |
| LossAfter               | -0.0066183666 |
| LossBefore              | -9.318782e-06 |
| Model-TimeModelFit      | 31.3          |
| ModelSampler-n_times... | 1400000       |
| Policy-AverageAbsPol... | 0.51811415    |
| Policy-AverageDiscou... | -2.67e+04     |
| Policy-AveragePolicyStd | 0.6150833     |
| Policy-AverageReturn    | -1.55e+05     |
| Policy-MaxReturn        | -44.7         |
| Policy-MinReturn        | -1.77e+06     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 4.27e+05      |
| Policy-TimeAlgoOpt      | 0.667         |
| Policy-TimeSampleProc   | 0.616         |
| Policy-TimeSampling     | 1.91          |
| Policy-TimeStep         | 3.22          |
| Time                    | 982           |
| n_timesteps             | 35000         |
-------------------------------------------

 ---------------- Iteration 35 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 350 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 351 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 352 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 353 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 354 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 355 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 356 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 357 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 358 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 359 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.557         |
| Data-EnvSampler-Poli... | 1.08          |
| Data-EnvTrajs-Averag... | -218          |
| Data-EnvTrajs-MaxReturn | 43.2          |
| Data-EnvTrajs-MinReturn | -311          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 132           |
| Data-TimeEnvSampleProc  | 0.00104       |
| Data-TimeEnvSampling    | 1.68          |
| Iteration               | 35            |
| ItrTime                 | 35.2          |
| LossAfter               | -0.005858539  |
| LossBefore              | -9.229345e-06 |
| Model-TimeModelFit      | 31.1          |
| ModelSampler-n_times... | 1440000       |
| Policy-AverageAbsPol... | 0.5217128     |
| Policy-AverageDiscou... | -55.1         |
| Policy-AveragePolicyStd | 0.6086743     |
| Policy-AverageReturn    | -215          |
| Policy-MaxReturn        | 51.3          |
| Policy-MinReturn        | -318          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 92.8          |
| Policy-TimeAlgoOpt      | 0.58          |
| Policy-TimeSampleProc   | 0.308         |
| Policy-TimeSampling     | 1.52          |
| Policy-TimeStep         | 2.44          |
| Time                    | 1.02e+03      |
| n_timesteps             | 36000         |
-------------------------------------------

 ---------------- Iteration 36 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 360 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 361 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 362 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 363 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 364 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 365 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 366 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 367 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 368 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 369 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.514         |
| Data-EnvSampler-Poli... | 1.12          |
| Data-EnvTrajs-Averag... | -134          |
| Data-EnvTrajs-MaxReturn | 34            |
| Data-EnvTrajs-MinReturn | -220          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 100           |
| Data-TimeEnvSampleProc  | 0.000608      |
| Data-TimeEnvSampling    | 1.68          |
| Iteration               | 36            |
| ItrTime                 | 37.1          |
| LossAfter               | -0.005522756  |
| LossBefore              | -9.129368e-06 |
| Model-TimeModelFit      | 32.6          |
| ModelSampler-n_times... | 1480000       |
| Policy-AverageAbsPol... | 0.7149032     |
| Policy-AverageDiscou... | -3.64e+03     |
| Policy-AveragePolicyStd | 0.60324544    |
| Policy-AverageReturn    | -2.56e+04     |
| Policy-MaxReturn        | 160           |
| Policy-MinReturn        | -3.06e+05     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 7.23e+04      |
| Policy-TimeAlgoOpt      | 0.602         |
| Policy-TimeSampleProc   | 0.483         |
| Policy-TimeSampling     | 1.65          |
| Policy-TimeStep         | 2.76          |
| Time                    | 1.05e+03      |
| n_timesteps             | 37000         |
-------------------------------------------

 ---------------- Iteration 37 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 370 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 371 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 372 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 373 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 374 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 375 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 376 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 377 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 378 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 379 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.464         |
| Data-EnvSampler-Poli... | 0.843         |
| Data-EnvTrajs-Averag... | 21.1          |
| Data-EnvTrajs-MaxReturn | 40.6          |
| Data-EnvTrajs-MinReturn | 8.74          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 10.7          |
| Data-TimeEnvSampleProc  | 0.001         |
| Data-TimeEnvSampling    | 1.34          |
| Iteration               | 37            |
| ItrTime                 | 35.8          |
| LossAfter               | -0.0052289786 |
| LossBefore              | -9.043867e-06 |
| Model-TimeModelFit      | 31.3          |
| ModelSampler-n_times... | 1520000       |
| Policy-AverageAbsPol... | 0.7719122     |
| Policy-AverageDiscou... | 17.2          |
| Policy-AveragePolicyStd | 0.5985953     |
| Policy-AverageReturn    | 1.16          |
| Policy-MaxReturn        | 341           |
| Policy-MinReturn        | -1.99e+03     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 504           |
| Policy-TimeAlgoOpt      | 0.612         |
| Policy-TimeSampleProc   | 0.596         |
| Policy-TimeSampling     | 1.86          |
| Policy-TimeStep         | 3.15          |
| Time                    | 1.09e+03      |
| n_timesteps             | 38000         |
-------------------------------------------

 ---------------- Iteration 38 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 380 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 381 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 382 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 383 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 384 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 385 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 386 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 387 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 388 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 389 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.494          |
| Data-EnvSampler-Poli... | 0.886          |
| Data-EnvTrajs-Averag... | 39.1           |
| Data-EnvTrajs-MaxReturn | 59.8           |
| Data-EnvTrajs-MinReturn | 19.5           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 15.9           |
| Data-TimeEnvSampleProc  | 0.00106        |
| Data-TimeEnvSampling    | 1.42           |
| Iteration               | 38             |
| ItrTime                 | 35.2           |
| LossAfter               | -0.004599452   |
| LossBefore              | -8.9645755e-06 |
| Model-TimeModelFit      | 31.4           |
| ModelSampler-n_times... | 1560000        |
| Policy-AverageAbsPol... | 0.7653708      |
| Policy-AverageDiscou... | -4.15e+03      |
| Policy-AveragePolicyStd | 0.5939763      |
| Policy-AverageReturn    | -2.81e+04      |
| Policy-MaxReturn        | 328            |
| Policy-MinReturn        | -5.3e+05       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.15e+05       |
| Policy-TimeAlgoOpt      | 0.586          |
| Policy-TimeSampleProc   | 0.291          |
| Policy-TimeSampling     | 1.48           |
| Policy-TimeStep         | 2.4            |
| Time                    | 1.12e+03       |
| n_timesteps             | 39000          |
--------------------------------------------

 ---------------- Iteration 39 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 390 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 391 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 392 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 393 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 394 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 395 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 396 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 397 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 398 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 399 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.474         |
| Data-EnvSampler-Poli... | 0.917         |
| Data-EnvTrajs-Averag... | 64.4          |
| Data-EnvTrajs-MaxReturn | 77.9          |
| Data-EnvTrajs-MinReturn | 55            |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 8.86          |
| Data-TimeEnvSampleProc  | 0.00102       |
| Data-TimeEnvSampling    | 1.44          |
| Iteration               | 39            |
| ItrTime                 | 38.1          |
| LossAfter               | -0.0067910035 |
| LossBefore              | -9.026463e-06 |
| Model-TimeModelFit      | 33.2          |
| ModelSampler-n_times... | 1600000       |
| Policy-AverageAbsPol... | 0.8497092     |
| Policy-AverageDiscou... | -1.04e+04     |
| Policy-AveragePolicyStd | 0.5977972     |
| Policy-AverageReturn    | -6.55e+04     |
| Policy-MaxReturn        | 144           |
| Policy-MinReturn        | -1.04e+06     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 2.3e+05       |
| Policy-TimeAlgoOpt      | 0.638         |
| Policy-TimeSampleProc   | 0.664         |
| Policy-TimeSampling     | 2.09          |
| Policy-TimeStep         | 3.47          |
| Time                    | 1.16e+03      |
| n_timesteps             | 40000         |
-------------------------------------------

 ---------------- Iteration 40 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 400 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 401 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 402 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 403 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 404 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 405 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 406 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 407 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 408 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 409 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.612         |
| Data-EnvSampler-Poli... | 1.4           |
| Data-EnvTrajs-Averag... | 59.3          |
| Data-EnvTrajs-MaxReturn | 74.5          |
| Data-EnvTrajs-MinReturn | 21.4          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 19.2          |
| Data-TimeEnvSampleProc  | 0.00127       |
| Data-TimeEnvSampling    | 2.07          |
| Iteration               | 40            |
| ItrTime                 | 36.5          |
| LossAfter               | -0.0020129585 |
| LossBefore              | -9.072811e-06 |
| Model-TimeModelFit      | 31.7          |
| ModelSampler-n_times... | 1640000       |
| Policy-AverageAbsPol... | 0.77473533    |
| Policy-AverageDiscou... | -196          |
| Policy-AveragePolicyStd | 0.5998379     |
| Policy-AverageReturn    | -1.22e+03     |
| Policy-MaxReturn        | 96.2          |
| Policy-MinReturn        | -6.85e+03     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 2.21e+03      |
| Policy-TimeAlgoOpt      | 0.637         |
| Policy-TimeSampleProc   | 0.402         |
| Policy-TimeSampling     | 1.65          |
| Policy-TimeStep         | 2.71          |
| Time                    | 1.2e+03       |
| n_timesteps             | 41000         |
-------------------------------------------

 ---------------- Iteration 41 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 410 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 411 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 412 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 413 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 414 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 415 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 416 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 417 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 418 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 419 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.689         |
| Data-EnvSampler-Poli... | 1.36          |
| Data-EnvTrajs-Averag... | 25.8          |
| Data-EnvTrajs-MaxReturn | 38.1          |
| Data-EnvTrajs-MinReturn | 12            |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 11.4          |
| Data-TimeEnvSampleProc  | 0.00112       |
| Data-TimeEnvSampling    | 2.11          |
| Iteration               | 41            |
| ItrTime                 | 37.1          |
| LossAfter               | -0.005957463  |
| LossBefore              | -8.815577e-06 |
| Model-TimeModelFit      | 32.3          |
| ModelSampler-n_times... | 1680000       |
| Policy-AverageAbsPol... | 0.57666487    |
| Policy-AverageDiscou... | 21.9          |
| Policy-AveragePolicyStd | 0.58416116    |
| Policy-AverageReturn    | 51.7          |
| Policy-MaxReturn        | 82            |
| Policy-MinReturn        | 13.7          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 15.2          |
| Policy-TimeAlgoOpt      | 0.594         |
| Policy-TimeSampleProc   | 0.368         |
| Policy-TimeSampling     | 1.64          |
| Policy-TimeStep         | 2.67          |
| Time                    | 1.24e+03      |
| n_timesteps             | 42000         |
-------------------------------------------

 ---------------- Iteration 42 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 420 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 421 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 422 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 423 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 424 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 425 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 426 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 427 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 428 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 429 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.537         |
| Data-EnvSampler-Poli... | 0.973         |
| Data-EnvTrajs-Averag... | 70.4          |
| Data-EnvTrajs-MaxReturn | 79            |
| Data-EnvTrajs-MinReturn | 49.9          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 10.5          |
| Data-TimeEnvSampleProc  | 0.00099       |
| Data-TimeEnvSampling    | 1.55          |
| Iteration               | 42            |
| ItrTime                 | 38.1          |
| LossAfter               | -0.00791475   |
| LossBefore              | -8.644409e-06 |
| Model-TimeModelFit      | 33            |
| ModelSampler-n_times... | 1720000       |
| Policy-AverageAbsPol... | 0.79277587    |
| Policy-AverageDiscou... | -3.98e+03     |
| Policy-AveragePolicyStd | 0.5740861     |
| Policy-AverageReturn    | -2.77e+04     |
| Policy-MaxReturn        | 187           |
| Policy-MinReturn        | -3.3e+05      |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 7.55e+04      |
| Policy-TimeAlgoOpt      | 0.725         |
| Policy-TimeSampleProc   | 0.573         |
| Policy-TimeSampling     | 2.14          |
| Policy-TimeStep         | 3.51          |
| Time                    | 1.27e+03      |
| n_timesteps             | 43000         |
-------------------------------------------

 ---------------- Iteration 43 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 430 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 431 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 432 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 433 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 434 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 435 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 436 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 437 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 438 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 439 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.618         |
| Data-EnvSampler-Poli... | 1.27          |
| Data-EnvTrajs-Averag... | -36.4         |
| Data-EnvTrajs-MaxReturn | 16.6          |
| Data-EnvTrajs-MinReturn | -212          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 87.8          |
| Data-TimeEnvSampleProc  | 0.00108       |
| Data-TimeEnvSampling    | 1.95          |
| Iteration               | 43            |
| ItrTime                 | 37.3          |
| LossAfter               | -0.0019058478 |
| LossBefore              | -8.322472e-06 |
| Model-TimeModelFit      | 32            |
| ModelSampler-n_times... | 1760000       |
| Policy-AverageAbsPol... | 0.49301568    |
| Policy-AverageDiscou... | 17.7          |
| Policy-AveragePolicyStd | 0.5570266     |
| Policy-AverageReturn    | 11            |
| Policy-MaxReturn        | 52.2          |
| Policy-MinReturn        | -96.5         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 35.4          |
| Policy-TimeAlgoOpt      | 0.684         |
| Policy-TimeSampleProc   | 0.47          |
| Policy-TimeSampling     | 2.14          |
| Policy-TimeStep         | 3.32          |
| Time                    | 1.31e+03      |
| n_timesteps             | 44000         |
-------------------------------------------

 ---------------- Iteration 44 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 440 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 441 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 442 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 443 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 444 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 445 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 446 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 447 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 448 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 449 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.555         |
| Data-EnvSampler-Poli... | 1.03          |
| Data-EnvTrajs-Averag... | 29.1          |
| Data-EnvTrajs-MaxReturn | 34.1          |
| Data-EnvTrajs-MinReturn | 25.7          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 3.1           |
| Data-TimeEnvSampleProc  | 0.0012        |
| Data-TimeEnvSampling    | 1.63          |
| Iteration               | 44            |
| ItrTime                 | 36.6          |
| LossAfter               | -0.0041258773 |
| LossBefore              | -8.04641e-06  |
| Model-TimeModelFit      | 32.4          |
| ModelSampler-n_times... | 1800000       |
| Policy-AverageAbsPol... | 0.522091      |
| Policy-AverageDiscou... | -6.13e+04     |
| Policy-AveragePolicyStd | 0.5410698     |
| Policy-AverageReturn    | -2.74e+05     |
| Policy-MaxReturn        | 111           |
| Policy-MinReturn        | -2.88e+06     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 8.23e+05      |
| Policy-TimeAlgoOpt      | 0.623         |
| Policy-TimeSampleProc   | 0.379         |
| Policy-TimeSampling     | 1.61          |
| Policy-TimeStep         | 2.64          |
| Time                    | 1.35e+03      |
| n_timesteps             | 45000         |
-------------------------------------------

 ---------------- Iteration 45 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 450 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 451 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 452 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 453 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 454 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 455 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 456 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 457 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 458 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 459 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.585         |
| Data-EnvSampler-Poli... | 1.42          |
| Data-EnvTrajs-Averag... | 89.5          |
| Data-EnvTrajs-MaxReturn | 117           |
| Data-EnvTrajs-MinReturn | 73.6          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 16.6          |
| Data-TimeEnvSampleProc  | 0.00332       |
| Data-TimeEnvSampling    | 2.06          |
| Iteration               | 45            |
| ItrTime                 | 37            |
| LossAfter               | -0.003837135  |
| LossBefore              | -7.883143e-06 |
| Model-TimeModelFit      | 32.1          |
| ModelSampler-n_times... | 1840000       |
| Policy-AverageAbsPol... | 0.5159595     |
| Policy-AverageDiscou... | -1.84e+04     |
| Policy-AveragePolicyStd | 0.5323842     |
| Policy-AverageReturn    | -1.2e+05      |
| Policy-MaxReturn        | -106          |
| Policy-MinReturn        | -9.27e+05     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 2.68e+05      |
| Policy-TimeAlgoOpt      | 0.61          |
| Policy-TimeSampleProc   | 0.451         |
| Policy-TimeSampling     | 1.72          |
| Policy-TimeStep         | 2.81          |
| Time                    | 1.39e+03      |
| n_timesteps             | 46000         |
-------------------------------------------

 ---------------- Iteration 46 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 460 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 461 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 462 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 463 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 464 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 465 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 466 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 467 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 468 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 469 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.568          |
| Data-EnvSampler-Poli... | 1.03           |
| Data-EnvTrajs-Averag... | 56             |
| Data-EnvTrajs-MaxReturn | 66.2           |
| Data-EnvTrajs-MinReturn | 40.2           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 9.65           |
| Data-TimeEnvSampleProc  | 0.00102        |
| Data-TimeEnvSampling    | 1.64           |
| Iteration               | 46             |
| ItrTime                 | 38.4           |
| LossAfter               | -0.0037187366  |
| LossBefore              | -7.8108715e-06 |
| Model-TimeModelFit      | 34             |
| ModelSampler-n_times... | 1880000        |
| Policy-AverageAbsPol... | 0.59311026     |
| Policy-AverageDiscou... | -82.6          |
| Policy-AveragePolicyStd | 0.5280978      |
| Policy-AverageReturn    | -483           |
| Policy-MaxReturn        | 38.1           |
| Policy-MinReturn        | -963           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 186            |
| Policy-TimeAlgoOpt      | 0.623          |
| Policy-TimeSampleProc   | 0.384          |
| Policy-TimeSampling     | 1.73           |
| Policy-TimeStep         | 2.76           |
| Time                    | 1.42e+03       |
| n_timesteps             | 47000          |
--------------------------------------------

 ---------------- Iteration 47 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 470 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 471 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 472 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 473 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 474 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 475 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 476 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 477 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 478 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 479 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.458         |
| Data-EnvSampler-Poli... | 0.875         |
| Data-EnvTrajs-Averag... | 64.3          |
| Data-EnvTrajs-MaxReturn | 75.6          |
| Data-EnvTrajs-MinReturn | 53.7          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 8.98          |
| Data-TimeEnvSampleProc  | 0.000706      |
| Data-TimeEnvSampling    | 1.39          |
| Iteration               | 47            |
| ItrTime                 | 37.6          |
| LossAfter               | -0.0063742073 |
| LossBefore              | -7.702393e-06 |
| Model-TimeModelFit      | 33.6          |
| ModelSampler-n_times... | 1920000       |
| Policy-AverageAbsPol... | 0.6203994     |
| Policy-AverageDiscou... | -1.95e+04     |
| Policy-AveragePolicyStd | 0.5224112     |
| Policy-AverageReturn    | -1.27e+05     |
| Policy-MaxReturn        | 109           |
| Policy-MinReturn        | -1e+06        |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 2.77e+05      |
| Policy-TimeAlgoOpt      | 0.61          |
| Policy-TimeSampleProc   | 0.389         |
| Policy-TimeSampling     | 1.62          |
| Policy-TimeStep         | 2.65          |
| Time                    | 1.46e+03      |
| n_timesteps             | 48000         |
-------------------------------------------

 ---------------- Iteration 48 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 480 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 481 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 482 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 483 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 484 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 485 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 486 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 487 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 488 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 489 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.473         |
| Data-EnvSampler-Poli... | 0.871         |
| Data-EnvTrajs-Averag... | -198          |
| Data-EnvTrajs-MaxReturn | 21.7          |
| Data-EnvTrajs-MinReturn | -270          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 111           |
| Data-TimeEnvSampleProc  | 0.00103       |
| Data-TimeEnvSampling    | 1.38          |
| Iteration               | 48            |
| ItrTime                 | 38.3          |
| LossAfter               | -0.003921735  |
| LossBefore              | -7.520949e-06 |
| Model-TimeModelFit      | 33.9          |
| ModelSampler-n_times... | 1960000       |
| Policy-AverageAbsPol... | 0.5276458     |
| Policy-AverageDiscou... | 5.47          |
| Policy-AveragePolicyStd | 0.51321185    |
| Policy-AverageReturn    | 2.88          |
| Policy-MaxReturn        | 67.4          |
| Policy-MinReturn        | -167          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 60.7          |
| Policy-TimeAlgoOpt      | 0.674         |
| Policy-TimeSampleProc   | 0.463         |
| Policy-TimeSampling     | 1.81          |
| Policy-TimeStep         | 3.01          |
| Time                    | 1.5e+03       |
| n_timesteps             | 49000         |
-------------------------------------------

 ---------------- Iteration 49 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 490 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 491 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 492 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 493 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 494 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 495 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 496 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 497 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 498 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 499 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.5           |
| Data-EnvSampler-Poli... | 0.944         |
| Data-EnvTrajs-Averag... | 68.7          |
| Data-EnvTrajs-MaxReturn | 95.7          |
| Data-EnvTrajs-MinReturn | 5.84          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 32            |
| Data-TimeEnvSampleProc  | 0.00103       |
| Data-TimeEnvSampling    | 1.49          |
| Iteration               | 49            |
| ItrTime                 | 38.1          |
| LossAfter               | -0.004674961  |
| LossBefore              | -7.439124e-06 |
| Model-TimeModelFit      | 33.7          |
| ModelSampler-n_times... | 2000000       |
| Policy-AverageAbsPol... | 0.5565244     |
| Policy-AverageDiscou... | -8.41         |
| Policy-AveragePolicyStd | 0.5096766     |
| Policy-AverageReturn    | -31.5         |
| Policy-MaxReturn        | 22.3          |
| Policy-MinReturn        | -329          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 81.9          |
| Policy-TimeAlgoOpt      | 0.61          |
| Policy-TimeSampleProc   | 0.507         |
| Policy-TimeSampling     | 1.72          |
| Policy-TimeStep         | 2.89          |
| Time                    | 1.54e+03      |
| n_timesteps             | 50000         |
-------------------------------------------

 ---------------- Iteration 50 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 500 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 501 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 502 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 503 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 504 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 505 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 506 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 507 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 508 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 509 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.529          |
| Data-EnvSampler-Poli... | 1.03           |
| Data-EnvTrajs-Averag... | 63.3           |
| Data-EnvTrajs-MaxReturn | 91.9           |
| Data-EnvTrajs-MinReturn | -5.24          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 35.9           |
| Data-TimeEnvSampleProc  | 0.00128        |
| Data-TimeEnvSampling    | 1.61           |
| Iteration               | 50             |
| ItrTime                 | 30.8           |
| LossAfter               | -0.0043803663  |
| LossBefore              | -7.2516777e-06 |
| Model-TimeModelFit      | 26.8           |
| ModelSampler-n_times... | 2040000        |
| Policy-AverageAbsPol... | 0.5822602      |
| Policy-AverageDiscou... | -2.89e+04      |
| Policy-AveragePolicyStd | 0.49889055     |
| Policy-AverageReturn    | -1.32e+05      |
| Policy-MaxReturn        | 30.3           |
| Policy-MinReturn        | -2.63e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 5.73e+05       |
| Policy-TimeAlgoOpt      | 0.631          |
| Policy-TimeSampleProc   | 0.33           |
| Policy-TimeSampling     | 1.47           |
| Policy-TimeStep         | 2.45           |
| Time                    | 1.57e+03       |
| n_timesteps             | 51000          |
--------------------------------------------
Training finished
