Logging to /home/vincent/workplace/CS_287_-_Advanced_Robotics/homework/hw5/cs287hw5/ppo/run_scripts/data/parallel_mb_ppo/mbppo_Hopper_l2_no_square//00

 ---------------- Iteration 0 ----------------
Obtaining random samples from the environment...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 0 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 1 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 2 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 3 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 4 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 5 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 6 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 7 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 8 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 9 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.282          |
| Data-EnvSampler-Poli... | 0.0615         |
| Data-EnvTrajs-Averag... | -261           |
| Data-EnvTrajs-MaxReturn | -174           |
| Data-EnvTrajs-MinReturn | -334           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 65.7           |
| Data-TimeEnvSampleProc  | 0.000727       |
| Data-TimeEnvSampling    | 0.36           |
| Iteration               | 0              |
| ItrTime                 | 13.3           |
| LossAfter               | -0.0054018633  |
| LossBefore              | -1.3832721e-05 |
| Model-TimeModelFit      | 4.5            |
| ModelSampler-n_times... | 40000          |
| Policy-AverageAbsPol... | 0.46060058     |
| Policy-AverageDiscou... | -2.09e+06      |
| Policy-AveragePolicyStd | 0.96554536     |
| Policy-AverageReturn    | -5.38e+06      |
| Policy-MaxReturn        | -5.33e+06      |
| Policy-MinReturn        | -5.45e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.56e+04       |
| Policy-TimeAlgoOpt      | 1.39           |
| Policy-TimeSampleProc   | 0.547          |
| Policy-TimeSampling     | 6.47           |
| Policy-TimeStep         | 8.45           |
| Time                    | 13.3           |
| n_timesteps             | 1000           |
--------------------------------------------

 ---------------- Iteration 1 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 10 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 11 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 12 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 13 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 14 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 15 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 16 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 17 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 18 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 19 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.385         |
| Data-EnvSampler-Poli... | 0.752         |
| Data-EnvTrajs-Averag... | 47.8          |
| Data-EnvTrajs-MaxReturn | 171           |
| Data-EnvTrajs-MinReturn | -47.6         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 72.5          |
| Data-TimeEnvSampleProc  | 0.000732      |
| Data-TimeEnvSampling    | 1.16          |
| Iteration               | 1             |
| ItrTime                 | 9             |
| LossAfter               | -0.0035864846 |
| LossBefore              | -1.36003e-05  |
| Model-TimeModelFit      | 5.25          |
| ModelSampler-n_times... | 80000         |
| Policy-AverageAbsPol... | 0.48836133    |
| Policy-AverageDiscou... | -1.12e+06     |
| Policy-AveragePolicyStd | 0.9432293     |
| Policy-AverageReturn    | -3.82e+06     |
| Policy-MaxReturn        | -7.16e+05     |
| Policy-MinReturn        | -5e+06        |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 8.76e+05      |
| Policy-TimeAlgoOpt      | 0.509         |
| Policy-TimeSampleProc   | 0.523         |
| Policy-TimeSampling     | 1.51          |
| Policy-TimeStep         | 2.59          |
| Time                    | 22.6          |
| n_timesteps             | 2000          |
-------------------------------------------

 ---------------- Iteration 2 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 20 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 21 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 22 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 23 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 24 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 25 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 26 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 27 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 28 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 29 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.326           |
| Data-EnvSampler-Poli... | 0.428           |
| Data-EnvTrajs-Averag... | -12.6           |
| Data-EnvTrajs-MaxReturn | 134             |
| Data-EnvTrajs-MinReturn | -101            |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 99.4            |
| Data-TimeEnvSampleProc  | 0.000549        |
| Data-TimeEnvSampling    | 0.776           |
| Iteration               | 2               |
| ItrTime                 | 9.2             |
| LossAfter               | -0.0047882874   |
| LossBefore              | -1.35544215e-05 |
| Model-TimeModelFit      | 5.77            |
| ModelSampler-n_times... | 120000          |
| Policy-AverageAbsPol... | 0.879525        |
| Policy-AverageDiscou... | -1.58e+06       |
| Policy-AveragePolicyStd | 0.9385565       |
| Policy-AverageReturn    | -4.53e+06       |
| Policy-MaxReturn        | -8.99e+05       |
| Policy-MinReturn        | -5.19e+06       |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 1.11e+06        |
| Policy-TimeAlgoOpt      | 0.539           |
| Policy-TimeSampleProc   | 0.508           |
| Policy-TimeSampling     | 1.56            |
| Policy-TimeStep         | 2.64            |
| Time                    | 31.8            |
| n_timesteps             | 3000            |
---------------------------------------------

 ---------------- Iteration 3 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 30 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 31 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 32 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 33 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 34 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 35 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 36 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 37 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 38 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 39 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.317          |
| Data-EnvSampler-Poli... | 0.459          |
| Data-EnvTrajs-Averag... | -375           |
| Data-EnvTrajs-MaxReturn | -320           |
| Data-EnvTrajs-MinReturn | -409           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 36             |
| Data-TimeEnvSampleProc  | 0.000532       |
| Data-TimeEnvSampling    | 0.801          |
| Iteration               | 3              |
| ItrTime                 | 11.3           |
| LossAfter               | -0.005707122   |
| LossBefore              | -1.3424636e-05 |
| Model-TimeModelFit      | 7.81           |
| ModelSampler-n_times... | 160000         |
| Policy-AverageAbsPol... | 0.7913075      |
| Policy-AverageDiscou... | -1.02e+06      |
| Policy-AveragePolicyStd | 0.9257736      |
| Policy-AverageReturn    | -3.39e+06      |
| Policy-MaxReturn        | -263           |
| Policy-MinReturn        | -4.96e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.46e+06       |
| Policy-TimeAlgoOpt      | 0.547          |
| Policy-TimeSampleProc   | 0.571          |
| Policy-TimeSampling     | 1.54           |
| Policy-TimeStep         | 2.7            |
| Time                    | 43.2           |
| n_timesteps             | 4000           |
--------------------------------------------

 ---------------- Iteration 4 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 40 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 41 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 42 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 43 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 44 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 45 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 46 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 47 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 48 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 49 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.334         |
| Data-EnvSampler-Poli... | 0.529         |
| Data-EnvTrajs-Averag... | -361          |
| Data-EnvTrajs-MaxReturn | -167          |
| Data-EnvTrajs-MinReturn | -494          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 109           |
| Data-TimeEnvSampleProc  | 0.000607      |
| Data-TimeEnvSampling    | 0.886         |
| Iteration               | 4             |
| ItrTime                 | 19.9          |
| LossAfter               | -0.004238476  |
| LossBefore              | -1.324779e-05 |
| Model-TimeModelFit      | 15            |
| ModelSampler-n_times... | 200000        |
| Policy-AverageAbsPol... | 0.8343073     |
| Policy-AverageDiscou... | -1.74e+06     |
| Policy-AveragePolicyStd | 0.9096366     |
| Policy-AverageReturn    | -4.92e+06     |
| Policy-MaxReturn        | -4.56e+06     |
| Policy-MinReturn        | -5.06e+06     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.28e+05      |
| Policy-TimeAlgoOpt      | 0.887         |
| Policy-TimeSampleProc   | 0.594         |
| Policy-TimeSampling     | 2.48          |
| Policy-TimeStep         | 3.98          |
| Time                    | 63.1          |
| n_timesteps             | 5000          |
-------------------------------------------

 ---------------- Iteration 5 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 50 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 51 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 52 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 53 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 54 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 55 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 56 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 57 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 58 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 59 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.421         |
| Data-EnvSampler-Poli... | 0.594         |
| Data-EnvTrajs-Averag... | 108           |
| Data-EnvTrajs-MaxReturn | 293           |
| Data-EnvTrajs-MinReturn | -63.4         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 134           |
| Data-TimeEnvSampleProc  | 0.000763      |
| Data-TimeEnvSampling    | 1.05          |
| Iteration               | 5             |
| ItrTime                 | 17.2          |
| LossAfter               | -0.00795449   |
| LossBefore              | -1.310397e-05 |
| Model-TimeModelFit      | 13.6          |
| ModelSampler-n_times... | 240000        |
| Policy-AverageAbsPol... | 0.63089395    |
| Policy-AverageDiscou... | -1.02e+05     |
| Policy-AveragePolicyStd | 0.89714617    |
| Policy-AverageReturn    | -4.1e+05      |
| Policy-MaxReturn        | -616          |
| Policy-MinReturn        | -4.48e+06     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1e+06         |
| Policy-TimeAlgoOpt      | 0.556         |
| Policy-TimeSampleProc   | 0.349         |
| Policy-TimeSampling     | 1.64          |
| Policy-TimeStep         | 2.6           |
| Time                    | 80.3          |
| n_timesteps             | 6000          |
-------------------------------------------

 ---------------- Iteration 6 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 60 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 61 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 62 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 63 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 64 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 65 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 66 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 67 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 68 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 69 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.306          |
| Data-EnvSampler-Poli... | 0.404          |
| Data-EnvTrajs-Averag... | -158           |
| Data-EnvTrajs-MaxReturn | -151           |
| Data-EnvTrajs-MinReturn | -175           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 9.02           |
| Data-TimeEnvSampleProc  | 0.000547       |
| Data-TimeEnvSampling    | 0.731          |
| Iteration               | 6              |
| ItrTime                 | 17.1           |
| LossAfter               | -0.007369725   |
| LossBefore              | -1.3073385e-05 |
| Model-TimeModelFit      | 13.7           |
| ModelSampler-n_times... | 280000         |
| Policy-AverageAbsPol... | 0.58907676     |
| Policy-AverageDiscou... | -1.46e+05      |
| Policy-AveragePolicyStd | 0.8947404      |
| Policy-AverageReturn    | -4.52e+05      |
| Policy-MaxReturn        | -452           |
| Policy-MinReturn        | -4.59e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.35e+06       |
| Policy-TimeAlgoOpt      | 0.491          |
| Policy-TimeSampleProc   | 0.68           |
| Policy-TimeSampling     | 1.51           |
| Policy-TimeStep         | 2.72           |
| Time                    | 97.5           |
| n_timesteps             | 7000           |
--------------------------------------------

 ---------------- Iteration 7 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 70 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 71 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 72 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 73 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 74 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 75 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 76 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 77 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 78 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 79 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.338          |
| Data-EnvSampler-Poli... | 0.486          |
| Data-EnvTrajs-Averag... | -177           |
| Data-EnvTrajs-MaxReturn | -161           |
| Data-EnvTrajs-MinReturn | -194           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 11.9           |
| Data-TimeEnvSampleProc  | 0.000935       |
| Data-TimeEnvSampling    | 0.847          |
| Iteration               | 7              |
| ItrTime                 | 29.6           |
| LossAfter               | -0.005727677   |
| LossBefore              | -1.3000377e-05 |
| Model-TimeModelFit      | 25             |
| ModelSampler-n_times... | 320000         |
| Policy-AverageAbsPol... | 0.8594539      |
| Policy-AverageDiscou... | -1.55e+06      |
| Policy-AveragePolicyStd | 0.88807464     |
| Policy-AverageReturn    | -4.65e+06      |
| Policy-MaxReturn        | -4.53e+06      |
| Policy-MinReturn        | -4.75e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 5.66e+04       |
| Policy-TimeAlgoOpt      | 0.735          |
| Policy-TimeSampleProc   | 0.689          |
| Policy-TimeSampling     | 2.24           |
| Policy-TimeStep         | 3.7            |
| Time                    | 127            |
| n_timesteps             | 8000           |
--------------------------------------------

 ---------------- Iteration 8 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 80 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 81 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 82 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 83 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 84 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 85 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 86 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 87 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 88 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 89 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.513           |
| Data-EnvSampler-Poli... | 0.699           |
| Data-EnvTrajs-Averag... | -128            |
| Data-EnvTrajs-MaxReturn | -121            |
| Data-EnvTrajs-MinReturn | -134            |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 4.49            |
| Data-TimeEnvSampleProc  | 0.000877        |
| Data-TimeEnvSampling    | 1.26            |
| Iteration               | 8               |
| ItrTime                 | 22.9            |
| LossAfter               | -0.0038444973   |
| LossBefore              | -1.27411895e-05 |
| Model-TimeModelFit      | 18.9            |
| ModelSampler-n_times... | 360000          |
| Policy-AverageAbsPol... | 0.7323219       |
| Policy-AverageDiscou... | -2.06e+05       |
| Policy-AveragePolicyStd | 0.8669476       |
| Policy-AverageReturn    | -7.44e+05       |
| Policy-MaxReturn        | -536            |
| Policy-MinReturn        | -4.07e+06       |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 1.49e+06        |
| Policy-TimeAlgoOpt      | 0.583           |
| Policy-TimeSampleProc   | 0.403           |
| Policy-TimeSampling     | 1.75            |
| Policy-TimeStep         | 2.78            |
| Time                    | 150             |
| n_timesteps             | 9000            |
---------------------------------------------

 ---------------- Iteration 9 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 90 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 91 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 92 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 93 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 94 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 95 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 96 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 97 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 98 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 99 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.333          |
| Data-EnvSampler-Poli... | 0.458          |
| Data-EnvTrajs-Averag... | -110           |
| Data-EnvTrajs-MaxReturn | -104           |
| Data-EnvTrajs-MinReturn | -116           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 4.89           |
| Data-TimeEnvSampleProc  | 0.000756       |
| Data-TimeEnvSampling    | 0.814          |
| Iteration               | 9              |
| ItrTime                 | 30.1           |
| LossAfter               | -0.010943884   |
| LossBefore              | -1.2544111e-05 |
| Model-TimeModelFit      | 25.3           |
| ModelSampler-n_times... | 400000         |
| Policy-AverageAbsPol... | 0.6621562      |
| Policy-AverageDiscou... | -185           |
| Policy-AveragePolicyStd | 0.848909       |
| Policy-AverageReturn    | -487           |
| Policy-MaxReturn        | -346           |
| Policy-MinReturn        | -587           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 63.8           |
| Policy-TimeAlgoOpt      | 0.785          |
| Policy-TimeSampleProc   | 0.757          |
| Policy-TimeSampling     | 2.32           |
| Policy-TimeStep         | 3.9            |
| Time                    | 180            |
| n_timesteps             | 10000          |
--------------------------------------------

 ---------------- Iteration 10 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 100 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 101 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 102 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 103 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 104 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 105 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 106 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 107 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 108 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 109 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.509          |
| Data-EnvSampler-Poli... | 0.728          |
| Data-EnvTrajs-Averag... | -100           |
| Data-EnvTrajs-MaxReturn | -97.3          |
| Data-EnvTrajs-MinReturn | -103           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.24           |
| Data-TimeEnvSampleProc  | 0.000781       |
| Data-TimeEnvSampling    | 1.27           |
| Iteration               | 10             |
| ItrTime                 | 27.5           |
| LossAfter               | -0.0070266994  |
| LossBefore              | -1.2454571e-05 |
| Model-TimeModelFit      | 23.8           |
| ModelSampler-n_times... | 440000         |
| Policy-AverageAbsPol... | 0.7599421      |
| Policy-AverageDiscou... | -1.57e+05      |
| Policy-AveragePolicyStd | 0.84257627     |
| Policy-AverageReturn    | -6.29e+05      |
| Policy-MaxReturn        | -544           |
| Policy-MinReturn        | -3.73e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.29e+06       |
| Policy-TimeAlgoOpt      | 0.594          |
| Policy-TimeSampleProc   | 0.425          |
| Policy-TimeSampling     | 1.39           |
| Policy-TimeStep         | 2.45           |
| Time                    | 208            |
| n_timesteps             | 11000          |
--------------------------------------------

 ---------------- Iteration 11 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 110 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 111 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 112 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 113 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 114 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 115 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 116 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 117 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 118 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 119 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.391           |
| Data-EnvSampler-Poli... | 0.619           |
| Data-EnvTrajs-Averag... | -108            |
| Data-EnvTrajs-MaxReturn | -65.1           |
| Data-EnvTrajs-MinReturn | -144            |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 28.4            |
| Data-TimeEnvSampleProc  | 0.000764        |
| Data-TimeEnvSampling    | 1.04            |
| Iteration               | 11              |
| ItrTime                 | 36              |
| LossAfter               | -0.0066866083   |
| LossBefore              | -1.22734245e-05 |
| Model-TimeModelFit      | 31.4            |
| ModelSampler-n_times... | 480000          |
| Policy-AverageAbsPol... | 0.7194085       |
| Policy-AverageDiscou... | -2.9e+03        |
| Policy-AveragePolicyStd | 0.8262737       |
| Policy-AverageReturn    | -1.94e+04       |
| Policy-MaxReturn        | -161            |
| Policy-MinReturn        | -3.73e+05       |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 8.12e+04        |
| Policy-TimeAlgoOpt      | 0.677           |
| Policy-TimeSampleProc   | 0.756           |
| Policy-TimeSampling     | 2.07            |
| Policy-TimeStep         | 3.55            |
| Time                    | 244             |
| n_timesteps             | 12000           |
---------------------------------------------

 ---------------- Iteration 12 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 120 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 121 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 122 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 123 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 124 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 125 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 126 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 127 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 128 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 129 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.442          |
| Data-EnvSampler-Poli... | 0.711          |
| Data-EnvTrajs-Averag... | -76            |
| Data-EnvTrajs-MaxReturn | -51.9          |
| Data-EnvTrajs-MinReturn | -108           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 19.9           |
| Data-TimeEnvSampleProc  | 0.000778       |
| Data-TimeEnvSampling    | 1.19           |
| Iteration               | 12             |
| ItrTime                 | 27.7           |
| LossAfter               | -0.005224043   |
| LossBefore              | -1.2153827e-05 |
| Model-TimeModelFit      | 23.6           |
| ModelSampler-n_times... | 520000         |
| Policy-AverageAbsPol... | 1.5295371      |
| Policy-AverageDiscou... | -1.2e+06       |
| Policy-AveragePolicyStd | 0.81901157     |
| Policy-AverageReturn    | -4.08e+06      |
| Policy-MaxReturn        | -3.99e+06      |
| Policy-MinReturn        | -4.16e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 4.68e+04       |
| Policy-TimeAlgoOpt      | 0.62           |
| Policy-TimeSampleProc   | 0.629          |
| Policy-TimeSampling     | 1.66           |
| Policy-TimeStep         | 2.93           |
| Time                    | 271            |
| n_timesteps             | 13000          |
--------------------------------------------

 ---------------- Iteration 13 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 130 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 131 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 132 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 133 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 134 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 135 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 136 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 137 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 138 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 139 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.773          |
| Data-EnvSampler-Poli... | 1.14           |
| Data-EnvTrajs-Averag... | 73.6           |
| Data-EnvTrajs-MaxReturn | 123            |
| Data-EnvTrajs-MinReturn | -2.81          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 41.8           |
| Data-TimeEnvSampleProc  | 0.00117        |
| Data-TimeEnvSampling    | 1.97           |
| Iteration               | 13             |
| ItrTime                 | 36.2           |
| LossAfter               | -0.005850944   |
| LossBefore              | -1.2084575e-05 |
| Model-TimeModelFit      | 31.8           |
| ModelSampler-n_times... | 560000         |
| Policy-AverageAbsPol... | 0.7493618      |
| Policy-AverageDiscou... | -1.82e+04      |
| Policy-AveragePolicyStd | 0.81285083     |
| Policy-AverageReturn    | -1.11e+05      |
| Policy-MaxReturn        | 241            |
| Policy-MinReturn        | -1.35e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 3.28e+05       |
| Policy-TimeAlgoOpt      | 0.593          |
| Policy-TimeSampleProc   | 0.366          |
| Policy-TimeSampling     | 1.45           |
| Policy-TimeStep         | 2.45           |
| Time                    | 307            |
| n_timesteps             | 14000          |
--------------------------------------------

 ---------------- Iteration 14 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 140 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 141 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 142 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 143 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 144 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 145 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 146 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 147 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 148 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 149 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.438          |
| Data-EnvSampler-Poli... | 0.751          |
| Data-EnvTrajs-Averag... | 113            |
| Data-EnvTrajs-MaxReturn | 223            |
| Data-EnvTrajs-MinReturn | 62.9           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 60             |
| Data-TimeEnvSampleProc  | 0.000751       |
| Data-TimeEnvSampling    | 1.22           |
| Iteration               | 14             |
| ItrTime                 | 36.4           |
| LossAfter               | -0.006810409   |
| LossBefore              | -1.1931512e-05 |
| Model-TimeModelFit      | 31.3           |
| ModelSampler-n_times... | 600000         |
| Policy-AverageAbsPol... | 1.2743791      |
| Policy-AverageDiscou... | -5.72e+05      |
| Policy-AveragePolicyStd | 0.79904604     |
| Policy-AverageReturn    | -2.6e+06       |
| Policy-MaxReturn        | -2.07e+06      |
| Policy-MinReturn        | -3.03e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.3e+05        |
| Policy-TimeAlgoOpt      | 0.875          |
| Policy-TimeSampleProc   | 0.486          |
| Policy-TimeSampling     | 2.43           |
| Policy-TimeStep         | 3.83           |
| Time                    | 344            |
| n_timesteps             | 15000          |
--------------------------------------------

 ---------------- Iteration 15 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 150 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 151 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 152 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 153 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 154 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 155 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 156 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 157 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 158 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 159 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.703          |
| Data-EnvSampler-Poli... | 1.16           |
| Data-EnvTrajs-Averag... | 266            |
| Data-EnvTrajs-MaxReturn | 348            |
| Data-EnvTrajs-MinReturn | 130            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 79.8           |
| Data-TimeEnvSampleProc  | 0.00171        |
| Data-TimeEnvSampling    | 1.91           |
| Iteration               | 15             |
| ItrTime                 | 31.1           |
| LossAfter               | -0.004474443   |
| LossBefore              | -1.1836309e-05 |
| Model-TimeModelFit      | 26.9           |
| ModelSampler-n_times... | 640000         |
| Policy-AverageAbsPol... | 0.69295233     |
| Policy-AverageDiscou... | 20.1           |
| Policy-AveragePolicyStd | 0.7924722      |
| Policy-AverageReturn    | 98.8           |
| Policy-MaxReturn        | 164            |
| Policy-MinReturn        | -11.1          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 39.8           |
| Policy-TimeAlgoOpt      | 0.496          |
| Policy-TimeSampleProc   | 0.418          |
| Policy-TimeSampling     | 1.33           |
| Policy-TimeStep         | 2.3            |
| Time                    | 375            |
| n_timesteps             | 16000          |
--------------------------------------------

 ---------------- Iteration 16 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 160 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 161 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 162 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 163 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 164 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 165 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 166 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 167 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 168 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 169 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.505           |
| Data-EnvSampler-Poli... | 1.1             |
| Data-EnvTrajs-Averag... | 298             |
| Data-EnvTrajs-MaxReturn | 348             |
| Data-EnvTrajs-MinReturn | 256             |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 31.9            |
| Data-TimeEnvSampleProc  | 0.000944        |
| Data-TimeEnvSampling    | 1.65            |
| Iteration               | 16              |
| ItrTime                 | 38.3            |
| LossAfter               | -0.006496431    |
| LossBefore              | -1.18094395e-05 |
| Model-TimeModelFit      | 34.4            |
| ModelSampler-n_times... | 680000          |
| Policy-AverageAbsPol... | 0.8122235       |
| Policy-AverageDiscou... | -43.1           |
| Policy-AveragePolicyStd | 0.79119956      |
| Policy-AverageReturn    | -633            |
| Policy-MaxReturn        | 398             |
| Policy-MinReturn        | -1.73e+04       |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 3.82e+03        |
| Policy-TimeAlgoOpt      | 0.535           |
| Policy-TimeSampleProc   | 0.321           |
| Policy-TimeSampling     | 1.33            |
| Policy-TimeStep         | 2.23            |
| Time                    | 413             |
| n_timesteps             | 17000           |
---------------------------------------------

 ---------------- Iteration 17 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 170 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 171 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 172 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 173 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 174 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 175 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 176 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 177 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 178 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 179 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.465          |
| Data-EnvSampler-Poli... | 0.867          |
| Data-EnvTrajs-Averag... | 223            |
| Data-EnvTrajs-MaxReturn | 320            |
| Data-EnvTrajs-MinReturn | 133            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 72.3           |
| Data-TimeEnvSampleProc  | 0.000798       |
| Data-TimeEnvSampling    | 1.37           |
| Iteration               | 17             |
| ItrTime                 | 33.4           |
| LossAfter               | -0.006289568   |
| LossBefore              | -1.1684871e-05 |
| Model-TimeModelFit      | 27.9           |
| ModelSampler-n_times... | 720000         |
| Policy-AverageAbsPol... | 0.75290185     |
| Policy-AverageDiscou... | -716           |
| Policy-AveragePolicyStd | 0.78222364     |
| Policy-AverageReturn    | -5.24e+03      |
| Policy-MaxReturn        | 20.4           |
| Policy-MinReturn        | -6.58e+04      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.44e+04       |
| Policy-TimeAlgoOpt      | 0.821          |
| Policy-TimeSampleProc   | 0.68           |
| Policy-TimeSampling     | 2.57           |
| Policy-TimeStep         | 4.09           |
| Time                    | 447            |
| n_timesteps             | 18000          |
--------------------------------------------

 ---------------- Iteration 18 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 180 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 181 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 182 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 183 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 184 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 185 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 186 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 187 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 188 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 189 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.703          |
| Data-EnvSampler-Poli... | 1.19           |
| Data-EnvTrajs-Averag... | 277            |
| Data-EnvTrajs-MaxReturn | 332            |
| Data-EnvTrajs-MinReturn | 204            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 47.1           |
| Data-TimeEnvSampleProc  | 0.00117        |
| Data-TimeEnvSampling    | 1.95           |
| Iteration               | 18             |
| ItrTime                 | 32.4           |
| LossAfter               | -0.007820719   |
| LossBefore              | -1.1589672e-05 |
| Model-TimeModelFit      | 28.1           |
| ModelSampler-n_times... | 760000         |
| Policy-AverageAbsPol... | 1.1192813      |
| Policy-AverageDiscou... | -1.56e+04      |
| Policy-AveragePolicyStd | 0.7738224      |
| Policy-AverageReturn    | -8.5e+04       |
| Policy-MaxReturn        | 203            |
| Policy-MinReturn        | -1.7e+06       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 3.71e+05       |
| Policy-TimeAlgoOpt      | 0.514          |
| Policy-TimeSampleProc   | 0.349          |
| Policy-TimeSampling     | 1.38           |
| Policy-TimeStep         | 2.3            |
| Time                    | 479            |
| n_timesteps             | 19000          |
--------------------------------------------

 ---------------- Iteration 19 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 190 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 191 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 192 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 193 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 194 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 195 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 196 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 197 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 198 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 199 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.482          |
| Data-EnvSampler-Poli... | 0.826          |
| Data-EnvTrajs-Averag... | 244            |
| Data-EnvTrajs-MaxReturn | 314            |
| Data-EnvTrajs-MinReturn | 163            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 53.9           |
| Data-TimeEnvSampleProc  | 0.000961       |
| Data-TimeEnvSampling    | 1.35           |
| Iteration               | 19             |
| ItrTime                 | 38.3           |
| LossAfter               | -0.006021115   |
| LossBefore              | -1.1600168e-05 |
| Model-TimeModelFit      | 34.6           |
| ModelSampler-n_times... | 800000         |
| Policy-AverageAbsPol... | 1.0979338      |
| Policy-AverageDiscou... | -75.8          |
| Policy-AveragePolicyStd | 0.77636003     |
| Policy-AverageReturn    | -551           |
| Policy-MaxReturn        | 228            |
| Policy-MinReturn        | -6.93e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.82e+03       |
| Policy-TimeAlgoOpt      | 0.495          |
| Policy-TimeSampleProc   | 0.359          |
| Policy-TimeSampling     | 1.36           |
| Policy-TimeStep         | 2.3            |
| Time                    | 517            |
| n_timesteps             | 20000          |
--------------------------------------------

 ---------------- Iteration 20 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 200 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 201 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 202 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 203 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 204 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 205 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 206 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 207 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 208 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 209 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.433          |
| Data-EnvSampler-Poli... | 0.795          |
| Data-EnvTrajs-Averag... | 290            |
| Data-EnvTrajs-MaxReturn | 344            |
| Data-EnvTrajs-MinReturn | 199            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 50.7           |
| Data-TimeEnvSampleProc  | 0.00109        |
| Data-TimeEnvSampling    | 1.26           |
| Iteration               | 20             |
| ItrTime                 | 33.3           |
| LossAfter               | -0.00046225314 |
| LossBefore              | -1.1289936e-05 |
| Model-TimeModelFit      | 28             |
| ModelSampler-n_times... | 840000         |
| Policy-AverageAbsPol... | 1.0127598      |
| Policy-AverageDiscou... | 97.1           |
| Policy-AveragePolicyStd | 0.75231713     |
| Policy-AverageReturn    | 225            |
| Policy-MaxReturn        | 452            |
| Policy-MinReturn        | -2.29e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 578            |
| Policy-TimeAlgoOpt      | 0.765          |
| Policy-TimeSampleProc   | 0.758          |
| Policy-TimeSampling     | 2.4            |
| Policy-TimeStep         | 3.99           |
| Time                    | 551            |
| n_timesteps             | 21000          |
--------------------------------------------

 ---------------- Iteration 21 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 210 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 211 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 212 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 213 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 214 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 215 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 216 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 217 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 218 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 219 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.703          |
| Data-EnvSampler-Poli... | 1.31           |
| Data-EnvTrajs-Averag... | 289            |
| Data-EnvTrajs-MaxReturn | 340            |
| Data-EnvTrajs-MinReturn | 232            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 39.1           |
| Data-TimeEnvSampleProc  | 0.00126        |
| Data-TimeEnvSampling    | 2.07           |
| Iteration               | 21             |
| ItrTime                 | 32.5           |
| LossAfter               | -0.0034213846  |
| LossBefore              | -1.1163973e-05 |
| Model-TimeModelFit      | 28.1           |
| ModelSampler-n_times... | 880000         |
| Policy-AverageAbsPol... | 1.1071451      |
| Policy-AverageDiscou... | 47.1           |
| Policy-AveragePolicyStd | 0.74303484     |
| Policy-AverageReturn    | 145            |
| Policy-MaxReturn        | 255            |
| Policy-MinReturn        | -407           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 134            |
| Policy-TimeAlgoOpt      | 0.587          |
| Policy-TimeSampleProc   | 0.324          |
| Policy-TimeSampling     | 1.38           |
| Policy-TimeStep         | 2.31           |
| Time                    | 583            |
| n_timesteps             | 22000          |
--------------------------------------------

 ---------------- Iteration 22 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 220 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 221 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 222 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 223 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 224 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 225 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 226 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 227 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 228 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 229 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.417          |
| Data-EnvSampler-Poli... | 0.808          |
| Data-EnvTrajs-Averag... | 308            |
| Data-EnvTrajs-MaxReturn | 334            |
| Data-EnvTrajs-MinReturn | 282            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 18.8           |
| Data-TimeEnvSampleProc  | 0.000919       |
| Data-TimeEnvSampling    | 1.26           |
| Iteration               | 22             |
| ItrTime                 | 41.3           |
| LossAfter               | -0.002764631   |
| LossBefore              | -1.0998457e-05 |
| Model-TimeModelFit      | 37             |
| ModelSampler-n_times... | 920000         |
| Policy-AverageAbsPol... | 0.9651586      |
| Policy-AverageDiscou... | 53.7           |
| Policy-AveragePolicyStd | 0.7310227      |
| Policy-AverageReturn    | 116            |
| Policy-MaxReturn        | 197            |
| Policy-MinReturn        | 45.1           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 37.7           |
| Policy-TimeAlgoOpt      | 0.689          |
| Policy-TimeSampleProc   | 0.464          |
| Policy-TimeSampling     | 1.92           |
| Policy-TimeStep         | 3.11           |
| Time                    | 625            |
| n_timesteps             | 23000          |
--------------------------------------------

 ---------------- Iteration 23 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 230 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 231 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 232 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 233 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 234 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 235 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 236 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 237 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 238 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 239 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.396          |
| Data-EnvSampler-Poli... | 0.812          |
| Data-EnvTrajs-Averag... | 210            |
| Data-EnvTrajs-MaxReturn | 265            |
| Data-EnvTrajs-MinReturn | 140            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 41.4           |
| Data-TimeEnvSampleProc  | 0.000852       |
| Data-TimeEnvSampling    | 1.24           |
| Iteration               | 23             |
| ItrTime                 | 30.4           |
| LossAfter               | -0.0051738266  |
| LossBefore              | -1.0802293e-05 |
| Model-TimeModelFit      | 25.4           |
| ModelSampler-n_times... | 960000         |
| Policy-AverageAbsPol... | 0.8727922      |
| Policy-AverageDiscou... | 104            |
| Policy-AveragePolicyStd | 0.7186872      |
| Policy-AverageReturn    | 232            |
| Policy-MaxReturn        | 284            |
| Policy-MinReturn        | 176            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 31.4           |
| Policy-TimeAlgoOpt      | 0.786          |
| Policy-TimeSampleProc   | 0.655          |
| Policy-TimeSampling     | 2.22           |
| Policy-TimeStep         | 3.7            |
| Time                    | 655            |
| n_timesteps             | 24000          |
--------------------------------------------

 ---------------- Iteration 24 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 240 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 241 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 242 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 243 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 244 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 245 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 246 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 247 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 248 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 249 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.688         |
| Data-EnvSampler-Poli... | 1.22          |
| Data-EnvTrajs-Averag... | 168           |
| Data-EnvTrajs-MaxReturn | 222           |
| Data-EnvTrajs-MinReturn | 111           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 36.8          |
| Data-TimeEnvSampleProc  | 0.00153       |
| Data-TimeEnvSampling    | 1.96          |
| Iteration               | 24            |
| ItrTime                 | 45.6          |
| LossAfter               | -0.0054422687 |
| LossBefore              | -1.066728e-05 |
| Model-TimeModelFit      | 40.8          |
| ModelSampler-n_times... | 1000000       |
| Policy-AverageAbsPol... | 0.8503249     |
| Policy-AverageDiscou... | 94.4          |
| Policy-AveragePolicyStd | 0.7045309     |
| Policy-AverageReturn    | 203           |
| Policy-MaxReturn        | 252           |
| Policy-MinReturn        | 63.8          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 49.3          |
| Policy-TimeAlgoOpt      | 0.649         |
| Policy-TimeSampleProc   | 0.339         |
| Policy-TimeSampling     | 1.89          |
| Policy-TimeStep         | 2.91          |
| Time                    | 701           |
| n_timesteps             | 25000         |
-------------------------------------------

 ---------------- Iteration 25 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 250 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 251 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 252 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 253 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 254 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 255 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 256 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 257 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 258 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 259 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.4            |
| Data-EnvSampler-Poli... | 0.78           |
| Data-EnvTrajs-Averag... | 264            |
| Data-EnvTrajs-MaxReturn | 291            |
| Data-EnvTrajs-MinReturn | 235            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 21.4           |
| Data-TimeEnvSampleProc  | 0.000851       |
| Data-TimeEnvSampling    | 1.21           |
| Iteration               | 25             |
| ItrTime                 | 31.2           |
| LossAfter               | -0.0039732424  |
| LossBefore              | -1.0280534e-05 |
| Model-TimeModelFit      | 25.9           |
| ModelSampler-n_times... | 1040000        |
| Policy-AverageAbsPol... | 0.6334003      |
| Policy-AverageDiscou... | 102            |
| Policy-AveragePolicyStd | 0.6804946      |
| Policy-AverageReturn    | 194            |
| Policy-MaxReturn        | 236            |
| Policy-MinReturn        | 135            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 25.3           |
| Policy-TimeAlgoOpt      | 0.784          |
| Policy-TimeSampleProc   | 0.754          |
| Policy-TimeSampling     | 2.52           |
| Policy-TimeStep         | 4.08           |
| Time                    | 732            |
| n_timesteps             | 26000          |
--------------------------------------------

 ---------------- Iteration 26 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 260 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 261 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 262 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 263 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 264 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 265 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 266 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 267 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 268 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 269 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.724          |
| Data-EnvSampler-Poli... | 1.29           |
| Data-EnvTrajs-Averag... | 275            |
| Data-EnvTrajs-MaxReturn | 339            |
| Data-EnvTrajs-MinReturn | 220            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 38.4           |
| Data-TimeEnvSampleProc  | 0.00168        |
| Data-TimeEnvSampling    | 2.07           |
| Iteration               | 26             |
| ItrTime                 | 39.3           |
| LossAfter               | -0.004120472   |
| LossBefore              | -1.0118772e-05 |
| Model-TimeModelFit      | 35             |
| ModelSampler-n_times... | 1080000        |
| Policy-AverageAbsPol... | 0.66567934     |
| Policy-AverageDiscou... | 131            |
| Policy-AveragePolicyStd | 0.6697566      |
| Policy-AverageReturn    | 275            |
| Policy-MaxReturn        | 327            |
| Policy-MinReturn        | 109            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 53.9           |
| Policy-TimeAlgoOpt      | 0.503          |
| Policy-TimeSampleProc   | 0.287          |
| Policy-TimeSampling     | 1.48           |
| Policy-TimeStep         | 2.28           |
| Time                    | 771            |
| n_timesteps             | 27000          |
--------------------------------------------

 ---------------- Iteration 27 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 270 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 271 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 272 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 273 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 274 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 275 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 276 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 277 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 278 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 279 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.429         |
| Data-EnvSampler-Poli... | 0.791         |
| Data-EnvTrajs-Averag... | 322           |
| Data-EnvTrajs-MaxReturn | 348           |
| Data-EnvTrajs-MinReturn | 263           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 30.6          |
| Data-TimeEnvSampleProc  | 0.000846      |
| Data-TimeEnvSampling    | 1.26          |
| Iteration               | 27            |
| ItrTime                 | 38            |
| LossAfter               | -0.0022030014 |
| LossBefore              | -9.838591e-06 |
| Model-TimeModelFit      | 32.8          |
| ModelSampler-n_times... | 1120000       |
| Policy-AverageAbsPol... | 0.60623187    |
| Policy-AverageDiscou... | 122           |
| Policy-AveragePolicyStd | 0.65423596    |
| Policy-AverageReturn    | 288           |
| Policy-MaxReturn        | 324           |
| Policy-MinReturn        | 228           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 23.1          |
| Policy-TimeAlgoOpt      | 0.782         |
| Policy-TimeSampleProc   | 0.687         |
| Policy-TimeSampling     | 2.34          |
| Policy-TimeStep         | 3.86          |
| Time                    | 809           |
| n_timesteps             | 28000         |
-------------------------------------------

 ---------------- Iteration 28 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 280 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 281 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 282 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 283 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 284 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 285 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 286 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 287 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 288 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 289 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.695         |
| Data-EnvSampler-Poli... | 1.17          |
| Data-EnvTrajs-Averag... | 304           |
| Data-EnvTrajs-MaxReturn | 348           |
| Data-EnvTrajs-MinReturn | 267           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 26.9          |
| Data-TimeEnvSampleProc  | 0.00151       |
| Data-TimeEnvSampling    | 1.92          |
| Iteration               | 28            |
| ItrTime                 | 31.9          |
| LossAfter               | -0.004451775  |
| LossBefore              | -9.663183e-06 |
| Model-TimeModelFit      | 27.7          |
| ModelSampler-n_times... | 1160000       |
| Policy-AverageAbsPol... | 0.5804036     |
| Policy-AverageDiscou... | 129           |
| Policy-AveragePolicyStd | 0.6426868     |
| Policy-AverageReturn    | 272           |
| Policy-MaxReturn        | 330           |
| Policy-MinReturn        | 199           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 31.7          |
| Policy-TimeAlgoOpt      | 0.567         |
| Policy-TimeSampleProc   | 0.239         |
| Policy-TimeSampling     | 1.44          |
| Policy-TimeStep         | 2.32          |
| Time                    | 841           |
| n_timesteps             | 29000         |
-------------------------------------------

 ---------------- Iteration 29 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 290 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 291 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 292 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 293 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 294 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 295 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 296 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 297 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 298 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 299 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.433         |
| Data-EnvSampler-Poli... | 0.769         |
| Data-EnvTrajs-Averag... | 258           |
| Data-EnvTrajs-MaxReturn | 292           |
| Data-EnvTrajs-MinReturn | 231           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 26.6          |
| Data-TimeEnvSampleProc  | 0.000864      |
| Data-TimeEnvSampling    | 1.23          |
| Iteration               | 29            |
| ItrTime                 | 43.3          |
| LossAfter               | -0.00359034   |
| LossBefore              | -9.394511e-06 |
| Model-TimeModelFit      | 39.8          |
| ModelSampler-n_times... | 1200000       |
| Policy-AverageAbsPol... | 0.518389      |
| Policy-AverageDiscou... | 134           |
| Policy-AveragePolicyStd | 0.6236919     |
| Policy-AverageReturn    | 342           |
| Policy-MaxReturn        | 367           |
| Policy-MinReturn        | 313           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 16.2          |
| Policy-TimeAlgoOpt      | 0.528         |
| Policy-TimeSampleProc   | 0.29          |
| Policy-TimeSampling     | 1.39          |
| Policy-TimeStep         | 2.23          |
| Time                    | 884           |
| n_timesteps             | 30000         |
-------------------------------------------

 ---------------- Iteration 30 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 300 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 301 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 302 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 303 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 304 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 305 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 306 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 307 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 308 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 309 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.405         |
| Data-EnvSampler-Poli... | 0.811         |
| Data-EnvTrajs-Averag... | 209           |
| Data-EnvTrajs-MaxReturn | 270           |
| Data-EnvTrajs-MinReturn | 134           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 45.4          |
| Data-TimeEnvSampleProc  | 0.000863      |
| Data-TimeEnvSampling    | 1.25          |
| Iteration               | 30            |
| ItrTime                 | 34.2          |
| LossAfter               | -0.0055869916 |
| LossBefore              | -9.201868e-06 |
| Model-TimeModelFit      | 29            |
| ModelSampler-n_times... | 1240000       |
| Policy-AverageAbsPol... | 0.57330996    |
| Policy-AverageDiscou... | 110           |
| Policy-AveragePolicyStd | 0.613623      |
| Policy-AverageReturn    | 104           |
| Policy-MaxReturn        | 248           |
| Policy-MinReturn        | -401          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 129           |
| Policy-TimeAlgoOpt      | 0.832         |
| Policy-TimeSampleProc   | 0.589         |
| Policy-TimeSampling     | 2.41          |
| Policy-TimeStep         | 3.86          |
| Time                    | 918           |
| n_timesteps             | 31000         |
-------------------------------------------

 ---------------- Iteration 31 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 310 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 311 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 312 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 313 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 314 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 315 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 316 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 317 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 318 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 319 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.695         |
| Data-EnvSampler-Poli... | 1.21          |
| Data-EnvTrajs-Averag... | 241           |
| Data-EnvTrajs-MaxReturn | 506           |
| Data-EnvTrajs-MinReturn | 101           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 139           |
| Data-TimeEnvSampleProc  | 0.00113       |
| Data-TimeEnvSampling    | 1.96          |
| Iteration               | 31            |
| ItrTime                 | 34.7          |
| LossAfter               | -0.006344932  |
| LossBefore              | -9.059828e-06 |
| Model-TimeModelFit      | 30.3          |
| ModelSampler-n_times... | 1280000       |
| Policy-AverageAbsPol... | 0.61211365    |
| Policy-AverageDiscou... | 118           |
| Policy-AveragePolicyStd | 0.60474896    |
| Policy-AverageReturn    | 142           |
| Policy-MaxReturn        | 480           |
| Policy-MinReturn        | -73           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 119           |
| Policy-TimeAlgoOpt      | 0.574         |
| Policy-TimeSampleProc   | 0.429         |
| Policy-TimeSampling     | 1.42          |
| Policy-TimeStep         | 2.45          |
| Time                    | 953           |
| n_timesteps             | 32000         |
-------------------------------------------

 ---------------- Iteration 32 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 320 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 321 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 322 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 323 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 324 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 325 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 326 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 327 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 328 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 329 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.428         |
| Data-EnvSampler-Poli... | 0.829         |
| Data-EnvTrajs-Averag... | 361           |
| Data-EnvTrajs-MaxReturn | 490           |
| Data-EnvTrajs-MinReturn | 215           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 105           |
| Data-TimeEnvSampleProc  | 0.00114       |
| Data-TimeEnvSampling    | 1.3           |
| Iteration               | 32            |
| ItrTime                 | 44.4          |
| LossAfter               | -0.004440625  |
| LossBefore              | -9.000954e-06 |
| Model-TimeModelFit      | 40.6          |
| ModelSampler-n_times... | 1320000       |
| Policy-AverageAbsPol... | 0.57713485    |
| Policy-AverageDiscou... | 81.7          |
| Policy-AveragePolicyStd | 0.6013602     |
| Policy-AverageReturn    | -88.4         |
| Policy-MaxReturn        | 449           |
| Policy-MinReturn        | -8.62e+03     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.96e+03      |
| Policy-TimeAlgoOpt      | 0.563         |
| Policy-TimeSampleProc   | 0.295         |
| Policy-TimeSampling     | 1.6           |
| Policy-TimeStep         | 2.48          |
| Time                    | 998           |
| n_timesteps             | 33000         |
-------------------------------------------

 ---------------- Iteration 33 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 330 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 331 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 332 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 333 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 334 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 335 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 336 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 337 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 338 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 339 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.38          |
| Data-EnvSampler-Poli... | 0.698         |
| Data-EnvTrajs-Averag... | 366           |
| Data-EnvTrajs-MaxReturn | 464           |
| Data-EnvTrajs-MinReturn | 266           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 74.2          |
| Data-TimeEnvSampleProc  | 0.000975      |
| Data-TimeEnvSampling    | 1.11          |
| Iteration               | 33            |
| ItrTime                 | 32.6          |
| LossAfter               | -0.007704764  |
| LossBefore              | -8.912492e-06 |
| Model-TimeModelFit      | 27.6          |
| ModelSampler-n_times... | 1360000       |
| Policy-AverageAbsPol... | 0.6796966     |
| Policy-AverageDiscou... | -1.94e+04     |
| Policy-AveragePolicyStd | 0.5956643     |
| Policy-AverageReturn    | -1e+05        |
| Policy-MaxReturn        | 384           |
| Policy-MinReturn        | -2e+06        |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 4.37e+05      |
| Policy-TimeAlgoOpt      | 0.756         |
| Policy-TimeSampleProc   | 0.772         |
| Policy-TimeSampling     | 2.37          |
| Policy-TimeStep         | 3.95          |
| Time                    | 1.03e+03      |
| n_timesteps             | 34000         |
-------------------------------------------

 ---------------- Iteration 34 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 340 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 341 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 342 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 343 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 344 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 345 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 346 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 347 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 348 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 349 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.693         |
| Data-EnvSampler-Poli... | 1.29          |
| Data-EnvTrajs-Averag... | 321           |
| Data-EnvTrajs-MaxReturn | 444           |
| Data-EnvTrajs-MinReturn | 64.9          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 132           |
| Data-TimeEnvSampleProc  | 0.00147       |
| Data-TimeEnvSampling    | 2.04          |
| Iteration               | 34            |
| ItrTime                 | 39.7          |
| LossAfter               | -0.003917054  |
| LossBefore              | -8.696179e-06 |
| Model-TimeModelFit      | 35.2          |
| ModelSampler-n_times... | 1400000       |
| Policy-AverageAbsPol... | 0.6452454     |
| Policy-AverageDiscou... | 150           |
| Policy-AveragePolicyStd | 0.58367866    |
| Policy-AverageReturn    | 403           |
| Policy-MaxReturn        | 536           |
| Policy-MinReturn        | 190           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 77.9          |
| Policy-TimeAlgoOpt      | 0.522         |
| Policy-TimeSampleProc   | 0.439         |
| Policy-TimeSampling     | 1.48          |
| Policy-TimeStep         | 2.47          |
| Time                    | 1.07e+03      |
| n_timesteps             | 35000         |
-------------------------------------------

 ---------------- Iteration 35 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...
Stopping DynamicsEnsemble Training since valid_loss_rolling_average decreased

 ---------------- Grad-Step 350 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 351 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 352 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 353 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 354 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 355 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 356 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 357 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 358 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 359 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.418         |
| Data-EnvSampler-Poli... | 0.801         |
| Data-EnvTrajs-Averag... | 446           |
| Data-EnvTrajs-MaxReturn | 558           |
| Data-EnvTrajs-MinReturn | 270           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 96.7          |
| Data-TimeEnvSampleProc  | 0.00092       |
| Data-TimeEnvSampling    | 1.25          |
| Iteration               | 35            |
| ItrTime                 | 28.6          |
| LossAfter               | -0.008709055  |
| LossBefore              | -8.594465e-06 |
| Model-TimeModelFit      | 23.6          |
| ModelSampler-n_times... | 1440000       |
| Policy-AverageAbsPol... | 0.69018704    |
| Policy-AverageDiscou... | -121          |
| Policy-AveragePolicyStd | 0.5781253     |
| Policy-AverageReturn    | -1.37e+03     |
| Policy-MaxReturn        | 440           |
| Policy-MinReturn        | -2.91e+04     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 6.36e+03      |
| Policy-TimeAlgoOpt      | 0.789         |
| Policy-TimeSampleProc   | 0.622         |
| Policy-TimeSampling     | 2.35          |
| Policy-TimeStep         | 3.81          |
| Time                    | 1.1e+03       |
| n_timesteps             | 36000         |
-------------------------------------------

 ---------------- Iteration 36 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 360 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 361 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 362 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 363 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 364 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 365 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 366 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 367 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 368 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 369 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.689         |
| Data-EnvSampler-Poli... | 1.33          |
| Data-EnvTrajs-Averag... | 358           |
| Data-EnvTrajs-MaxReturn | 548           |
| Data-EnvTrajs-MinReturn | 189           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 120           |
| Data-TimeEnvSampleProc  | 0.00117       |
| Data-TimeEnvSampling    | 2.08          |
| Iteration               | 36            |
| ItrTime                 | 37.1          |
| LossAfter               | -0.0036690745 |
| LossBefore              | -8.317759e-06 |
| Model-TimeModelFit      | 32.7          |
| ModelSampler-n_times... | 1480000       |
| Policy-AverageAbsPol... | 0.6022284     |
| Policy-AverageDiscou... | 158           |
| Policy-AveragePolicyStd | 0.56255144    |
| Policy-AverageReturn    | 425           |
| Policy-MaxReturn        | 565           |
| Policy-MinReturn        | 209           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 87.9          |
| Policy-TimeAlgoOpt      | 0.508         |
| Policy-TimeSampleProc   | 0.359         |
| Policy-TimeSampling     | 1.41          |
| Policy-TimeStep         | 2.31          |
| Time                    | 1.14e+03      |
| n_timesteps             | 37000         |
-------------------------------------------

 ---------------- Iteration 37 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 370 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 371 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 372 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 373 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 374 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 375 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 376 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 377 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 378 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 379 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.417         |
| Data-EnvSampler-Poli... | 0.823         |
| Data-EnvTrajs-Averag... | 404           |
| Data-EnvTrajs-MaxReturn | 428           |
| Data-EnvTrajs-MinReturn | 374           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 21            |
| Data-TimeEnvSampleProc  | 0.000796      |
| Data-TimeEnvSampling    | 1.27          |
| Iteration               | 37            |
| ItrTime                 | 44.8          |
| LossAfter               | -0.004402415  |
| LossBefore              | -8.149177e-06 |
| Model-TimeModelFit      | 39.9          |
| ModelSampler-n_times... | 1520000       |
| Policy-AverageAbsPol... | 0.5870833     |
| Policy-AverageDiscou... | 183           |
| Policy-AveragePolicyStd | 0.5525642     |
| Policy-AverageReturn    | 494           |
| Policy-MaxReturn        | 979           |
| Policy-MinReturn        | -542          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 277           |
| Policy-TimeAlgoOpt      | 0.739         |
| Policy-TimeSampleProc   | 0.644         |
| Policy-TimeSampling     | 2.2           |
| Policy-TimeStep         | 3.61          |
| Time                    | 1.18e+03      |
| n_timesteps             | 38000         |
-------------------------------------------

 ---------------- Iteration 38 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 380 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 381 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 382 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 383 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 384 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 385 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 386 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 387 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 388 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 389 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.376         |
| Data-EnvSampler-Poli... | 0.702         |
| Data-EnvTrajs-Averag... | 453           |
| Data-EnvTrajs-MaxReturn | 521           |
| Data-EnvTrajs-MinReturn | 356           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 53.9          |
| Data-TimeEnvSampleProc  | 0.00202       |
| Data-TimeEnvSampling    | 1.11          |
| Iteration               | 38            |
| ItrTime                 | 32.5          |
| LossAfter               | -0.00803509   |
| LossBefore              | -8.034938e-06 |
| Model-TimeModelFit      | 27.5          |
| ModelSampler-n_times... | 1560000       |
| Policy-AverageAbsPol... | 0.6372565     |
| Policy-AverageDiscou... | 180           |
| Policy-AveragePolicyStd | 0.54805       |
| Policy-AverageReturn    | 482           |
| Policy-MaxReturn        | 596           |
| Policy-MinReturn        | 367           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 67.5          |
| Policy-TimeAlgoOpt      | 0.811         |
| Policy-TimeSampleProc   | 0.612         |
| Policy-TimeSampling     | 2.38          |
| Policy-TimeStep         | 3.85          |
| Time                    | 1.21e+03      |
| n_timesteps             | 39000         |
-------------------------------------------

 ---------------- Iteration 39 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 390 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 391 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 392 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 393 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 394 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 395 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 396 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 397 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 398 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 399 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.714         |
| Data-EnvSampler-Poli... | 1.31          |
| Data-EnvTrajs-Averag... | 466           |
| Data-EnvTrajs-MaxReturn | 537           |
| Data-EnvTrajs-MinReturn | 243           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 112           |
| Data-TimeEnvSampleProc  | 0.00153       |
| Data-TimeEnvSampling    | 2.08          |
| Iteration               | 39            |
| ItrTime                 | 41            |
| LossAfter               | -0.004076983  |
| LossBefore              | -7.968292e-06 |
| Model-TimeModelFit      | 36.5          |
| ModelSampler-n_times... | 1600000       |
| Policy-AverageAbsPol... | 0.70820636    |
| Policy-AverageDiscou... | 101           |
| Policy-AveragePolicyStd | 0.5428547     |
| Policy-AverageReturn    | 199           |
| Policy-MaxReturn        | 427           |
| Policy-MinReturn        | -234          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 206           |
| Policy-TimeAlgoOpt      | 0.534         |
| Policy-TimeSampleProc   | 0.478         |
| Policy-TimeSampling     | 1.37          |
| Policy-TimeStep         | 2.42          |
| Time                    | 1.25e+03      |
| n_timesteps             | 40000         |
-------------------------------------------

 ---------------- Iteration 40 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 400 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 401 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 402 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 403 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 404 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 405 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 406 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 407 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 408 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 409 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.407         |
| Data-EnvSampler-Poli... | 0.813         |
| Data-EnvTrajs-Averag... | 394           |
| Data-EnvTrajs-MaxReturn | 497           |
| Data-EnvTrajs-MinReturn | 259           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 77.9          |
| Data-TimeEnvSampleProc  | 0.00079       |
| Data-TimeEnvSampling    | 1.25          |
| Iteration               | 40            |
| ItrTime                 | 42.4          |
| LossAfter               | -0.006798742  |
| LossBefore              | -7.837436e-06 |
| Model-TimeModelFit      | 37.4          |
| ModelSampler-n_times... | 1640000       |
| Policy-AverageAbsPol... | 0.65761054    |
| Policy-AverageDiscou... | 194           |
| Policy-AveragePolicyStd | 0.535547      |
| Policy-AverageReturn    | 511           |
| Policy-MaxReturn        | 715           |
| Policy-MinReturn        | 292           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 122           |
| Policy-TimeAlgoOpt      | 0.822         |
| Policy-TimeSampleProc   | 0.557         |
| Policy-TimeSampling     | 2.35          |
| Policy-TimeStep         | 3.76          |
| Time                    | 1.3e+03       |
| n_timesteps             | 41000         |
-------------------------------------------

 ---------------- Iteration 41 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 410 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 411 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 412 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 413 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 414 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 415 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 416 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 417 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 418 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 419 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.698         |
| Data-EnvSampler-Poli... | 1.34          |
| Data-EnvTrajs-Averag... | 417           |
| Data-EnvTrajs-MaxReturn | 523           |
| Data-EnvTrajs-MinReturn | 232           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 104           |
| Data-TimeEnvSampleProc  | 0.00155       |
| Data-TimeEnvSampling    | 2.09          |
| Iteration               | 41            |
| ItrTime                 | 34.1          |
| LossAfter               | -0.0049728253 |
| LossBefore              | -7.743542e-06 |
| Model-TimeModelFit      | 29.6          |
| ModelSampler-n_times... | 1680000       |
| Policy-AverageAbsPol... | 0.66733634    |
| Policy-AverageDiscou... | 183           |
| Policy-AveragePolicyStd | 0.53077596    |
| Policy-AverageReturn    | 484           |
| Policy-MaxReturn        | 698           |
| Policy-MinReturn        | 195           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 115           |
| Policy-TimeAlgoOpt      | 0.565         |
| Policy-TimeSampleProc   | 0.34          |
| Policy-TimeSampling     | 1.47          |
| Policy-TimeStep         | 2.39          |
| Time                    | 1.33e+03      |
| n_timesteps             | 42000         |
-------------------------------------------

 ---------------- Iteration 42 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 420 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 421 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 422 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 423 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 424 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 425 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 426 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 427 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 428 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 429 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.472         |
| Data-EnvSampler-Poli... | 0.859         |
| Data-EnvTrajs-Averag... | 479           |
| Data-EnvTrajs-MaxReturn | 550           |
| Data-EnvTrajs-MinReturn | 401           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 53.2          |
| Data-TimeEnvSampleProc  | 0.0014        |
| Data-TimeEnvSampling    | 1.37          |
| Iteration               | 42            |
| ItrTime                 | 45.3          |
| LossAfter               | -0.0053978045 |
| LossBefore              | -7.480685e-06 |
| Model-TimeModelFit      | 41.6          |
| ModelSampler-n_times... | 1720000       |
| Policy-AverageAbsPol... | 0.64914626    |
| Policy-AverageDiscou... | 141           |
| Policy-AveragePolicyStd | 0.51542085    |
| Policy-AverageReturn    | 335           |
| Policy-MaxReturn        | 469           |
| Policy-MinReturn        | 32.3          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 97.8          |
| Policy-TimeAlgoOpt      | 0.495         |
| Policy-TimeSampleProc   | 0.399         |
| Policy-TimeSampling     | 1.34          |
| Policy-TimeStep         | 2.27          |
| Time                    | 1.38e+03      |
| n_timesteps             | 43000         |
-------------------------------------------

 ---------------- Iteration 43 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 430 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 431 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 432 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 433 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 434 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 435 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 436 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 437 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 438 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 439 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.399          |
| Data-EnvSampler-Poli... | 0.833          |
| Data-EnvTrajs-Averag... | 434            |
| Data-EnvTrajs-MaxReturn | 542            |
| Data-EnvTrajs-MinReturn | 344            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 70.7           |
| Data-TimeEnvSampleProc  | 0.000875       |
| Data-TimeEnvSampling    | 1.27           |
| Iteration               | 43             |
| ItrTime                 | 38.6           |
| LossAfter               | -0.0066134804  |
| LossBefore              | -7.4021737e-06 |
| Model-TimeModelFit      | 33.5           |
| ModelSampler-n_times... | 1760000        |
| Policy-AverageAbsPol... | 0.57116884     |
| Policy-AverageDiscou... | 182            |
| Policy-AveragePolicyStd | 0.5100532      |
| Policy-AverageReturn    | 483            |
| Policy-MaxReturn        | 685            |
| Policy-MinReturn        | 205            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 114            |
| Policy-TimeAlgoOpt      | 0.79           |
| Policy-TimeSampleProc   | 0.532          |
| Policy-TimeSampling     | 2.54           |
| Policy-TimeStep         | 3.89           |
| Time                    | 1.41e+03       |
| n_timesteps             | 44000          |
--------------------------------------------

 ---------------- Iteration 44 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 440 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 441 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 442 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 443 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 444 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 445 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 446 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 447 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 448 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 449 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.666         |
| Data-EnvSampler-Poli... | 1.34          |
| Data-EnvTrajs-Averag... | 543           |
| Data-EnvTrajs-MaxReturn | 647           |
| Data-EnvTrajs-MinReturn | 435           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 85.8          |
| Data-TimeEnvSampleProc  | 0.00097       |
| Data-TimeEnvSampling    | 2.06          |
| Iteration               | 44            |
| ItrTime                 | 33.9          |
| LossAfter               | -0.0048334673 |
| LossBefore              | -7.421337e-06 |
| Model-TimeModelFit      | 29.4          |
| ModelSampler-n_times... | 1800000       |
| Policy-AverageAbsPol... | 0.7010918     |
| Policy-AverageDiscou... | 137           |
| Policy-AveragePolicyStd | 0.5104865     |
| Policy-AverageReturn    | 243           |
| Policy-MaxReturn        | 496           |
| Policy-MinReturn        | -302          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 200           |
| Policy-TimeAlgoOpt      | 0.635         |
| Policy-TimeSampleProc   | 0.266         |
| Policy-TimeSampling     | 1.49          |
| Policy-TimeStep         | 2.42          |
| Time                    | 1.45e+03      |
| n_timesteps             | 45000         |
-------------------------------------------

 ---------------- Iteration 45 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 450 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 451 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 452 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 453 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 454 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 455 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 456 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 457 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 458 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 459 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.56           |
| Data-EnvSampler-Poli... | 1.06           |
| Data-EnvTrajs-Averag... | 509            |
| Data-EnvTrajs-MaxReturn | 579            |
| Data-EnvTrajs-MinReturn | 351            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 83             |
| Data-TimeEnvSampleProc  | 0.00146        |
| Data-TimeEnvSampling    | 1.66           |
| Iteration               | 45             |
| ItrTime                 | 43.3           |
| LossAfter               | -0.005417536   |
| LossBefore              | -7.3709543e-06 |
| Model-TimeModelFit      | 39.4           |
| ModelSampler-n_times... | 1840000        |
| Policy-AverageAbsPol... | 0.72659904     |
| Policy-AverageDiscou... | 175            |
| Policy-AveragePolicyStd | 0.5072336      |
| Policy-AverageReturn    | 480            |
| Policy-MaxReturn        | 605            |
| Policy-MinReturn        | 338            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 55.1           |
| Policy-TimeAlgoOpt      | 0.538          |
| Policy-TimeSampleProc   | 0.254          |
| Policy-TimeSampling     | 1.42           |
| Policy-TimeStep         | 2.25           |
| Time                    | 1.49e+03       |
| n_timesteps             | 46000          |
--------------------------------------------

 ---------------- Iteration 46 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 460 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 461 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 462 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 463 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 464 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 465 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 466 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 467 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 468 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 469 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.435          |
| Data-EnvSampler-Poli... | 0.832          |
| Data-EnvTrajs-Averag... | 490            |
| Data-EnvTrajs-MaxReturn | 622            |
| Data-EnvTrajs-MinReturn | 273            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 136            |
| Data-TimeEnvSampleProc  | 0.000959       |
| Data-TimeEnvSampling    | 1.3            |
| Iteration               | 46             |
| ItrTime                 | 41.4           |
| LossAfter               | -0.005009277   |
| LossBefore              | -7.2976904e-06 |
| Model-TimeModelFit      | 36.2           |
| ModelSampler-n_times... | 1880000        |
| Policy-AverageAbsPol... | 0.7534519      |
| Policy-AverageDiscou... | 169            |
| Policy-AveragePolicyStd | 0.50455564     |
| Policy-AverageReturn    | 444            |
| Policy-MaxReturn        | 558            |
| Policy-MinReturn        | 168            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 116            |
| Policy-TimeAlgoOpt      | 0.788          |
| Policy-TimeSampleProc   | 0.766          |
| Policy-TimeSampling     | 2.35           |
| Policy-TimeStep         | 3.93           |
| Time                    | 1.53e+03       |
| n_timesteps             | 47000          |
--------------------------------------------

 ---------------- Iteration 47 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 470 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 471 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 472 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 473 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 474 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 475 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 476 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 477 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 478 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 479 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.663          |
| Data-EnvSampler-Poli... | 1.32           |
| Data-EnvTrajs-Averag... | 479            |
| Data-EnvTrajs-MaxReturn | 608            |
| Data-EnvTrajs-MinReturn | 362            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 103            |
| Data-TimeEnvSampleProc  | 0.00157        |
| Data-TimeEnvSampling    | 2.03           |
| Iteration               | 47             |
| ItrTime                 | 39.3           |
| LossAfter               | -0.0050696223  |
| LossBefore              | -7.2159805e-06 |
| Model-TimeModelFit      | 34.9           |
| ModelSampler-n_times... | 1920000        |
| Policy-AverageAbsPol... | 0.7295875      |
| Policy-AverageDiscou... | 168            |
| Policy-AveragePolicyStd | 0.50047755     |
| Policy-AverageReturn    | 455            |
| Policy-MaxReturn        | 572            |
| Policy-MinReturn        | 267            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 78.3           |
| Policy-TimeAlgoOpt      | 0.515          |
| Policy-TimeSampleProc   | 0.345          |
| Policy-TimeSampling     | 1.45           |
| Policy-TimeStep         | 2.34           |
| Time                    | 1.57e+03       |
| n_timesteps             | 48000          |
--------------------------------------------

 ---------------- Iteration 48 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 480 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 481 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 482 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 483 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 484 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 485 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 486 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 487 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 488 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 489 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.417         |
| Data-EnvSampler-Poli... | 0.861         |
| Data-EnvTrajs-Averag... | 367           |
| Data-EnvTrajs-MaxReturn | 573           |
| Data-EnvTrajs-MinReturn | 110           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 159           |
| Data-TimeEnvSampleProc  | 0.000975      |
| Data-TimeEnvSampling    | 1.32          |
| Iteration               | 48            |
| ItrTime                 | 48.4          |
| LossAfter               | -0.0047114883 |
| LossBefore              | -7.175532e-06 |
| Model-TimeModelFit      | 43.2          |
| ModelSampler-n_times... | 1960000       |
| Policy-AverageAbsPol... | 0.72264665    |
| Policy-AverageDiscou... | 147           |
| Policy-AveragePolicyStd | 0.49938256    |
| Policy-AverageReturn    | 393           |
| Policy-MaxReturn        | 532           |
| Policy-MinReturn        | 192           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 76.5          |
| Policy-TimeAlgoOpt      | 0.778         |
| Policy-TimeSampleProc   | 0.662         |
| Policy-TimeSampling     | 2.34          |
| Policy-TimeStep         | 3.83          |
| Time                    | 1.62e+03      |
| n_timesteps             | 49000         |
-------------------------------------------

 ---------------- Iteration 49 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 490 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 491 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 492 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 493 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 494 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 495 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 496 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 497 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 498 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 499 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.376         |
| Data-EnvSampler-Poli... | 0.79          |
| Data-EnvTrajs-Averag... | 386           |
| Data-EnvTrajs-MaxReturn | 515           |
| Data-EnvTrajs-MinReturn | 170           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 120           |
| Data-TimeEnvSampleProc  | 0.000852      |
| Data-TimeEnvSampling    | 1.2           |
| Iteration               | 49            |
| ItrTime                 | 35.6          |
| LossAfter               | -0.006203354  |
| LossBefore              | -6.974169e-06 |
| Model-TimeModelFit      | 30.4          |
| ModelSampler-n_times... | 2000000       |
| Policy-AverageAbsPol... | 0.6811747     |
| Policy-AverageDiscou... | 179           |
| Policy-AveragePolicyStd | 0.4891404     |
| Policy-AverageReturn    | 440           |
| Policy-MaxReturn        | 608           |
| Policy-MinReturn        | 187           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 130           |
| Policy-TimeAlgoOpt      | 0.771         |
| Policy-TimeSampleProc   | 0.778         |
| Policy-TimeSampling     | 2.42          |
| Policy-TimeStep         | 4.02          |
| Time                    | 1.66e+03      |
| n_timesteps             | 50000         |
-------------------------------------------

 ---------------- Iteration 50 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 500 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 501 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 502 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 503 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 504 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 505 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 506 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 507 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 508 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 509 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.704          |
| Data-EnvSampler-Poli... | 1.4            |
| Data-EnvTrajs-Averag... | 555            |
| Data-EnvTrajs-MaxReturn | 609            |
| Data-EnvTrajs-MinReturn | 456            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 58.7           |
| Data-TimeEnvSampleProc  | 0.00157        |
| Data-TimeEnvSampling    | 2.18           |
| Iteration               | 50             |
| ItrTime                 | 41.3           |
| LossAfter               | -0.0045266347  |
| LossBefore              | -6.8072723e-06 |
| Model-TimeModelFit      | 36.7           |
| ModelSampler-n_times... | 2040000        |
| Policy-AverageAbsPol... | 0.67845845     |
| Policy-AverageDiscou... | 192            |
| Policy-AveragePolicyStd | 0.4807423      |
| Policy-AverageReturn    | 534            |
| Policy-MaxReturn        | 654            |
| Policy-MinReturn        | 90.5           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 123            |
| Policy-TimeAlgoOpt      | 0.568          |
| Policy-TimeSampleProc   | 0.329          |
| Policy-TimeSampling     | 1.51           |
| Policy-TimeStep         | 2.43           |
| Time                    | 1.7e+03        |
| n_timesteps             | 51000          |
--------------------------------------------
Training finished
