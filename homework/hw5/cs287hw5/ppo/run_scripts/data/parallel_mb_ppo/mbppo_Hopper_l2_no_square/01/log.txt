Logging to /home/vincent/workplace/CS_287_-_Advanced_Robotics/homework/hw5/cs287hw5/ppo/run_scripts/data/parallel_mb_ppo/mbppo_Hopper_l2_no_square//01

 ---------------- Iteration 0 ----------------
Obtaining random samples from the environment...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 0 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 1 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 2 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 3 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 4 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 5 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 6 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 7 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 8 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 9 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.284          |
| Data-EnvSampler-Poli... | 0.0619         |
| Data-EnvTrajs-Averag... | -279           |
| Data-EnvTrajs-MaxReturn | -192           |
| Data-EnvTrajs-MinReturn | -332           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 51.5           |
| Data-TimeEnvSampleProc  | 0.000721       |
| Data-TimeEnvSampling    | 0.362          |
| Iteration               | 0              |
| ItrTime                 | 13.5           |
| LossAfter               | -0.005750063   |
| LossBefore              | -1.3822002e-05 |
| Model-TimeModelFit      | 4.55           |
| ModelSampler-n_times... | 40000          |
| Policy-AverageAbsPol... | 0.62661815     |
| Policy-AverageDiscou... | -2.03e+06      |
| Policy-AveragePolicyStd | 0.96340126     |
| Policy-AverageReturn    | -5.31e+06      |
| Policy-MaxReturn        | -5.2e+06       |
| Policy-MinReturn        | -5.42e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 5.31e+04       |
| Policy-TimeAlgoOpt      | 1.38           |
| Policy-TimeSampleProc   | 0.471          |
| Policy-TimeSampling     | 6.7            |
| Policy-TimeStep         | 8.57           |
| Time                    | 13.5           |
| n_timesteps             | 1000           |
--------------------------------------------

 ---------------- Iteration 1 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 10 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 11 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 12 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 13 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 14 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 15 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 16 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 17 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 18 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 19 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.39           |
| Data-EnvSampler-Poli... | 0.68           |
| Data-EnvTrajs-Averag... | -30.5          |
| Data-EnvTrajs-MaxReturn | 245            |
| Data-EnvTrajs-MinReturn | -366           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 223            |
| Data-TimeEnvSampleProc  | 0.000976       |
| Data-TimeEnvSampling    | 1.1            |
| Iteration               | 1              |
| ItrTime                 | 9              |
| LossAfter               | -0.0045537786  |
| LossBefore              | -1.3577295e-05 |
| Model-TimeModelFit      | 5.28           |
| ModelSampler-n_times... | 80000          |
| Policy-AverageAbsPol... | 0.53959036     |
| Policy-AverageDiscou... | -1.78e+06      |
| Policy-AveragePolicyStd | 0.9407015      |
| Policy-AverageReturn    | -4.99e+06      |
| Policy-MaxReturn        | -4.55e+06      |
| Policy-MinReturn        | -5.17e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.55e+05       |
| Policy-TimeAlgoOpt      | 0.556          |
| Policy-TimeSampleProc   | 0.4            |
| Policy-TimeSampling     | 1.61           |
| Policy-TimeStep         | 2.62           |
| Time                    | 22.8           |
| n_timesteps             | 2000           |
--------------------------------------------

 ---------------- Iteration 2 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 20 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 21 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 22 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 23 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 24 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 25 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 26 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 27 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 28 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 29 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.281          |
| Data-EnvSampler-Poli... | 0.387          |
| Data-EnvTrajs-Averag... | -504           |
| Data-EnvTrajs-MaxReturn | -468           |
| Data-EnvTrajs-MinReturn | -524           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 20             |
| Data-TimeEnvSampleProc  | 0.000518       |
| Data-TimeEnvSampling    | 0.688          |
| Iteration               | 2              |
| ItrTime                 | 9.17           |
| LossAfter               | -0.0030450302  |
| LossBefore              | -1.3340033e-05 |
| Model-TimeModelFit      | 5.93           |
| ModelSampler-n_times... | 120000         |
| Policy-AverageAbsPol... | 0.84083366     |
| Policy-AverageDiscou... | -1.61e+06      |
| Policy-AveragePolicyStd | 0.9182113      |
| Policy-AverageReturn    | -4.75e+06      |
| Policy-MaxReturn        | -4.5e+06       |
| Policy-MinReturn        | -4.83e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 7.79e+04       |
| Policy-TimeAlgoOpt      | 0.623          |
| Policy-TimeSampleProc   | 0.316          |
| Policy-TimeSampling     | 1.59           |
| Policy-TimeStep         | 2.55           |
| Time                    | 31.9           |
| n_timesteps             | 3000           |
--------------------------------------------

 ---------------- Iteration 3 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 30 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 31 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 32 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 33 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 34 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 35 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 36 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 37 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 38 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 39 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.307          |
| Data-EnvSampler-Poli... | 0.399          |
| Data-EnvTrajs-Averag... | -511           |
| Data-EnvTrajs-MaxReturn | -494           |
| Data-EnvTrajs-MinReturn | -520           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 9.02           |
| Data-TimeEnvSampleProc  | 0.000547       |
| Data-TimeEnvSampling    | 0.726          |
| Iteration               | 3              |
| ItrTime                 | 11.3           |
| LossAfter               | -0.0043507293  |
| LossBefore              | -1.3220442e-05 |
| Model-TimeModelFit      | 7.88           |
| ModelSampler-n_times... | 160000         |
| Policy-AverageAbsPol... | 0.8668812      |
| Policy-AverageDiscou... | -8.4e+05       |
| Policy-AveragePolicyStd | 0.90761083     |
| Policy-AverageReturn    | -3.32e+06      |
| Policy-MaxReturn        | -2.29e+06      |
| Policy-MinReturn        | -3.7e+06       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.9e+05        |
| Policy-TimeAlgoOpt      | 0.539          |
| Policy-TimeSampleProc   | 0.459          |
| Policy-TimeSampling     | 1.61           |
| Policy-TimeStep         | 2.65           |
| Time                    | 43.2           |
| n_timesteps             | 4000           |
--------------------------------------------

 ---------------- Iteration 4 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 40 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 41 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 42 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 43 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 44 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 45 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 46 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 47 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 48 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 49 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.333          |
| Data-EnvSampler-Poli... | 0.42           |
| Data-EnvTrajs-Averag... | -492           |
| Data-EnvTrajs-MaxReturn | -476           |
| Data-EnvTrajs-MinReturn | -503           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 9.04           |
| Data-TimeEnvSampleProc  | 0.000566       |
| Data-TimeEnvSampling    | 0.774          |
| Iteration               | 4              |
| ItrTime                 | 19.8           |
| LossAfter               | -0.0045272917  |
| LossBefore              | -1.3105636e-05 |
| Model-TimeModelFit      | 15.1           |
| ModelSampler-n_times... | 200000         |
| Policy-AverageAbsPol... | 0.96928775     |
| Policy-AverageDiscou... | -6.27e+05      |
| Policy-AveragePolicyStd | 0.89718324     |
| Policy-AverageReturn    | -2.18e+06      |
| Policy-MaxReturn        | -484           |
| Policy-MinReturn        | -4.37e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.98e+06       |
| Policy-TimeAlgoOpt      | 0.762          |
| Policy-TimeSampleProc   | 0.75           |
| Policy-TimeSampling     | 2.36           |
| Policy-TimeStep         | 3.9            |
| Time                    | 63             |
| n_timesteps             | 5000           |
--------------------------------------------

 ---------------- Iteration 5 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 50 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 51 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 52 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 53 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 54 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 55 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 56 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 57 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 58 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 59 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.461          |
| Data-EnvSampler-Poli... | 0.567          |
| Data-EnvTrajs-Averag... | -525           |
| Data-EnvTrajs-MaxReturn | -514           |
| Data-EnvTrajs-MinReturn | -536           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 9.77           |
| Data-TimeEnvSampleProc  | 0.00152        |
| Data-TimeEnvSampling    | 1.06           |
| Iteration               | 5              |
| ItrTime                 | 17.3           |
| LossAfter               | -0.007357618   |
| LossBefore              | -1.2904839e-05 |
| Model-TimeModelFit      | 13.6           |
| ModelSampler-n_times... | 240000         |
| Policy-AverageAbsPol... | 1.083187       |
| Policy-AverageDiscou... | -2.29e+05      |
| Policy-AveragePolicyStd | 0.8798665      |
| Policy-AverageReturn    | -8.11e+05      |
| Policy-MaxReturn        | -415           |
| Policy-MinReturn        | -4.29e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.56e+06       |
| Policy-TimeAlgoOpt      | 0.564          |
| Policy-TimeSampleProc   | 0.727          |
| Policy-TimeSampling     | 1.38           |
| Policy-TimeStep         | 2.69           |
| Time                    | 80.3           |
| n_timesteps             | 6000           |
--------------------------------------------

 ---------------- Iteration 6 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 60 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 61 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 62 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 63 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 64 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 65 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 66 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 67 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 68 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 69 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.271         |
| Data-EnvSampler-Poli... | 0.38          |
| Data-EnvTrajs-Averag... | -509          |
| Data-EnvTrajs-MaxReturn | -455          |
| Data-EnvTrajs-MinReturn | -536          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 27.7          |
| Data-TimeEnvSampleProc  | 0.00048       |
| Data-TimeEnvSampling    | 0.668         |
| Iteration               | 6             |
| ItrTime                 | 17.3          |
| LossAfter               | -0.0030953202 |
| LossBefore              | -1.253316e-05 |
| Model-TimeModelFit      | 13.8          |
| ModelSampler-n_times... | 280000        |
| Policy-AverageAbsPol... | 0.9607214     |
| Policy-AverageDiscou... | -1.43e+06     |
| Policy-AveragePolicyStd | 0.84812444    |
| Policy-AverageReturn    | -4.48e+06     |
| Policy-MaxReturn        | -4.36e+06     |
| Policy-MinReturn        | -4.64e+06     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 7.92e+04      |
| Policy-TimeAlgoOpt      | 0.627         |
| Policy-TimeSampleProc   | 0.561         |
| Policy-TimeSampling     | 1.59          |
| Policy-TimeStep         | 2.81          |
| Time                    | 97.6          |
| n_timesteps             | 7000          |
-------------------------------------------

 ---------------- Iteration 7 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 70 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 71 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 72 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 73 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 74 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 75 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 76 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 77 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 78 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 79 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.323          |
| Data-EnvSampler-Poli... | 0.407          |
| Data-EnvTrajs-Averag... | -490           |
| Data-EnvTrajs-MaxReturn | -459           |
| Data-EnvTrajs-MinReturn | -504           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 16.2           |
| Data-TimeEnvSampleProc  | 0.00095        |
| Data-TimeEnvSampling    | 0.752          |
| Iteration               | 7              |
| ItrTime                 | 29.8           |
| LossAfter               | -0.0032002241  |
| LossBefore              | -1.2470146e-05 |
| Model-TimeModelFit      | 25.2           |
| ModelSampler-n_times... | 320000         |
| Policy-AverageAbsPol... | 1.040415       |
| Policy-AverageDiscou... | -1.38e+05      |
| Policy-AveragePolicyStd | 0.84322315     |
| Policy-AverageReturn    | -7.63e+05      |
| Policy-MaxReturn        | -547           |
| Policy-MinReturn        | -2.4e+06       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 7.94e+05       |
| Policy-TimeAlgoOpt      | 0.731          |
| Policy-TimeSampleProc   | 0.877          |
| Policy-TimeSampling     | 2.16           |
| Policy-TimeStep         | 3.82           |
| Time                    | 127            |
| n_timesteps             | 8000           |
--------------------------------------------

 ---------------- Iteration 8 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 80 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 81 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 82 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 83 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 84 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 85 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 86 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 87 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 88 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 89 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.479          |
| Data-EnvSampler-Poli... | 0.641          |
| Data-EnvTrajs-Averag... | -461           |
| Data-EnvTrajs-MaxReturn | -444           |
| Data-EnvTrajs-MinReturn | -471           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 9.22           |
| Data-TimeEnvSampleProc  | 0.00133        |
| Data-TimeEnvSampling    | 1.15           |
| Iteration               | 8              |
| ItrTime                 | 22.8           |
| LossAfter               | -0.005147472   |
| LossBefore              | -1.2488235e-05 |
| Model-TimeModelFit      | 18.9           |
| ModelSampler-n_times... | 360000         |
| Policy-AverageAbsPol... | 0.9789502      |
| Policy-AverageDiscou... | -4.91e+04      |
| Policy-AveragePolicyStd | 0.8449032      |
| Policy-AverageReturn    | -2.63e+05      |
| Policy-MaxReturn        | 36.9           |
| Policy-MinReturn        | -2.14e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 6.36e+05       |
| Policy-TimeAlgoOpt      | 0.541          |
| Policy-TimeSampleProc   | 0.394          |
| Policy-TimeSampling     | 1.76           |
| Policy-TimeStep         | 2.78           |
| Time                    | 150            |
| n_timesteps             | 9000           |
--------------------------------------------

 ---------------- Iteration 9 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 90 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 91 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 92 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 93 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 94 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 95 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 96 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 97 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 98 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 99 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.288          |
| Data-EnvSampler-Poli... | 0.392          |
| Data-EnvTrajs-Averag... | -441           |
| Data-EnvTrajs-MaxReturn | -430           |
| Data-EnvTrajs-MinReturn | -464           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 12.2           |
| Data-TimeEnvSampleProc  | 0.00101        |
| Data-TimeEnvSampling    | 0.701          |
| Iteration               | 9              |
| ItrTime                 | 30             |
| LossAfter               | -0.0056930115  |
| LossBefore              | -1.2518415e-05 |
| Model-TimeModelFit      | 25.5           |
| ModelSampler-n_times... | 400000         |
| Policy-AverageAbsPol... | 0.9565851      |
| Policy-AverageDiscou... | -9.02e+04      |
| Policy-AveragePolicyStd | 0.84546405     |
| Policy-AverageReturn    | -5.33e+05      |
| Policy-MaxReturn        | -625           |
| Policy-MinReturn        | -1.89e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 6.12e+05       |
| Policy-TimeAlgoOpt      | 0.882          |
| Policy-TimeSampleProc   | 0.648          |
| Policy-TimeSampling     | 2.3            |
| Policy-TimeStep         | 3.87           |
| Time                    | 180            |
| n_timesteps             | 10000          |
--------------------------------------------

 ---------------- Iteration 10 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 100 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 101 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 102 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 103 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 104 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 105 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 106 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 107 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 108 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 109 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.455          |
| Data-EnvSampler-Poli... | 0.606          |
| Data-EnvTrajs-Averag... | -433           |
| Data-EnvTrajs-MaxReturn | -427           |
| Data-EnvTrajs-MinReturn | -451           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 8.93           |
| Data-TimeEnvSampleProc  | 0.000885       |
| Data-TimeEnvSampling    | 1.09           |
| Iteration               | 10             |
| ItrTime                 | 27.7           |
| LossAfter               | -0.006354915   |
| LossBefore              | -1.2283148e-05 |
| Model-TimeModelFit      | 24.1           |
| ModelSampler-n_times... | 440000         |
| Policy-AverageAbsPol... | 1.2426146      |
| Policy-AverageDiscou... | -5.53e+05      |
| Policy-AveragePolicyStd | 0.8267034      |
| Policy-AverageReturn    | -2.52e+06      |
| Policy-MaxReturn        | -1.71e+06      |
| Policy-MinReturn        | -3.84e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 4.73e+05       |
| Policy-TimeAlgoOpt      | 0.497          |
| Policy-TimeSampleProc   | 0.575          |
| Policy-TimeSampling     | 1.39           |
| Policy-TimeStep         | 2.52           |
| Time                    | 208            |
| n_timesteps             | 11000          |
--------------------------------------------

 ---------------- Iteration 11 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 110 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 111 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 112 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 113 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 114 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 115 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 116 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 117 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 118 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 119 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.337          |
| Data-EnvSampler-Poli... | 0.528          |
| Data-EnvTrajs-Averag... | -440           |
| Data-EnvTrajs-MaxReturn | -415           |
| Data-EnvTrajs-MinReturn | -464           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 18.5           |
| Data-TimeEnvSampleProc  | 0.000873       |
| Data-TimeEnvSampling    | 0.888          |
| Iteration               | 11             |
| ItrTime                 | 36.3           |
| LossAfter               | -0.004479289   |
| LossBefore              | -1.2240428e-05 |
| Model-TimeModelFit      | 32.4           |
| ModelSampler-n_times... | 480000         |
| Policy-AverageAbsPol... | 1.2467856      |
| Policy-AverageDiscou... | -4.8e+05       |
| Policy-AveragePolicyStd | 0.82301235     |
| Policy-AverageReturn    | -2.07e+06      |
| Policy-MaxReturn        | -881           |
| Policy-MinReturn        | -3.51e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.3e+06        |
| Policy-TimeAlgoOpt      | 0.596          |
| Policy-TimeSampleProc   | 0.608          |
| Policy-TimeSampling     | 1.75           |
| Policy-TimeStep         | 3              |
| Time                    | 244            |
| n_timesteps             | 12000          |
--------------------------------------------

 ---------------- Iteration 12 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 120 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 121 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 122 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 123 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 124 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 125 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 126 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 127 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 128 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 129 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.342          |
| Data-EnvSampler-Poli... | 0.593          |
| Data-EnvTrajs-Averag... | -449           |
| Data-EnvTrajs-MaxReturn | -431           |
| Data-EnvTrajs-MinReturn | -463           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 10.7           |
| Data-TimeEnvSampleProc  | 0.000824       |
| Data-TimeEnvSampling    | 0.96           |
| Iteration               | 12             |
| ItrTime                 | 28.4           |
| LossAfter               | -0.0025961506  |
| LossBefore              | -1.2128887e-05 |
| Model-TimeModelFit      | 24.1           |
| ModelSampler-n_times... | 520000         |
| Policy-AverageAbsPol... | 1.1200325      |
| Policy-AverageDiscou... | -1.61e+05      |
| Policy-AveragePolicyStd | 0.81282485     |
| Policy-AverageReturn    | -9.9e+05       |
| Policy-MaxReturn        | -6.08e+05      |
| Policy-MinReturn        | -1.32e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.3e+05        |
| Policy-TimeAlgoOpt      | 0.823          |
| Policy-TimeSampleProc   | 0.356          |
| Policy-TimeSampling     | 2.16           |
| Policy-TimeStep         | 3.36           |
| Time                    | 273            |
| n_timesteps             | 13000          |
--------------------------------------------

 ---------------- Iteration 13 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 130 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 131 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 132 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 133 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 134 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 135 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 136 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 137 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 138 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 139 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.639           |
| Data-EnvSampler-Poli... | 0.923           |
| Data-EnvTrajs-Averag... | -384            |
| Data-EnvTrajs-MaxReturn | -372            |
| Data-EnvTrajs-MinReturn | -395            |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 8.14            |
| Data-TimeEnvSampleProc  | 0.00122         |
| Data-TimeEnvSampling    | 1.61            |
| Iteration               | 13              |
| ItrTime                 | 35.7            |
| LossAfter               | -0.0031613219   |
| LossBefore              | -1.21072535e-05 |
| Model-TimeModelFit      | 31.8            |
| ModelSampler-n_times... | 560000          |
| Policy-AverageAbsPol... | 1.1808425       |
| Policy-AverageDiscou... | -5.25e+05       |
| Policy-AveragePolicyStd | 0.81002784      |
| Policy-AverageReturn    | -2.41e+06       |
| Policy-MaxReturn        | -9.73e+05       |
| Policy-MinReturn        | -3.25e+06       |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 5.85e+05        |
| Policy-TimeAlgoOpt      | 0.627           |
| Policy-TimeSampleProc   | 0.339           |
| Policy-TimeSampling     | 1.33            |
| Policy-TimeStep         | 2.34            |
| Time                    | 308             |
| n_timesteps             | 14000           |
---------------------------------------------

 ---------------- Iteration 14 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 140 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 141 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 142 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 143 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 144 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 145 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 146 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 147 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 148 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 149 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.393           |
| Data-EnvSampler-Poli... | 0.663           |
| Data-EnvTrajs-Averag... | -367            |
| Data-EnvTrajs-MaxReturn | -323            |
| Data-EnvTrajs-MinReturn | -448            |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 45.9            |
| Data-TimeEnvSampleProc  | 0.000815        |
| Data-TimeEnvSampling    | 1.08            |
| Iteration               | 14              |
| ItrTime                 | 37.7            |
| LossAfter               | -0.006941688    |
| LossBefore              | -1.20252025e-05 |
| Model-TimeModelFit      | 32.8            |
| ModelSampler-n_times... | 600000          |
| Policy-AverageAbsPol... | 1.115943        |
| Policy-AverageDiscou... | -5.03e+05       |
| Policy-AveragePolicyStd | 0.80496305      |
| Policy-AverageReturn    | -2.27e+06       |
| Policy-MaxReturn        | -8.61e+05       |
| Policy-MinReturn        | -3.44e+06       |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 8.53e+05        |
| Policy-TimeAlgoOpt      | 0.697           |
| Policy-TimeSampleProc   | 0.747           |
| Policy-TimeSampling     | 2.27            |
| Policy-TimeStep         | 3.76            |
| Time                    | 346             |
| n_timesteps             | 15000           |
---------------------------------------------

 ---------------- Iteration 15 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 150 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 151 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 152 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 153 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 154 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 155 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 156 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 157 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 158 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 159 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.654          |
| Data-EnvSampler-Poli... | 1.07           |
| Data-EnvTrajs-Averag... | -407           |
| Data-EnvTrajs-MaxReturn | -348           |
| Data-EnvTrajs-MinReturn | -439           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 34.1           |
| Data-TimeEnvSampleProc  | 0.00138        |
| Data-TimeEnvSampling    | 1.77           |
| Iteration               | 15             |
| ItrTime                 | 31.2           |
| LossAfter               | -0.006035779   |
| LossBefore              | -1.1956149e-05 |
| Model-TimeModelFit      | 26.9           |
| ModelSampler-n_times... | 640000         |
| Policy-AverageAbsPol... | 0.93412644     |
| Policy-AverageDiscou... | -1.16e+05      |
| Policy-AveragePolicyStd | 0.79757583     |
| Policy-AverageReturn    | -6.64e+05      |
| Policy-MaxReturn        | -509           |
| Policy-MinReturn        | -2.49e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 6.99e+05       |
| Policy-TimeAlgoOpt      | 0.522          |
| Policy-TimeSampleProc   | 0.515          |
| Policy-TimeSampling     | 1.47           |
| Policy-TimeStep         | 2.54           |
| Time                    | 377            |
| n_timesteps             | 16000          |
--------------------------------------------

 ---------------- Iteration 16 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 160 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 161 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 162 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 163 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 164 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 165 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 166 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 167 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 168 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 169 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.458          |
| Data-EnvSampler-Poli... | 0.763          |
| Data-EnvTrajs-Averag... | -413           |
| Data-EnvTrajs-MaxReturn | -406           |
| Data-EnvTrajs-MinReturn | -419           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 4.26           |
| Data-TimeEnvSampleProc  | 0.000625       |
| Data-TimeEnvSampling    | 1.26           |
| Iteration               | 16             |
| ItrTime                 | 38.5           |
| LossAfter               | -0.0035211754  |
| LossBefore              | -1.1943239e-05 |
| Model-TimeModelFit      | 34.9           |
| ModelSampler-n_times... | 680000         |
| Policy-AverageAbsPol... | 1.2217672      |
| Policy-AverageDiscou... | -6.71e+05      |
| Policy-AveragePolicyStd | 0.79928905     |
| Policy-AverageReturn    | -2.74e+06      |
| Policy-MaxReturn        | -564           |
| Policy-MinReturn        | -3.91e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.01e+06       |
| Policy-TimeAlgoOpt      | 0.503          |
| Policy-TimeSampleProc   | 0.401          |
| Policy-TimeSampling     | 1.34           |
| Policy-TimeStep         | 2.29           |
| Time                    | 416            |
| n_timesteps             | 17000          |
--------------------------------------------

 ---------------- Iteration 17 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 170 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 171 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 172 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 173 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 174 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 175 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 176 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 177 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 178 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 179 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.446          |
| Data-EnvSampler-Poli... | 0.77           |
| Data-EnvTrajs-Averag... | -378           |
| Data-EnvTrajs-MaxReturn | -353           |
| Data-EnvTrajs-MinReturn | -421           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 23.8           |
| Data-TimeEnvSampleProc  | 0.00109        |
| Data-TimeEnvSampling    | 1.25           |
| Iteration               | 17             |
| ItrTime                 | 34.6           |
| LossAfter               | -0.0057889647  |
| LossBefore              | -1.1875071e-05 |
| Model-TimeModelFit      | 29.6           |
| ModelSampler-n_times... | 720000         |
| Policy-AverageAbsPol... | 1.1587136      |
| Policy-AverageDiscou... | -3.45e+05      |
| Policy-AveragePolicyStd | 0.79404604     |
| Policy-AverageReturn    | -1.67e+06      |
| Policy-MaxReturn        | -633           |
| Policy-MinReturn        | -3.64e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1e+06          |
| Policy-TimeAlgoOpt      | 0.784          |
| Policy-TimeSampleProc   | 0.567          |
| Policy-TimeSampling     | 2.33           |
| Policy-TimeStep         | 3.7            |
| Time                    | 450            |
| n_timesteps             | 18000          |
--------------------------------------------

 ---------------- Iteration 18 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 180 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 181 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 182 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 183 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 184 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 185 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 186 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 187 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 188 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 189 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.681          |
| Data-EnvSampler-Poli... | 1.13           |
| Data-EnvTrajs-Averag... | -339           |
| Data-EnvTrajs-MaxReturn | -334           |
| Data-EnvTrajs-MinReturn | -342           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.7            |
| Data-TimeEnvSampleProc  | 0.00211        |
| Data-TimeEnvSampling    | 1.86           |
| Iteration               | 18             |
| ItrTime                 | 31.5           |
| LossAfter               | -0.004580577   |
| LossBefore              | -1.1776006e-05 |
| Model-TimeModelFit      | 27.3           |
| ModelSampler-n_times... | 760000         |
| Policy-AverageAbsPol... | 1.0988222      |
| Policy-AverageDiscou... | -2.87e+05      |
| Policy-AveragePolicyStd | 0.78381616     |
| Policy-AverageReturn    | -1.52e+06      |
| Policy-MaxReturn        | -451           |
| Policy-MinReturn        | -2.52e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 6.98e+05       |
| Policy-TimeAlgoOpt      | 0.542          |
| Policy-TimeSampleProc   | 0.386          |
| Policy-TimeSampling     | 1.38           |
| Policy-TimeStep         | 2.33           |
| Time                    | 482            |
| n_timesteps             | 19000          |
--------------------------------------------

 ---------------- Iteration 19 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 190 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 191 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 192 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 193 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 194 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 195 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 196 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 197 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 198 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 199 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.454          |
| Data-EnvSampler-Poli... | 0.808          |
| Data-EnvTrajs-Averag... | -347           |
| Data-EnvTrajs-MaxReturn | -329           |
| Data-EnvTrajs-MinReturn | -362           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 11.5           |
| Data-TimeEnvSampleProc  | 0.00087        |
| Data-TimeEnvSampling    | 1.29           |
| Iteration               | 19             |
| ItrTime                 | 38.5           |
| LossAfter               | -0.0055897273  |
| LossBefore              | -1.1406534e-05 |
| Model-TimeModelFit      | 34.7           |
| ModelSampler-n_times... | 800000         |
| Policy-AverageAbsPol... | 1.296475       |
| Policy-AverageDiscou... | -1.22e+06      |
| Policy-AveragePolicyStd | 0.7570101      |
| Policy-AverageReturn    | -4.1e+06       |
| Policy-MaxReturn        | -3.92e+06      |
| Policy-MinReturn        | -4.21e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 9.17e+04       |
| Policy-TimeAlgoOpt      | 0.54           |
| Policy-TimeSampleProc   | 0.461          |
| Policy-TimeSampling     | 1.44           |
| Policy-TimeStep         | 2.47           |
| Time                    | 520            |
| n_timesteps             | 20000          |
--------------------------------------------

 ---------------- Iteration 20 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 200 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 201 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 202 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 203 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 204 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 205 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 206 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 207 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 208 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 209 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.39            |
| Data-EnvSampler-Poli... | 0.652           |
| Data-EnvTrajs-Averag... | -361            |
| Data-EnvTrajs-MaxReturn | -355            |
| Data-EnvTrajs-MinReturn | -370            |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 5.14            |
| Data-TimeEnvSampleProc  | 0.000758        |
| Data-TimeEnvSampling    | 1.07            |
| Iteration               | 20              |
| ItrTime                 | 35.5            |
| LossAfter               | -0.007282276    |
| LossBefore              | -1.10578285e-05 |
| Model-TimeModelFit      | 30.6            |
| ModelSampler-n_times... | 840000          |
| Policy-AverageAbsPol... | 0.9782029       |
| Policy-AverageDiscou... | -3.07e+05       |
| Policy-AveragePolicyStd | 0.73195916      |
| Policy-AverageReturn    | -1.26e+06       |
| Policy-MaxReturn        | -392            |
| Policy-MinReturn        | -3.55e+06       |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 1.53e+06        |
| Policy-TimeAlgoOpt      | 0.816           |
| Policy-TimeSampleProc   | 0.599           |
| Policy-TimeSampling     | 2.38            |
| Policy-TimeStep         | 3.81            |
| Time                    | 556             |
| n_timesteps             | 21000           |
---------------------------------------------

 ---------------- Iteration 21 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 210 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 211 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 212 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 213 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 214 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 215 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 216 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 217 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 218 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 219 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.559         |
| Data-EnvSampler-Poli... | 0.874         |
| Data-EnvTrajs-Averag... | -374          |
| Data-EnvTrajs-MaxReturn | -339          |
| Data-EnvTrajs-MinReturn | -401          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 22.5          |
| Data-TimeEnvSampleProc  | 0.00127       |
| Data-TimeEnvSampling    | 1.47          |
| Iteration               | 21            |
| ItrTime                 | 31.5          |
| LossAfter               | -0.0042357068 |
| LossBefore              | -1.078329e-05 |
| Model-TimeModelFit      | 27.4          |
| ModelSampler-n_times... | 880000        |
| Policy-AverageAbsPol... | 0.725214      |
| Policy-AverageDiscou... | -2.37e+04     |
| Policy-AveragePolicyStd | 0.7126984     |
| Policy-AverageReturn    | -1.15e+05     |
| Policy-MaxReturn        | -415          |
| Policy-MinReturn        | -2.29e+06     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 4.99e+05      |
| Policy-TimeAlgoOpt      | 0.565         |
| Policy-TimeSampleProc   | 0.506         |
| Policy-TimeSampling     | 1.51          |
| Policy-TimeStep         | 2.62          |
| Time                    | 587           |
| n_timesteps             | 22000         |
-------------------------------------------

 ---------------- Iteration 22 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 220 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 221 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 222 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 223 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 224 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 225 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 226 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 227 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 228 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 229 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.368          |
| Data-EnvSampler-Poli... | 0.57           |
| Data-EnvTrajs-Averag... | -366           |
| Data-EnvTrajs-MaxReturn | -351           |
| Data-EnvTrajs-MinReturn | -380           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 11.5           |
| Data-TimeEnvSampleProc  | 0.00069        |
| Data-TimeEnvSampling    | 0.966          |
| Iteration               | 22             |
| ItrTime                 | 41.4           |
| LossAfter               | -0.0049598604  |
| LossBefore              | -1.0712276e-05 |
| Model-TimeModelFit      | 38             |
| ModelSampler-n_times... | 920000         |
| Policy-AverageAbsPol... | 0.8732329      |
| Policy-AverageDiscou... | -1.88e+04      |
| Policy-AveragePolicyStd | 0.70720094     |
| Policy-AverageReturn    | -1.13e+05      |
| Policy-MaxReturn        | -442           |
| Policy-MinReturn        | -1.29e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 3.42e+05       |
| Policy-TimeAlgoOpt      | 0.541          |
| Policy-TimeSampleProc   | 0.408          |
| Policy-TimeSampling     | 1.45           |
| Policy-TimeStep         | 2.45           |
| Time                    | 629            |
| n_timesteps             | 23000          |
--------------------------------------------

 ---------------- Iteration 23 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 230 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 231 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 232 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 233 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 234 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 235 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 236 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 237 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 238 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 239 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.339          |
| Data-EnvSampler-Poli... | 0.54           |
| Data-EnvTrajs-Averag... | -364           |
| Data-EnvTrajs-MaxReturn | -342           |
| Data-EnvTrajs-MinReturn | -389           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 18.6           |
| Data-TimeEnvSampleProc  | 0.000512       |
| Data-TimeEnvSampling    | 0.906          |
| Iteration               | 23             |
| ItrTime                 | 33.5           |
| LossAfter               | -0.004811427   |
| LossBefore              | -1.0431238e-05 |
| Model-TimeModelFit      | 28.5           |
| ModelSampler-n_times... | 960000         |
| Policy-AverageAbsPol... | 0.8092502      |
| Policy-AverageDiscou... | -8.45e+04      |
| Policy-AveragePolicyStd | 0.68858397     |
| Policy-AverageReturn    | -4.23e+05      |
| Policy-MaxReturn        | -451           |
| Policy-MinReturn        | -2.81e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 8.35e+05       |
| Policy-TimeAlgoOpt      | 0.769          |
| Policy-TimeSampleProc   | 0.829          |
| Policy-TimeSampling     | 2.44           |
| Policy-TimeStep         | 4.11           |
| Time                    | 662            |
| n_timesteps             | 24000          |
--------------------------------------------

 ---------------- Iteration 24 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 240 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 241 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 242 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 243 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 244 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 245 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 246 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 247 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 248 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 249 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.568          |
| Data-EnvSampler-Poli... | 0.858          |
| Data-EnvTrajs-Averag... | -416           |
| Data-EnvTrajs-MaxReturn | -406           |
| Data-EnvTrajs-MinReturn | -423           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 5.94           |
| Data-TimeEnvSampleProc  | 0.00136        |
| Data-TimeEnvSampling    | 1.47           |
| Iteration               | 24             |
| ItrTime                 | 43.3           |
| LossAfter               | -0.005695606   |
| LossBefore              | -1.0203484e-05 |
| Model-TimeModelFit      | 39.3           |
| ModelSampler-n_times... | 1000000        |
| Policy-AverageAbsPol... | 0.84259295     |
| Policy-AverageDiscou... | -2.24e+05      |
| Policy-AveragePolicyStd | 0.67226636     |
| Policy-AverageReturn    | -1.07e+06      |
| Policy-MaxReturn        | -379           |
| Policy-MinReturn        | -3.4e+06       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.14e+06       |
| Policy-TimeAlgoOpt      | 0.491          |
| Policy-TimeSampleProc   | 0.468          |
| Policy-TimeSampling     | 1.56           |
| Policy-TimeStep         | 2.55           |
| Time                    | 706            |
| n_timesteps             | 25000          |
--------------------------------------------

 ---------------- Iteration 25 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 250 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 251 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 252 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 253 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 254 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 255 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 256 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 257 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 258 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 259 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.349         |
| Data-EnvSampler-Poli... | 0.571         |
| Data-EnvTrajs-Averag... | -425          |
| Data-EnvTrajs-MaxReturn | -410          |
| Data-EnvTrajs-MinReturn | -438          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 10.9          |
| Data-TimeEnvSampleProc  | 0.000716      |
| Data-TimeEnvSampling    | 0.946         |
| Iteration               | 25            |
| ItrTime                 | 34.4          |
| LossAfter               | -0.0060192556 |
| LossBefore              | -9.921486e-06 |
| Model-TimeModelFit      | 29.2          |
| ModelSampler-n_times... | 1040000       |
| Policy-AverageAbsPol... | 0.93218637    |
| Policy-AverageDiscou... | -3.18e+05     |
| Policy-AveragePolicyStd | 0.6543952     |
| Policy-AverageReturn    | -1.43e+06     |
| Policy-MaxReturn        | -516          |
| Policy-MinReturn        | -3.68e+06     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.29e+06      |
| Policy-TimeAlgoOpt      | 0.759         |
| Policy-TimeSampleProc   | 0.79          |
| Policy-TimeSampling     | 2.68          |
| Policy-TimeStep         | 4.29          |
| Time                    | 740           |
| n_timesteps             | 26000         |
-------------------------------------------

 ---------------- Iteration 26 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 260 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 261 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 262 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 263 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 264 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 265 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 266 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 267 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 268 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 269 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Data-EnvSampler-EnvE... | 0.566       |
| Data-EnvSampler-Poli... | 0.867       |
| Data-EnvTrajs-Averag... | -437        |
| Data-EnvTrajs-MaxReturn | -433        |
| Data-EnvTrajs-MinReturn | -442        |
| Data-EnvTrajs-NumTrajs  | 5           |
| Data-EnvTrajs-StdReturn | 3.45        |
| Data-TimeEnvSampleProc  | 0.0016      |
| Data-TimeEnvSampling    | 1.47        |
| Iteration               | 26          |
| ItrTime                 | 36.7        |
| LossAfter               | -0.00659248 |
| LossBefore              | -9.7983e-06 |
| Model-TimeModelFit      | 32.6        |
| ModelSampler-n_times... | 1080000     |
| Policy-AverageAbsPol... | 0.79891986  |
| Policy-AverageDiscou... | -1.03e+05   |
| Policy-AveragePolicyStd | 0.64539015  |
| Policy-AverageReturn    | -5.87e+05   |
| Policy-MaxReturn        | -237        |
| Policy-MinReturn        | -1.81e+06   |
| Policy-NumTrajs         | 20          |
| Policy-StdReturn        | 7.17e+05    |
| Policy-TimeAlgoOpt      | 0.506       |
| Policy-TimeSampleProc   | 0.611       |
| Policy-TimeSampling     | 1.46        |
| Policy-TimeStep         | 2.59        |
| Time                    | 777         |
| n_timesteps             | 27000       |
-----------------------------------------

 ---------------- Iteration 27 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 270 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 271 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 272 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 273 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 274 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 275 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 276 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 277 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 278 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 279 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.367         |
| Data-EnvSampler-Poli... | 0.563         |
| Data-EnvTrajs-Averag... | -436          |
| Data-EnvTrajs-MaxReturn | -415          |
| Data-EnvTrajs-MinReturn | -455          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 13.2          |
| Data-TimeEnvSampleProc  | 0.00103       |
| Data-TimeEnvSampling    | 0.958         |
| Iteration               | 27            |
| ItrTime                 | 41            |
| LossAfter               | -0.004987019  |
| LossBefore              | -9.816505e-06 |
| Model-TimeModelFit      | 37.2          |
| ModelSampler-n_times... | 1120000       |
| Policy-AverageAbsPol... | 0.73244756    |
| Policy-AverageDiscou... | -5.25e+04     |
| Policy-AveragePolicyStd | 0.6470006     |
| Policy-AverageReturn    | -3.06e+05     |
| Policy-MaxReturn        | -388          |
| Policy-MinReturn        | -1.66e+06     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 5.62e+05      |
| Policy-TimeAlgoOpt      | 0.703         |
| Policy-TimeSampleProc   | 0.379         |
| Policy-TimeSampling     | 1.73          |
| Policy-TimeStep         | 2.83          |
| Time                    | 818           |
| n_timesteps             | 28000         |
-------------------------------------------

 ---------------- Iteration 28 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 280 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 281 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 282 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 283 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 284 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 285 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 286 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 287 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 288 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 289 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.351          |
| Data-EnvSampler-Poli... | 0.568          |
| Data-EnvTrajs-Averag... | -433           |
| Data-EnvTrajs-MaxReturn | -428           |
| Data-EnvTrajs-MinReturn | -439           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 3.73           |
| Data-TimeEnvSampleProc  | 0.000928       |
| Data-TimeEnvSampling    | 0.946          |
| Iteration               | 28             |
| ItrTime                 | 32.9           |
| LossAfter               | -0.0063083824  |
| LossBefore              | -9.6591375e-06 |
| Model-TimeModelFit      | 28             |
| ModelSampler-n_times... | 1160000        |
| Policy-AverageAbsPol... | 0.6785936      |
| Policy-AverageDiscou... | -1.21e+04      |
| Policy-AveragePolicyStd | 0.63790923     |
| Policy-AverageReturn    | -6.99e+04      |
| Policy-MaxReturn        | -427           |
| Policy-MinReturn        | -1.39e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 3.03e+05       |
| Policy-TimeAlgoOpt      | 0.853          |
| Policy-TimeSampleProc   | 0.55           |
| Policy-TimeSampling     | 2.49           |
| Policy-TimeStep         | 3.92           |
| Time                    | 851            |
| n_timesteps             | 29000          |
--------------------------------------------

 ---------------- Iteration 29 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 290 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 291 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 292 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 293 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 294 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 295 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 296 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 297 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 298 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 299 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.594         |
| Data-EnvSampler-Poli... | 0.927         |
| Data-EnvTrajs-Averag... | -432          |
| Data-EnvTrajs-MaxReturn | -421          |
| Data-EnvTrajs-MinReturn | -440          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 6.85          |
| Data-TimeEnvSampleProc  | 0.00143       |
| Data-TimeEnvSampling    | 1.56          |
| Iteration               | 29            |
| ItrTime                 | 40.7          |
| LossAfter               | -0.0066208043 |
| LossBefore              | -9.495702e-06 |
| Model-TimeModelFit      | 36.7          |
| ModelSampler-n_times... | 1200000       |
| Policy-AverageAbsPol... | 0.6220376     |
| Policy-AverageDiscou... | -1.19e+04     |
| Policy-AveragePolicyStd | 0.6249318     |
| Policy-AverageReturn    | -7.68e+04     |
| Policy-MaxReturn        | -411          |
| Policy-MinReturn        | -9.32e+05     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 2.24e+05      |
| Policy-TimeAlgoOpt      | 0.501         |
| Policy-TimeSampleProc   | 0.3           |
| Policy-TimeSampling     | 1.59          |
| Policy-TimeStep         | 2.44          |
| Time                    | 892           |
| n_timesteps             | 30000         |
-------------------------------------------

 ---------------- Iteration 30 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 300 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 301 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 302 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 303 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 304 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 305 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 306 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 307 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 308 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 309 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.378          |
| Data-EnvSampler-Poli... | 0.653          |
| Data-EnvTrajs-Averag... | -403           |
| Data-EnvTrajs-MaxReturn | -377           |
| Data-EnvTrajs-MinReturn | -416           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 13.6           |
| Data-TimeEnvSampleProc  | 0.000759       |
| Data-TimeEnvSampling    | 1.06           |
| Iteration               | 30             |
| ItrTime                 | 39.8           |
| LossAfter               | -0.007140951   |
| LossBefore              | -9.2956225e-06 |
| Model-TimeModelFit      | 34.8           |
| ModelSampler-n_times... | 1240000        |
| Policy-AverageAbsPol... | 0.65905875     |
| Policy-AverageDiscou... | -4.04e+04      |
| Policy-AveragePolicyStd | 0.61455536     |
| Policy-AverageReturn    | -2.05e+05      |
| Policy-MaxReturn        | -400           |
| Policy-MinReturn        | -2.22e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 6.17e+05       |
| Policy-TimeAlgoOpt      | 0.776          |
| Policy-TimeSampleProc   | 0.793          |
| Policy-TimeSampling     | 2.39           |
| Policy-TimeStep         | 3.99           |
| Time                    | 931            |
| n_timesteps             | 31000          |
--------------------------------------------

 ---------------- Iteration 31 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 310 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 311 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 312 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 313 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 314 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 315 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 316 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 317 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 318 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 319 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.447         |
| Data-EnvSampler-Poli... | 0.727         |
| Data-EnvTrajs-Averag... | -366          |
| Data-EnvTrajs-MaxReturn | -352          |
| Data-EnvTrajs-MinReturn | -383          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 13.3          |
| Data-TimeEnvSampleProc  | 0.000782      |
| Data-TimeEnvSampling    | 1.21          |
| Iteration               | 31            |
| ItrTime                 | 31.7          |
| LossAfter               | -0.0072763064 |
| LossBefore              | -9.03765e-06  |
| Model-TimeModelFit      | 26.6          |
| ModelSampler-n_times... | 1280000       |
| Policy-AverageAbsPol... | 0.60434353    |
| Policy-AverageDiscou... | -5.15e+03     |
| Policy-AveragePolicyStd | 0.59714353    |
| Policy-AverageReturn    | -3.36e+04     |
| Policy-MaxReturn        | -411          |
| Policy-MinReturn        | -6.63e+05     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.44e+05      |
| Policy-TimeAlgoOpt      | 0.906         |
| Policy-TimeSampleProc   | 0.626         |
| Policy-TimeSampling     | 2.34          |
| Policy-TimeStep         | 3.91          |
| Time                    | 963           |
| n_timesteps             | 32000         |
-------------------------------------------

 ---------------- Iteration 32 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 320 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 321 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 322 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 323 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 324 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 325 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 326 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 327 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 328 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 329 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.645         |
| Data-EnvSampler-Poli... | 1.04          |
| Data-EnvTrajs-Averag... | -379          |
| Data-EnvTrajs-MaxReturn | -353          |
| Data-EnvTrajs-MinReturn | -397          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 14.4          |
| Data-TimeEnvSampleProc  | 0.00147       |
| Data-TimeEnvSampling    | 1.72          |
| Iteration               | 32            |
| ItrTime                 | 42.9          |
| LossAfter               | -0.00513375   |
| LossBefore              | -8.869711e-06 |
| Model-TimeModelFit      | 38.7          |
| ModelSampler-n_times... | 1320000       |
| Policy-AverageAbsPol... | 0.5569468     |
| Policy-AverageDiscou... | -1.81e+04     |
| Policy-AveragePolicyStd | 0.58891815    |
| Policy-AverageReturn    | -9.49e+04     |
| Policy-MaxReturn        | -257          |
| Policy-MinReturn        | -1.89e+06     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 4.12e+05      |
| Policy-TimeAlgoOpt      | 0.556         |
| Policy-TimeSampleProc   | 0.304         |
| Policy-TimeSampling     | 1.52          |
| Policy-TimeStep         | 2.41          |
| Time                    | 1.01e+03      |
| n_timesteps             | 33000         |
-------------------------------------------

 ---------------- Iteration 33 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 330 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 331 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 332 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 333 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 334 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 335 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 336 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 337 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 338 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 339 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.365         |
| Data-EnvSampler-Poli... | 0.607         |
| Data-EnvTrajs-Averag... | -367          |
| Data-EnvTrajs-MaxReturn | -351          |
| Data-EnvTrajs-MinReturn | -383          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 11            |
| Data-TimeEnvSampleProc  | 0.000913      |
| Data-TimeEnvSampling    | 1             |
| Iteration               | 33            |
| ItrTime                 | 39.1          |
| LossAfter               | -0.0044946778 |
| LossBefore              | -8.838818e-06 |
| Model-TimeModelFit      | 34.1          |
| ModelSampler-n_times... | 1360000       |
| Policy-AverageAbsPol... | 0.6946603     |
| Policy-AverageDiscou... | -3.47e+05     |
| Policy-AveragePolicyStd | 0.5864506     |
| Policy-AverageReturn    | -1.69e+06     |
| Policy-MaxReturn        | -350          |
| Policy-MinReturn        | -3.27e+06     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 9.64e+05      |
| Policy-TimeAlgoOpt      | 0.793         |
| Policy-TimeSampleProc   | 0.859         |
| Policy-TimeSampling     | 2.3           |
| Policy-TimeStep         | 4             |
| Time                    | 1.05e+03      |
| n_timesteps             | 34000         |
-------------------------------------------

 ---------------- Iteration 34 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 340 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 341 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 342 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 343 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 344 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 345 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 346 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 347 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 348 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 349 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.602         |
| Data-EnvSampler-Poli... | 0.957         |
| Data-EnvTrajs-Averag... | -326          |
| Data-EnvTrajs-MaxReturn | -294          |
| Data-EnvTrajs-MinReturn | -359          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 21.1          |
| Data-TimeEnvSampleProc  | 0.00153       |
| Data-TimeEnvSampling    | 1.6           |
| Iteration               | 34            |
| ItrTime                 | 34.4          |
| LossAfter               | -0.007620215  |
| LossBefore              | -8.563566e-06 |
| Model-TimeModelFit      | 30.3          |
| ModelSampler-n_times... | 1400000       |
| Policy-AverageAbsPol... | 0.6079062     |
| Policy-AverageDiscou... | -132          |
| Policy-AveragePolicyStd | 0.57111686    |
| Policy-AverageReturn    | -424          |
| Policy-MaxReturn        | -396          |
| Policy-MinReturn        | -443          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 13.5          |
| Policy-TimeAlgoOpt      | 0.533         |
| Policy-TimeSampleProc   | 0.343         |
| Policy-TimeSampling     | 1.61          |
| Policy-TimeStep         | 2.51          |
| Time                    | 1.08e+03      |
| n_timesteps             | 35000         |
-------------------------------------------

 ---------------- Iteration 35 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 350 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 351 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 352 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 353 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 354 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 355 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 356 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 357 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 358 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 359 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.417         |
| Data-EnvSampler-Poli... | 0.709         |
| Data-EnvTrajs-Averag... | -329          |
| Data-EnvTrajs-MaxReturn | -313          |
| Data-EnvTrajs-MinReturn | -344          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 11.5          |
| Data-TimeEnvSampleProc  | 0.00108       |
| Data-TimeEnvSampling    | 1.16          |
| Iteration               | 35            |
| ItrTime                 | 43.3          |
| LossAfter               | -0.0042421916 |
| LossBefore              | -8.396051e-06 |
| Model-TimeModelFit      | 39.8          |
| ModelSampler-n_times... | 1440000       |
| Policy-AverageAbsPol... | 0.34024402    |
| Policy-AverageDiscou... | -4.39e+03     |
| Policy-AveragePolicyStd | 0.56028163    |
| Policy-AverageReturn    | -3.05e+04     |
| Policy-MaxReturn        | -186          |
| Policy-MinReturn        | -4.03e+05     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 9.61e+04      |
| Policy-TimeAlgoOpt      | 0.494         |
| Policy-TimeSampleProc   | 0.371         |
| Policy-TimeSampling     | 1.35          |
| Policy-TimeStep         | 2.26          |
| Time                    | 1.12e+03      |
| n_timesteps             | 36000         |
-------------------------------------------

 ---------------- Iteration 36 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 360 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 361 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 362 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 363 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 364 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 365 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 366 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 367 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 368 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 369 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.389         |
| Data-EnvSampler-Poli... | 0.71          |
| Data-EnvTrajs-Averag... | -236          |
| Data-EnvTrajs-MaxReturn | -208          |
| Data-EnvTrajs-MinReturn | -256          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 19.1          |
| Data-TimeEnvSampleProc  | 0.000489      |
| Data-TimeEnvSampling    | 1.13          |
| Iteration               | 36            |
| ItrTime                 | 37.4          |
| LossAfter               | -0.005630981  |
| LossBefore              | -8.135725e-06 |
| Model-TimeModelFit      | 32.5          |
| ModelSampler-n_times... | 1480000       |
| Policy-AverageAbsPol... | 0.37010416    |
| Policy-AverageDiscou... | -84           |
| Policy-AveragePolicyStd | 0.54666466    |
| Policy-AverageReturn    | -631          |
| Policy-MaxReturn        | -34.1         |
| Policy-MinReturn        | -1.13e+04     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 2.45e+03      |
| Policy-TimeAlgoOpt      | 0.748         |
| Policy-TimeSampleProc   | 0.753         |
| Policy-TimeSampling     | 2.25          |
| Policy-TimeStep         | 3.78          |
| Time                    | 1.16e+03      |
| n_timesteps             | 37000         |
-------------------------------------------

 ---------------- Iteration 37 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 370 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 371 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 372 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 373 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 374 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 375 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 376 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 377 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 378 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 379 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.696         |
| Data-EnvSampler-Poli... | 1.2           |
| Data-EnvTrajs-Averag... | -198          |
| Data-EnvTrajs-MaxReturn | -166          |
| Data-EnvTrajs-MinReturn | -219          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 19.3          |
| Data-TimeEnvSampleProc  | 0.00165       |
| Data-TimeEnvSampling    | 1.94          |
| Iteration               | 37            |
| ItrTime                 | 38.3          |
| LossAfter               | -0.0037828314 |
| LossBefore              | -7.93154e-06  |
| Model-TimeModelFit      | 34.2          |
| ModelSampler-n_times... | 1520000       |
| Policy-AverageAbsPol... | 0.3994305     |
| Policy-AverageDiscou... | 12.5          |
| Policy-AveragePolicyStd | 0.5354592     |
| Policy-AverageReturn    | -22.7         |
| Policy-MaxReturn        | 18.6          |
| Policy-MinReturn        | -96.6         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 30.1          |
| Policy-TimeAlgoOpt      | 0.495         |
| Policy-TimeSampleProc   | 0.257         |
| Policy-TimeSampling     | 1.37          |
| Policy-TimeStep         | 2.16          |
| Time                    | 1.2e+03       |
| n_timesteps             | 38000         |
-------------------------------------------

 ---------------- Iteration 38 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 380 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 381 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 382 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 383 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 384 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 385 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 386 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 387 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 388 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 389 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.442         |
| Data-EnvSampler-Poli... | 0.82          |
| Data-EnvTrajs-Averag... | 81.3          |
| Data-EnvTrajs-MaxReturn | 102           |
| Data-EnvTrajs-MinReturn | 59.6          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 16.6          |
| Data-TimeEnvSampleProc  | 0.0071        |
| Data-TimeEnvSampling    | 1.29          |
| Iteration               | 38            |
| ItrTime                 | 43.9          |
| LossAfter               | -0.009464216  |
| LossBefore              | -7.641895e-06 |
| Model-TimeModelFit      | 40.6          |
| ModelSampler-n_times... | 1560000       |
| Policy-AverageAbsPol... | 0.546828      |
| Policy-AverageDiscou... | -1.14e+03     |
| Policy-AveragePolicyStd | 0.51927924    |
| Policy-AverageReturn    | -8.6e+03      |
| Policy-MaxReturn        | 263           |
| Policy-MinReturn        | -1.65e+05     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 3.6e+04       |
| Policy-TimeAlgoOpt      | 0.473         |
| Policy-TimeSampleProc   | 0.278         |
| Policy-TimeSampling     | 1.27          |
| Policy-TimeStep         | 2.06          |
| Time                    | 1.24e+03      |
| n_timesteps             | 39000         |
-------------------------------------------

 ---------------- Iteration 39 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 390 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 391 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 392 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 393 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 394 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 395 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 396 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 397 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 398 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 399 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.411          |
| Data-EnvSampler-Poli... | 0.826          |
| Data-EnvTrajs-Averag... | 172            |
| Data-EnvTrajs-MaxReturn | 178            |
| Data-EnvTrajs-MinReturn | 165            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 4.63           |
| Data-TimeEnvSampleProc  | 0.00105        |
| Data-TimeEnvSampling    | 1.27           |
| Iteration               | 39             |
| ItrTime                 | 35.3           |
| LossAfter               | -0.0023579032  |
| LossBefore              | -7.3540664e-06 |
| Model-TimeModelFit      | 30.4           |
| ModelSampler-n_times... | 1600000        |
| Policy-AverageAbsPol... | 0.41849905     |
| Policy-AverageDiscou... | 91.8           |
| Policy-AveragePolicyStd | 0.50519395     |
| Policy-AverageReturn    | 199            |
| Policy-MaxReturn        | 234            |
| Policy-MinReturn        | 146            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 22.4           |
| Policy-TimeAlgoOpt      | 0.81           |
| Policy-TimeSampleProc   | 0.543          |
| Policy-TimeSampling     | 2.25           |
| Policy-TimeStep         | 3.63           |
| Time                    | 1.28e+03       |
| n_timesteps             | 40000          |
--------------------------------------------

 ---------------- Iteration 40 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 400 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 401 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 402 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 403 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 404 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 405 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 406 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 407 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 408 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 409 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.726          |
| Data-EnvSampler-Poli... | 1.32           |
| Data-EnvTrajs-Averag... | 214            |
| Data-EnvTrajs-MaxReturn | 218            |
| Data-EnvTrajs-MinReturn | 205            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 4.86           |
| Data-TimeEnvSampleProc  | 0.00154        |
| Data-TimeEnvSampling    | 2.09           |
| Iteration               | 40             |
| ItrTime                 | 41.1           |
| LossAfter               | -0.005558892   |
| LossBefore              | -7.1353575e-06 |
| Model-TimeModelFit      | 36.8           |
| ModelSampler-n_times... | 1640000        |
| Policy-AverageAbsPol... | 0.8386211      |
| Policy-AverageDiscou... | -2.67e+05      |
| Policy-AveragePolicyStd | 0.4932044      |
| Policy-AverageReturn    | -1.31e+06      |
| Policy-MaxReturn        | 79.3           |
| Policy-MinReturn        | -3.25e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.08e+06       |
| Policy-TimeAlgoOpt      | 0.538          |
| Policy-TimeSampleProc   | 0.355          |
| Policy-TimeSampling     | 1.26           |
| Policy-TimeStep         | 2.17           |
| Time                    | 1.32e+03       |
| n_timesteps             | 41000          |
--------------------------------------------

 ---------------- Iteration 41 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 410 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 411 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 412 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 413 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 414 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 415 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 416 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 417 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 418 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 419 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.459         |
| Data-EnvSampler-Poli... | 0.839         |
| Data-EnvTrajs-Averag... | 204           |
| Data-EnvTrajs-MaxReturn | 209           |
| Data-EnvTrajs-MinReturn | 196           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 4.6           |
| Data-TimeEnvSampleProc  | 0.000669      |
| Data-TimeEnvSampling    | 1.33          |
| Iteration               | 41            |
| ItrTime                 | 43.2          |
| LossAfter               | -0.005976064  |
| LossBefore              | -6.897686e-06 |
| Model-TimeModelFit      | 38.5          |
| ModelSampler-n_times... | 1680000       |
| Policy-AverageAbsPol... | 0.53236926    |
| Policy-AverageDiscou... | -5.38e+03     |
| Policy-AveragePolicyStd | 0.48281845    |
| Policy-AverageReturn    | -3.75e+04     |
| Policy-MaxReturn        | 249           |
| Policy-MinReturn        | -4.51e+05     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.15e+05      |
| Policy-TimeAlgoOpt      | 0.708         |
| Policy-TimeSampleProc   | 0.5           |
| Policy-TimeSampling     | 2.1           |
| Policy-TimeStep         | 3.36          |
| Time                    | 1.36e+03      |
| n_timesteps             | 42000         |
-------------------------------------------

 ---------------- Iteration 42 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 420 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 421 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 422 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 423 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 424 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 425 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 426 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 427 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 428 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 429 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.738         |
| Data-EnvSampler-Poli... | 1.24          |
| Data-EnvTrajs-Averag... | 209           |
| Data-EnvTrajs-MaxReturn | 213           |
| Data-EnvTrajs-MinReturn | 205           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 2.7           |
| Data-TimeEnvSampleProc  | 0.000898      |
| Data-TimeEnvSampling    | 2.03          |
| Iteration               | 42            |
| ItrTime                 | 34            |
| LossAfter               | -0.009532735  |
| LossBefore              | -6.910402e-06 |
| Model-TimeModelFit      | 29.7          |
| ModelSampler-n_times... | 1720000       |
| Policy-AverageAbsPol... | 0.6175514     |
| Policy-AverageDiscou... | -4.85e+04     |
| Policy-AveragePolicyStd | 0.48325875    |
| Policy-AverageReturn    | -2.84e+05     |
| Policy-MaxReturn        | 166           |
| Policy-MinReturn        | -2.01e+06     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 5.32e+05      |
| Policy-TimeAlgoOpt      | 0.578         |
| Policy-TimeSampleProc   | 0.313         |
| Policy-TimeSampling     | 1.38          |
| Policy-TimeStep         | 2.29          |
| Time                    | 1.4e+03       |
| n_timesteps             | 43000         |
-------------------------------------------

 ---------------- Iteration 43 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 430 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 431 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 432 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 433 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 434 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 435 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 436 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 437 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 438 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 439 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.731          |
| Data-EnvSampler-Poli... | 1.27           |
| Data-EnvTrajs-Averag... | 192            |
| Data-EnvTrajs-MaxReturn | 196            |
| Data-EnvTrajs-MinReturn | 189            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.57           |
| Data-TimeEnvSampleProc  | 0.00169        |
| Data-TimeEnvSampling    | 2.05           |
| Iteration               | 43             |
| ItrTime                 | 41.2           |
| LossAfter               | -0.0068628453  |
| LossBefore              | -6.9976622e-06 |
| Model-TimeModelFit      | 36.8           |
| ModelSampler-n_times... | 1760000        |
| Policy-AverageAbsPol... | 1.1535369      |
| Policy-AverageDiscou... | -7.68e+05      |
| Policy-AveragePolicyStd | 0.48730627     |
| Policy-AverageReturn    | -3.13e+06      |
| Policy-MaxReturn        | -2.22e+06      |
| Policy-MinReturn        | -3.59e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 3.94e+05       |
| Policy-TimeAlgoOpt      | 0.497          |
| Policy-TimeSampleProc   | 0.41           |
| Policy-TimeSampling     | 1.48           |
| Policy-TimeStep         | 2.4            |
| Time                    | 1.44e+03       |
| n_timesteps             | 44000          |
--------------------------------------------

 ---------------- Iteration 44 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 440 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 441 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 442 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 443 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 444 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 445 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 446 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 447 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 448 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 449 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.468         |
| Data-EnvSampler-Poli... | 0.862         |
| Data-EnvTrajs-Averag... | 73            |
| Data-EnvTrajs-MaxReturn | 94.3          |
| Data-EnvTrajs-MinReturn | 52.8          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 17.4          |
| Data-TimeEnvSampleProc  | 0.000866      |
| Data-TimeEnvSampling    | 1.36          |
| Iteration               | 44            |
| ItrTime                 | 44.5          |
| LossAfter               | -0.008794795  |
| LossBefore              | -7.011334e-06 |
| Model-TimeModelFit      | 40.6          |
| ModelSampler-n_times... | 1800000       |
| Policy-AverageAbsPol... | 0.4851004     |
| Policy-AverageDiscou... | -7.21e+03     |
| Policy-AveragePolicyStd | 0.4864297     |
| Policy-AverageReturn    | -4.55e+04     |
| Policy-MaxReturn        | -216          |
| Policy-MinReturn        | -9.03e+05     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.97e+05      |
| Policy-TimeAlgoOpt      | 0.528         |
| Policy-TimeSampleProc   | 0.463         |
| Policy-TimeSampling     | 1.51          |
| Policy-TimeStep         | 2.54          |
| Time                    | 1.48e+03      |
| n_timesteps             | 45000         |
-------------------------------------------

 ---------------- Iteration 45 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 450 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 451 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 452 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 453 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 454 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 455 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 456 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 457 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 458 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 459 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.445         |
| Data-EnvSampler-Poli... | 0.875         |
| Data-EnvTrajs-Averag... | 152           |
| Data-EnvTrajs-MaxReturn | 164           |
| Data-EnvTrajs-MinReturn | 145           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 6.75          |
| Data-TimeEnvSampleProc  | 0.000814      |
| Data-TimeEnvSampling    | 1.35          |
| Iteration               | 45            |
| ItrTime                 | 35.7          |
| LossAfter               | -0.0061030034 |
| LossBefore              | -6.854834e-06 |
| Model-TimeModelFit      | 30.6          |
| ModelSampler-n_times... | 1840000       |
| Policy-AverageAbsPol... | 0.6219456     |
| Policy-AverageDiscou... | -2.74e+05     |
| Policy-AveragePolicyStd | 0.48056608    |
| Policy-AverageReturn    | -1.36e+06     |
| Policy-MaxReturn        | -212          |
| Policy-MinReturn        | -2.86e+06     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.07e+06      |
| Policy-TimeAlgoOpt      | 0.753         |
| Policy-TimeSampleProc   | 0.75          |
| Policy-TimeSampling     | 2.19          |
| Policy-TimeStep         | 3.73          |
| Time                    | 1.52e+03      |
| n_timesteps             | 46000         |
-------------------------------------------

 ---------------- Iteration 46 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 460 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 461 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 462 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 463 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 464 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 465 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 466 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 467 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 468 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 469 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.738          |
| Data-EnvSampler-Poli... | 1.36           |
| Data-EnvTrajs-Averag... | 156            |
| Data-EnvTrajs-MaxReturn | 168            |
| Data-EnvTrajs-MinReturn | 150            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 6.42           |
| Data-TimeEnvSampleProc  | 0.00165        |
| Data-TimeEnvSampling    | 2.14           |
| Iteration               | 46             |
| ItrTime                 | 45.1           |
| LossAfter               | -0.0071053747  |
| LossBefore              | -6.6792004e-06 |
| Model-TimeModelFit      | 40.7           |
| ModelSampler-n_times... | 1880000        |
| Policy-AverageAbsPol... | 1.1501887      |
| Policy-AverageDiscou... | -1.19e+06      |
| Policy-AveragePolicyStd | 0.47195014     |
| Policy-AverageReturn    | -4.03e+06      |
| Policy-MaxReturn        | -3.43e+06      |
| Policy-MinReturn        | -4.73e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 4.22e+05       |
| Policy-TimeAlgoOpt      | 0.5            |
| Policy-TimeSampleProc   | 0.371          |
| Policy-TimeSampling     | 1.33           |
| Policy-TimeStep         | 2.25           |
| Time                    | 1.56e+03       |
| n_timesteps             | 47000          |
--------------------------------------------

 ---------------- Iteration 47 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 470 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 471 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 472 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 473 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 474 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 475 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 476 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 477 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 478 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 479 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.429         |
| Data-EnvSampler-Poli... | 0.821         |
| Data-EnvTrajs-Averag... | 132           |
| Data-EnvTrajs-MaxReturn | 137           |
| Data-EnvTrajs-MinReturn | 123           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 5.76          |
| Data-TimeEnvSampleProc  | 0.000955      |
| Data-TimeEnvSampling    | 1.28          |
| Iteration               | 47            |
| ItrTime                 | 41.8          |
| LossAfter               | -0.008769572  |
| LossBefore              | -6.600415e-06 |
| Model-TimeModelFit      | 36.8          |
| ModelSampler-n_times... | 1920000       |
| Policy-AverageAbsPol... | 1.0344836     |
| Policy-AverageDiscou... | -9.18e+04     |
| Policy-AveragePolicyStd | 0.46799174    |
| Policy-AverageReturn    | -3.84e+05     |
| Policy-MaxReturn        | -271          |
| Policy-MinReturn        | -4.03e+06     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 9.75e+05      |
| Policy-TimeAlgoOpt      | 0.77          |
| Policy-TimeSampleProc   | 0.746         |
| Policy-TimeSampling     | 2.15          |
| Policy-TimeStep         | 3.68          |
| Time                    | 1.6e+03       |
| n_timesteps             | 48000         |
-------------------------------------------

 ---------------- Iteration 48 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 480 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 481 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 482 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 483 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 484 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 485 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 486 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 487 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 488 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 489 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.742          |
| Data-EnvSampler-Poli... | 1.28           |
| Data-EnvTrajs-Averag... | 169            |
| Data-EnvTrajs-MaxReturn | 179            |
| Data-EnvTrajs-MinReturn | 160            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 6.82           |
| Data-TimeEnvSampleProc  | 0.00157        |
| Data-TimeEnvSampling    | 2.08           |
| Iteration               | 48             |
| ItrTime                 | 38.1           |
| LossAfter               | -0.007126964   |
| LossBefore              | -6.7414835e-06 |
| Model-TimeModelFit      | 33.7           |
| ModelSampler-n_times... | 1960000        |
| Policy-AverageAbsPol... | 1.5243816      |
| Policy-AverageDiscou... | -1.8e+06       |
| Policy-AveragePolicyStd | 0.4746486      |
| Policy-AverageReturn    | -5.01e+06      |
| Policy-MaxReturn        | -4.82e+06      |
| Policy-MinReturn        | -5.13e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 8.82e+04       |
| Policy-TimeAlgoOpt      | 0.568          |
| Policy-TimeSampleProc   | 0.328          |
| Policy-TimeSampling     | 1.39           |
| Policy-TimeStep         | 2.31           |
| Time                    | 1.64e+03       |
| n_timesteps             | 49000          |
--------------------------------------------

 ---------------- Iteration 49 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 490 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 491 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 492 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 493 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 494 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 495 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 496 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 497 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 498 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 499 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.434         |
| Data-EnvSampler-Poli... | 0.844         |
| Data-EnvTrajs-Averag... | 188           |
| Data-EnvTrajs-MaxReturn | 195           |
| Data-EnvTrajs-MinReturn | 183           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 4.26          |
| Data-TimeEnvSampleProc  | 0.000995      |
| Data-TimeEnvSampling    | 1.31          |
| Iteration               | 49            |
| ItrTime                 | 44.9          |
| LossAfter               | -0.007071846  |
| LossBefore              | -6.754314e-06 |
| Model-TimeModelFit      | 41.3          |
| ModelSampler-n_times... | 2000000       |
| Policy-AverageAbsPol... | 1.0789086     |
| Policy-AverageDiscou... | -7.16e+05     |
| Policy-AveragePolicyStd | 0.47485295    |
| Policy-AverageReturn    | -2.72e+06     |
| Policy-MaxReturn        | -567          |
| Policy-MinReturn        | -4.99e+06     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.32e+06      |
| Policy-TimeAlgoOpt      | 0.586         |
| Policy-TimeSampleProc   | 0.288         |
| Policy-TimeSampling     | 1.37          |
| Policy-TimeStep         | 2.28          |
| Time                    | 1.69e+03      |
| n_timesteps             | 50000         |
-------------------------------------------

 ---------------- Iteration 50 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 500 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 501 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 502 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 503 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 504 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 505 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 506 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 507 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 508 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 509 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.429         |
| Data-EnvSampler-Poli... | 0.863         |
| Data-EnvTrajs-Averag... | 191           |
| Data-EnvTrajs-MaxReturn | 194           |
| Data-EnvTrajs-MinReturn | 188           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 2.33          |
| Data-TimeEnvSampleProc  | 0.000787      |
| Data-TimeEnvSampling    | 1.33          |
| Iteration               | 50            |
| ItrTime                 | 28.3          |
| LossAfter               | -0.0041491673 |
| LossBefore              | -6.586705e-06 |
| Model-TimeModelFit      | 24.9          |
| ModelSampler-n_times... | 2040000       |
| Policy-AverageAbsPol... | 1.1489635     |
| Policy-AverageDiscou... | -1.35e+06     |
| Policy-AveragePolicyStd | 0.46763468    |
| Policy-AverageReturn    | -4.32e+06     |
| Policy-MaxReturn        | -4.01e+06     |
| Policy-MinReturn        | -5.41e+06     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 3.37e+05      |
| Policy-TimeAlgoOpt      | 0.666         |
| Policy-TimeSampleProc   | 0.274         |
| Policy-TimeSampling     | 1.09          |
| Policy-TimeStep         | 2.04          |
| Time                    | 1.72e+03      |
| n_timesteps             | 51000         |
-------------------------------------------
Training finished
