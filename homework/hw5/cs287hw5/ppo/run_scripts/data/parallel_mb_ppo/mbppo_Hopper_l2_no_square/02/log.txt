Logging to /home/vincent/workplace/CS_287_-_Advanced_Robotics/homework/hw5/cs287hw5/ppo/run_scripts/data/parallel_mb_ppo/mbppo_Hopper_l2_no_square//02

 ---------------- Iteration 0 ----------------
Obtaining random samples from the environment...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 0 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 1 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 2 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 3 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 4 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 5 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 6 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 7 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 8 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 9 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.278          |
| Data-EnvSampler-Poli... | 0.0597         |
| Data-EnvTrajs-Averag... | -277           |
| Data-EnvTrajs-MaxReturn | -216           |
| Data-EnvTrajs-MinReturn | -325           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 41.4           |
| Data-TimeEnvSampleProc  | 0.000823       |
| Data-TimeEnvSampling    | 0.353          |
| Iteration               | 0              |
| ItrTime                 | 13.6           |
| LossAfter               | -0.0073199267  |
| LossBefore              | -1.3905411e-05 |
| Model-TimeModelFit      | 4.62           |
| ModelSampler-n_times... | 40000          |
| Policy-AverageAbsPol... | 0.7972223      |
| Policy-AverageDiscou... | -2.09e+06      |
| Policy-AveragePolicyStd | 0.97253597     |
| Policy-AverageReturn    | -5.38e+06      |
| Policy-MaxReturn        | -5.3e+06       |
| Policy-MinReturn        | -5.44e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 3.35e+04       |
| Policy-TimeAlgoOpt      | 1.31           |
| Policy-TimeSampleProc   | 0.561          |
| Policy-TimeSampling     | 6.71           |
| Policy-TimeStep         | 8.61           |
| Time                    | 13.6           |
| n_timesteps             | 1000           |
--------------------------------------------

 ---------------- Iteration 1 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 10 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 11 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 12 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 13 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 14 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 15 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 16 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 17 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 18 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 19 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.43            |
| Data-EnvSampler-Poli... | 0.732           |
| Data-EnvTrajs-Averag... | -93             |
| Data-EnvTrajs-MaxReturn | -62.6           |
| Data-EnvTrajs-MinReturn | -130            |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 22.3            |
| Data-TimeEnvSampleProc  | 0.00114         |
| Data-TimeEnvSampling    | 1.19            |
| Iteration               | 1               |
| ItrTime                 | 9.06            |
| LossAfter               | -0.0070505734   |
| LossBefore              | -1.35675455e-05 |
| Model-TimeModelFit      | 5.22            |
| ModelSampler-n_times... | 80000           |
| Policy-AverageAbsPol... | 0.96204996      |
| Policy-AverageDiscou... | -1.68e+06       |
| Policy-AveragePolicyStd | 0.9391929       |
| Policy-AverageReturn    | -4.84e+06       |
| Policy-MaxReturn        | -4.54e+06       |
| Policy-MinReturn        | -5.25e+06       |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 2.37e+05        |
| Policy-TimeAlgoOpt      | 0.587           |
| Policy-TimeSampleProc   | 0.53            |
| Policy-TimeSampling     | 1.49            |
| Policy-TimeStep         | 2.65            |
| Time                    | 22.8            |
| n_timesteps             | 2000            |
---------------------------------------------

 ---------------- Iteration 2 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 20 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 21 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 22 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 23 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 24 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 25 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 26 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 27 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 28 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 29 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.28           |
| Data-EnvSampler-Poli... | 0.414          |
| Data-EnvTrajs-Averag... | -367           |
| Data-EnvTrajs-MaxReturn | -322           |
| Data-EnvTrajs-MinReturn | -442           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 44.7           |
| Data-TimeEnvSampleProc  | 0.000552       |
| Data-TimeEnvSampling    | 0.715          |
| Iteration               | 2              |
| ItrTime                 | 9.2            |
| LossAfter               | -0.0036580446  |
| LossBefore              | -1.3333563e-05 |
| Model-TimeModelFit      | 5.95           |
| ModelSampler-n_times... | 120000         |
| Policy-AverageAbsPol... | 0.7591426      |
| Policy-AverageDiscou... | -1.02e+06      |
| Policy-AveragePolicyStd | 0.91770566     |
| Policy-AverageReturn    | -3.51e+06      |
| Policy-MaxReturn        | -1.13e+06      |
| Policy-MinReturn        | -4.95e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.15e+06       |
| Policy-TimeAlgoOpt      | 0.593          |
| Policy-TimeSampleProc   | 0.463          |
| Policy-TimeSampling     | 1.42           |
| Policy-TimeStep         | 2.53           |
| Time                    | 32             |
| n_timesteps             | 3000           |
--------------------------------------------

 ---------------- Iteration 3 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 30 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 31 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 32 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 33 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 34 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 35 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 36 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 37 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 38 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 39 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.285          |
| Data-EnvSampler-Poli... | 0.425          |
| Data-EnvTrajs-Averag... | -493           |
| Data-EnvTrajs-MaxReturn | -459           |
| Data-EnvTrajs-MinReturn | -521           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 24.1           |
| Data-TimeEnvSampleProc  | 0.000901       |
| Data-TimeEnvSampling    | 0.732          |
| Iteration               | 3              |
| ItrTime                 | 11.3           |
| LossAfter               | -0.0033870072  |
| LossBefore              | -1.3327552e-05 |
| Model-TimeModelFit      | 7.87           |
| ModelSampler-n_times... | 160000         |
| Policy-AverageAbsPol... | 0.9568377      |
| Policy-AverageDiscou... | -1.38e+06      |
| Policy-AveragePolicyStd | 0.91847        |
| Policy-AverageReturn    | -4.33e+06      |
| Policy-MaxReturn        | -3.37e+06      |
| Policy-MinReturn        | -5.08e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 6.01e+05       |
| Policy-TimeAlgoOpt      | 0.63           |
| Policy-TimeSampleProc   | 0.42           |
| Policy-TimeSampling     | 1.58           |
| Policy-TimeStep         | 2.66           |
| Time                    | 43.3           |
| n_timesteps             | 4000           |
--------------------------------------------

 ---------------- Iteration 4 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 40 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 41 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 42 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 43 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 44 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 45 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 46 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 47 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 48 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 49 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.304          |
| Data-EnvSampler-Poli... | 0.445          |
| Data-EnvTrajs-Averag... | -411           |
| Data-EnvTrajs-MaxReturn | -313           |
| Data-EnvTrajs-MinReturn | -472           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 57.4           |
| Data-TimeEnvSampleProc  | 0.000939       |
| Data-TimeEnvSampling    | 0.772          |
| Iteration               | 4              |
| ItrTime                 | 19.8           |
| LossAfter               | -0.007801532   |
| LossBefore              | -1.3308112e-05 |
| Model-TimeModelFit      | 15.1           |
| ModelSampler-n_times... | 200000         |
| Policy-AverageAbsPol... | 0.71475244     |
| Policy-AverageDiscou... | -1.75e+05      |
| Policy-AveragePolicyStd | 0.9141164      |
| Policy-AverageReturn    | -7.63e+05      |
| Policy-MaxReturn        | -340           |
| Policy-MinReturn        | -4.49e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.19e+06       |
| Policy-TimeAlgoOpt      | 0.806          |
| Policy-TimeSampleProc   | 0.851          |
| Policy-TimeSampling     | 2.31           |
| Policy-TimeStep         | 4.01           |
| Time                    | 63.1           |
| n_timesteps             | 5000           |
--------------------------------------------

 ---------------- Iteration 5 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 50 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 51 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 52 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 53 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 54 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 55 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 56 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 57 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 58 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 59 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.411          |
| Data-EnvSampler-Poli... | 0.596          |
| Data-EnvTrajs-Averag... | -323           |
| Data-EnvTrajs-MaxReturn | -292           |
| Data-EnvTrajs-MinReturn | -410           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 44.1           |
| Data-TimeEnvSampleProc  | 0.00123        |
| Data-TimeEnvSampling    | 1.04           |
| Iteration               | 5              |
| ItrTime                 | 17.2           |
| LossAfter               | -0.009466268   |
| LossBefore              | -1.3082522e-05 |
| Model-TimeModelFit      | 13.6           |
| ModelSampler-n_times... | 240000         |
| Policy-AverageAbsPol... | 0.5416228      |
| Policy-AverageDiscou... | -3.17e+04      |
| Policy-AveragePolicyStd | 0.89501446     |
| Policy-AverageReturn    | -1.62e+05      |
| Policy-MaxReturn        | -286           |
| Policy-MinReturn        | -2.46e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 5.37e+05       |
| Policy-TimeAlgoOpt      | 0.578          |
| Policy-TimeSampleProc   | 0.567          |
| Policy-TimeSampling     | 1.33           |
| Policy-TimeStep         | 2.58           |
| Time                    | 80.4           |
| n_timesteps             | 6000           |
--------------------------------------------

 ---------------- Iteration 6 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 60 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 61 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 62 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 63 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 64 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 65 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 66 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 67 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 68 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 69 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.262          |
| Data-EnvSampler-Poli... | 0.363          |
| Data-EnvTrajs-Averag... | -325           |
| Data-EnvTrajs-MaxReturn | -234           |
| Data-EnvTrajs-MinReturn | -434           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 64.5           |
| Data-TimeEnvSampleProc  | 0.00101        |
| Data-TimeEnvSampling    | 0.645          |
| Iteration               | 6              |
| ItrTime                 | 17.1           |
| LossAfter               | -0.0044712406  |
| LossBefore              | -1.3058363e-05 |
| Model-TimeModelFit      | 13.7           |
| ModelSampler-n_times... | 280000         |
| Policy-AverageAbsPol... | 0.69397575     |
| Policy-AverageDiscou... | -8.28e+05      |
| Policy-AveragePolicyStd | 0.89357066     |
| Policy-AverageReturn    | -3.14e+06      |
| Policy-MaxReturn        | -7.46e+05      |
| Policy-MinReturn        | -4.55e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.03e+06       |
| Policy-TimeAlgoOpt      | 0.671          |
| Policy-TimeSampleProc   | 0.448          |
| Policy-TimeSampling     | 1.61           |
| Policy-TimeStep         | 2.77           |
| Time                    | 97.5           |
| n_timesteps             | 7000           |
--------------------------------------------

 ---------------- Iteration 7 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 70 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 71 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 72 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 73 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 74 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 75 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 76 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 77 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 78 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 79 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.285          |
| Data-EnvSampler-Poli... | 0.381          |
| Data-EnvTrajs-Averag... | -411           |
| Data-EnvTrajs-MaxReturn | -366           |
| Data-EnvTrajs-MinReturn | -458           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 33.2           |
| Data-TimeEnvSampleProc  | 0.000923       |
| Data-TimeEnvSampling    | 0.688          |
| Iteration               | 7              |
| ItrTime                 | 29.8           |
| LossAfter               | -0.006451678   |
| LossBefore              | -1.2897948e-05 |
| Model-TimeModelFit      | 25.2           |
| ModelSampler-n_times... | 320000         |
| Policy-AverageAbsPol... | 0.5020585      |
| Policy-AverageDiscou... | -134           |
| Policy-AveragePolicyStd | 0.8788658      |
| Policy-AverageReturn    | -376           |
| Policy-MaxReturn        | -288           |
| Policy-MinReturn        | -477           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 51.2           |
| Policy-TimeAlgoOpt      | 0.837          |
| Policy-TimeSampleProc   | 0.796          |
| Policy-TimeSampling     | 2.23           |
| Policy-TimeStep         | 3.91           |
| Time                    | 127            |
| n_timesteps             | 8000           |
--------------------------------------------

 ---------------- Iteration 8 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 80 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 81 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 82 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 83 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 84 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 85 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 86 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 87 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 88 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 89 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.465          |
| Data-EnvSampler-Poli... | 0.619          |
| Data-EnvTrajs-Averag... | -400           |
| Data-EnvTrajs-MaxReturn | -267           |
| Data-EnvTrajs-MinReturn | -455           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 68.3           |
| Data-TimeEnvSampleProc  | 0.00127        |
| Data-TimeEnvSampling    | 1.12           |
| Iteration               | 8              |
| ItrTime                 | 22.7           |
| LossAfter               | -0.0038218282  |
| LossBefore              | -1.2778483e-05 |
| Model-TimeModelFit      | 18.8           |
| ModelSampler-n_times... | 360000         |
| Policy-AverageAbsPol... | 1.1043645      |
| Policy-AverageDiscou... | -1.19e+06      |
| Policy-AveragePolicyStd | 0.86812466     |
| Policy-AverageReturn    | -4.06e+06      |
| Policy-MaxReturn        | -3.19e+06      |
| Policy-MinReturn        | -4.26e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.26e+05       |
| Policy-TimeAlgoOpt      | 0.607          |
| Policy-TimeSampleProc   | 0.419          |
| Policy-TimeSampling     | 1.69           |
| Policy-TimeStep         | 2.77           |
| Time                    | 150            |
| n_timesteps             | 9000           |
--------------------------------------------

 ---------------- Iteration 9 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 90 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 91 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 92 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 93 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 94 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 95 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 96 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 97 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 98 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 99 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.289          |
| Data-EnvSampler-Poli... | 0.371          |
| Data-EnvTrajs-Averag... | 80             |
| Data-EnvTrajs-MaxReturn | 274            |
| Data-EnvTrajs-MinReturn | -248           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 186            |
| Data-TimeEnvSampleProc  | 0.000864       |
| Data-TimeEnvSampling    | 0.681          |
| Iteration               | 9              |
| ItrTime                 | 30.4           |
| LossAfter               | -0.0055528497  |
| LossBefore              | -1.2835964e-05 |
| Model-TimeModelFit      | 25.9           |
| ModelSampler-n_times... | 400000         |
| Policy-AverageAbsPol... | 0.52921945     |
| Policy-AverageDiscou... | -5.49e+03      |
| Policy-AveragePolicyStd | 0.8733946      |
| Policy-AverageReturn    | -3.82e+04      |
| Policy-MaxReturn        | -228           |
| Policy-MinReturn        | -3.81e+05      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.07e+05       |
| Policy-TimeAlgoOpt      | 0.748          |
| Policy-TimeSampleProc   | 0.905          |
| Policy-TimeSampling     | 2.16           |
| Policy-TimeStep         | 3.86           |
| Time                    | 180            |
| n_timesteps             | 10000          |
--------------------------------------------

 ---------------- Iteration 10 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 100 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 101 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 102 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 103 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 104 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 105 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 106 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 107 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 108 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 109 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.462          |
| Data-EnvSampler-Poli... | 0.646          |
| Data-EnvTrajs-Averag... | -67.1          |
| Data-EnvTrajs-MaxReturn | -8.88          |
| Data-EnvTrajs-MinReturn | -105           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 31.6           |
| Data-TimeEnvSampleProc  | 0.00304        |
| Data-TimeEnvSampling    | 1.14           |
| Iteration               | 10             |
| ItrTime                 | 27.8           |
| LossAfter               | -0.007708398   |
| LossBefore              | -1.2756818e-05 |
| Model-TimeModelFit      | 24.2           |
| ModelSampler-n_times... | 440000         |
| Policy-AverageAbsPol... | 0.56382513     |
| Policy-AverageDiscou... | -143           |
| Policy-AveragePolicyStd | 0.8664243      |
| Policy-AverageReturn    | -568           |
| Policy-MaxReturn        | -391           |
| Policy-MinReturn        | -632           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 50.8           |
| Policy-TimeAlgoOpt      | 0.597          |
| Policy-TimeSampleProc   | 0.387          |
| Policy-TimeSampling     | 1.34           |
| Policy-TimeStep         | 2.38           |
| Time                    | 208            |
| n_timesteps             | 11000          |
--------------------------------------------

 ---------------- Iteration 11 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 110 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 111 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 112 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 113 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 114 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 115 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 116 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 117 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 118 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 119 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.339          |
| Data-EnvSampler-Poli... | 0.523          |
| Data-EnvTrajs-Averag... | -79.3          |
| Data-EnvTrajs-MaxReturn | -68.1          |
| Data-EnvTrajs-MinReturn | -96.4          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 12             |
| Data-TimeEnvSampleProc  | 0.000959       |
| Data-TimeEnvSampling    | 0.887          |
| Iteration               | 11             |
| ItrTime                 | 36.3           |
| LossAfter               | -0.006005464   |
| LossBefore              | -1.2684103e-05 |
| Model-TimeModelFit      | 32.9           |
| ModelSampler-n_times... | 480000         |
| Policy-AverageAbsPol... | 0.6178682      |
| Policy-AverageDiscou... | -1.86e+04      |
| Policy-AveragePolicyStd | 0.8581808      |
| Policy-AverageReturn    | -9.72e+04      |
| Policy-MaxReturn        | -104           |
| Policy-MinReturn        | -1.94e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 4.23e+05       |
| Policy-TimeAlgoOpt      | 0.54           |
| Policy-TimeSampleProc   | 0.323          |
| Policy-TimeSampling     | 1.59           |
| Policy-TimeStep         | 2.51           |
| Time                    | 245            |
| n_timesteps             | 12000          |
--------------------------------------------

 ---------------- Iteration 12 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 120 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 121 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 122 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 123 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 124 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 125 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 126 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 127 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 128 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 129 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.342          |
| Data-EnvSampler-Poli... | 0.545          |
| Data-EnvTrajs-Averag... | -50.7          |
| Data-EnvTrajs-MaxReturn | -32.3          |
| Data-EnvTrajs-MinReturn | -60.3          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 9.95           |
| Data-TimeEnvSampleProc  | 0.000899       |
| Data-TimeEnvSampling    | 0.914          |
| Iteration               | 12             |
| ItrTime                 | 28.9           |
| LossAfter               | -0.006816109   |
| LossBefore              | -1.2391375e-05 |
| Model-TimeModelFit      | 24.4           |
| ModelSampler-n_times... | 520000         |
| Policy-AverageAbsPol... | 1.1737623      |
| Policy-AverageDiscou... | -7.15e+05      |
| Policy-AveragePolicyStd | 0.8374877      |
| Policy-AverageReturn    | -3.02e+06      |
| Policy-MaxReturn        | -2.82e+06      |
| Policy-MinReturn        | -3.19e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 8.85e+04       |
| Policy-TimeAlgoOpt      | 0.743          |
| Policy-TimeSampleProc   | 0.618          |
| Policy-TimeSampling     | 2.13           |
| Policy-TimeStep         | 3.52           |
| Time                    | 273            |
| n_timesteps             | 13000          |
--------------------------------------------

 ---------------- Iteration 13 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 130 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 131 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 132 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 133 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 134 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 135 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 136 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 137 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 138 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 139 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.666          |
| Data-EnvSampler-Poli... | 1.02           |
| Data-EnvTrajs-Averag... | -56.8          |
| Data-EnvTrajs-MaxReturn | -40.3          |
| Data-EnvTrajs-MinReturn | -80            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 13.4           |
| Data-TimeEnvSampleProc  | 0.00151        |
| Data-TimeEnvSampling    | 1.74           |
| Iteration               | 13             |
| ItrTime                 | 35.6           |
| LossAfter               | -0.0057906066  |
| LossBefore              | -1.2364656e-05 |
| Model-TimeModelFit      | 31.6           |
| ModelSampler-n_times... | 560000         |
| Policy-AverageAbsPol... | 0.6422984      |
| Policy-AverageDiscou... | -1.03e+04      |
| Policy-AveragePolicyStd | 0.83349943     |
| Policy-AverageReturn    | -6.2e+04       |
| Policy-MaxReturn        | 66.6           |
| Policy-MinReturn        | -1.18e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.56e+05       |
| Policy-TimeAlgoOpt      | 0.543          |
| Policy-TimeSampleProc   | 0.473          |
| Policy-TimeSampling     | 1.22           |
| Policy-TimeStep         | 2.26           |
| Time                    | 309            |
| n_timesteps             | 14000          |
--------------------------------------------

 ---------------- Iteration 14 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 140 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 141 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 142 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 143 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 144 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 145 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 146 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 147 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 148 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 149 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.412         |
| Data-EnvSampler-Poli... | 0.737         |
| Data-EnvTrajs-Averag... | -79.7         |
| Data-EnvTrajs-MaxReturn | -64           |
| Data-EnvTrajs-MinReturn | -93.3         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 9.55          |
| Data-TimeEnvSampleProc  | 0.00122       |
| Data-TimeEnvSampling    | 1.18          |
| Iteration               | 14            |
| ItrTime                 | 38.2          |
| LossAfter               | -0.006694578  |
| LossBefore              | -1.212366e-05 |
| Model-TimeModelFit      | 33.7          |
| ModelSampler-n_times... | 600000        |
| Policy-AverageAbsPol... | 0.98501       |
| Policy-AverageDiscou... | -6.25e+05     |
| Policy-AveragePolicyStd | 0.81326365    |
| Policy-AverageReturn    | -2.76e+06     |
| Policy-MaxReturn        | -2.57e+06     |
| Policy-MinReturn        | -2.95e+06     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 8.71e+04      |
| Policy-TimeAlgoOpt      | 0.767         |
| Policy-TimeSampleProc   | 0.537         |
| Policy-TimeSampling     | 1.94          |
| Policy-TimeStep         | 3.29          |
| Time                    | 347           |
| n_timesteps             | 15000         |
-------------------------------------------

 ---------------- Iteration 15 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 150 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 151 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 152 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 153 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 154 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 155 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 156 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 157 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 158 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 159 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.624          |
| Data-EnvSampler-Poli... | 1.03           |
| Data-EnvTrajs-Averag... | -120           |
| Data-EnvTrajs-MaxReturn | -105           |
| Data-EnvTrajs-MinReturn | -133           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 12             |
| Data-TimeEnvSampleProc  | 0.00197        |
| Data-TimeEnvSampling    | 1.69           |
| Iteration               | 15             |
| ItrTime                 | 30.8           |
| LossAfter               | -0.0039178785  |
| LossBefore              | -1.1686859e-05 |
| Model-TimeModelFit      | 26.7           |
| ModelSampler-n_times... | 640000         |
| Policy-AverageAbsPol... | 0.6437602      |
| Policy-AverageDiscou... | 90.5           |
| Policy-AveragePolicyStd | 0.7795809      |
| Policy-AverageReturn    | 164            |
| Policy-MaxReturn        | 232            |
| Policy-MinReturn        | 59.1           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 53.9           |
| Policy-TimeAlgoOpt      | 0.517          |
| Policy-TimeSampleProc   | 0.444          |
| Policy-TimeSampling     | 1.46           |
| Policy-TimeStep         | 2.45           |
| Time                    | 378            |
| n_timesteps             | 16000          |
--------------------------------------------

 ---------------- Iteration 16 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 160 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 161 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 162 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 163 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 164 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 165 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 166 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 167 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 168 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 169 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.431         |
| Data-EnvSampler-Poli... | 0.744         |
| Data-EnvTrajs-Averag... | -133          |
| Data-EnvTrajs-MaxReturn | -120          |
| Data-EnvTrajs-MinReturn | -148          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 9.94          |
| Data-TimeEnvSampleProc  | 0.000937      |
| Data-TimeEnvSampling    | 1.21          |
| Iteration               | 16            |
| ItrTime                 | 38.4          |
| LossAfter               | -0.0039509754 |
| LossBefore              | -1.149617e-05 |
| Model-TimeModelFit      | 34.9          |
| ModelSampler-n_times... | 680000        |
| Policy-AverageAbsPol... | 0.5543521     |
| Policy-AverageDiscou... | -203          |
| Policy-AveragePolicyStd | 0.7644255     |
| Policy-AverageReturn    | -743          |
| Policy-MaxReturn        | -145          |
| Policy-MinReturn        | -952          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 183           |
| Policy-TimeAlgoOpt      | 0.534         |
| Policy-TimeSampleProc   | 0.273         |
| Policy-TimeSampling     | 1.45          |
| Policy-TimeStep         | 2.29          |
| Time                    | 417           |
| n_timesteps             | 17000         |
-------------------------------------------

 ---------------- Iteration 17 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 170 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 171 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 172 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 173 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 174 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 175 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 176 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 177 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 178 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 179 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.385          |
| Data-EnvSampler-Poli... | 0.627          |
| Data-EnvTrajs-Averag... | -105           |
| Data-EnvTrajs-MaxReturn | -93.5          |
| Data-EnvTrajs-MinReturn | -117           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 8.39           |
| Data-TimeEnvSampleProc  | 0.000918       |
| Data-TimeEnvSampling    | 1.04           |
| Iteration               | 17             |
| ItrTime                 | 34.8           |
| LossAfter               | -0.0060750903  |
| LossBefore              | -1.1321458e-05 |
| Model-TimeModelFit      | 30             |
| ModelSampler-n_times... | 720000         |
| Policy-AverageAbsPol... | 0.8634367      |
| Policy-AverageDiscou... | -7.86e+04      |
| Policy-AveragePolicyStd | 0.75103694     |
| Policy-AverageReturn    | -4.82e+05      |
| Policy-MaxReturn        | 171            |
| Policy-MinReturn        | -1.91e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 5.09e+05       |
| Policy-TimeAlgoOpt      | 0.77           |
| Policy-TimeSampleProc   | 0.649          |
| Policy-TimeSampling     | 2.29           |
| Policy-TimeStep         | 3.75           |
| Time                    | 451            |
| n_timesteps             | 18000          |
--------------------------------------------

 ---------------- Iteration 18 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 180 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 181 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 182 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 183 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 184 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 185 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 186 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 187 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 188 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 189 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.688          |
| Data-EnvSampler-Poli... | 1.09           |
| Data-EnvTrajs-Averag... | -98.3          |
| Data-EnvTrajs-MaxReturn | -82.3          |
| Data-EnvTrajs-MinReturn | -113           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 11.2           |
| Data-TimeEnvSampleProc  | 0.0016         |
| Data-TimeEnvSampling    | 1.82           |
| Iteration               | 18             |
| ItrTime                 | 31.4           |
| LossAfter               | -0.004759132   |
| LossBefore              | -1.1110366e-05 |
| Model-TimeModelFit      | 27.3           |
| ModelSampler-n_times... | 760000         |
| Policy-AverageAbsPol... | 0.70622927     |
| Policy-AverageDiscou... | -5.03e+03      |
| Policy-AveragePolicyStd | 0.7356023      |
| Policy-AverageReturn    | -3.34e+04      |
| Policy-MaxReturn        | 151            |
| Policy-MinReturn        | -6.69e+05      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.46e+05       |
| Policy-TimeAlgoOpt      | 0.54           |
| Policy-TimeSampleProc   | 0.216          |
| Policy-TimeSampling     | 1.55           |
| Policy-TimeStep         | 2.32           |
| Time                    | 483            |
| n_timesteps             | 19000          |
--------------------------------------------

 ---------------- Iteration 19 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 190 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 191 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 192 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 193 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 194 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 195 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 196 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 197 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 198 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 199 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.415          |
| Data-EnvSampler-Poli... | 0.7            |
| Data-EnvTrajs-Averag... | -74.1          |
| Data-EnvTrajs-MaxReturn | -66.6          |
| Data-EnvTrajs-MinReturn | -81.5          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 5.92           |
| Data-TimeEnvSampleProc  | 0.000957       |
| Data-TimeEnvSampling    | 1.15           |
| Iteration               | 19             |
| ItrTime                 | 37.9           |
| LossAfter               | -0.0054189577  |
| LossBefore              | -1.0927141e-05 |
| Model-TimeModelFit      | 34.3           |
| ModelSampler-n_times... | 800000         |
| Policy-AverageAbsPol... | 0.8788934      |
| Policy-AverageDiscou... | -4.79e+05      |
| Policy-AveragePolicyStd | 0.72272754     |
| Policy-AverageReturn    | -2.32e+06      |
| Policy-MaxReturn        | -2.02e+06      |
| Policy-MinReturn        | -2.65e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.46e+05       |
| Policy-TimeAlgoOpt      | 0.5            |
| Policy-TimeSampleProc   | 0.432          |
| Policy-TimeSampling     | 1.4            |
| Policy-TimeStep         | 2.36           |
| Time                    | 521            |
| n_timesteps             | 20000          |
--------------------------------------------

 ---------------- Iteration 20 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 200 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 201 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 202 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 203 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 204 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 205 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 206 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 207 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 208 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 209 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.374           |
| Data-EnvSampler-Poli... | 0.57            |
| Data-EnvTrajs-Averag... | -34.4           |
| Data-EnvTrajs-MaxReturn | -27.4           |
| Data-EnvTrajs-MinReturn | -43.6           |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 5.66            |
| Data-TimeEnvSampleProc  | 0.000737        |
| Data-TimeEnvSampling    | 0.972           |
| Iteration               | 20              |
| ItrTime                 | 35.1            |
| LossAfter               | -0.005119644    |
| LossBefore              | -1.07938895e-05 |
| Model-TimeModelFit      | 30.3            |
| ModelSampler-n_times... | 840000          |
| Policy-AverageAbsPol... | 0.41091773      |
| Policy-AverageDiscou... | 40.7            |
| Policy-AveragePolicyStd | 0.7118588       |
| Policy-AverageReturn    | -4.01           |
| Policy-MaxReturn        | 122             |
| Policy-MinReturn        | -141            |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 66.8            |
| Policy-TimeAlgoOpt      | 0.871           |
| Policy-TimeSampleProc   | 0.544           |
| Policy-TimeSampling     | 2.41            |
| Policy-TimeStep         | 3.86            |
| Time                    | 556             |
| n_timesteps             | 21000           |
---------------------------------------------

 ---------------- Iteration 21 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 210 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 211 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 212 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 213 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 214 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 215 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 216 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 217 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 218 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 219 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.581          |
| Data-EnvSampler-Poli... | 0.886          |
| Data-EnvTrajs-Averag... | -34.3          |
| Data-EnvTrajs-MaxReturn | -18.3          |
| Data-EnvTrajs-MinReturn | -55.9          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 17.4           |
| Data-TimeEnvSampleProc  | 0.00119        |
| Data-TimeEnvSampling    | 1.51           |
| Iteration               | 21             |
| ItrTime                 | 31.6           |
| LossAfter               | -0.0059812437  |
| LossBefore              | -1.0685285e-05 |
| Model-TimeModelFit      | 27.4           |
| ModelSampler-n_times... | 880000         |
| Policy-AverageAbsPol... | 0.4481473      |
| Policy-AverageDiscou... | -1.19e+04      |
| Policy-AveragePolicyStd | 0.70585823     |
| Policy-AverageReturn    | -6.97e+04      |
| Policy-MaxReturn        | 76.6           |
| Policy-MinReturn        | -1.39e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 3.02e+05       |
| Policy-TimeAlgoOpt      | 0.62           |
| Policy-TimeSampleProc   | 0.476          |
| Policy-TimeSampling     | 1.51           |
| Policy-TimeStep         | 2.63           |
| Time                    | 587            |
| n_timesteps             | 22000          |
--------------------------------------------

 ---------------- Iteration 22 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 220 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 221 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 222 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 223 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 224 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 225 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 226 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 227 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 228 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 229 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.372         |
| Data-EnvSampler-Poli... | 0.572         |
| Data-EnvTrajs-Averag... | -38.8         |
| Data-EnvTrajs-MaxReturn | -25.1         |
| Data-EnvTrajs-MinReturn | -55.9         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 9.99          |
| Data-TimeEnvSampleProc  | 0.000771      |
| Data-TimeEnvSampling    | 0.973         |
| Iteration               | 22            |
| ItrTime                 | 41.3          |
| LossAfter               | -0.006792045  |
| LossBefore              | -1.056524e-05 |
| Model-TimeModelFit      | 38            |
| ModelSampler-n_times... | 920000        |
| Policy-AverageAbsPol... | 0.5527829     |
| Policy-AverageDiscou... | -4.79e+04     |
| Policy-AveragePolicyStd | 0.6972412     |
| Policy-AverageReturn    | -2.46e+05     |
| Policy-MaxReturn        | 73.3          |
| Policy-MinReturn        | -2.72e+06     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 6.48e+05      |
| Policy-TimeAlgoOpt      | 0.589         |
| Policy-TimeSampleProc   | 0.281         |
| Policy-TimeSampling     | 1.51          |
| Policy-TimeStep         | 2.41          |
| Time                    | 629           |
| n_timesteps             | 23000         |
-------------------------------------------

 ---------------- Iteration 23 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 230 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 231 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 232 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 233 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 234 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 235 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 236 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 237 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 238 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 239 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.352          |
| Data-EnvSampler-Poli... | 0.583          |
| Data-EnvTrajs-Averag... | -60.9          |
| Data-EnvTrajs-MaxReturn | -39.5          |
| Data-EnvTrajs-MinReturn | -73.5          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 13.8           |
| Data-TimeEnvSampleProc  | 0.000908       |
| Data-TimeEnvSampling    | 0.962          |
| Iteration               | 23             |
| ItrTime                 | 33.6           |
| LossAfter               | -0.0034424202  |
| LossBefore              | -1.0387411e-05 |
| Model-TimeModelFit      | 28.6           |
| ModelSampler-n_times... | 960000         |
| Policy-AverageAbsPol... | 0.41982755     |
| Policy-AverageDiscou... | -1.08e+03      |
| Policy-AveragePolicyStd | 0.6835938      |
| Policy-AverageReturn    | -8.54e+03      |
| Policy-MaxReturn        | 574            |
| Policy-MinReturn        | -1.76e+05      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 3.85e+04       |
| Policy-TimeAlgoOpt      | 0.771          |
| Policy-TimeSampleProc   | 0.818          |
| Policy-TimeSampling     | 2.37           |
| Policy-TimeStep         | 3.99           |
| Time                    | 662            |
| n_timesteps             | 24000          |
--------------------------------------------

 ---------------- Iteration 24 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 240 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 241 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 242 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 243 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 244 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 245 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 246 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 247 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 248 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 249 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.573          |
| Data-EnvSampler-Poli... | 0.86           |
| Data-EnvTrajs-Averag... | -47.7          |
| Data-EnvTrajs-MaxReturn | -25.8          |
| Data-EnvTrajs-MinReturn | -70.2          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 14.8           |
| Data-TimeEnvSampleProc  | 0.00149        |
| Data-TimeEnvSampling    | 1.48           |
| Iteration               | 24             |
| ItrTime                 | 43.2           |
| LossAfter               | -0.0046843165  |
| LossBefore              | -1.0319427e-05 |
| Model-TimeModelFit      | 39.4           |
| ModelSampler-n_times... | 1000000        |
| Policy-AverageAbsPol... | 0.41650432     |
| Policy-AverageDiscou... | 43.4           |
| Policy-AveragePolicyStd | 0.6803564      |
| Policy-AverageReturn    | -93.2          |
| Policy-MaxReturn        | -26.3          |
| Policy-MinReturn        | -225           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 52.4           |
| Policy-TimeAlgoOpt      | 0.573          |
| Policy-TimeSampleProc   | 0.251          |
| Policy-TimeSampling     | 1.52           |
| Policy-TimeStep         | 2.35           |
| Time                    | 705            |
| n_timesteps             | 25000          |
--------------------------------------------

 ---------------- Iteration 25 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 250 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 251 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 252 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 253 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 254 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 255 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 256 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 257 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 258 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 259 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.355          |
| Data-EnvSampler-Poli... | 0.579          |
| Data-EnvTrajs-Averag... | -34.1          |
| Data-EnvTrajs-MaxReturn | -20            |
| Data-EnvTrajs-MinReturn | -48.7          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 10             |
| Data-TimeEnvSampleProc  | 0.000861       |
| Data-TimeEnvSampling    | 0.962          |
| Iteration               | 25             |
| ItrTime                 | 34.5           |
| LossAfter               | -0.010277842   |
| LossBefore              | -1.0261567e-05 |
| Model-TimeModelFit      | 29.3           |
| ModelSampler-n_times... | 1040000        |
| Policy-AverageAbsPol... | 0.5899841      |
| Policy-AverageDiscou... | -2.86e+04      |
| Policy-AveragePolicyStd | 0.67639744     |
| Policy-AverageReturn    | -1.65e+05      |
| Policy-MaxReturn        | -76.9          |
| Policy-MinReturn        | -1.91e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 4.42e+05       |
| Policy-TimeAlgoOpt      | 0.987          |
| Policy-TimeSampleProc   | 0.571          |
| Policy-TimeSampling     | 2.64           |
| Policy-TimeStep         | 4.24           |
| Time                    | 740            |
| n_timesteps             | 26000          |
--------------------------------------------

 ---------------- Iteration 26 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 260 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 261 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 262 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 263 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 264 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 265 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 266 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 267 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 268 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 269 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.601          |
| Data-EnvSampler-Poli... | 0.875          |
| Data-EnvTrajs-Averag... | -62.7          |
| Data-EnvTrajs-MaxReturn | -50.9          |
| Data-EnvTrajs-MinReturn | -76.1          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 8.73           |
| Data-TimeEnvSampleProc  | 0.00134        |
| Data-TimeEnvSampling    | 1.52           |
| Iteration               | 26             |
| ItrTime                 | 36.7           |
| LossAfter               | -0.0061073746  |
| LossBefore              | -1.0075043e-05 |
| Model-TimeModelFit      | 32.6           |
| ModelSampler-n_times... | 1080000        |
| Policy-AverageAbsPol... | 0.48234078     |
| Policy-AverageDiscou... | -8.47e+03      |
| Policy-AveragePolicyStd | 0.6629781      |
| Policy-AverageReturn    | -5.24e+04      |
| Policy-MaxReturn        | 131            |
| Policy-MinReturn        | -1.05e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.28e+05       |
| Policy-TimeAlgoOpt      | 0.541          |
| Policy-TimeSampleProc   | 0.363          |
| Policy-TimeSampling     | 1.63           |
| Policy-TimeStep         | 2.55           |
| Time                    | 777            |
| n_timesteps             | 27000          |
--------------------------------------------

 ---------------- Iteration 27 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 270 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 271 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 272 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 273 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 274 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 275 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 276 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 277 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 278 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 279 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.357         |
| Data-EnvSampler-Poli... | 0.556         |
| Data-EnvTrajs-Averag... | -50           |
| Data-EnvTrajs-MaxReturn | -44.8         |
| Data-EnvTrajs-MinReturn | -54.1         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 3.48          |
| Data-TimeEnvSampleProc  | 0.000711      |
| Data-TimeEnvSampling    | 0.942         |
| Iteration               | 27            |
| ItrTime                 | 41            |
| LossAfter               | -0.004722198  |
| LossBefore              | -1.001651e-05 |
| Model-TimeModelFit      | 37.3          |
| ModelSampler-n_times... | 1120000       |
| Policy-AverageAbsPol... | 0.5628127     |
| Policy-AverageDiscou... | 104           |
| Policy-AveragePolicyStd | 0.65887123    |
| Policy-AverageReturn    | 177           |
| Policy-MaxReturn        | 328           |
| Policy-MinReturn        | -3.2          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 95.1          |
| Policy-TimeAlgoOpt      | 0.608         |
| Policy-TimeSampleProc   | 0.365         |
| Policy-TimeSampling     | 1.66          |
| Policy-TimeStep         | 2.67          |
| Time                    | 818           |
| n_timesteps             | 28000         |
-------------------------------------------

 ---------------- Iteration 28 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 280 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 281 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 282 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 283 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 284 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 285 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 286 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 287 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 288 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 289 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.351          |
| Data-EnvSampler-Poli... | 0.588          |
| Data-EnvTrajs-Averag... | -33.6          |
| Data-EnvTrajs-MaxReturn | -19.5          |
| Data-EnvTrajs-MinReturn | -60.4          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 14.8           |
| Data-TimeEnvSampleProc  | 0.000884       |
| Data-TimeEnvSampling    | 0.967          |
| Iteration               | 28             |
| ItrTime                 | 32.4           |
| LossAfter               | -0.005266468   |
| LossBefore              | -9.8892315e-06 |
| Model-TimeModelFit      | 27.2           |
| ModelSampler-n_times... | 1160000        |
| Policy-AverageAbsPol... | 0.43556604     |
| Policy-AverageDiscou... | 85.2           |
| Policy-AveragePolicyStd | 0.6502861      |
| Policy-AverageReturn    | 6.8            |
| Policy-MaxReturn        | 144            |
| Policy-MinReturn        | -103           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 51.2           |
| Policy-TimeAlgoOpt      | 0.832          |
| Policy-TimeSampleProc   | 0.809          |
| Policy-TimeSampling     | 2.55           |
| Policy-TimeStep         | 4.23           |
| Time                    | 850            |
| n_timesteps             | 29000          |
--------------------------------------------

 ---------------- Iteration 29 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 290 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 291 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 292 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 293 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 294 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 295 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 296 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 297 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 298 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 299 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.642         |
| Data-EnvSampler-Poli... | 0.955         |
| Data-EnvTrajs-Averag... | -5.19         |
| Data-EnvTrajs-MaxReturn | 9.91          |
| Data-EnvTrajs-MinReturn | -25.3         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 13.9          |
| Data-TimeEnvSampleProc  | 0.00126       |
| Data-TimeEnvSampling    | 1.64          |
| Iteration               | 29            |
| ItrTime                 | 40.8          |
| LossAfter               | -0.009144271  |
| LossBefore              | -9.720556e-06 |
| Model-TimeModelFit      | 36.7          |
| ModelSampler-n_times... | 1200000       |
| Policy-AverageAbsPol... | 0.41871068    |
| Policy-AverageDiscou... | -6.18e+03     |
| Policy-AveragePolicyStd | 0.64136016    |
| Policy-AverageReturn    | -4.34e+04     |
| Policy-MaxReturn        | 560           |
| Policy-MinReturn        | -5.03e+05     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.27e+05      |
| Policy-TimeAlgoOpt      | 0.556         |
| Policy-TimeSampleProc   | 0.373         |
| Policy-TimeSampling     | 1.51          |
| Policy-TimeStep         | 2.46          |
| Time                    | 891           |
| n_timesteps             | 30000         |
-------------------------------------------

 ---------------- Iteration 30 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 300 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 301 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 302 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 303 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 304 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 305 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 306 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 307 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 308 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 309 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.415         |
| Data-EnvSampler-Poli... | 0.689         |
| Data-EnvTrajs-Averag... | 0.955         |
| Data-EnvTrajs-MaxReturn | 17.1          |
| Data-EnvTrajs-MinReturn | -12.5         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 10.2          |
| Data-TimeEnvSampleProc  | 0.000861      |
| Data-TimeEnvSampling    | 1.14          |
| Iteration               | 30            |
| ItrTime                 | 39.6          |
| LossAfter               | -0.00361776   |
| LossBefore              | -9.635687e-06 |
| Model-TimeModelFit      | 34.3          |
| ModelSampler-n_times... | 1240000       |
| Policy-AverageAbsPol... | 0.44544032    |
| Policy-AverageDiscou... | 104           |
| Policy-AveragePolicyStd | 0.6335197     |
| Policy-AverageReturn    | 115           |
| Policy-MaxReturn        | 295           |
| Policy-MinReturn        | 1.34          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 70            |
| Policy-TimeAlgoOpt      | 0.859         |
| Policy-TimeSampleProc   | 0.661         |
| Policy-TimeSampling     | 2.56          |
| Policy-TimeStep         | 4.12          |
| Time                    | 931           |
| n_timesteps             | 31000         |
-------------------------------------------

 ---------------- Iteration 31 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 310 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 311 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 312 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 313 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 314 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 315 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 316 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 317 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 318 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 319 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.576         |
| Data-EnvSampler-Poli... | 0.894         |
| Data-EnvTrajs-Averag... | -3.22         |
| Data-EnvTrajs-MaxReturn | 36.3          |
| Data-EnvTrajs-MinReturn | -35           |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 22.9          |
| Data-TimeEnvSampleProc  | 0.000777      |
| Data-TimeEnvSampling    | 1.51          |
| Iteration               | 31            |
| ItrTime                 | 31.5          |
| LossAfter               | -0.004790947  |
| LossBefore              | -9.524027e-06 |
| Model-TimeModelFit      | 26.4          |
| ModelSampler-n_times... | 1280000       |
| Policy-AverageAbsPol... | 1.1045424     |
| Policy-AverageDiscou... | -4.1e+05      |
| Policy-AveragePolicyStd | 0.62727463    |
| Policy-AverageReturn    | -2.03e+06     |
| Policy-MaxReturn        | -84.3         |
| Policy-MinReturn        | -2.81e+06     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 5.74e+05      |
| Policy-TimeAlgoOpt      | 0.724         |
| Policy-TimeSampleProc   | 0.683         |
| Policy-TimeSampling     | 2.15          |
| Policy-TimeStep         | 3.59          |
| Time                    | 962           |
| n_timesteps             | 32000         |
-------------------------------------------

 ---------------- Iteration 32 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 320 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 321 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 322 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 323 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 324 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 325 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 326 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 327 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 328 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 329 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.67           |
| Data-EnvSampler-Poli... | 1.07           |
| Data-EnvTrajs-Averag... | 0.809          |
| Data-EnvTrajs-MaxReturn | 24             |
| Data-EnvTrajs-MinReturn | -20.9          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 14.9           |
| Data-TimeEnvSampleProc  | 0.00102        |
| Data-TimeEnvSampling    | 1.79           |
| Iteration               | 32             |
| ItrTime                 | 43.4           |
| LossAfter               | -0.004283575   |
| LossBefore              | -9.4853995e-06 |
| Model-TimeModelFit      | 39.1           |
| ModelSampler-n_times... | 1320000        |
| Policy-AverageAbsPol... | 0.52321124     |
| Policy-AverageDiscou... | 109            |
| Policy-AveragePolicyStd | 0.6236005      |
| Policy-AverageReturn    | 154            |
| Policy-MaxReturn        | 385            |
| Policy-MinReturn        | -1.06e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 287            |
| Policy-TimeAlgoOpt      | 0.562          |
| Policy-TimeSampleProc   | 0.471          |
| Policy-TimeSampling     | 1.47           |
| Policy-TimeStep         | 2.57           |
| Time                    | 1.01e+03       |
| n_timesteps             | 33000          |
--------------------------------------------

 ---------------- Iteration 33 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 330 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 331 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 332 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 333 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 334 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 335 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 336 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 337 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 338 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 339 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.397         |
| Data-EnvSampler-Poli... | 0.665         |
| Data-EnvTrajs-Averag... | 6.36          |
| Data-EnvTrajs-MaxReturn | 14.1          |
| Data-EnvTrajs-MinReturn | 1.08          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 4.25          |
| Data-TimeEnvSampleProc  | 0.000562      |
| Data-TimeEnvSampling    | 1.09          |
| Iteration               | 33            |
| ItrTime                 | 38.4          |
| LossAfter               | -0.0071691764 |
| LossBefore              | -9.297343e-06 |
| Model-TimeModelFit      | 33.4          |
| ModelSampler-n_times... | 1360000       |
| Policy-AverageAbsPol... | 0.48359594    |
| Policy-AverageDiscou... | -654          |
| Policy-AveragePolicyStd | 0.6138056     |
| Policy-AverageReturn    | -5.51e+03     |
| Policy-MaxReturn        | 385           |
| Policy-MinReturn        | -7.89e+04     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.75e+04      |
| Policy-TimeAlgoOpt      | 0.817         |
| Policy-TimeSampleProc   | 0.622         |
| Policy-TimeSampling     | 2.39          |
| Policy-TimeStep         | 3.87          |
| Time                    | 1.04e+03      |
| n_timesteps             | 34000         |
-------------------------------------------

 ---------------- Iteration 34 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 340 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 341 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 342 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 343 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 344 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 345 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 346 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 347 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 348 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 349 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.675         |
| Data-EnvSampler-Poli... | 1.12          |
| Data-EnvTrajs-Averag... | -0.837        |
| Data-EnvTrajs-MaxReturn | 21.5          |
| Data-EnvTrajs-MinReturn | -37.5         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 20.8          |
| Data-TimeEnvSampleProc  | 0.00136       |
| Data-TimeEnvSampling    | 1.84          |
| Iteration               | 34            |
| ItrTime                 | 34.6          |
| LossAfter               | -0.006706783  |
| LossBefore              | -9.234015e-06 |
| Model-TimeModelFit      | 30.1          |
| ModelSampler-n_times... | 1400000       |
| Policy-AverageAbsPol... | 0.5672823     |
| Policy-AverageDiscou... | 157           |
| Policy-AveragePolicyStd | 0.61042726    |
| Policy-AverageReturn    | 365           |
| Policy-MaxReturn        | 506           |
| Policy-MinReturn        | 242           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 70.5          |
| Policy-TimeAlgoOpt      | 0.622         |
| Policy-TimeSampleProc   | 0.334         |
| Policy-TimeSampling     | 1.75          |
| Policy-TimeStep         | 2.72          |
| Time                    | 1.08e+03      |
| n_timesteps             | 35000         |
-------------------------------------------

 ---------------- Iteration 35 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 350 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 351 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 352 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 353 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 354 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 355 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 356 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 357 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 358 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 359 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.423         |
| Data-EnvSampler-Poli... | 0.745         |
| Data-EnvTrajs-Averag... | -3.69         |
| Data-EnvTrajs-MaxReturn | 9.06          |
| Data-EnvTrajs-MinReturn | -35.4         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 16.3          |
| Data-TimeEnvSampleProc  | 0.000631      |
| Data-TimeEnvSampling    | 1.21          |
| Iteration               | 35            |
| ItrTime                 | 43.1          |
| LossAfter               | -0.0057673263 |
| LossBefore              | -9.244527e-06 |
| Model-TimeModelFit      | 39.6          |
| ModelSampler-n_times... | 1440000       |
| Policy-AverageAbsPol... | 0.58671474    |
| Policy-AverageDiscou... | -1.04e+05     |
| Policy-AveragePolicyStd | 0.6099952     |
| Policy-AverageReturn    | -4.46e+05     |
| Policy-MaxReturn        | 208           |
| Policy-MinReturn        | -3.03e+06     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.06e+06      |
| Policy-TimeAlgoOpt      | 0.538         |
| Policy-TimeSampleProc   | 0.303         |
| Policy-TimeSampling     | 1.39          |
| Policy-TimeStep         | 2.28          |
| Time                    | 1.12e+03      |
| n_timesteps             | 36000         |
-------------------------------------------

 ---------------- Iteration 36 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 360 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 361 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 362 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 363 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 364 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 365 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 366 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 367 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 368 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 369 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.451         |
| Data-EnvSampler-Poli... | 0.772         |
| Data-EnvTrajs-Averag... | 0.685         |
| Data-EnvTrajs-MaxReturn | 9.47          |
| Data-EnvTrajs-MinReturn | -4.94         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 4.95          |
| Data-TimeEnvSampleProc  | 0.000874      |
| Data-TimeEnvSampling    | 1.26          |
| Iteration               | 36            |
| ItrTime                 | 36.8          |
| LossAfter               | -0.0048579946 |
| LossBefore              | -9.079005e-06 |
| Model-TimeModelFit      | 31.6          |
| ModelSampler-n_times... | 1480000       |
| Policy-AverageAbsPol... | 0.7560747     |
| Policy-AverageDiscou... | -3.08e+05     |
| Policy-AveragePolicyStd | 0.6002793     |
| Policy-AverageReturn    | -1.46e+06     |
| Policy-MaxReturn        | 179           |
| Policy-MinReturn        | -2.68e+06     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.2e+06       |
| Policy-TimeAlgoOpt      | 0.77          |
| Policy-TimeSampleProc   | 0.696         |
| Policy-TimeSampling     | 2.41          |
| Policy-TimeStep         | 3.92          |
| Time                    | 1.16e+03      |
| n_timesteps             | 37000         |
-------------------------------------------

 ---------------- Iteration 37 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 370 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 371 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 372 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 373 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 374 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 375 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 376 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 377 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 378 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 379 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.738         |
| Data-EnvSampler-Poli... | 1.2           |
| Data-EnvTrajs-Averag... | 6.53          |
| Data-EnvTrajs-MaxReturn | 18.9          |
| Data-EnvTrajs-MinReturn | -18.5         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 12.9          |
| Data-TimeEnvSampleProc  | 0.00142       |
| Data-TimeEnvSampling    | 1.99          |
| Iteration               | 37            |
| ItrTime                 | 38.4          |
| LossAfter               | -0.0011589677 |
| LossBefore              | -8.897221e-06 |
| Model-TimeModelFit      | 34.1          |
| ModelSampler-n_times... | 1520000       |
| Policy-AverageAbsPol... | 0.37505248    |
| Policy-AverageDiscou... | 138           |
| Policy-AveragePolicyStd | 0.5903061     |
| Policy-AverageReturn    | 213           |
| Policy-MaxReturn        | 307           |
| Policy-MinReturn        | 137           |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 36.9          |
| Policy-TimeAlgoOpt      | 0.591         |
| Policy-TimeSampleProc   | 0.285         |
| Policy-TimeSampling     | 1.48          |
| Policy-TimeStep         | 2.38          |
| Time                    | 1.2e+03       |
| n_timesteps             | 38000         |
-------------------------------------------

 ---------------- Iteration 38 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 380 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 381 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 382 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 383 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 384 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 385 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 386 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 387 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 388 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 389 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.509          |
| Data-EnvSampler-Poli... | 0.85           |
| Data-EnvTrajs-Averag... | 17.5           |
| Data-EnvTrajs-MaxReturn | 24.1           |
| Data-EnvTrajs-MinReturn | 1.82           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 8.02           |
| Data-TimeEnvSampleProc  | 0.000888       |
| Data-TimeEnvSampling    | 1.4            |
| Iteration               | 38             |
| ItrTime                 | 44             |
| LossAfter               | -0.004951323   |
| LossBefore              | -8.6552445e-06 |
| Model-TimeModelFit      | 39.2           |
| ModelSampler-n_times... | 1560000        |
| Policy-AverageAbsPol... | 0.47152668     |
| Policy-AverageDiscou... | -2e+04         |
| Policy-AveragePolicyStd | 0.57594883     |
| Policy-AverageReturn    | -1.03e+05      |
| Policy-MaxReturn        | 348            |
| Policy-MinReturn        | -2.05e+06      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 4.47e+05       |
| Policy-TimeAlgoOpt      | 0.687          |
| Policy-TimeSampleProc   | 0.476          |
| Policy-TimeSampling     | 2.16           |
| Policy-TimeStep         | 3.35           |
| Time                    | 1.24e+03       |
| n_timesteps             | 39000          |
--------------------------------------------

 ---------------- Iteration 39 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 390 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 391 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 392 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 393 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 394 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 395 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 396 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 397 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 398 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 399 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.471         |
| Data-EnvSampler-Poli... | 0.987         |
| Data-EnvTrajs-Averag... | 15.7          |
| Data-EnvTrajs-MaxReturn | 24.3          |
| Data-EnvTrajs-MinReturn | 8.68          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 5.88          |
| Data-TimeEnvSampleProc  | 0.000651      |
| Data-TimeEnvSampling    | 1.49          |
| Iteration               | 39            |
| ItrTime                 | 34.3          |
| LossAfter               | -0.010454581  |
| LossBefore              | -8.605398e-06 |
| Model-TimeModelFit      | 28.8          |
| ModelSampler-n_times... | 1600000       |
| Policy-AverageAbsPol... | 0.50077665    |
| Policy-AverageDiscou... | -4.28e+03     |
| Policy-AveragePolicyStd | 0.57321453    |
| Policy-AverageReturn    | -3.01e+04     |
| Policy-MaxReturn        | 123           |
| Policy-MinReturn        | -4.53e+05     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.02e+05      |
| Policy-TimeAlgoOpt      | 0.801         |
| Policy-TimeSampleProc   | 0.765         |
| Policy-TimeSampling     | 2.4           |
| Policy-TimeStep         | 4             |
| Time                    | 1.28e+03      |
| n_timesteps             | 40000         |
-------------------------------------------

 ---------------- Iteration 40 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 400 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 401 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 402 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 403 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 404 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 405 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 406 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 407 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 408 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 409 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.775         |
| Data-EnvSampler-Poli... | 1.22          |
| Data-EnvTrajs-Averag... | -22.6         |
| Data-EnvTrajs-MaxReturn | -9.97         |
| Data-EnvTrajs-MinReturn | -34.6         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 8.72          |
| Data-TimeEnvSampleProc  | 0.00279       |
| Data-TimeEnvSampling    | 2.04          |
| Iteration               | 40            |
| ItrTime                 | 41.9          |
| LossAfter               | -0.0046918076 |
| LossBefore              | -8.321552e-06 |
| Model-TimeModelFit      | 37.5          |
| ModelSampler-n_times... | 1640000       |
| Policy-AverageAbsPol... | 0.6318391     |
| Policy-AverageDiscou... | 112           |
| Policy-AveragePolicyStd | 0.556537      |
| Policy-AverageReturn    | 193           |
| Policy-MaxReturn        | 313           |
| Policy-MinReturn        | 23.8          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 111           |
| Policy-TimeAlgoOpt      | 0.548         |
| Policy-TimeSampleProc   | 0.325         |
| Policy-TimeSampling     | 1.39          |
| Policy-TimeStep         | 2.34          |
| Time                    | 1.32e+03      |
| n_timesteps             | 41000         |
-------------------------------------------

 ---------------- Iteration 41 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 410 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 411 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 412 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 413 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 414 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 415 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 416 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 417 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 418 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 419 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.505         |
| Data-EnvSampler-Poli... | 0.912         |
| Data-EnvTrajs-Averag... | -3.43         |
| Data-EnvTrajs-MaxReturn | 13.7          |
| Data-EnvTrajs-MinReturn | -14.4         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 10.5          |
| Data-TimeEnvSampleProc  | 0.000529      |
| Data-TimeEnvSampling    | 1.45          |
| Iteration               | 41            |
| ItrTime                 | 41.9          |
| LossAfter               | -0.0056121466 |
| LossBefore              | -8.195405e-06 |
| Model-TimeModelFit      | 36.4          |
| ModelSampler-n_times... | 1680000       |
| Policy-AverageAbsPol... | 0.4687085     |
| Policy-AverageDiscou... | 119           |
| Policy-AveragePolicyStd | 0.5490967     |
| Policy-AverageReturn    | 146           |
| Policy-MaxReturn        | 249           |
| Policy-MinReturn        | 26.5          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 46.5          |
| Policy-TimeAlgoOpt      | 0.771         |
| Policy-TimeSampleProc   | 0.778         |
| Policy-TimeSampling     | 2.4           |
| Policy-TimeStep         | 4             |
| Time                    | 1.36e+03      |
| n_timesteps             | 42000         |
-------------------------------------------

 ---------------- Iteration 42 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 420 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 421 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 422 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 423 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 424 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 425 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 426 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 427 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 428 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 429 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.766         |
| Data-EnvSampler-Poli... | 1.34          |
| Data-EnvTrajs-Averag... | 2.88          |
| Data-EnvTrajs-MaxReturn | 6.49          |
| Data-EnvTrajs-MinReturn | -5.48         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 4.37          |
| Data-TimeEnvSampleProc  | 0.00147       |
| Data-TimeEnvSampling    | 2.17          |
| Iteration               | 42            |
| ItrTime                 | 34.7          |
| LossAfter               | -0.004747798  |
| LossBefore              | -7.982839e-06 |
| Model-TimeModelFit      | 30.1          |
| ModelSampler-n_times... | 1720000       |
| Policy-AverageAbsPol... | 0.44942093    |
| Policy-AverageDiscou... | 129           |
| Policy-AveragePolicyStd | 0.5386984     |
| Policy-AverageReturn    | 212           |
| Policy-MaxReturn        | 345           |
| Policy-MinReturn        | 28.2          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 96.9          |
| Policy-TimeAlgoOpt      | 0.579         |
| Policy-TimeSampleProc   | 0.333         |
| Policy-TimeSampling     | 1.49          |
| Policy-TimeStep         | 2.41          |
| Time                    | 1.39e+03      |
| n_timesteps             | 43000         |
-------------------------------------------

 ---------------- Iteration 43 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 430 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 431 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 432 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 433 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 434 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 435 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 436 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 437 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 438 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 439 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.523         |
| Data-EnvSampler-Poli... | 0.927         |
| Data-EnvTrajs-Averag... | 16.4          |
| Data-EnvTrajs-MaxReturn | 32.3          |
| Data-EnvTrajs-MinReturn | 8.47          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 9.37          |
| Data-TimeEnvSampleProc  | 0.00332       |
| Data-TimeEnvSampling    | 1.49          |
| Iteration               | 43            |
| ItrTime                 | 41.2          |
| LossAfter               | -0.005848333  |
| LossBefore              | -7.705071e-06 |
| Model-TimeModelFit      | 37.2          |
| ModelSampler-n_times... | 1760000       |
| Policy-AverageAbsPol... | 0.6499923     |
| Policy-AverageDiscou... | -651          |
| Policy-AveragePolicyStd | 0.5231668     |
| Policy-AverageReturn    | -5.26e+03     |
| Policy-MaxReturn        | 194           |
| Policy-MinReturn        | -1.06e+05     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 2.31e+04      |
| Policy-TimeAlgoOpt      | 0.548         |
| Policy-TimeSampleProc   | 0.288         |
| Policy-TimeSampling     | 1.62          |
| Policy-TimeStep         | 2.47          |
| Time                    | 1.43e+03      |
| n_timesteps             | 44000         |
-------------------------------------------

 ---------------- Iteration 44 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 440 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 441 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 442 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 443 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 444 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 445 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 446 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 447 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 448 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 449 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.434          |
| Data-EnvSampler-Poli... | 0.724          |
| Data-EnvTrajs-Averag... | 33.7           |
| Data-EnvTrajs-MaxReturn | 49.3           |
| Data-EnvTrajs-MinReturn | 8.23           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 13.7           |
| Data-TimeEnvSampleProc  | 0.00099        |
| Data-TimeEnvSampling    | 1.2            |
| Iteration               | 44             |
| ItrTime                 | 43.9           |
| LossAfter               | -0.0063444627  |
| LossBefore              | -7.5611656e-06 |
| Model-TimeModelFit      | 38.6           |
| ModelSampler-n_times... | 1800000        |
| Policy-AverageAbsPol... | 0.6350402      |
| Policy-AverageDiscou... | -978           |
| Policy-AveragePolicyStd | 0.51704925     |
| Policy-AverageReturn    | -7.71e+03      |
| Policy-MaxReturn        | 185            |
| Policy-MinReturn        | -1.5e+05       |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 3.27e+04       |
| Policy-TimeAlgoOpt      | 0.781          |
| Policy-TimeSampleProc   | 0.873          |
| Policy-TimeSampling     | 2.41           |
| Policy-TimeStep         | 4.09           |
| Time                    | 1.48e+03       |
| n_timesteps             | 45000          |
--------------------------------------------

 ---------------- Iteration 45 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 450 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 451 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 452 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 453 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 454 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 455 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 456 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 457 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 458 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 459 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.653          |
| Data-EnvSampler-Poli... | 1.05           |
| Data-EnvTrajs-Averag... | 48.7           |
| Data-EnvTrajs-MaxReturn | 63.4           |
| Data-EnvTrajs-MinReturn | 30.2           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 11.7           |
| Data-TimeEnvSampleProc  | 0.000933       |
| Data-TimeEnvSampling    | 1.75           |
| Iteration               | 45             |
| ItrTime                 | 34.2           |
| LossAfter               | -0.0029332284  |
| LossBefore              | -7.4611094e-06 |
| Model-TimeModelFit      | 28.5           |
| ModelSampler-n_times... | 1840000        |
| Policy-AverageAbsPol... | 1.0963554      |
| Policy-AverageDiscou... | 102            |
| Policy-AveragePolicyStd | 0.5110588      |
| Policy-AverageReturn    | 246            |
| Policy-MaxReturn        | 262            |
| Policy-MinReturn        | 132            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 27.3           |
| Policy-TimeAlgoOpt      | 0.834          |
| Policy-TimeSampleProc   | 0.615          |
| Policy-TimeSampling     | 2.47           |
| Policy-TimeStep         | 3.94           |
| Time                    | 1.51e+03       |
| n_timesteps             | 46000          |
--------------------------------------------

 ---------------- Iteration 46 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 460 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 461 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 462 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 463 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 464 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 465 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 466 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 467 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 468 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 469 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.77           |
| Data-EnvSampler-Poli... | 1.37           |
| Data-EnvTrajs-Averag... | 11.5           |
| Data-EnvTrajs-MaxReturn | 48             |
| Data-EnvTrajs-MinReturn | -8.74          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 19.5           |
| Data-TimeEnvSampleProc  | 0.00136        |
| Data-TimeEnvSampling    | 2.2            |
| Iteration               | 46             |
| ItrTime                 | 46.6           |
| LossAfter               | -0.004899342   |
| LossBefore              | -7.2835614e-06 |
| Model-TimeModelFit      | 42.2           |
| ModelSampler-n_times... | 1880000        |
| Policy-AverageAbsPol... | 0.53326935     |
| Policy-AverageDiscou... | 119            |
| Policy-AveragePolicyStd | 0.5028165      |
| Policy-AverageReturn    | 149            |
| Policy-MaxReturn        | 190            |
| Policy-MinReturn        | 92.3           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 24.6           |
| Policy-TimeAlgoOpt      | 0.502          |
| Policy-TimeSampleProc   | 0.318          |
| Policy-TimeSampling     | 1.37           |
| Policy-TimeStep         | 2.21           |
| Time                    | 1.56e+03       |
| n_timesteps             | 47000          |
--------------------------------------------

 ---------------- Iteration 47 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 470 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 471 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 472 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 473 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 474 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 475 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 476 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 477 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 478 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 479 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.427          |
| Data-EnvSampler-Poli... | 0.77           |
| Data-EnvTrajs-Averag... | 24.6           |
| Data-EnvTrajs-MaxReturn | 30.7           |
| Data-EnvTrajs-MinReturn | 18.9           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 4.19           |
| Data-TimeEnvSampleProc  | 0.000637       |
| Data-TimeEnvSampling    | 1.23           |
| Iteration               | 47             |
| ItrTime                 | 40.3           |
| LossAfter               | -0.0036325387  |
| LossBefore              | -7.1224217e-06 |
| Model-TimeModelFit      | 35.2           |
| ModelSampler-n_times... | 1920000        |
| Policy-AverageAbsPol... | 0.47348145     |
| Policy-AverageDiscou... | 91.4           |
| Policy-AveragePolicyStd | 0.4947421      |
| Policy-AverageReturn    | 47             |
| Policy-MaxReturn        | 305            |
| Policy-MinReturn        | -89.1          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 81.1           |
| Policy-TimeAlgoOpt      | 0.748          |
| Policy-TimeSampleProc   | 0.748          |
| Policy-TimeSampling     | 2.38           |
| Policy-TimeStep         | 3.92           |
| Time                    | 1.6e+03        |
| n_timesteps             | 48000          |
--------------------------------------------

 ---------------- Iteration 48 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 480 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 481 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 482 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 483 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 484 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 485 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 486 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 487 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 488 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 489 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.781          |
| Data-EnvSampler-Poli... | 1.25           |
| Data-EnvTrajs-Averag... | 30.7           |
| Data-EnvTrajs-MaxReturn | 49.2           |
| Data-EnvTrajs-MinReturn | 21             |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 9.83           |
| Data-TimeEnvSampleProc  | 0.00159        |
| Data-TimeEnvSampling    | 2.08           |
| Iteration               | 48             |
| ItrTime                 | 39.6           |
| LossAfter               | -0.0066539766  |
| LossBefore              | -6.9745956e-06 |
| Model-TimeModelFit      | 35.1           |
| ModelSampler-n_times... | 1960000        |
| Policy-AverageAbsPol... | 0.55626106     |
| Policy-AverageDiscou... | 118            |
| Policy-AveragePolicyStd | 0.48747712     |
| Policy-AverageReturn    | 155            |
| Policy-MaxReturn        | 306            |
| Policy-MinReturn        | -8.4           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 87.4           |
| Policy-TimeAlgoOpt      | 0.532          |
| Policy-TimeSampleProc   | 0.345          |
| Policy-TimeSampling     | 1.46           |
| Policy-TimeStep         | 2.38           |
| Time                    | 1.64e+03       |
| n_timesteps             | 49000          |
--------------------------------------------

 ---------------- Iteration 49 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 490 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 491 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 492 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 493 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 494 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 495 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 496 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 497 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 498 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 499 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.458         |
| Data-EnvSampler-Poli... | 0.789         |
| Data-EnvTrajs-Averag... | 58.6          |
| Data-EnvTrajs-MaxReturn | 78.4          |
| Data-EnvTrajs-MinReturn | 38.4          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 14.3          |
| Data-TimeEnvSampleProc  | 0.00112       |
| Data-TimeEnvSampling    | 1.29          |
| Iteration               | 49            |
| ItrTime                 | 44.6          |
| LossAfter               | -0.008967244  |
| LossBefore              | -6.846311e-06 |
| Model-TimeModelFit      | 41            |
| ModelSampler-n_times... | 2000000       |
| Policy-AverageAbsPol... | 0.5545532     |
| Policy-AverageDiscou... | -1.24e+04     |
| Policy-AveragePolicyStd | 0.4796256     |
| Policy-AverageReturn    | -7.18e+04     |
| Policy-MaxReturn        | 357           |
| Policy-MinReturn        | -1.44e+06     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 3.13e+05      |
| Policy-TimeAlgoOpt      | 0.596         |
| Policy-TimeSampleProc   | 0.334         |
| Policy-TimeSampling     | 1.35          |
| Policy-TimeStep         | 2.31          |
| Time                    | 1.68e+03      |
| n_timesteps             | 50000         |
-------------------------------------------

 ---------------- Iteration 50 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 500 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 501 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 502 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 503 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 504 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 505 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 506 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 507 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 508 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 509 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.438         |
| Data-EnvSampler-Poli... | 0.812         |
| Data-EnvTrajs-Averag... | 51            |
| Data-EnvTrajs-MaxReturn | 65.6          |
| Data-EnvTrajs-MinReturn | 30.9          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 12.1          |
| Data-TimeEnvSampleProc  | 0.000928      |
| Data-TimeEnvSampling    | 1.29          |
| Iteration               | 50            |
| ItrTime                 | 28.8          |
| LossAfter               | -0.0034057794 |
| LossBefore              | -6.738159e-06 |
| Model-TimeModelFit      | 24.6          |
| ModelSampler-n_times... | 2040000       |
| Policy-AverageAbsPol... | 0.5227485     |
| Policy-AverageDiscou... | 56.2          |
| Policy-AveragePolicyStd | 0.47651774    |
| Policy-AverageReturn    | -84           |
| Policy-MaxReturn        | 58.6          |
| Policy-MinReturn        | -167          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 58.4          |
| Policy-TimeAlgoOpt      | 0.674         |
| Policy-TimeSampleProc   | 0.377         |
| Policy-TimeSampling     | 1.76          |
| Policy-TimeStep         | 2.86          |
| Time                    | 1.71e+03      |
| n_timesteps             | 51000         |
-------------------------------------------
Training finished
