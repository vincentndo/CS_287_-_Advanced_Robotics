Logging to /home/vincent/workplace/CS_287_-_Advanced_Robotics/homework/hw5/cs287hw5/ppo/run_scripts/data/parallel_mb_ppo/mbppo_Swimmer_l2_no_square//02

 ---------------- Iteration 0 ----------------
Obtaining random samples from the environment...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 0 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 1 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 2 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 3 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 4 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 5 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 6 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 7 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 8 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 9 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.11           |
| Data-EnvSampler-Poli... | 0.0336         |
| Data-EnvTrajs-Averag... | -1.13          |
| Data-EnvTrajs-MaxReturn | 4.37           |
| Data-EnvTrajs-MinReturn | -8.4           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 4.53           |
| Data-TimeEnvSampleProc  | 0.000624       |
| Data-TimeEnvSampling    | 0.153          |
| Iteration               | 0              |
| ItrTime                 | 8              |
| LossAfter               | -0.004121616   |
| LossBefore              | -1.4045934e-05 |
| Model-TimeModelFit      | 2.65           |
| ModelSampler-n_times... | 40000          |
| Policy-AverageAbsPol... | 1.009498       |
| Policy-AverageDiscou... | 234            |
| Policy-AveragePolicyStd | 0.9842195      |
| Policy-AverageReturn    | 517            |
| Policy-MaxReturn        | 782            |
| Policy-MinReturn        | -927           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 456            |
| Policy-TimeAlgoOpt      | 0.887          |
| Policy-TimeSampleProc   | 0.431          |
| Policy-TimeSampling     | 3.84           |
| Policy-TimeStep         | 5.2            |
| Time                    | 8              |
| n_timesteps             | 1000           |
--------------------------------------------

 ---------------- Iteration 1 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 10 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 11 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 12 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 13 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 14 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 15 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 16 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 17 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 18 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 19 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.198          |
| Data-EnvSampler-Poli... | 0.512          |
| Data-EnvTrajs-Averag... | 24.1           |
| Data-EnvTrajs-MaxReturn | 28.7           |
| Data-EnvTrajs-MinReturn | 18.1           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 4.54           |
| Data-TimeEnvSampleProc  | 0.000594       |
| Data-TimeEnvSampling    | 0.727          |
| Iteration               | 1              |
| ItrTime                 | 7.14           |
| LossAfter               | -0.0027457776  |
| LossBefore              | -1.3878995e-05 |
| Model-TimeModelFit      | 3.89           |
| ModelSampler-n_times... | 80000          |
| Policy-AverageAbsPol... | 0.43002388     |
| Policy-AverageDiscou... | -315           |
| Policy-AveragePolicyStd | 0.9674082      |
| Policy-AverageReturn    | -1.35e+03      |
| Policy-MaxReturn        | 181            |
| Policy-MinReturn        | -3.31e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.19e+03       |
| Policy-TimeAlgoOpt      | 0.546          |
| Policy-TimeSampleProc   | 0.398          |
| Policy-TimeSampling     | 1.52           |
| Policy-TimeStep         | 2.52           |
| Time                    | 15.3           |
| n_timesteps             | 2000           |
--------------------------------------------

 ---------------- Iteration 2 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 20 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 21 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 22 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 23 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 24 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 25 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 26 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 27 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 28 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 29 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.24           |
| Data-EnvSampler-Poli... | 0.556          |
| Data-EnvTrajs-Averag... | 17.7           |
| Data-EnvTrajs-MaxReturn | 27.9           |
| Data-EnvTrajs-MinReturn | -2.31          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 11             |
| Data-TimeEnvSampleProc  | 0.000548       |
| Data-TimeEnvSampling    | 0.816          |
| Iteration               | 2              |
| ItrTime                 | 9.32           |
| LossAfter               | -0.003082962   |
| LossBefore              | -1.3673176e-05 |
| Model-TimeModelFit      | 5.93           |
| ModelSampler-n_times... | 120000         |
| Policy-AverageAbsPol... | 0.41788772     |
| Policy-AverageDiscou... | -231           |
| Policy-AveragePolicyStd | 0.95008653     |
| Policy-AverageReturn    | -1.04e+03      |
| Policy-MaxReturn        | 88.3           |
| Policy-MinReturn        | -7.72e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.72e+03       |
| Policy-TimeAlgoOpt      | 0.533          |
| Policy-TimeSampleProc   | 0.468          |
| Policy-TimeSampling     | 1.49           |
| Policy-TimeStep         | 2.56           |
| Time                    | 24.7           |
| n_timesteps             | 3000           |
--------------------------------------------

 ---------------- Iteration 3 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 30 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 31 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 32 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 33 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 34 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 35 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 36 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 37 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 38 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 39 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.263          |
| Data-EnvSampler-Poli... | 0.507          |
| Data-EnvTrajs-Averag... | -1.3           |
| Data-EnvTrajs-MaxReturn | 3.75           |
| Data-EnvTrajs-MinReturn | -6.26          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 3.26           |
| Data-TimeEnvSampleProc  | 0.000899       |
| Data-TimeEnvSampling    | 0.795          |
| Iteration               | 3              |
| ItrTime                 | 14.7           |
| LossAfter               | -0.0043038414  |
| LossBefore              | -1.3786413e-05 |
| Model-TimeModelFit      | 10.4           |
| ModelSampler-n_times... | 160000         |
| Policy-AverageAbsPol... | 0.638978       |
| Policy-AverageDiscou... | 105            |
| Policy-AveragePolicyStd | 0.95930296     |
| Policy-AverageReturn    | 327            |
| Policy-MaxReturn        | 665            |
| Policy-MinReturn        | -1.27e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 414            |
| Policy-TimeAlgoOpt      | 0.752          |
| Policy-TimeSampleProc   | 0.537          |
| Policy-TimeSampling     | 2.19           |
| Policy-TimeStep         | 3.5            |
| Time                    | 39.3           |
| n_timesteps             | 4000           |
--------------------------------------------

 ---------------- Iteration 4 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 40 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 41 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 42 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 43 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 44 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 45 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 46 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 47 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 48 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 49 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.362          |
| Data-EnvSampler-Poli... | 0.651          |
| Data-EnvTrajs-Averag... | 14.6           |
| Data-EnvTrajs-MaxReturn | 22             |
| Data-EnvTrajs-MinReturn | 2.43           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 6.57           |
| Data-TimeEnvSampleProc  | 0.0011         |
| Data-TimeEnvSampling    | 1.04           |
| Iteration               | 4              |
| ItrTime                 | 20.1           |
| LossAfter               | -0.0058736657  |
| LossBefore              | -1.3603588e-05 |
| Model-TimeModelFit      | 15.3           |
| ModelSampler-n_times... | 200000         |
| Policy-AverageAbsPol... | 0.69686294     |
| Policy-AverageDiscou... | 82.7           |
| Policy-AveragePolicyStd | 0.94324124     |
| Policy-AverageReturn    | 142            |
| Policy-MaxReturn        | 508            |
| Policy-MinReturn        | -738           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 295            |
| Policy-TimeAlgoOpt      | 0.842          |
| Policy-TimeSampleProc   | 0.614          |
| Policy-TimeSampling     | 2.19           |
| Policy-TimeStep         | 3.71           |
| Time                    | 59.4           |
| n_timesteps             | 5000           |
--------------------------------------------

 ---------------- Iteration 5 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 50 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 51 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 52 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 53 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 54 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 55 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 56 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 57 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 58 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 59 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.374          |
| Data-EnvSampler-Poli... | 0.638          |
| Data-EnvTrajs-Averag... | 18.5           |
| Data-EnvTrajs-MaxReturn | 29.4           |
| Data-EnvTrajs-MinReturn | 10.5           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 6.78           |
| Data-TimeEnvSampleProc  | 0.000824       |
| Data-TimeEnvSampling    | 1.04           |
| Iteration               | 5              |
| ItrTime                 | 22             |
| LossAfter               | -0.002658509   |
| LossBefore              | -1.3582435e-05 |
| Model-TimeModelFit      | 17.4           |
| ModelSampler-n_times... | 240000         |
| Policy-AverageAbsPol... | 0.93311983     |
| Policy-AverageDiscou... | 20.1           |
| Policy-AveragePolicyStd | 0.9410587      |
| Policy-AverageReturn    | 43.5           |
| Policy-MaxReturn        | 160            |
| Policy-MinReturn        | -383           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 122            |
| Policy-TimeAlgoOpt      | 0.661          |
| Policy-TimeSampleProc   | 0.694          |
| Policy-TimeSampling     | 2.2            |
| Policy-TimeStep         | 3.6            |
| Time                    | 81.4           |
| n_timesteps             | 6000           |
--------------------------------------------

 ---------------- Iteration 6 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 60 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 61 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 62 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 63 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 64 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 65 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 66 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 67 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 68 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 69 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.432          |
| Data-EnvSampler-Poli... | 0.716          |
| Data-EnvTrajs-Averag... | 17.5           |
| Data-EnvTrajs-MaxReturn | 29.8           |
| Data-EnvTrajs-MinReturn | 7.2            |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 8.25           |
| Data-TimeEnvSampleProc  | 0.00125        |
| Data-TimeEnvSampling    | 1.18           |
| Iteration               | 6              |
| ItrTime                 | 21.4           |
| LossAfter               | -0.0025944123  |
| LossBefore              | -1.3318226e-05 |
| Model-TimeModelFit      | 17.8           |
| ModelSampler-n_times... | 280000         |
| Policy-AverageAbsPol... | 0.79556584     |
| Policy-AverageDiscou... | 96             |
| Policy-AveragePolicyStd | 0.9172186      |
| Policy-AverageReturn    | 341            |
| Policy-MaxReturn        | 1.11e+03       |
| Policy-MinReturn        | -356           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 449            |
| Policy-TimeAlgoOpt      | 0.431          |
| Policy-TimeSampleProc   | 0.573          |
| Policy-TimeSampling     | 1.37           |
| Policy-TimeStep         | 2.43           |
| Time                    | 103            |
| n_timesteps             | 7000           |
--------------------------------------------

 ---------------- Iteration 7 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 70 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 71 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 72 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 73 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 74 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 75 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 76 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 77 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 78 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 79 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.275         |
| Data-EnvSampler-Poli... | 0.62          |
| Data-EnvTrajs-Averag... | 29.1          |
| Data-EnvTrajs-MaxReturn | 30.7          |
| Data-EnvTrajs-MinReturn | 27.4          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.05          |
| Data-TimeEnvSampleProc  | 0.000543      |
| Data-TimeEnvSampling    | 0.916         |
| Iteration               | 7             |
| ItrTime                 | 18.6          |
| LossAfter               | -0.004118927  |
| LossBefore              | -1.330573e-05 |
| Model-TimeModelFit      | 15.1          |
| ModelSampler-n_times... | 320000        |
| Policy-AverageAbsPol... | 1.0407027     |
| Policy-AverageDiscou... | 10.8          |
| Policy-AveragePolicyStd | 0.9149227     |
| Policy-AverageReturn    | 58.3          |
| Policy-MaxReturn        | 759           |
| Policy-MinReturn        | -53.6         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 169           |
| Policy-TimeAlgoOpt      | 0.547         |
| Policy-TimeSampleProc   | 0.463         |
| Policy-TimeSampling     | 1.47          |
| Policy-TimeStep         | 2.53          |
| Time                    | 121           |
| n_timesteps             | 8000          |
-------------------------------------------

 ---------------- Iteration 8 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 80 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 81 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 82 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 83 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 84 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 85 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 86 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 87 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 88 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 89 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.304         |
| Data-EnvSampler-Poli... | 0.616         |
| Data-EnvTrajs-Averag... | 29.5          |
| Data-EnvTrajs-MaxReturn | 30.5          |
| Data-EnvTrajs-MinReturn | 28.6          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 0.603         |
| Data-TimeEnvSampleProc  | 0.000586      |
| Data-TimeEnvSampling    | 0.946         |
| Iteration               | 8             |
| ItrTime                 | 32            |
| LossAfter               | -0.0037050326 |
| LossBefore              | -1.310463e-05 |
| Model-TimeModelFit      | 27.1          |
| ModelSampler-n_times... | 360000        |
| Policy-AverageAbsPol... | 1.1101863     |
| Policy-AverageDiscou... | 32.8          |
| Policy-AveragePolicyStd | 0.897544      |
| Policy-AverageReturn    | 64            |
| Policy-MaxReturn        | 70.3          |
| Policy-MinReturn        | 38.4          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 6.48          |
| Policy-TimeAlgoOpt      | 0.763         |
| Policy-TimeSampleProc   | 0.839         |
| Policy-TimeSampling     | 2.28          |
| Policy-TimeStep         | 3.94          |
| Time                    | 153           |
| n_timesteps             | 9000          |
-------------------------------------------

 ---------------- Iteration 9 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 90 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 91 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 92 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 93 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 94 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 95 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 96 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 97 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 98 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 99 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.416         |
| Data-EnvSampler-Poli... | 0.732         |
| Data-EnvTrajs-Averag... | 28.6          |
| Data-EnvTrajs-MaxReturn | 32            |
| Data-EnvTrajs-MinReturn | 27.1          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.85          |
| Data-TimeEnvSampleProc  | 0.000857      |
| Data-TimeEnvSampling    | 1.18          |
| Iteration               | 9             |
| ItrTime                 | 25.5          |
| LossAfter               | -0.0044735186 |
| LossBefore              | -1.297066e-05 |
| Model-TimeModelFit      | 22            |
| ModelSampler-n_times... | 400000        |
| Policy-AverageAbsPol... | 1.1146091     |
| Policy-AverageDiscou... | 2.23          |
| Policy-AveragePolicyStd | 0.88566005    |
| Policy-AverageReturn    | -3.68         |
| Policy-MaxReturn        | 123           |
| Policy-MinReturn        | -578          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 191           |
| Policy-TimeAlgoOpt      | 0.559         |
| Policy-TimeSampleProc   | 0.294         |
| Policy-TimeSampling     | 1.49          |
| Policy-TimeStep         | 2.39          |
| Time                    | 179           |
| n_timesteps             | 10000         |
-------------------------------------------

 ---------------- Iteration 10 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 100 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 101 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 102 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 103 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 104 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 105 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 106 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 107 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 108 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 109 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.311          |
| Data-EnvSampler-Poli... | 0.59           |
| Data-EnvTrajs-Averag... | 27.8           |
| Data-EnvTrajs-MaxReturn | 29.5           |
| Data-EnvTrajs-MinReturn | 24.7           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.65           |
| Data-TimeEnvSampleProc  | 0.00052        |
| Data-TimeEnvSampling    | 0.93           |
| Iteration               | 10             |
| ItrTime                 | 32             |
| LossAfter               | -0.008916978   |
| LossBefore              | -1.2407177e-05 |
| Model-TimeModelFit      | 27.1           |
| ModelSampler-n_times... | 440000         |
| Policy-AverageAbsPol... | 1.778768       |
| Policy-AverageDiscou... | 44.9           |
| Policy-AveragePolicyStd | 0.8360935      |
| Policy-AverageReturn    | 90.2           |
| Policy-MaxReturn        | 109            |
| Policy-MinReturn        | 77.5           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 7.98           |
| Policy-TimeAlgoOpt      | 0.956          |
| Policy-TimeSampleProc   | 0.622          |
| Policy-TimeSampling     | 2.39           |
| Policy-TimeStep         | 4.01           |
| Time                    | 211            |
| n_timesteps             | 11000          |
--------------------------------------------

 ---------------- Iteration 11 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 110 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 111 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 112 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 113 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 114 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 115 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 116 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 117 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 118 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 119 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.449          |
| Data-EnvSampler-Poli... | 0.854          |
| Data-EnvTrajs-Averag... | 25.9           |
| Data-EnvTrajs-MaxReturn | 28.4           |
| Data-EnvTrajs-MinReturn | 21.4           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.42           |
| Data-TimeEnvSampleProc  | 0.00078        |
| Data-TimeEnvSampling    | 1.35           |
| Iteration               | 11             |
| ItrTime                 | 34.9           |
| LossAfter               | -0.0033343518  |
| LossBefore              | -1.2074462e-05 |
| Model-TimeModelFit      | 31             |
| ModelSampler-n_times... | 480000         |
| Policy-AverageAbsPol... | 1.9352585      |
| Policy-AverageDiscou... | 33.3           |
| Policy-AveragePolicyStd | 0.8087097      |
| Policy-AverageReturn    | 63.6           |
| Policy-MaxReturn        | 91.9           |
| Policy-MinReturn        | -34.5          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 36.5           |
| Policy-TimeAlgoOpt      | 0.563          |
| Policy-TimeSampleProc   | 0.267          |
| Policy-TimeSampling     | 1.74           |
| Policy-TimeStep         | 2.6            |
| Time                    | 246            |
| n_timesteps             | 12000          |
--------------------------------------------

 ---------------- Iteration 12 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 120 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 121 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 122 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 123 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 124 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 125 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 126 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 127 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 128 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 129 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.298         |
| Data-EnvSampler-Poli... | 0.592         |
| Data-EnvTrajs-Averag... | 25            |
| Data-EnvTrajs-MaxReturn | 28.5          |
| Data-EnvTrajs-MinReturn | 22.1          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 2.52          |
| Data-TimeEnvSampleProc  | 0.000914      |
| Data-TimeEnvSampling    | 0.915         |
| Iteration               | 12            |
| ItrTime                 | 32.9          |
| LossAfter               | -0.0039186142 |
| LossBefore              | -1.189399e-05 |
| Model-TimeModelFit      | 28.4          |
| ModelSampler-n_times... | 520000        |
| Policy-AverageAbsPol... | 1.0975034     |
| Policy-AverageDiscou... | 24.3          |
| Policy-AveragePolicyStd | 0.79699486    |
| Policy-AverageReturn    | 45.3          |
| Policy-MaxReturn        | 56.3          |
| Policy-MinReturn        | 36.4          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 4.69          |
| Policy-TimeAlgoOpt      | 0.742         |
| Policy-TimeSampleProc   | 0.536         |
| Policy-TimeSampling     | 2.27          |
| Policy-TimeStep         | 3.58          |
| Time                    | 279           |
| n_timesteps             | 13000         |
-------------------------------------------

 ---------------- Iteration 13 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 130 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 131 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 132 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 133 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 134 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 135 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 136 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 137 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 138 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 139 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.475          |
| Data-EnvSampler-Poli... | 0.955          |
| Data-EnvTrajs-Averag... | 24.9           |
| Data-EnvTrajs-MaxReturn | 28.6           |
| Data-EnvTrajs-MinReturn | 19.9           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 3.36           |
| Data-TimeEnvSampleProc  | 0.000852       |
| Data-TimeEnvSampling    | 1.47           |
| Iteration               | 13             |
| ItrTime                 | 41.2           |
| LossAfter               | -0.0026060217  |
| LossBefore              | -1.1761113e-05 |
| Model-TimeModelFit      | 37.3           |
| ModelSampler-n_times... | 560000         |
| Policy-AverageAbsPol... | 0.93921185     |
| Policy-AverageDiscou... | 19.5           |
| Policy-AveragePolicyStd | 0.7854864      |
| Policy-AverageReturn    | 31.9           |
| Policy-MaxReturn        | 47.9           |
| Policy-MinReturn        | 12.6           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 8.4            |
| Policy-TimeAlgoOpt      | 0.489          |
| Policy-TimeSampleProc   | 0.384          |
| Policy-TimeSampling     | 1.44           |
| Policy-TimeStep         | 2.37           |
| Time                    | 320            |
| n_timesteps             | 14000          |
--------------------------------------------

 ---------------- Iteration 14 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 140 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 141 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 142 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 143 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 144 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 145 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 146 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 147 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 148 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 149 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.28            |
| Data-EnvSampler-Poli... | 0.56            |
| Data-EnvTrajs-Averag... | 21.1            |
| Data-EnvTrajs-MaxReturn | 23.5            |
| Data-EnvTrajs-MinReturn | 16.2            |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 2.75            |
| Data-TimeEnvSampleProc  | 0.000855        |
| Data-TimeEnvSampling    | 0.863           |
| Iteration               | 14              |
| ItrTime                 | 29.7            |
| LossAfter               | -0.001661105    |
| LossBefore              | -1.15347275e-05 |
| Model-TimeModelFit      | 24.9            |
| ModelSampler-n_times... | 600000          |
| Policy-AverageAbsPol... | 1.0913799       |
| Policy-AverageDiscou... | 34.1            |
| Policy-AveragePolicyStd | 0.76741534      |
| Policy-AverageReturn    | 68.7            |
| Policy-MaxReturn        | 85.8            |
| Policy-MinReturn        | 45.7            |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 8.17            |
| Policy-TimeAlgoOpt      | 0.754           |
| Policy-TimeSampleProc   | 0.864           |
| Policy-TimeSampling     | 2.27            |
| Policy-TimeStep         | 3.93            |
| Time                    | 350             |
| n_timesteps             | 15000           |
---------------------------------------------

 ---------------- Iteration 15 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 150 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 151 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 152 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 153 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 154 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 155 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 156 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 157 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 158 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 159 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.457          |
| Data-EnvSampler-Poli... | 0.926          |
| Data-EnvTrajs-Averag... | 24.3           |
| Data-EnvTrajs-MaxReturn | 31.8           |
| Data-EnvTrajs-MinReturn | 16             |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 5.23           |
| Data-TimeEnvSampleProc  | 0.0013         |
| Data-TimeEnvSampling    | 1.42           |
| Iteration               | 15             |
| ItrTime                 | 44.3           |
| LossAfter               | -0.0040057832  |
| LossBefore              | -1.1426844e-05 |
| Model-TimeModelFit      | 39.1           |
| ModelSampler-n_times... | 640000         |
| Policy-AverageAbsPol... | 0.8497227      |
| Policy-AverageDiscou... | -560           |
| Policy-AveragePolicyStd | 0.7584029      |
| Policy-AverageReturn    | -2.08e+03      |
| Policy-MaxReturn        | 84.4           |
| Policy-MinReturn        | -1.48e+04      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 4.72e+03       |
| Policy-TimeAlgoOpt      | 0.782          |
| Policy-TimeSampleProc   | 0.727          |
| Policy-TimeSampling     | 2.21           |
| Policy-TimeStep         | 3.74           |
| Time                    | 394            |
| n_timesteps             | 16000          |
--------------------------------------------

 ---------------- Iteration 16 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 160 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 161 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 162 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 163 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 164 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 165 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 166 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 167 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 168 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 169 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.438          |
| Data-EnvSampler-Poli... | 0.918          |
| Data-EnvTrajs-Averag... | 19.4           |
| Data-EnvTrajs-MaxReturn | 23.9           |
| Data-EnvTrajs-MinReturn | 14.5           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 3.77           |
| Data-TimeEnvSampleProc  | 0.00116        |
| Data-TimeEnvSampling    | 1.4            |
| Iteration               | 16             |
| ItrTime                 | 30.8           |
| LossAfter               | -0.0013258712  |
| LossBefore              | -1.1207246e-05 |
| Model-TimeModelFit      | 26.9           |
| ModelSampler-n_times... | 680000         |
| Policy-AverageAbsPol... | 0.67854714     |
| Policy-AverageDiscou... | -130           |
| Policy-AveragePolicyStd | 0.74223375     |
| Policy-AverageReturn    | -878           |
| Policy-MaxReturn        | 66.2           |
| Policy-MinReturn        | -6.34e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.74e+03       |
| Policy-TimeAlgoOpt      | 0.519          |
| Policy-TimeSampleProc   | 0.511          |
| Policy-TimeSampling     | 1.41           |
| Policy-TimeStep         | 2.46           |
| Time                    | 425            |
| n_timesteps             | 17000          |
--------------------------------------------

 ---------------- Iteration 17 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 170 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 171 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 172 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 173 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 174 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 175 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 176 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 177 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 178 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 179 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.298          |
| Data-EnvSampler-Poli... | 0.647          |
| Data-EnvTrajs-Averag... | 18.3           |
| Data-EnvTrajs-MaxReturn | 21.8           |
| Data-EnvTrajs-MinReturn | 16.4           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.84           |
| Data-TimeEnvSampleProc  | 0.000942       |
| Data-TimeEnvSampling    | 0.975          |
| Iteration               | 17             |
| ItrTime                 | 41.6           |
| LossAfter               | -0.0016641761  |
| LossBefore              | -1.1123173e-05 |
| Model-TimeModelFit      | 37             |
| ModelSampler-n_times... | 720000         |
| Policy-AverageAbsPol... | 0.8409211      |
| Policy-AverageDiscou... | 33.1           |
| Policy-AveragePolicyStd | 0.73638374     |
| Policy-AverageReturn    | 80.2           |
| Policy-MaxReturn        | 123            |
| Policy-MinReturn        | 40.2           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 23.1           |
| Policy-TimeAlgoOpt      | 0.781          |
| Policy-TimeSampleProc   | 0.568          |
| Policy-TimeSampling     | 2.27           |
| Policy-TimeStep         | 3.64           |
| Time                    | 466            |
| n_timesteps             | 18000          |
--------------------------------------------

 ---------------- Iteration 18 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 180 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 181 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 182 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 183 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 184 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 185 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 186 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 187 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 188 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 189 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.492          |
| Data-EnvSampler-Poli... | 1.03           |
| Data-EnvTrajs-Averag... | 19.7           |
| Data-EnvTrajs-MaxReturn | 21.7           |
| Data-EnvTrajs-MinReturn | 18.2           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.49           |
| Data-TimeEnvSampleProc  | 0.00388        |
| Data-TimeEnvSampling    | 1.57           |
| Iteration               | 18             |
| ItrTime                 | 34             |
| LossAfter               | -0.0030151857  |
| LossBefore              | -1.0884725e-05 |
| Model-TimeModelFit      | 29.8           |
| ModelSampler-n_times... | 760000         |
| Policy-AverageAbsPol... | 1.0179486      |
| Policy-AverageDiscou... | 24.5           |
| Policy-AveragePolicyStd | 0.71703196     |
| Policy-AverageReturn    | 49.6           |
| Policy-MaxReturn        | 82.9           |
| Policy-MinReturn        | 1.21           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 17.8           |
| Policy-TimeAlgoOpt      | 0.525          |
| Policy-TimeSampleProc   | 0.514          |
| Policy-TimeSampling     | 1.57           |
| Policy-TimeStep         | 2.62           |
| Time                    | 500            |
| n_timesteps             | 19000          |
--------------------------------------------

 ---------------- Iteration 19 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 190 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 191 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 192 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 193 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 194 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 195 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 196 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 197 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 198 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 199 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.316          |
| Data-EnvSampler-Poli... | 0.638          |
| Data-EnvTrajs-Averag... | 17.3           |
| Data-EnvTrajs-MaxReturn | 19.5           |
| Data-EnvTrajs-MinReturn | 14.8           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.78           |
| Data-TimeEnvSampleProc  | 0.000781       |
| Data-TimeEnvSampling    | 0.982          |
| Iteration               | 19             |
| ItrTime                 | 39.2           |
| LossAfter               | -0.00309831    |
| LossBefore              | -1.0564356e-05 |
| Model-TimeModelFit      | 34.9           |
| ModelSampler-n_times... | 800000         |
| Policy-AverageAbsPol... | 0.788176       |
| Policy-AverageDiscou... | 6.77           |
| Policy-AveragePolicyStd | 0.6949708      |
| Policy-AverageReturn    | -0.888         |
| Policy-MaxReturn        | 10.6           |
| Policy-MinReturn        | -7.06          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 3.97           |
| Policy-TimeAlgoOpt      | 0.707          |
| Policy-TimeSampleProc   | 0.545          |
| Policy-TimeSampling     | 2.08           |
| Policy-TimeStep         | 3.37           |
| Time                    | 540            |
| n_timesteps             | 20000          |
--------------------------------------------

 ---------------- Iteration 20 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 200 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 201 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 202 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 203 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 204 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 205 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 206 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 207 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 208 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 209 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.563          |
| Data-EnvSampler-Poli... | 1.14           |
| Data-EnvTrajs-Averag... | 16             |
| Data-EnvTrajs-MaxReturn | 17.6           |
| Data-EnvTrajs-MinReturn | 14.4           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.25           |
| Data-TimeEnvSampleProc  | 0.0014         |
| Data-TimeEnvSampling    | 1.76           |
| Iteration               | 20             |
| ItrTime                 | 32.4           |
| LossAfter               | -0.002822534   |
| LossBefore              | -1.0410736e-05 |
| Model-TimeModelFit      | 28.4           |
| ModelSampler-n_times... | 840000         |
| Policy-AverageAbsPol... | 0.840409       |
| Policy-AverageDiscou... | 31.7           |
| Policy-AveragePolicyStd | 0.68566287     |
| Policy-AverageReturn    | 58             |
| Policy-MaxReturn        | 121            |
| Policy-MinReturn        | 6.1            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 29.5           |
| Policy-TimeAlgoOpt      | 0.517          |
| Policy-TimeSampleProc   | 0.32           |
| Policy-TimeSampling     | 1.35           |
| Policy-TimeStep         | 2.24           |
| Time                    | 572            |
| n_timesteps             | 21000          |
--------------------------------------------

 ---------------- Iteration 21 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 210 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 211 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 212 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 213 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 214 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 215 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 216 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 217 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 218 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 219 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.376          |
| Data-EnvSampler-Poli... | 0.799          |
| Data-EnvTrajs-Averag... | 18.7           |
| Data-EnvTrajs-MaxReturn | 22.8           |
| Data-EnvTrajs-MinReturn | 11.5           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 3.97           |
| Data-TimeEnvSampleProc  | 0.000742       |
| Data-TimeEnvSampling    | 1.22           |
| Iteration               | 21             |
| ItrTime                 | 41.6           |
| LossAfter               | -0.0039363448  |
| LossBefore              | -1.0644052e-05 |
| Model-TimeModelFit      | 37.5           |
| ModelSampler-n_times... | 880000         |
| Policy-AverageAbsPol... | 1.005669       |
| Policy-AverageDiscou... | 15.9           |
| Policy-AveragePolicyStd | 0.7015863      |
| Policy-AverageReturn    | 26.4           |
| Policy-MaxReturn        | 33.4           |
| Policy-MinReturn        | 18.8           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 4.24           |
| Policy-TimeAlgoOpt      | 0.562          |
| Policy-TimeSampleProc   | 0.702          |
| Policy-TimeSampling     | 1.56           |
| Policy-TimeStep         | 2.86           |
| Time                    | 614            |
| n_timesteps             | 22000          |
--------------------------------------------

 ---------------- Iteration 22 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 220 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 221 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 222 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 223 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 224 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 225 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 226 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 227 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 228 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 229 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.318          |
| Data-EnvSampler-Poli... | 0.66           |
| Data-EnvTrajs-Averag... | 23.4           |
| Data-EnvTrajs-MaxReturn | 28.5           |
| Data-EnvTrajs-MinReturn | 20.1           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 3.14           |
| Data-TimeEnvSampleProc  | 0.000807       |
| Data-TimeEnvSampling    | 1.01           |
| Iteration               | 22             |
| ItrTime                 | 29.4           |
| LossAfter               | -0.0054464573  |
| LossBefore              | -1.0602634e-05 |
| Model-TimeModelFit      | 24.8           |
| ModelSampler-n_times... | 920000         |
| Policy-AverageAbsPol... | 0.79244846     |
| Policy-AverageDiscou... | -245           |
| Policy-AveragePolicyStd | 0.6993893      |
| Policy-AverageReturn    | -731           |
| Policy-MaxReturn        | 140            |
| Policy-MinReturn        | -1.66e+04      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 3.64e+03       |
| Policy-TimeAlgoOpt      | 0.704          |
| Policy-TimeSampleProc   | 0.78           |
| Policy-TimeSampling     | 2.07           |
| Policy-TimeStep         | 3.6            |
| Time                    | 643            |
| n_timesteps             | 23000          |
--------------------------------------------

 ---------------- Iteration 23 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 230 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 231 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 232 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 233 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 234 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 235 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 236 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 237 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 238 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 239 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.581          |
| Data-EnvSampler-Poli... | 1.16           |
| Data-EnvTrajs-Averag... | 25.3           |
| Data-EnvTrajs-MaxReturn | 27.9           |
| Data-EnvTrajs-MinReturn | 22.4           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.99           |
| Data-TimeEnvSampleProc  | 0.00163        |
| Data-TimeEnvSampling    | 1.79           |
| Iteration               | 23             |
| ItrTime                 | 39.7           |
| LossAfter               | -0.0034559038  |
| LossBefore              | -1.0601077e-05 |
| Model-TimeModelFit      | 35.6           |
| ModelSampler-n_times... | 960000         |
| Policy-AverageAbsPol... | 0.9813252      |
| Policy-AverageDiscou... | -210           |
| Policy-AveragePolicyStd | 0.6990653      |
| Policy-AverageReturn    | -681           |
| Policy-MaxReturn        | 222            |
| Policy-MinReturn        | -1.54e+04      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 3.37e+03       |
| Policy-TimeAlgoOpt      | 0.518          |
| Policy-TimeSampleProc   | 0.399          |
| Policy-TimeSampling     | 1.36           |
| Policy-TimeStep         | 2.32           |
| Time                    | 683            |
| n_timesteps             | 24000          |
--------------------------------------------

 ---------------- Iteration 24 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 240 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 241 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 242 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 243 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 244 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 245 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 246 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 247 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 248 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 249 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.349          |
| Data-EnvSampler-Poli... | 0.828          |
| Data-EnvTrajs-Averag... | 27             |
| Data-EnvTrajs-MaxReturn | 29.7           |
| Data-EnvTrajs-MinReturn | 25.2           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.54           |
| Data-TimeEnvSampleProc  | 0.000934       |
| Data-TimeEnvSampling    | 1.21           |
| Iteration               | 24             |
| ItrTime                 | 36.6           |
| LossAfter               | -0.004149052   |
| LossBefore              | -1.0639162e-05 |
| Model-TimeModelFit      | 31.6           |
| ModelSampler-n_times... | 1000000        |
| Policy-AverageAbsPol... | 0.9984626      |
| Policy-AverageDiscou... | 36.4           |
| Policy-AveragePolicyStd | 0.7013678      |
| Policy-AverageReturn    | 92.3           |
| Policy-MaxReturn        | 189            |
| Policy-MinReturn        | 32             |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 38.8           |
| Policy-TimeAlgoOpt      | 0.874          |
| Policy-TimeSampleProc   | 0.666          |
| Policy-TimeSampling     | 2.22           |
| Policy-TimeStep         | 3.81           |
| Time                    | 719            |
| n_timesteps             | 25000          |
--------------------------------------------

 ---------------- Iteration 25 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 250 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 251 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 252 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 253 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 254 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 255 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 256 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 257 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 258 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 259 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.516          |
| Data-EnvSampler-Poli... | 0.922          |
| Data-EnvTrajs-Averag... | 25.5           |
| Data-EnvTrajs-MaxReturn | 27.9           |
| Data-EnvTrajs-MinReturn | 19.8           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 3.01           |
| Data-TimeEnvSampleProc  | 0.00102        |
| Data-TimeEnvSampling    | 1.48           |
| Iteration               | 25             |
| ItrTime                 | 33.2           |
| LossAfter               | -0.003325612   |
| LossBefore              | -1.0535433e-05 |
| Model-TimeModelFit      | 29.2           |
| ModelSampler-n_times... | 1040000        |
| Policy-AverageAbsPol... | 1.1122355      |
| Policy-AverageDiscou... | 20.2           |
| Policy-AveragePolicyStd | 0.6935481      |
| Policy-AverageReturn    | 33.7           |
| Policy-MaxReturn        | 43.2           |
| Policy-MinReturn        | 22.1           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 7.43           |
| Policy-TimeAlgoOpt      | 0.513          |
| Policy-TimeSampleProc   | 0.502          |
| Policy-TimeSampling     | 1.46           |
| Policy-TimeStep         | 2.49           |
| Time                    | 753            |
| n_timesteps             | 26000          |
--------------------------------------------

 ---------------- Iteration 26 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 260 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 261 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 262 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 263 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 264 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 265 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 266 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 267 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 268 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 269 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.333          |
| Data-EnvSampler-Poli... | 0.746          |
| Data-EnvTrajs-Averag... | 28.4           |
| Data-EnvTrajs-MaxReturn | 30.4           |
| Data-EnvTrajs-MinReturn | 25.9           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.9            |
| Data-TimeEnvSampleProc  | 0.000883       |
| Data-TimeEnvSampling    | 1.11           |
| Iteration               | 26             |
| ItrTime                 | 41.8           |
| LossAfter               | -0.0021087264  |
| LossBefore              | -1.0207444e-05 |
| Model-TimeModelFit      | 38             |
| ModelSampler-n_times... | 1080000        |
| Policy-AverageAbsPol... | 1.0318801      |
| Policy-AverageDiscou... | 28.4           |
| Policy-AveragePolicyStd | 0.67192215     |
| Policy-AverageReturn    | 47.9           |
| Policy-MaxReturn        | 58             |
| Policy-MinReturn        | 35.8           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 6.3            |
| Policy-TimeAlgoOpt      | 0.538          |
| Policy-TimeSampleProc   | 0.34           |
| Policy-TimeSampling     | 1.77           |
| Policy-TimeStep         | 2.67           |
| Time                    | 794            |
| n_timesteps             | 27000          |
--------------------------------------------

 ---------------- Iteration 27 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 270 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 271 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 272 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 273 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 274 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 275 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 276 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 277 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 278 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 279 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.306          |
| Data-EnvSampler-Poli... | 0.622          |
| Data-EnvTrajs-Averag... | 32.4           |
| Data-EnvTrajs-MaxReturn | 33.8           |
| Data-EnvTrajs-MinReturn | 30.3           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.21           |
| Data-TimeEnvSampleProc  | 0.000841       |
| Data-TimeEnvSampling    | 0.954          |
| Iteration               | 27             |
| ItrTime                 | 31.2           |
| LossAfter               | -0.0023305337  |
| LossBefore              | -1.0042784e-05 |
| Model-TimeModelFit      | 26.2           |
| ModelSampler-n_times... | 1120000        |
| Policy-AverageAbsPol... | 1.2250404      |
| Policy-AverageDiscou... | 26.8           |
| Policy-AveragePolicyStd | 0.66113275     |
| Policy-AverageReturn    | 41             |
| Policy-MaxReturn        | 56.3           |
| Policy-MinReturn        | 29.9           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 7.02           |
| Policy-TimeAlgoOpt      | 0.788          |
| Policy-TimeSampleProc   | 0.779          |
| Policy-TimeSampling     | 2.37           |
| Policy-TimeStep         | 3.98           |
| Time                    | 826            |
| n_timesteps             | 28000          |
--------------------------------------------

 ---------------- Iteration 28 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 280 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 281 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 282 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 283 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 284 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 285 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 286 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 287 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 288 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 289 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.531         |
| Data-EnvSampler-Poli... | 1             |
| Data-EnvTrajs-Averag... | 33.6          |
| Data-EnvTrajs-MaxReturn | 35.3          |
| Data-EnvTrajs-MinReturn | 31.3          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.47          |
| Data-TimeEnvSampleProc  | 0.00159       |
| Data-TimeEnvSampling    | 1.58          |
| Iteration               | 28            |
| ItrTime                 | 40.9          |
| LossAfter               | -0.0033184215 |
| LossBefore              | -9.796762e-06 |
| Model-TimeModelFit      | 36.9          |
| ModelSampler-n_times... | 1160000       |
| Policy-AverageAbsPol... | 1.1367214     |
| Policy-AverageDiscou... | 28.1          |
| Policy-AveragePolicyStd | 0.64484245    |
| Policy-AverageReturn    | 42.7          |
| Policy-MaxReturn        | 52.6          |
| Policy-MinReturn        | 35.8          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 3.96          |
| Policy-TimeAlgoOpt      | 0.54          |
| Policy-TimeSampleProc   | 0.445         |
| Policy-TimeSampling     | 1.37          |
| Policy-TimeStep         | 2.42          |
| Time                    | 866           |
| n_timesteps             | 29000         |
-------------------------------------------

 ---------------- Iteration 29 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 290 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 291 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 292 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 293 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 294 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 295 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 296 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 297 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 298 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 299 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.273         |
| Data-EnvSampler-Poli... | 0.537         |
| Data-EnvTrajs-Averag... | 33.3          |
| Data-EnvTrajs-MaxReturn | 35.4          |
| Data-EnvTrajs-MinReturn | 30.2          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.74          |
| Data-TimeEnvSampleProc  | 0.0008        |
| Data-TimeEnvSampling    | 0.838         |
| Iteration               | 29            |
| ItrTime                 | 37.3          |
| LossAfter               | -0.0043219025 |
| LossBefore              | -9.559818e-06 |
| Model-TimeModelFit      | 32.6          |
| ModelSampler-n_times... | 1200000       |
| Policy-AverageAbsPol... | 1.0808513     |
| Policy-AverageDiscou... | 23.8          |
| Policy-AveragePolicyStd | 0.6294275     |
| Policy-AverageReturn    | 39.2          |
| Policy-MaxReturn        | 49.9          |
| Policy-MinReturn        | 29.5          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 5.56          |
| Policy-TimeAlgoOpt      | 0.78          |
| Policy-TimeSampleProc   | 0.798         |
| Policy-TimeSampling     | 2.27          |
| Policy-TimeStep         | 3.89          |
| Time                    | 904           |
| n_timesteps             | 30000         |
-------------------------------------------

 ---------------- Iteration 30 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 300 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 301 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 302 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 303 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 304 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 305 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 306 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 307 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 308 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 309 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.361         |
| Data-EnvSampler-Poli... | 0.657         |
| Data-EnvTrajs-Averag... | 33            |
| Data-EnvTrajs-MaxReturn | 34.7          |
| Data-EnvTrajs-MinReturn | 30.8          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.5           |
| Data-TimeEnvSampleProc  | 0.000823      |
| Data-TimeEnvSampling    | 1.05          |
| Iteration               | 30            |
| ItrTime                 | 30.1          |
| LossAfter               | -0.0024803358 |
| LossBefore              | -9.32503e-06  |
| Model-TimeModelFit      | 26.2          |
| ModelSampler-n_times... | 1240000       |
| Policy-AverageAbsPol... | 1.2193872     |
| Policy-AverageDiscou... | 24.2          |
| Policy-AveragePolicyStd | 0.61693895    |
| Policy-AverageReturn    | 36.4          |
| Policy-MaxReturn        | 45.2          |
| Policy-MinReturn        | 23            |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 5.64          |
| Policy-TimeAlgoOpt      | 0.606         |
| Policy-TimeSampleProc   | 0.59          |
| Policy-TimeSampling     | 1.62          |
| Policy-TimeStep         | 2.89          |
| Time                    | 934           |
| n_timesteps             | 31000         |
-------------------------------------------

 ---------------- Iteration 31 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 310 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 311 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 312 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 313 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 314 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 315 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 316 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 317 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 318 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 319 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.475         |
| Data-EnvSampler-Poli... | 0.904         |
| Data-EnvTrajs-Averag... | 33.4          |
| Data-EnvTrajs-MaxReturn | 35.2          |
| Data-EnvTrajs-MinReturn | 31.1          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.4           |
| Data-TimeEnvSampleProc  | 0.00154       |
| Data-TimeEnvSampling    | 1.42          |
| Iteration               | 31            |
| ItrTime                 | 42.7          |
| LossAfter               | -0.0039319135 |
| LossBefore              | -8.86775e-06  |
| Model-TimeModelFit      | 39            |
| ModelSampler-n_times... | 1280000       |
| Policy-AverageAbsPol... | 1.2798374     |
| Policy-AverageDiscou... | 26            |
| Policy-AveragePolicyStd | 0.58779603    |
| Policy-AverageReturn    | 48.2          |
| Policy-MaxReturn        | 53.8          |
| Policy-MinReturn        | 43.2          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 2.75          |
| Policy-TimeAlgoOpt      | 0.559         |
| Policy-TimeSampleProc   | 0.265         |
| Policy-TimeSampling     | 1.51          |
| Policy-TimeStep         | 2.37          |
| Time                    | 977           |
| n_timesteps             | 32000         |
-------------------------------------------

 ---------------- Iteration 32 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 320 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 321 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 322 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 323 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 324 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 325 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 326 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 327 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 328 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 329 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.305         |
| Data-EnvSampler-Poli... | 0.652         |
| Data-EnvTrajs-Averag... | 34.9          |
| Data-EnvTrajs-MaxReturn | 36.4          |
| Data-EnvTrajs-MinReturn | 33.8          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 0.888         |
| Data-TimeEnvSampleProc  | 0.00138       |
| Data-TimeEnvSampling    | 0.986         |
| Iteration               | 32            |
| ItrTime                 | 36            |
| LossAfter               | -0.0012204127 |
| LossBefore              | -8.795537e-06 |
| Model-TimeModelFit      | 31.2          |
| ModelSampler-n_times... | 1320000       |
| Policy-AverageAbsPol... | 1.2261544     |
| Policy-AverageDiscou... | 28.2          |
| Policy-AveragePolicyStd | 0.5839739     |
| Policy-AverageReturn    | 49.8          |
| Policy-MaxReturn        | 53.9          |
| Policy-MinReturn        | 46.2          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 2.21          |
| Policy-TimeAlgoOpt      | 0.693         |
| Policy-TimeSampleProc   | 0.755         |
| Policy-TimeSampling     | 2.26          |
| Policy-TimeStep         | 3.75          |
| Time                    | 1.01e+03      |
| n_timesteps             | 33000         |
-------------------------------------------

 ---------------- Iteration 33 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 330 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 331 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 332 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 333 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 334 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 335 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 336 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 337 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 338 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 339 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.492         |
| Data-EnvSampler-Poli... | 0.996         |
| Data-EnvTrajs-Averag... | 34.8          |
| Data-EnvTrajs-MaxReturn | 36.1          |
| Data-EnvTrajs-MinReturn | 34.1          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 0.767         |
| Data-TimeEnvSampleProc  | 0.000778      |
| Data-TimeEnvSampling    | 1.53          |
| Iteration               | 33            |
| ItrTime                 | 43.5          |
| LossAfter               | -0.0023511548 |
| LossBefore              | -8.698448e-06 |
| Model-TimeModelFit      | 39.7          |
| ModelSampler-n_times... | 1360000       |
| Policy-AverageAbsPol... | 1.2554235     |
| Policy-AverageDiscou... | 26.2          |
| Policy-AveragePolicyStd | 0.57857263    |
| Policy-AverageReturn    | 43.9          |
| Policy-MaxReturn        | 46.3          |
| Policy-MinReturn        | 41.1          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.48          |
| Policy-TimeAlgoOpt      | 0.483         |
| Policy-TimeSampleProc   | 0.418         |
| Policy-TimeSampling     | 1.37          |
| Policy-TimeStep         | 2.29          |
| Time                    | 1.06e+03      |
| n_timesteps             | 34000         |
-------------------------------------------

 ---------------- Iteration 34 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 340 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 341 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 342 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 343 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 344 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 345 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 346 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 347 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 348 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 349 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.287         |
| Data-EnvSampler-Poli... | 0.591         |
| Data-EnvTrajs-Averag... | 35.5          |
| Data-EnvTrajs-MaxReturn | 36.4          |
| Data-EnvTrajs-MinReturn | 34.6          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 0.586         |
| Data-TimeEnvSampleProc  | 0.00284       |
| Data-TimeEnvSampling    | 0.907         |
| Iteration               | 34            |
| ItrTime                 | 34.7          |
| LossAfter               | -0.0015076575 |
| LossBefore              | -8.41017e-06  |
| Model-TimeModelFit      | 29.9          |
| ModelSampler-n_times... | 1400000       |
| Policy-AverageAbsPol... | 1.3876467     |
| Policy-AverageDiscou... | 28.7          |
| Policy-AveragePolicyStd | 0.561507      |
| Policy-AverageReturn    | 52            |
| Policy-MaxReturn        | 54.6          |
| Policy-MinReturn        | 49.2          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.44          |
| Policy-TimeAlgoOpt      | 0.744         |
| Policy-TimeSampleProc   | 0.602         |
| Policy-TimeSampling     | 2.5           |
| Policy-TimeStep         | 3.87          |
| Time                    | 1.09e+03      |
| n_timesteps             | 35000         |
-------------------------------------------

 ---------------- Iteration 35 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 350 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 351 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 352 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 353 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 354 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 355 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 356 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 357 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 358 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 359 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.485         |
| Data-EnvSampler-Poli... | 0.928         |
| Data-EnvTrajs-Averag... | 36.7          |
| Data-EnvTrajs-MaxReturn | 37.6          |
| Data-EnvTrajs-MinReturn | 35.4          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 0.785         |
| Data-TimeEnvSampleProc  | 0.00136       |
| Data-TimeEnvSampling    | 1.46          |
| Iteration               | 35            |
| ItrTime                 | 37.8          |
| LossAfter               | -0.002182811  |
| LossBefore              | -8.046601e-06 |
| Model-TimeModelFit      | 34            |
| ModelSampler-n_times... | 1440000       |
| Policy-AverageAbsPol... | 1.3408625     |
| Policy-AverageDiscou... | 30.7          |
| Policy-AveragePolicyStd | 0.5414719     |
| Policy-AverageReturn    | 60.9          |
| Policy-MaxReturn        | 86.4          |
| Policy-MinReturn        | 51.6          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 8.17          |
| Policy-TimeAlgoOpt      | 0.547         |
| Policy-TimeSampleProc   | 0.339         |
| Policy-TimeSampling     | 1.44          |
| Policy-TimeStep         | 2.36          |
| Time                    | 1.13e+03      |
| n_timesteps             | 36000         |
-------------------------------------------

 ---------------- Iteration 36 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 360 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 361 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 362 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 363 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 364 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 365 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 366 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 367 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 368 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 369 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.284         |
| Data-EnvSampler-Poli... | 0.515         |
| Data-EnvTrajs-Averag... | 36.3          |
| Data-EnvTrajs-MaxReturn | 37.4          |
| Data-EnvTrajs-MinReturn | 34.8          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 0.959         |
| Data-TimeEnvSampleProc  | 0.00086       |
| Data-TimeEnvSampling    | 0.826         |
| Iteration               | 36            |
| ItrTime                 | 42.4          |
| LossAfter               | -0.0036314894 |
| LossBefore              | -7.810099e-06 |
| Model-TimeModelFit      | 37.7          |
| ModelSampler-n_times... | 1480000       |
| Policy-AverageAbsPol... | 1.3105544     |
| Policy-AverageDiscou... | 28.9          |
| Policy-AveragePolicyStd | 0.52777976    |
| Policy-AverageReturn    | 47.5          |
| Policy-MaxReturn        | 54.1          |
| Policy-MinReturn        | 40.2          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 3.13          |
| Policy-TimeAlgoOpt      | 0.769         |
| Policy-TimeSampleProc   | 0.719         |
| Policy-TimeSampling     | 2.3           |
| Policy-TimeStep         | 3.83          |
| Time                    | 1.17e+03      |
| n_timesteps             | 37000         |
-------------------------------------------

 ---------------- Iteration 37 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 370 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 371 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 372 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 373 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 374 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 375 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 376 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 377 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 378 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 379 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.445         |
| Data-EnvSampler-Poli... | 0.856         |
| Data-EnvTrajs-Averag... | 35.5          |
| Data-EnvTrajs-MaxReturn | 36.4          |
| Data-EnvTrajs-MinReturn | 34.5          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 0.719         |
| Data-TimeEnvSampleProc  | 0.00116       |
| Data-TimeEnvSampling    | 1.34          |
| Iteration               | 37            |
| ItrTime                 | 37.3          |
| LossAfter               | -0.0016159366 |
| LossBefore              | -7.780849e-06 |
| Model-TimeModelFit      | 33.4          |
| ModelSampler-n_times... | 1520000       |
| Policy-AverageAbsPol... | 1.2484021     |
| Policy-AverageDiscou... | 22.6          |
| Policy-AveragePolicyStd | 0.5281159     |
| Policy-AverageReturn    | 27.1          |
| Policy-MaxReturn        | 31.6          |
| Policy-MinReturn        | 23.3          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 2.35          |
| Policy-TimeAlgoOpt      | 0.517         |
| Policy-TimeSampleProc   | 0.461         |
| Policy-TimeSampling     | 1.44          |
| Policy-TimeStep         | 2.49          |
| Time                    | 1.21e+03      |
| n_timesteps             | 38000         |
-------------------------------------------

 ---------------- Iteration 38 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 380 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 381 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 382 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 383 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 384 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 385 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 386 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 387 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 388 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 389 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.284         |
| Data-EnvSampler-Poli... | 0.518         |
| Data-EnvTrajs-Averag... | 35.5          |
| Data-EnvTrajs-MaxReturn | 36.6          |
| Data-EnvTrajs-MinReturn | 34.7          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 0.639         |
| Data-TimeEnvSampleProc  | 0.00087       |
| Data-TimeEnvSampling    | 0.827         |
| Iteration               | 38            |
| ItrTime                 | 41.8          |
| LossAfter               | -0.00254685   |
| LossBefore              | -7.691484e-06 |
| Model-TimeModelFit      | 38.1          |
| ModelSampler-n_times... | 1560000       |
| Policy-AverageAbsPol... | 1.1744089     |
| Policy-AverageDiscou... | 27.1          |
| Policy-AveragePolicyStd | 0.5211716     |
| Policy-AverageReturn    | 44.1          |
| Policy-MaxReturn        | 75            |
| Policy-MinReturn        | 20            |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 15.4          |
| Policy-TimeAlgoOpt      | 0.568         |
| Policy-TimeSampleProc   | 0.459         |
| Policy-TimeSampling     | 1.81          |
| Policy-TimeStep         | 2.87          |
| Time                    | 1.25e+03      |
| n_timesteps             | 39000         |
-------------------------------------------

 ---------------- Iteration 39 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 390 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 391 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 392 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 393 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 394 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 395 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 396 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 397 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 398 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 399 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.288         |
| Data-EnvSampler-Poli... | 0.528         |
| Data-EnvTrajs-Averag... | 36.4          |
| Data-EnvTrajs-MaxReturn | 37.6          |
| Data-EnvTrajs-MinReturn | 36            |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 0.615         |
| Data-TimeEnvSampleProc  | 0.000594      |
| Data-TimeEnvSampling    | 0.843         |
| Iteration               | 39            |
| ItrTime                 | 33.5          |
| LossAfter               | -0.0028491342 |
| LossBefore              | -7.533601e-06 |
| Model-TimeModelFit      | 28.6          |
| ModelSampler-n_times... | 1600000       |
| Policy-AverageAbsPol... | 1.1148524     |
| Policy-AverageDiscou... | 23.1          |
| Policy-AveragePolicyStd | 0.515192      |
| Policy-AverageReturn    | 26.6          |
| Policy-MaxReturn        | 33.4          |
| Policy-MinReturn        | 19.1          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 3.88          |
| Policy-TimeAlgoOpt      | 0.812         |
| Policy-TimeSampleProc   | 0.699         |
| Policy-TimeSampling     | 2.37          |
| Policy-TimeStep         | 3.96          |
| Time                    | 1.28e+03      |
| n_timesteps             | 40000         |
-------------------------------------------

 ---------------- Iteration 40 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 400 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 401 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 402 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 403 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 404 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 405 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 406 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 407 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 408 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 409 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.476          |
| Data-EnvSampler-Poli... | 0.878          |
| Data-EnvTrajs-Averag... | 34.6           |
| Data-EnvTrajs-MaxReturn | 35.7           |
| Data-EnvTrajs-MinReturn | 33.8           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 0.677          |
| Data-TimeEnvSampleProc  | 0.00159        |
| Data-TimeEnvSampling    | 1.4            |
| Iteration               | 40             |
| ItrTime                 | 41.5           |
| LossAfter               | -0.0038705936  |
| LossBefore              | -7.3374936e-06 |
| Model-TimeModelFit      | 37.7           |
| ModelSampler-n_times... | 1640000        |
| Policy-AverageAbsPol... | 1.0946968      |
| Policy-AverageDiscou... | -7.04          |
| Policy-AveragePolicyStd | 0.50312024     |
| Policy-AverageReturn    | -175           |
| Policy-MaxReturn        | 109            |
| Policy-MinReturn        | -4.24e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 936            |
| Policy-TimeAlgoOpt      | 0.498          |
| Policy-TimeSampleProc   | 0.365          |
| Policy-TimeSampling     | 1.49           |
| Policy-TimeStep         | 2.38           |
| Time                    | 1.33e+03       |
| n_timesteps             | 41000          |
--------------------------------------------

 ---------------- Iteration 41 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 410 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 411 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 412 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 413 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 414 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 415 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 416 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 417 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 418 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 419 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.275         |
| Data-EnvSampler-Poli... | 0.521         |
| Data-EnvTrajs-Averag... | 35.1          |
| Data-EnvTrajs-MaxReturn | 36.5          |
| Data-EnvTrajs-MinReturn | 33.8          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.03          |
| Data-TimeEnvSampleProc  | 0.000858      |
| Data-TimeEnvSampling    | 0.822         |
| Iteration               | 41            |
| ItrTime                 | 41.4          |
| LossAfter               | -0.0012687164 |
| LossBefore              | -7.200461e-06 |
| Model-TimeModelFit      | 36.6          |
| ModelSampler-n_times... | 1680000       |
| Policy-AverageAbsPol... | 1.1949645     |
| Policy-AverageDiscou... | 37            |
| Policy-AveragePolicyStd | 0.49716803    |
| Policy-AverageReturn    | 91.1          |
| Policy-MaxReturn        | 157           |
| Policy-MinReturn        | 34.9          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 26.5          |
| Policy-TimeAlgoOpt      | 0.734         |
| Policy-TimeSampleProc   | 0.773         |
| Policy-TimeSampling     | 2.42          |
| Policy-TimeStep         | 3.97          |
| Time                    | 1.37e+03      |
| n_timesteps             | 42000         |
-------------------------------------------

 ---------------- Iteration 42 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 420 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 421 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 422 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 423 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 424 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 425 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 426 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 427 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 428 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 429 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.467          |
| Data-EnvSampler-Poli... | 0.884          |
| Data-EnvTrajs-Averag... | 35.1           |
| Data-EnvTrajs-MaxReturn | 36             |
| Data-EnvTrajs-MinReturn | 34.3           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 0.629          |
| Data-TimeEnvSampleProc  | 0.00141        |
| Data-TimeEnvSampling    | 1.39           |
| Iteration               | 42             |
| ItrTime                 | 34.6           |
| LossAfter               | -0.004712725   |
| LossBefore              | -7.0440183e-06 |
| Model-TimeModelFit      | 30.5           |
| ModelSampler-n_times... | 1720000        |
| Policy-AverageAbsPol... | 1.0591474      |
| Policy-AverageDiscou... | 29.6           |
| Policy-AveragePolicyStd | 0.4888482      |
| Policy-AverageReturn    | 49.7           |
| Policy-MaxReturn        | 86.6           |
| Policy-MinReturn        | 27.8           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 18.8           |
| Policy-TimeAlgoOpt      | 0.5            |
| Policy-TimeSampleProc   | 0.606          |
| Policy-TimeSampling     | 1.55           |
| Policy-TimeStep         | 2.69           |
| Time                    | 1.4e+03        |
| n_timesteps             | 43000          |
--------------------------------------------

 ---------------- Iteration 43 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 430 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 431 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 432 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 433 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 434 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 435 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 436 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 437 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 438 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 439 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.298         |
| Data-EnvSampler-Poli... | 0.593         |
| Data-EnvTrajs-Averag... | 35.5          |
| Data-EnvTrajs-MaxReturn | 36.9          |
| Data-EnvTrajs-MinReturn | 33.3          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.29          |
| Data-TimeEnvSampleProc  | 0.000596      |
| Data-TimeEnvSampling    | 0.919         |
| Iteration               | 43            |
| ItrTime                 | 50.2          |
| LossAfter               | -0.004014565  |
| LossBefore              | -6.853058e-06 |
| Model-TimeModelFit      | 45.5          |
| ModelSampler-n_times... | 1760000       |
| Policy-AverageAbsPol... | 1.0206288     |
| Policy-AverageDiscou... | 23.2          |
| Policy-AveragePolicyStd | 0.47982863    |
| Policy-AverageReturn    | -29.6         |
| Policy-MaxReturn        | 179           |
| Policy-MinReturn        | -1.21e+03     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 320           |
| Policy-TimeAlgoOpt      | 0.817         |
| Policy-TimeSampleProc   | 0.608         |
| Policy-TimeSampling     | 2.25          |
| Policy-TimeStep         | 3.76          |
| Time                    | 1.45e+03      |
| n_timesteps             | 44000         |
-------------------------------------------

 ---------------- Iteration 44 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 440 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 441 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 442 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 443 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 444 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 445 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 446 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 447 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 448 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 449 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.45          |
| Data-EnvSampler-Poli... | 0.883         |
| Data-EnvTrajs-Averag... | 37.4          |
| Data-EnvTrajs-MaxReturn | 40            |
| Data-EnvTrajs-MinReturn | 34.9          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 2             |
| Data-TimeEnvSampleProc  | 0.00132       |
| Data-TimeEnvSampling    | 1.37          |
| Iteration               | 44            |
| ItrTime                 | 54.5          |
| LossAfter               | -0.0017718701 |
| LossBefore              | -7.000974e-06 |
| Model-TimeModelFit      | 49.3          |
| ModelSampler-n_times... | 1800000       |
| Policy-AverageAbsPol... | 1.0842558     |
| Policy-AverageDiscou... | 24.4          |
| Policy-AveragePolicyStd | 0.4857409     |
| Policy-AverageReturn    | 25.5          |
| Policy-MaxReturn        | 32.3          |
| Policy-MinReturn        | 16.6          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 4.57          |
| Policy-TimeAlgoOpt      | 0.777         |
| Policy-TimeSampleProc   | 0.69          |
| Policy-TimeSampling     | 2.24          |
| Policy-TimeStep         | 3.75          |
| Time                    | 1.51e+03      |
| n_timesteps             | 45000         |
-------------------------------------------

 ---------------- Iteration 45 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 450 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 451 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 452 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 453 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 454 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 455 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 456 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 457 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 458 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 459 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.455         |
| Data-EnvSampler-Poli... | 0.907         |
| Data-EnvTrajs-Averag... | 36.8          |
| Data-EnvTrajs-MaxReturn | 37.5          |
| Data-EnvTrajs-MinReturn | 35.8          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 0.663         |
| Data-TimeEnvSampleProc  | 0.00129       |
| Data-TimeEnvSampling    | 1.4           |
| Iteration               | 45            |
| ItrTime                 | 43            |
| LossAfter               | -0.0023976234 |
| LossBefore              | -6.797541e-06 |
| Model-TimeModelFit      | 39.1          |
| ModelSampler-n_times... | 1840000       |
| Policy-AverageAbsPol... | 1.0164098     |
| Policy-AverageDiscou... | 24            |
| Policy-AveragePolicyStd | 0.47964403    |
| Policy-AverageReturn    | 9.47          |
| Policy-MaxReturn        | 45.3          |
| Policy-MinReturn        | -564          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 132           |
| Policy-TimeAlgoOpt      | 0.536         |
| Policy-TimeSampleProc   | 0.446         |
| Policy-TimeSampling     | 1.49          |
| Policy-TimeStep         | 2.55          |
| Time                    | 1.55e+03      |
| n_timesteps             | 46000         |
-------------------------------------------

 ---------------- Iteration 46 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 460 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 461 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 462 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 463 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 464 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 465 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 466 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 467 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 468 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 469 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.301         |
| Data-EnvSampler-Poli... | 0.573         |
| Data-EnvTrajs-Averag... | 37.5          |
| Data-EnvTrajs-MaxReturn | 38.2          |
| Data-EnvTrajs-MinReturn | 36.5          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 0.637         |
| Data-TimeEnvSampleProc  | 0.00088       |
| Data-TimeEnvSampling    | 0.901         |
| Iteration               | 46            |
| ItrTime                 | 48.6          |
| LossAfter               | -0.0034973538 |
| LossBefore              | -6.629231e-06 |
| Model-TimeModelFit      | 43.6          |
| ModelSampler-n_times... | 1880000       |
| Policy-AverageAbsPol... | 1.2010573     |
| Policy-AverageDiscou... | 16.6          |
| Policy-AveragePolicyStd | 0.4707842     |
| Policy-AverageReturn    | -52           |
| Policy-MaxReturn        | 71.6          |
| Policy-MinReturn        | -1.71e+03     |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 394           |
| Policy-TimeAlgoOpt      | 0.705         |
| Policy-TimeSampleProc   | 0.878         |
| Policy-TimeSampling     | 2.46          |
| Policy-TimeStep         | 4.1           |
| Time                    | 1.6e+03       |
| n_timesteps             | 47000         |
-------------------------------------------

 ---------------- Iteration 47 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 470 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 471 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 472 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 473 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 474 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 475 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 476 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 477 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 478 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 479 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.466          |
| Data-EnvSampler-Poli... | 0.939          |
| Data-EnvTrajs-Averag... | 37.2           |
| Data-EnvTrajs-MaxReturn | 38.2           |
| Data-EnvTrajs-MinReturn | 36             |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 0.871          |
| Data-TimeEnvSampleProc  | 0.00124        |
| Data-TimeEnvSampling    | 1.45           |
| Iteration               | 47             |
| ItrTime                 | 55.8           |
| LossAfter               | -0.0019354186  |
| LossBefore              | -6.5458967e-06 |
| Model-TimeModelFit      | 50.6           |
| ModelSampler-n_times... | 1920000        |
| Policy-AverageAbsPol... | 1.1123596      |
| Policy-AverageDiscou... | 23.1           |
| Policy-AveragePolicyStd | 0.46561554     |
| Policy-AverageReturn    | 29.5           |
| Policy-MaxReturn        | 40.3           |
| Policy-MinReturn        | 21.4           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 5.44           |
| Policy-TimeAlgoOpt      | 0.768          |
| Policy-TimeSampleProc   | 0.676          |
| Policy-TimeSampling     | 2.3            |
| Policy-TimeStep         | 3.77           |
| Time                    | 1.65e+03       |
| n_timesteps             | 48000          |
--------------------------------------------

 ---------------- Iteration 48 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 480 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 481 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 482 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 483 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 484 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 485 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 486 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 487 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 488 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 489 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.468          |
| Data-EnvSampler-Poli... | 0.922          |
| Data-EnvTrajs-Averag... | 37.8           |
| Data-EnvTrajs-MaxReturn | 39.9           |
| Data-EnvTrajs-MinReturn | 36.5           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.27           |
| Data-TimeEnvSampleProc  | 0.00131        |
| Data-TimeEnvSampling    | 1.43           |
| Iteration               | 48             |
| ItrTime                 | 54.1           |
| LossAfter               | -0.00173155    |
| LossBefore              | -6.4798933e-06 |
| Model-TimeModelFit      | 48.9           |
| ModelSampler-n_times... | 1960000        |
| Policy-AverageAbsPol... | 1.2694763      |
| Policy-AverageDiscou... | 26.2           |
| Policy-AveragePolicyStd | 0.4614668      |
| Policy-AverageReturn    | 32.1           |
| Policy-MaxReturn        | 41.5           |
| Policy-MinReturn        | 22.1           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 4.78           |
| Policy-TimeAlgoOpt      | 0.765          |
| Policy-TimeSampleProc   | 0.483          |
| Policy-TimeSampling     | 2.49           |
| Policy-TimeStep         | 3.77           |
| Time                    | 1.71e+03       |
| n_timesteps             | 49000          |
--------------------------------------------

 ---------------- Iteration 49 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 490 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 491 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 492 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 493 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 494 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 495 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 496 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 497 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 498 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 499 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.469          |
| Data-EnvSampler-Poli... | 0.975          |
| Data-EnvTrajs-Averag... | 37.4           |
| Data-EnvTrajs-MaxReturn | 39.4           |
| Data-EnvTrajs-MinReturn | 36             |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.19           |
| Data-TimeEnvSampleProc  | 0.00129        |
| Data-TimeEnvSampling    | 1.49           |
| Iteration               | 49             |
| ItrTime                 | 37.3           |
| LossAfter               | -0.001989139   |
| LossBefore              | -6.3637012e-06 |
| Model-TimeModelFit      | 32.9           |
| ModelSampler-n_times... | 2000000        |
| Policy-AverageAbsPol... | 1.1704048      |
| Policy-AverageDiscou... | 17.9           |
| Policy-AveragePolicyStd | 0.4573213      |
| Policy-AverageReturn    | 14.1           |
| Policy-MaxReturn        | 29.6           |
| Policy-MinReturn        | 1.59           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 7.44           |
| Policy-TimeAlgoOpt      | 0.581          |
| Policy-TimeSampleProc   | 0.482          |
| Policy-TimeSampling     | 1.73           |
| Policy-TimeStep         | 2.82           |
| Time                    | 1.74e+03       |
| n_timesteps             | 50000          |
--------------------------------------------

 ---------------- Iteration 50 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 500 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 501 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 502 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 503 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 504 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 505 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 506 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 507 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 508 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 509 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.382         |
| Data-EnvSampler-Poli... | 0.755         |
| Data-EnvTrajs-Averag... | 37.5          |
| Data-EnvTrajs-MaxReturn | 38.8          |
| Data-EnvTrajs-MinReturn | 36.3          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 0.971         |
| Data-TimeEnvSampleProc  | 0.00128       |
| Data-TimeEnvSampling    | 1.17          |
| Iteration               | 50            |
| ItrTime                 | 48            |
| LossAfter               | -0.0027289898 |
| LossBefore              | -6.289018e-06 |
| Model-TimeModelFit      | 43.9          |
| ModelSampler-n_times... | 2040000       |
| Policy-AverageAbsPol... | 1.3694807     |
| Policy-AverageDiscou... | 23.7          |
| Policy-AveragePolicyStd | 0.45394757    |
| Policy-AverageReturn    | 33.4          |
| Policy-MaxReturn        | 42.3          |
| Policy-MinReturn        | 24            |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 4.06          |
| Policy-TimeAlgoOpt      | 0.665         |
| Policy-TimeSampleProc   | 0.493         |
| Policy-TimeSampling     | 1.76          |
| Policy-TimeStep         | 2.95          |
| Time                    | 1.79e+03      |
| n_timesteps             | 51000         |
-------------------------------------------
Training finished
