Logging to /home/vincent/workplace/CS_287_-_Advanced_Robotics/homework/hw5/cs287hw5/ppo/run_scripts/data/parallel_mb_ppo/mbppo_Swimmer_l2_no_square//01

 ---------------- Iteration 0 ----------------
Obtaining random samples from the environment...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 0 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 1 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 2 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 3 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 4 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 5 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 6 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 7 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 8 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 9 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.113          |
| Data-EnvSampler-Poli... | 0.0352         |
| Data-EnvTrajs-Averag... | -1.47          |
| Data-EnvTrajs-MaxReturn | 2.28           |
| Data-EnvTrajs-MinReturn | -10.1          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 4.49           |
| Data-TimeEnvSampleProc  | 0.000458       |
| Data-TimeEnvSampling    | 0.157          |
| Iteration               | 0              |
| ItrTime                 | 8.16           |
| LossAfter               | -0.0043414473  |
| LossBefore              | -1.4071802e-05 |
| Model-TimeModelFit      | 2.74           |
| ModelSampler-n_times... | 40000          |
| Policy-AverageAbsPol... | 0.5711607      |
| Policy-AverageDiscou... | -52.4          |
| Policy-AveragePolicyStd | 0.98890114     |
| Policy-AverageReturn    | -217           |
| Policy-MaxReturn        | -1.23          |
| Policy-MinReturn        | -955           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 240            |
| Policy-TimeAlgoOpt      | 0.96           |
| Policy-TimeSampleProc   | 0.486          |
| Policy-TimeSampling     | 3.79           |
| Policy-TimeStep         | 5.26           |
| Time                    | 8.16           |
| n_timesteps             | 1000           |
--------------------------------------------

 ---------------- Iteration 1 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 10 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 11 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 12 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 13 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 14 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 15 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 16 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 17 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 18 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 19 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.209          |
| Data-EnvSampler-Poli... | 0.464          |
| Data-EnvTrajs-Averag... | -12.2          |
| Data-EnvTrajs-MaxReturn | 0.996          |
| Data-EnvTrajs-MinReturn | -22.7          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 9.21           |
| Data-TimeEnvSampleProc  | 0.00055        |
| Data-TimeEnvSampling    | 0.694          |
| Iteration               | 1              |
| ItrTime                 | 7.3            |
| LossAfter               | -0.005853444   |
| LossBefore              | -1.4066898e-05 |
| Model-TimeModelFit      | 4.07           |
| ModelSampler-n_times... | 80000          |
| Policy-AverageAbsPol... | 0.3564837      |
| Policy-AverageDiscou... | -3.24          |
| Policy-AveragePolicyStd | 0.98562706     |
| Policy-AverageReturn    | -6.17          |
| Policy-MaxReturn        | 4.66           |
| Policy-MinReturn        | -13.7          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 5.28           |
| Policy-TimeAlgoOpt      | 0.518          |
| Policy-TimeSampleProc   | 0.616          |
| Policy-TimeSampling     | 1.35           |
| Policy-TimeStep         | 2.53           |
| Time                    | 15.6           |
| n_timesteps             | 2000           |
--------------------------------------------

 ---------------- Iteration 2 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 20 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 21 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 22 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 23 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 24 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 25 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 26 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 27 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 28 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 29 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.205         |
| Data-EnvSampler-Poli... | 0.358         |
| Data-EnvTrajs-Averag... | -6.65         |
| Data-EnvTrajs-MaxReturn | -1.84         |
| Data-EnvTrajs-MinReturn | -13.5         |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 5.09          |
| Data-TimeEnvSampleProc  | 0.00063       |
| Data-TimeEnvSampling    | 0.584         |
| Iteration               | 2             |
| ItrTime                 | 9.15          |
| LossAfter               | -0.0026254791 |
| LossBefore              | -1.416449e-05 |
| Model-TimeModelFit      | 5.91          |
| ModelSampler-n_times... | 120000        |
| Policy-AverageAbsPol... | 0.46836835    |
| Policy-AverageDiscou... | 6.06          |
| Policy-AveragePolicyStd | 0.998265      |
| Policy-AverageReturn    | 15.9          |
| Policy-MaxReturn        | 54            |
| Policy-MinReturn        | -8.06         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 17.8          |
| Policy-TimeAlgoOpt      | 0.614         |
| Policy-TimeSampleProc   | 0.408         |
| Policy-TimeSampling     | 1.57          |
| Policy-TimeStep         | 2.64          |
| Time                    | 24.7          |
| n_timesteps             | 3000          |
-------------------------------------------

 ---------------- Iteration 3 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 30 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 31 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 32 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 33 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 34 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 35 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 36 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 37 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 38 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 39 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.25           |
| Data-EnvSampler-Poli... | 0.453          |
| Data-EnvTrajs-Averag... | 8.55           |
| Data-EnvTrajs-MaxReturn | 14             |
| Data-EnvTrajs-MinReturn | -2.97          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 6.36           |
| Data-TimeEnvSampleProc  | 0.000871       |
| Data-TimeEnvSampling    | 0.727          |
| Iteration               | 3              |
| ItrTime                 | 14.8           |
| LossAfter               | -0.0035864941  |
| LossBefore              | -1.3931642e-05 |
| Model-TimeModelFit      | 10.4           |
| ModelSampler-n_times... | 160000         |
| Policy-AverageAbsPol... | 1.0094644      |
| Policy-AverageDiscou... | -1.2e+03       |
| Policy-AveragePolicyStd | 0.9739395      |
| Policy-AverageReturn    | -5.36e+03      |
| Policy-MaxReturn        | 13.3           |
| Policy-MinReturn        | -7.61e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.01e+03       |
| Policy-TimeAlgoOpt      | 0.688          |
| Policy-TimeSampleProc   | 0.586          |
| Policy-TimeSampling     | 2.27           |
| Policy-TimeStep         | 3.65           |
| Time                    | 39.5           |
| n_timesteps             | 4000           |
--------------------------------------------

 ---------------- Iteration 4 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 40 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 41 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 42 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 43 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 44 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 45 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 46 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 47 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 48 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 49 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.318          |
| Data-EnvSampler-Poli... | 0.565          |
| Data-EnvTrajs-Averag... | 1.17           |
| Data-EnvTrajs-MaxReturn | 8.06           |
| Data-EnvTrajs-MinReturn | -6.4           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 5.06           |
| Data-TimeEnvSampleProc  | 0.00137        |
| Data-TimeEnvSampling    | 0.914          |
| Iteration               | 4              |
| ItrTime                 | 19.9           |
| LossAfter               | -0.0045462204  |
| LossBefore              | -1.3961155e-05 |
| Model-TimeModelFit      | 15.4           |
| ModelSampler-n_times... | 200000         |
| Policy-AverageAbsPol... | 0.7049336      |
| Policy-AverageDiscou... | 50.1           |
| Policy-AveragePolicyStd | 0.9751398      |
| Policy-AverageReturn    | 167            |
| Policy-MaxReturn        | 290            |
| Policy-MinReturn        | 49.7           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 57             |
| Policy-TimeAlgoOpt      | 0.707          |
| Policy-TimeSampleProc   | 0.671          |
| Policy-TimeSampling     | 2.14           |
| Policy-TimeStep         | 3.57           |
| Time                    | 59.4           |
| n_timesteps             | 5000           |
--------------------------------------------

 ---------------- Iteration 5 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 50 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 51 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 52 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 53 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 54 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 55 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 56 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 57 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 58 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 59 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.35           |
| Data-EnvSampler-Poli... | 0.599          |
| Data-EnvTrajs-Averag... | 12.7           |
| Data-EnvTrajs-MaxReturn | 19.6           |
| Data-EnvTrajs-MinReturn | 6.33           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 5.18           |
| Data-TimeEnvSampleProc  | 0.0012         |
| Data-TimeEnvSampling    | 0.981          |
| Iteration               | 5              |
| ItrTime                 | 22.4           |
| LossAfter               | -0.0026230335  |
| LossBefore              | -1.3904695e-05 |
| Model-TimeModelFit      | 17.7           |
| ModelSampler-n_times... | 240000         |
| Policy-AverageAbsPol... | 0.651775       |
| Policy-AverageDiscou... | -3.48          |
| Policy-AveragePolicyStd | 0.97079563     |
| Policy-AverageReturn    | -15.3          |
| Policy-MaxReturn        | 21.5           |
| Policy-MinReturn        | -25.6          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 9.49           |
| Policy-TimeAlgoOpt      | 0.797          |
| Policy-TimeSampleProc   | 0.701          |
| Policy-TimeSampling     | 2.15           |
| Policy-TimeStep         | 3.67           |
| Time                    | 81.8           |
| n_timesteps             | 6000           |
--------------------------------------------

 ---------------- Iteration 6 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 60 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 61 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 62 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 63 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 64 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 65 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 66 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 67 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 68 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 69 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.358           |
| Data-EnvSampler-Poli... | 0.619           |
| Data-EnvTrajs-Averag... | 22.3            |
| Data-EnvTrajs-MaxReturn | 25.1            |
| Data-EnvTrajs-MinReturn | 19.8            |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 1.81            |
| Data-TimeEnvSampleProc  | 0.00131         |
| Data-TimeEnvSampling    | 1.01            |
| Iteration               | 6               |
| ItrTime                 | 21.4            |
| LossAfter               | -0.0034040853   |
| LossBefore              | -1.41729815e-05 |
| Model-TimeModelFit      | 18              |
| ModelSampler-n_times... | 280000          |
| Policy-AverageAbsPol... | 1.0951715       |
| Policy-AverageDiscou... | 48              |
| Policy-AveragePolicyStd | 0.99846035      |
| Policy-AverageReturn    | 141             |
| Policy-MaxReturn        | 261             |
| Policy-MinReturn        | 54.5            |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 50.8            |
| Policy-TimeAlgoOpt      | 0.611           |
| Policy-TimeSampleProc   | 0.381           |
| Policy-TimeSampling     | 1.41            |
| Policy-TimeStep         | 2.41            |
| Time                    | 103             |
| n_timesteps             | 7000            |
---------------------------------------------

 ---------------- Iteration 7 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 70 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 71 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 72 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 73 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 74 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 75 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 76 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 77 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 78 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 79 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.246          |
| Data-EnvSampler-Poli... | 0.449          |
| Data-EnvTrajs-Averag... | 28.9           |
| Data-EnvTrajs-MaxReturn | 31             |
| Data-EnvTrajs-MinReturn | 27.8           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.13           |
| Data-TimeEnvSampleProc  | 0.00088        |
| Data-TimeEnvSampling    | 0.717          |
| Iteration               | 7              |
| ItrTime                 | 18.6           |
| LossAfter               | -0.003104484   |
| LossBefore              | -1.4127395e-05 |
| Model-TimeModelFit      | 15.4           |
| ModelSampler-n_times... | 320000         |
| Policy-AverageAbsPol... | 0.66692436     |
| Policy-AverageDiscou... | 32.8           |
| Policy-AveragePolicyStd | 0.99337476     |
| Policy-AverageReturn    | 66.3           |
| Policy-MaxReturn        | 111            |
| Policy-MinReturn        | 34.5           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 15.4           |
| Policy-TimeAlgoOpt      | 0.516          |
| Policy-TimeSampleProc   | 0.516          |
| Policy-TimeSampling     | 1.35           |
| Policy-TimeStep         | 2.42           |
| Time                    | 122            |
| n_timesteps             | 8000           |
--------------------------------------------

 ---------------- Iteration 8 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 80 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 81 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 82 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 83 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 84 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 85 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 86 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 87 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 88 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 89 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.269         |
| Data-EnvSampler-Poli... | 0.52          |
| Data-EnvTrajs-Averag... | 20.9          |
| Data-EnvTrajs-MaxReturn | 28.7          |
| Data-EnvTrajs-MinReturn | 15.7          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 4.32          |
| Data-TimeEnvSampleProc  | 0.000947      |
| Data-TimeEnvSampling    | 0.816         |
| Iteration               | 8             |
| ItrTime                 | 32.2          |
| LossAfter               | -0.0049167257 |
| LossBefore              | -1.384413e-05 |
| Model-TimeModelFit      | 27.6          |
| ModelSampler-n_times... | 360000        |
| Policy-AverageAbsPol... | 0.7958609     |
| Policy-AverageDiscou... | 31.4          |
| Policy-AveragePolicyStd | 0.96584475    |
| Policy-AverageReturn    | 58.1          |
| Policy-MaxReturn        | 80            |
| Policy-MinReturn        | 24.1          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 12.8          |
| Policy-TimeAlgoOpt      | 0.759         |
| Policy-TimeSampleProc   | 0.73          |
| Policy-TimeSampling     | 2.2           |
| Policy-TimeStep         | 3.72          |
| Time                    | 154           |
| n_timesteps             | 9000          |
-------------------------------------------

 ---------------- Iteration 9 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 90 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 91 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 92 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 93 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 94 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 95 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 96 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 97 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 98 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 99 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.415          |
| Data-EnvSampler-Poli... | 0.796          |
| Data-EnvTrajs-Averag... | 28.3           |
| Data-EnvTrajs-MaxReturn | 31.1           |
| Data-EnvTrajs-MinReturn | 22.4           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 3.11           |
| Data-TimeEnvSampleProc  | 0.00133        |
| Data-TimeEnvSampling    | 1.25           |
| Iteration               | 9              |
| ItrTime                 | 25.6           |
| LossAfter               | -0.003203444   |
| LossBefore              | -1.3576072e-05 |
| Model-TimeModelFit      | 21.9           |
| ModelSampler-n_times... | 400000         |
| Policy-AverageAbsPol... | 0.9256176      |
| Policy-AverageDiscou... | 54.7           |
| Policy-AveragePolicyStd | 0.9413595      |
| Policy-AverageReturn    | 117            |
| Policy-MaxReturn        | 143            |
| Policy-MinReturn        | 83.3           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 15.1           |
| Policy-TimeAlgoOpt      | 0.471          |
| Policy-TimeSampleProc   | 0.561          |
| Policy-TimeSampling     | 1.33           |
| Policy-TimeStep         | 2.41           |
| Time                    | 180            |
| n_timesteps             | 10000          |
--------------------------------------------

 ---------------- Iteration 10 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 100 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 101 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 102 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 103 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 104 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 105 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 106 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 107 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 108 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 109 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.309          |
| Data-EnvSampler-Poli... | 0.649          |
| Data-EnvTrajs-Averag... | 29.6           |
| Data-EnvTrajs-MaxReturn | 31.1           |
| Data-EnvTrajs-MinReturn | 27.8           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.06           |
| Data-TimeEnvSampleProc  | 0.000895       |
| Data-TimeEnvSampling    | 0.99           |
| Iteration               | 10             |
| ItrTime                 | 32.4           |
| LossAfter               | -0.0026345795  |
| LossBefore              | -1.3391633e-05 |
| Model-TimeModelFit      | 28.3           |
| ModelSampler-n_times... | 440000         |
| Policy-AverageAbsPol... | 0.9983137      |
| Policy-AverageDiscou... | 32.5           |
| Policy-AveragePolicyStd | 0.92236316     |
| Policy-AverageReturn    | 50.5           |
| Policy-MaxReturn        | 70.3           |
| Policy-MinReturn        | 36             |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 8.51           |
| Policy-TimeAlgoOpt      | 0.673          |
| Policy-TimeSampleProc   | 0.499          |
| Policy-TimeSampling     | 1.89           |
| Policy-TimeStep         | 3.1            |
| Time                    | 212            |
| n_timesteps             | 11000          |
--------------------------------------------

 ---------------- Iteration 11 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 110 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 111 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 112 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 113 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 114 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 115 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 116 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 117 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 118 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 119 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.507          |
| Data-EnvSampler-Poli... | 1.01           |
| Data-EnvTrajs-Averag... | 29.2           |
| Data-EnvTrajs-MaxReturn | 32.1           |
| Data-EnvTrajs-MinReturn | 25.3           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.27           |
| Data-TimeEnvSampleProc  | 0.00132        |
| Data-TimeEnvSampling    | 1.57           |
| Iteration               | 11             |
| ItrTime                 | 34.4           |
| LossAfter               | -0.0036531235  |
| LossBefore              | -1.3276335e-05 |
| Model-TimeModelFit      | 30.5           |
| ModelSampler-n_times... | 480000         |
| Policy-AverageAbsPol... | 0.98408103     |
| Policy-AverageDiscou... | 17.9           |
| Policy-AveragePolicyStd | 0.9104562      |
| Policy-AverageReturn    | 25.6           |
| Policy-MaxReturn        | 43.3           |
| Policy-MinReturn        | -4.24          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 10.6           |
| Policy-TimeAlgoOpt      | 0.472          |
| Policy-TimeSampleProc   | 0.387          |
| Policy-TimeSampling     | 1.5            |
| Policy-TimeStep         | 2.38           |
| Time                    | 246            |
| n_timesteps             | 12000          |
--------------------------------------------

 ---------------- Iteration 12 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 120 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 121 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 122 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 123 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 124 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 125 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 126 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 127 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 128 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 129 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.329         |
| Data-EnvSampler-Poli... | 0.692         |
| Data-EnvTrajs-Averag... | 29.3          |
| Data-EnvTrajs-MaxReturn | 30.6          |
| Data-EnvTrajs-MinReturn | 27.7          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 0.993         |
| Data-TimeEnvSampleProc  | 0.00109       |
| Data-TimeEnvSampling    | 1.05          |
| Iteration               | 12            |
| ItrTime                 | 33.5          |
| LossAfter               | -0.005851209  |
| LossBefore              | -1.319343e-05 |
| Model-TimeModelFit      | 29.5          |
| ModelSampler-n_times... | 520000        |
| Policy-AverageAbsPol... | 1.13722       |
| Policy-AverageDiscou... | 33.9          |
| Policy-AveragePolicyStd | 0.9054482     |
| Policy-AverageReturn    | 85.5          |
| Policy-MaxReturn        | 198           |
| Policy-MinReturn        | -91.9         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 70.8          |
| Policy-TimeAlgoOpt      | 0.657         |
| Policy-TimeSampleProc   | 0.476         |
| Policy-TimeSampling     | 1.74          |
| Policy-TimeStep         | 2.94          |
| Time                    | 280           |
| n_timesteps             | 13000         |
-------------------------------------------

 ---------------- Iteration 13 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 130 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 131 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 132 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 133 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 134 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 135 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 136 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 137 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 138 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 139 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.488          |
| Data-EnvSampler-Poli... | 1.04           |
| Data-EnvTrajs-Averag... | 27.5           |
| Data-EnvTrajs-MaxReturn | 29.8           |
| Data-EnvTrajs-MinReturn | 22.3           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.8            |
| Data-TimeEnvSampleProc  | 0.00136        |
| Data-TimeEnvSampling    | 1.57           |
| Iteration               | 13             |
| ItrTime                 | 40.5           |
| LossAfter               | -0.0021296074  |
| LossBefore              | -1.3030057e-05 |
| Model-TimeModelFit      | 36.8           |
| ModelSampler-n_times... | 560000         |
| Policy-AverageAbsPol... | 0.95096666     |
| Policy-AverageDiscou... | 22.8           |
| Policy-AveragePolicyStd | 0.88851017     |
| Policy-AverageReturn    | 39.6           |
| Policy-MaxReturn        | 44.9           |
| Policy-MinReturn        | 31.7           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 3.58           |
| Policy-TimeAlgoOpt      | 0.499          |
| Policy-TimeSampleProc   | 0.283          |
| Policy-TimeSampling     | 1.23           |
| Policy-TimeStep         | 2.04           |
| Time                    | 320            |
| n_timesteps             | 14000          |
--------------------------------------------

 ---------------- Iteration 14 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 140 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 141 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 142 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 143 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 144 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 145 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 146 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 147 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 148 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 149 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.304           |
| Data-EnvSampler-Poli... | 0.646           |
| Data-EnvTrajs-Averag... | 28.2            |
| Data-EnvTrajs-MaxReturn | 31.4            |
| Data-EnvTrajs-MinReturn | 23.1            |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 2.96            |
| Data-TimeEnvSampleProc  | 0.000874        |
| Data-TimeEnvSampling    | 0.98            |
| Iteration               | 14              |
| ItrTime                 | 30.2            |
| LossAfter               | -0.003238228    |
| LossBefore              | -1.26992345e-05 |
| Model-TimeModelFit      | 26.2            |
| ModelSampler-n_times... | 600000          |
| Policy-AverageAbsPol... | 1.0892857       |
| Policy-AverageDiscou... | 30.8            |
| Policy-AveragePolicyStd | 0.860349        |
| Policy-AverageReturn    | 58              |
| Policy-MaxReturn        | 74.8            |
| Policy-MinReturn        | 40.4            |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 10              |
| Policy-TimeAlgoOpt      | 0.629           |
| Policy-TimeSampleProc   | 0.622           |
| Policy-TimeSampling     | 1.81            |
| Policy-TimeStep         | 3.08            |
| Time                    | 351             |
| n_timesteps             | 15000           |
---------------------------------------------

 ---------------- Iteration 15 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 150 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 151 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 152 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 153 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 154 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 155 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 156 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 157 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 158 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 159 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.502          |
| Data-EnvSampler-Poli... | 1.05           |
| Data-EnvTrajs-Averag... | 28.3           |
| Data-EnvTrajs-MaxReturn | 29.7           |
| Data-EnvTrajs-MinReturn | 26.7           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.04           |
| Data-TimeEnvSampleProc  | 0.00139        |
| Data-TimeEnvSampling    | 1.6            |
| Iteration               | 15             |
| ItrTime                 | 44.3           |
| LossAfter               | -0.0030694641  |
| LossBefore              | -1.2680212e-05 |
| Model-TimeModelFit      | 39.6           |
| ModelSampler-n_times... | 640000         |
| Policy-AverageAbsPol... | 0.9553314      |
| Policy-AverageDiscou... | -53.2          |
| Policy-AveragePolicyStd | 0.8594695      |
| Policy-AverageReturn    | -396           |
| Policy-MaxReturn        | 64.4           |
| Policy-MinReturn        | -4.46e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.29e+03       |
| Policy-TimeAlgoOpt      | 0.643          |
| Policy-TimeSampleProc   | 0.649          |
| Policy-TimeSampling     | 1.79           |
| Policy-TimeStep         | 3.11           |
| Time                    | 395            |
| n_timesteps             | 16000          |
--------------------------------------------

 ---------------- Iteration 16 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 160 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 161 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 162 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 163 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 164 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 165 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 166 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 167 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 168 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 169 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.533          |
| Data-EnvSampler-Poli... | 1.13           |
| Data-EnvTrajs-Averag... | 28.3           |
| Data-EnvTrajs-MaxReturn | 31.6           |
| Data-EnvTrajs-MinReturn | 24.2           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.53           |
| Data-TimeEnvSampleProc  | 0.00167        |
| Data-TimeEnvSampling    | 1.7            |
| Iteration               | 16             |
| ItrTime                 | 30.6           |
| LossAfter               | -0.0035120368  |
| LossBefore              | -1.2550347e-05 |
| Model-TimeModelFit      | 26.9           |
| ModelSampler-n_times... | 680000         |
| Policy-AverageAbsPol... | 0.96158165     |
| Policy-AverageDiscou... | 39.7           |
| Policy-AveragePolicyStd | 0.84789354     |
| Policy-AverageReturn    | 88             |
| Policy-MaxReturn        | 136            |
| Policy-MinReturn        | 45.5           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 25.9           |
| Policy-TimeAlgoOpt      | 0.473          |
| Policy-TimeSampleProc   | 0.359          |
| Policy-TimeSampling     | 1.18           |
| Policy-TimeStep         | 2.05           |
| Time                    | 426            |
| n_timesteps             | 17000          |
--------------------------------------------

 ---------------- Iteration 17 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 170 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 171 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 172 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 173 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 174 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 175 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 176 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 177 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 178 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 179 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.323          |
| Data-EnvSampler-Poli... | 0.752          |
| Data-EnvTrajs-Averag... | 28.8           |
| Data-EnvTrajs-MaxReturn | 30.9           |
| Data-EnvTrajs-MinReturn | 23.9           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.64           |
| Data-TimeEnvSampleProc  | 0.000738       |
| Data-TimeEnvSampling    | 1.11           |
| Iteration               | 17             |
| ItrTime                 | 42.2           |
| LossAfter               | -0.0036407746  |
| LossBefore              | -1.2451894e-05 |
| Model-TimeModelFit      | 38.1           |
| ModelSampler-n_times... | 720000         |
| Policy-AverageAbsPol... | 0.7485614      |
| Policy-AverageDiscou... | 17.6           |
| Policy-AveragePolicyStd | 0.8408972      |
| Policy-AverageReturn    | 29.2           |
| Policy-MaxReturn        | 49.1           |
| Policy-MinReturn        | 4.36           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 10.5           |
| Policy-TimeAlgoOpt      | 0.662          |
| Policy-TimeSampleProc   | 0.518          |
| Policy-TimeSampling     | 1.76           |
| Policy-TimeStep         | 2.96           |
| Time                    | 468            |
| n_timesteps             | 18000          |
--------------------------------------------

 ---------------- Iteration 18 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 180 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 181 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 182 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 183 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 184 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 185 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 186 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 187 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 188 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 189 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.538           |
| Data-EnvSampler-Poli... | 1.18            |
| Data-EnvTrajs-Averag... | 20.7            |
| Data-EnvTrajs-MaxReturn | 25.8            |
| Data-EnvTrajs-MinReturn | 14.9            |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 3.65            |
| Data-TimeEnvSampleProc  | 0.00136         |
| Data-TimeEnvSampling    | 1.77            |
| Iteration               | 18              |
| ItrTime                 | 32.9            |
| LossAfter               | -0.0037248943   |
| LossBefore              | -1.22009815e-05 |
| Model-TimeModelFit      | 29              |
| ModelSampler-n_times... | 760000          |
| Policy-AverageAbsPol... | 0.88955116      |
| Policy-AverageDiscou... | 23.1            |
| Policy-AveragePolicyStd | 0.8204523       |
| Policy-AverageReturn    | 38              |
| Policy-MaxReturn        | 58.8            |
| Policy-MinReturn        | 18.3            |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 11.2            |
| Policy-TimeAlgoOpt      | 0.501           |
| Policy-TimeSampleProc   | 0.283           |
| Policy-TimeSampling     | 1.35            |
| Policy-TimeStep         | 2.17            |
| Time                    | 501             |
| n_timesteps             | 19000           |
---------------------------------------------

 ---------------- Iteration 19 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 190 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 191 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 192 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 193 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 194 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 195 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 196 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 197 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 198 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 199 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.32           |
| Data-EnvSampler-Poli... | 0.683          |
| Data-EnvTrajs-Averag... | 29.9           |
| Data-EnvTrajs-MaxReturn | 33.4           |
| Data-EnvTrajs-MinReturn | 26.1           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.45           |
| Data-TimeEnvSampleProc  | 0.00087        |
| Data-TimeEnvSampling    | 1.03           |
| Iteration               | 19             |
| ItrTime                 | 39.9           |
| LossAfter               | -0.0026355353  |
| LossBefore              | -1.1952626e-05 |
| Model-TimeModelFit      | 35.6           |
| ModelSampler-n_times... | 800000         |
| Policy-AverageAbsPol... | 0.91002357     |
| Policy-AverageDiscou... | 32.6           |
| Policy-AveragePolicyStd | 0.80125475     |
| Policy-AverageReturn    | 70.3           |
| Policy-MaxReturn        | 82.8           |
| Policy-MinReturn        | 56.1           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 6.47           |
| Policy-TimeAlgoOpt      | 0.642          |
| Policy-TimeSampleProc   | 0.608          |
| Policy-TimeSampling     | 1.93           |
| Policy-TimeStep         | 3.2            |
| Time                    | 541            |
| n_timesteps             | 20000          |
--------------------------------------------

 ---------------- Iteration 20 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 200 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 201 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 202 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 203 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 204 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 205 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 206 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 207 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 208 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 209 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.477           |
| Data-EnvSampler-Poli... | 1.03            |
| Data-EnvTrajs-Averag... | 24.7            |
| Data-EnvTrajs-MaxReturn | 27.9            |
| Data-EnvTrajs-MinReturn | 21.7            |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 2.18            |
| Data-TimeEnvSampleProc  | 0.00154         |
| Data-TimeEnvSampling    | 1.55            |
| Iteration               | 20              |
| ItrTime                 | 32              |
| LossAfter               | -0.002797565    |
| LossBefore              | -1.17902555e-05 |
| Model-TimeModelFit      | 28.3            |
| ModelSampler-n_times... | 840000          |
| Policy-AverageAbsPol... | 1.0662366       |
| Policy-AverageDiscou... | 14.4            |
| Policy-AveragePolicyStd | 0.7872771       |
| Policy-AverageReturn    | 23.9            |
| Policy-MaxReturn        | 48              |
| Policy-MinReturn        | 5.67            |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 10.7            |
| Policy-TimeAlgoOpt      | 0.489           |
| Policy-TimeSampleProc   | 0.349           |
| Policy-TimeSampling     | 1.28            |
| Policy-TimeStep         | 2.14            |
| Time                    | 573             |
| n_timesteps             | 21000           |
---------------------------------------------

 ---------------- Iteration 21 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 210 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 211 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 212 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 213 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 214 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 215 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 216 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 217 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 218 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 219 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.337          |
| Data-EnvSampler-Poli... | 0.704          |
| Data-EnvTrajs-Averag... | 24.5           |
| Data-EnvTrajs-MaxReturn | 27.1           |
| Data-EnvTrajs-MinReturn | 22.9           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.47           |
| Data-TimeEnvSampleProc  | 0.000932       |
| Data-TimeEnvSampling    | 1.07           |
| Iteration               | 21             |
| ItrTime                 | 41.2           |
| LossAfter               | -0.0033907925  |
| LossBefore              | -1.1510828e-05 |
| Model-TimeModelFit      | 37.9           |
| ModelSampler-n_times... | 880000         |
| Policy-AverageAbsPol... | 1.074708       |
| Policy-AverageDiscou... | 29.5           |
| Policy-AveragePolicyStd | 0.7650652      |
| Policy-AverageReturn    | 64.4           |
| Policy-MaxReturn        | 79.4           |
| Policy-MinReturn        | 46.3           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 8.83           |
| Policy-TimeAlgoOpt      | 0.515          |
| Policy-TimeSampleProc   | 0.252          |
| Policy-TimeSampling     | 1.38           |
| Policy-TimeStep         | 2.17           |
| Time                    | 614            |
| n_timesteps             | 22000          |
--------------------------------------------

 ---------------- Iteration 22 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 220 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 221 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 222 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 223 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 224 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 225 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 226 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 227 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 228 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 229 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.299         |
| Data-EnvSampler-Poli... | 0.612         |
| Data-EnvTrajs-Averag... | 23.7          |
| Data-EnvTrajs-MaxReturn | 27.9          |
| Data-EnvTrajs-MinReturn | 19.7          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 2.89          |
| Data-TimeEnvSampleProc  | 0.000897      |
| Data-TimeEnvSampling    | 0.94          |
| Iteration               | 22            |
| ItrTime                 | 30.3          |
| LossAfter               | -0.0022952303 |
| LossBefore              | -1.133051e-05 |
| Model-TimeModelFit      | 25.6          |
| ModelSampler-n_times... | 920000        |
| Policy-AverageAbsPol... | 1.1371777     |
| Policy-AverageDiscou... | 12.7          |
| Policy-AveragePolicyStd | 0.75148255    |
| Policy-AverageReturn    | 9.34          |
| Policy-MaxReturn        | 21.5          |
| Policy-MinReturn        | -1.62         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 6.64          |
| Policy-TimeAlgoOpt      | 0.742         |
| Policy-TimeSampleProc   | 0.794         |
| Policy-TimeSampling     | 2.17          |
| Policy-TimeStep         | 3.76          |
| Time                    | 644           |
| n_timesteps             | 23000         |
-------------------------------------------

 ---------------- Iteration 23 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 230 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 231 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 232 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 233 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 234 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 235 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 236 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 237 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 238 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 239 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.554          |
| Data-EnvSampler-Poli... | 1.12           |
| Data-EnvTrajs-Averag... | 28.9           |
| Data-EnvTrajs-MaxReturn | 32.3           |
| Data-EnvTrajs-MinReturn | 22.6           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 3.47           |
| Data-TimeEnvSampleProc  | 0.00124        |
| Data-TimeEnvSampling    | 1.73           |
| Iteration               | 23             |
| ItrTime                 | 39.2           |
| LossAfter               | -0.0030690997  |
| LossBefore              | -1.1237593e-05 |
| Model-TimeModelFit      | 35.2           |
| ModelSampler-n_times... | 960000         |
| Policy-AverageAbsPol... | 1.2808932      |
| Policy-AverageDiscou... | 25.2           |
| Policy-AveragePolicyStd | 0.745935       |
| Policy-AverageReturn    | 42.9           |
| Policy-MaxReturn        | 51.2           |
| Policy-MinReturn        | 30             |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 6.46           |
| Policy-TimeAlgoOpt      | 0.469          |
| Policy-TimeSampleProc   | 0.281          |
| Policy-TimeSampling     | 1.47           |
| Policy-TimeStep         | 2.26           |
| Time                    | 683            |
| n_timesteps             | 24000          |
--------------------------------------------

 ---------------- Iteration 24 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 240 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 241 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 242 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 243 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 244 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 245 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 246 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 247 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 248 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 249 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.311          |
| Data-EnvSampler-Poli... | 0.669          |
| Data-EnvTrajs-Averag... | 27.6           |
| Data-EnvTrajs-MaxReturn | 29.2           |
| Data-EnvTrajs-MinReturn | 24.9           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.53           |
| Data-TimeEnvSampleProc  | 0.000923       |
| Data-TimeEnvSampling    | 1.01           |
| Iteration               | 24             |
| ItrTime                 | 36.3           |
| LossAfter               | -0.0017102814  |
| LossBefore              | -1.1121053e-05 |
| Model-TimeModelFit      | 31.6           |
| ModelSampler-n_times... | 1000000        |
| Policy-AverageAbsPol... | 1.3749319      |
| Policy-AverageDiscou... | 18.2           |
| Policy-AveragePolicyStd | 0.73531055     |
| Policy-AverageReturn    | 23.2           |
| Policy-MaxReturn        | 33.8           |
| Policy-MinReturn        | 15.8           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 4.87           |
| Policy-TimeAlgoOpt      | 0.678          |
| Policy-TimeSampleProc   | 0.814          |
| Policy-TimeSampling     | 2.23           |
| Policy-TimeStep         | 3.76           |
| Time                    | 720            |
| n_timesteps             | 25000          |
--------------------------------------------

 ---------------- Iteration 25 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 250 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 251 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 252 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 253 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 254 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 255 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 256 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 257 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 258 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 259 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.473          |
| Data-EnvSampler-Poli... | 0.884          |
| Data-EnvTrajs-Averag... | 30.8           |
| Data-EnvTrajs-MaxReturn | 35.5           |
| Data-EnvTrajs-MinReturn | 27.3           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.9            |
| Data-TimeEnvSampleProc  | 0.00142        |
| Data-TimeEnvSampling    | 1.4            |
| Iteration               | 25             |
| ItrTime                 | 32.9           |
| LossAfter               | -0.0031646185  |
| LossBefore              | -1.1064031e-05 |
| Model-TimeModelFit      | 29.1           |
| ModelSampler-n_times... | 1040000        |
| Policy-AverageAbsPol... | 1.2634419      |
| Policy-AverageDiscou... | 20.3           |
| Policy-AveragePolicyStd | 0.73100525     |
| Policy-AverageReturn    | 25.7           |
| Policy-MaxReturn        | 35.5           |
| Policy-MinReturn        | 16.9           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 5.1            |
| Policy-TimeAlgoOpt      | 0.541          |
| Policy-TimeSampleProc   | 0.36           |
| Policy-TimeSampling     | 1.48           |
| Policy-TimeStep         | 2.4            |
| Time                    | 753            |
| n_timesteps             | 26000          |
--------------------------------------------

 ---------------- Iteration 26 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 260 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 261 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 262 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 263 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 264 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 265 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 266 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 267 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 268 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 269 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.307          |
| Data-EnvSampler-Poli... | 0.612          |
| Data-EnvTrajs-Averag... | 31.3           |
| Data-EnvTrajs-MaxReturn | 32.9           |
| Data-EnvTrajs-MinReturn | 30             |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.02           |
| Data-TimeEnvSampleProc  | 0.000551       |
| Data-TimeEnvSampling    | 0.953          |
| Iteration               | 26             |
| ItrTime                 | 41.8           |
| LossAfter               | -0.0065716156  |
| LossBefore              | -1.0951552e-05 |
| Model-TimeModelFit      | 38.6           |
| ModelSampler-n_times... | 1080000        |
| Policy-AverageAbsPol... | 1.4288144      |
| Policy-AverageDiscou... | 24.3           |
| Policy-AveragePolicyStd | 0.7235714      |
| Policy-AverageReturn    | 41.2           |
| Policy-MaxReturn        | 53.9           |
| Policy-MinReturn        | 34.3           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 4.39           |
| Policy-TimeAlgoOpt      | 0.474          |
| Policy-TimeSampleProc   | 0.352          |
| Policy-TimeSampling     | 1.42           |
| Policy-TimeStep         | 2.27           |
| Time                    | 795            |
| n_timesteps             | 27000          |
--------------------------------------------

 ---------------- Iteration 27 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 270 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 271 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 272 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 273 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 274 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 275 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 276 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 277 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 278 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 279 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.292          |
| Data-EnvSampler-Poli... | 0.578          |
| Data-EnvTrajs-Averag... | 32.9           |
| Data-EnvTrajs-MaxReturn | 37.7           |
| Data-EnvTrajs-MinReturn | 30.4           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.54           |
| Data-TimeEnvSampleProc  | 0.000937       |
| Data-TimeEnvSampling    | 0.9            |
| Iteration               | 27             |
| ItrTime                 | 31.4           |
| LossAfter               | -0.0044481987  |
| LossBefore              | -1.0573752e-05 |
| Model-TimeModelFit      | 26.8           |
| ModelSampler-n_times... | 1120000        |
| Policy-AverageAbsPol... | 1.3863326      |
| Policy-AverageDiscou... | 29.1           |
| Policy-AveragePolicyStd | 0.69748855     |
| Policy-AverageReturn    | 54.7           |
| Policy-MaxReturn        | 62.2           |
| Policy-MinReturn        | 42             |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 5.23           |
| Policy-TimeAlgoOpt      | 0.75           |
| Policy-TimeSampleProc   | 0.726          |
| Policy-TimeSampling     | 2.27           |
| Policy-TimeStep         | 3.77           |
| Time                    | 826            |
| n_timesteps             | 28000          |
--------------------------------------------

 ---------------- Iteration 28 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 280 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 281 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 282 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 283 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 284 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 285 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 286 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 287 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 288 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 289 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.489          |
| Data-EnvSampler-Poli... | 0.939          |
| Data-EnvTrajs-Averag... | 32.7           |
| Data-EnvTrajs-MaxReturn | 34.2           |
| Data-EnvTrajs-MinReturn | 30.5           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.19           |
| Data-TimeEnvSampleProc  | 0.00151        |
| Data-TimeEnvSampling    | 1.47           |
| Iteration               | 28             |
| ItrTime                 | 40.3           |
| LossAfter               | -0.00081721734 |
| LossBefore              | -1.0105781e-05 |
| Model-TimeModelFit      | 36.4           |
| ModelSampler-n_times... | 1160000        |
| Policy-AverageAbsPol... | 1.4504781      |
| Policy-AverageDiscou... | 28.8           |
| Policy-AveragePolicyStd | 0.66538        |
| Policy-AverageReturn    | 50.6           |
| Policy-MaxReturn        | 57.1           |
| Policy-MinReturn        | 44.3           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 3.41           |
| Policy-TimeAlgoOpt      | 0.594          |
| Policy-TimeSampleProc   | 0.365          |
| Policy-TimeSampling     | 1.4            |
| Policy-TimeStep         | 2.41           |
| Time                    | 866            |
| n_timesteps             | 29000          |
--------------------------------------------

 ---------------- Iteration 29 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 290 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 291 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 292 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 293 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 294 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 295 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 296 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 297 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 298 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 299 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.271         |
| Data-EnvSampler-Poli... | 0.522         |
| Data-EnvTrajs-Averag... | 35.2          |
| Data-EnvTrajs-MaxReturn | 36.5          |
| Data-EnvTrajs-MinReturn | 32.8          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.35          |
| Data-TimeEnvSampleProc  | 0.000859      |
| Data-TimeEnvSampling    | 0.819         |
| Iteration               | 29            |
| ItrTime                 | 37.3          |
| LossAfter               | -0.0014207651 |
| LossBefore              | -9.733636e-06 |
| Model-TimeModelFit      | 32.6          |
| ModelSampler-n_times... | 1200000       |
| Policy-AverageAbsPol... | 1.3644954     |
| Policy-AverageDiscou... | 17.7          |
| Policy-AveragePolicyStd | 0.6413497     |
| Policy-AverageReturn    | 20.6          |
| Policy-MaxReturn        | 27.6          |
| Policy-MinReturn        | 14.1          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 3.41          |
| Policy-TimeAlgoOpt      | 0.79          |
| Policy-TimeSampleProc   | 0.779         |
| Policy-TimeSampling     | 2.26          |
| Policy-TimeStep         | 3.86          |
| Time                    | 904           |
| n_timesteps             | 30000         |
-------------------------------------------

 ---------------- Iteration 30 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 300 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 301 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 302 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 303 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 304 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 305 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 306 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 307 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 308 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 309 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.359         |
| Data-EnvSampler-Poli... | 0.676         |
| Data-EnvTrajs-Averag... | 37.3          |
| Data-EnvTrajs-MaxReturn | 39            |
| Data-EnvTrajs-MinReturn | 35.7          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.36          |
| Data-TimeEnvSampleProc  | 0.000819      |
| Data-TimeEnvSampling    | 1.07          |
| Iteration               | 30            |
| ItrTime                 | 29.8          |
| LossAfter               | -0.0029631215 |
| LossBefore              | -9.595266e-06 |
| Model-TimeModelFit      | 25.8          |
| ModelSampler-n_times... | 1240000       |
| Policy-AverageAbsPol... | 1.4696062     |
| Policy-AverageDiscou... | 27.1          |
| Policy-AveragePolicyStd | 0.63190365    |
| Policy-AverageReturn    | 45.8          |
| Policy-MaxReturn        | 52.4          |
| Policy-MinReturn        | 30.3          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 4.89          |
| Policy-TimeAlgoOpt      | 0.671         |
| Policy-TimeSampleProc   | 0.448         |
| Policy-TimeSampling     | 1.71          |
| Policy-TimeStep         | 2.86          |
| Time                    | 933           |
| n_timesteps             | 31000         |
-------------------------------------------

 ---------------- Iteration 31 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 310 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 311 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 312 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 313 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 314 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 315 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 316 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 317 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 318 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 319 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.471         |
| Data-EnvSampler-Poli... | 0.867         |
| Data-EnvTrajs-Averag... | 36            |
| Data-EnvTrajs-MaxReturn | 38.1          |
| Data-EnvTrajs-MinReturn | 33.9          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.38          |
| Data-TimeEnvSampleProc  | 0.00133       |
| Data-TimeEnvSampling    | 1.38          |
| Iteration               | 31            |
| ItrTime                 | 42.5          |
| LossAfter               | -0.0027117021 |
| LossBefore              | -9.441078e-06 |
| Model-TimeModelFit      | 38.8          |
| ModelSampler-n_times... | 1280000       |
| Policy-AverageAbsPol... | 1.6452363     |
| Policy-AverageDiscou... | 20.8          |
| Policy-AveragePolicyStd | 0.62230754    |
| Policy-AverageReturn    | 25.3          |
| Policy-MaxReturn        | 28.6          |
| Policy-MinReturn        | 20.3          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 2.68          |
| Policy-TimeAlgoOpt      | 0.561         |
| Policy-TimeSampleProc   | 0.287         |
| Policy-TimeSampling     | 1.49          |
| Policy-TimeStep         | 2.36          |
| Time                    | 976           |
| n_timesteps             | 32000         |
-------------------------------------------

 ---------------- Iteration 32 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 320 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 321 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 322 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 323 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 324 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 325 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 326 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 327 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 328 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 329 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.341         |
| Data-EnvSampler-Poli... | 0.669         |
| Data-EnvTrajs-Averag... | 36.8          |
| Data-EnvTrajs-MaxReturn | 38.4          |
| Data-EnvTrajs-MinReturn | 35.1          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.12          |
| Data-TimeEnvSampleProc  | 0.00111       |
| Data-TimeEnvSampling    | 1.04          |
| Iteration               | 32            |
| ItrTime                 | 35.8          |
| LossAfter               | -0.0019414491 |
| LossBefore              | -9.233898e-06 |
| Model-TimeModelFit      | 30.8          |
| ModelSampler-n_times... | 1320000       |
| Policy-AverageAbsPol... | 1.6911047     |
| Policy-AverageDiscou... | 29.3          |
| Policy-AveragePolicyStd | 0.60784763    |
| Policy-AverageReturn    | 46            |
| Policy-MaxReturn        | 49.8          |
| Policy-MinReturn        | 41.1          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 2.44          |
| Policy-TimeAlgoOpt      | 0.819         |
| Policy-TimeSampleProc   | 0.739         |
| Policy-TimeSampling     | 2.37          |
| Policy-TimeStep         | 3.96          |
| Time                    | 1.01e+03      |
| n_timesteps             | 33000         |
-------------------------------------------

 ---------------- Iteration 33 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 330 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 331 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 332 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 333 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 334 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 335 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 336 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 337 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 338 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 339 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.529         |
| Data-EnvSampler-Poli... | 0.983         |
| Data-EnvTrajs-Averag... | 36.7          |
| Data-EnvTrajs-MaxReturn | 37.8          |
| Data-EnvTrajs-MinReturn | 36.1          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 0.614         |
| Data-TimeEnvSampleProc  | 0.000952      |
| Data-TimeEnvSampling    | 1.56          |
| Iteration               | 33            |
| ItrTime                 | 43.7          |
| LossAfter               | 2.7494068e-05 |
| LossBefore              | -9.005726e-06 |
| Model-TimeModelFit      | 39.8          |
| ModelSampler-n_times... | 1360000       |
| Policy-AverageAbsPol... | 1.682564      |
| Policy-AverageDiscou... | 26            |
| Policy-AveragePolicyStd | 0.5960104     |
| Policy-AverageReturn    | 43.3          |
| Policy-MaxReturn        | 47.3          |
| Policy-MinReturn        | 36.6          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 2.61          |
| Policy-TimeAlgoOpt      | 0.484         |
| Policy-TimeSampleProc   | 0.352         |
| Policy-TimeSampling     | 1.47          |
| Policy-TimeStep         | 2.33          |
| Time                    | 1.06e+03      |
| n_timesteps             | 34000         |
-------------------------------------------

 ---------------- Iteration 34 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 340 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 341 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 342 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 343 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 344 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 345 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 346 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 347 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 348 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 349 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.31          |
| Data-EnvSampler-Poli... | 0.678         |
| Data-EnvTrajs-Averag... | 37.8          |
| Data-EnvTrajs-MaxReturn | 38.8          |
| Data-EnvTrajs-MinReturn | 35.8          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.08          |
| Data-TimeEnvSampleProc  | 0.000754      |
| Data-TimeEnvSampling    | 1.02          |
| Iteration               | 34            |
| ItrTime                 | 34.7          |
| LossAfter               | -0.0026494747 |
| LossBefore              | -9.041705e-06 |
| Model-TimeModelFit      | 29.4          |
| ModelSampler-n_times... | 1400000       |
| Policy-AverageAbsPol... | 1.8700815     |
| Policy-AverageDiscou... | 27.1          |
| Policy-AveragePolicyStd | 0.5979132     |
| Policy-AverageReturn    | 40.4          |
| Policy-MaxReturn        | 49.1          |
| Policy-MinReturn        | 30.8          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 3.96          |
| Policy-TimeAlgoOpt      | 0.736         |
| Policy-TimeSampleProc   | 0.832         |
| Policy-TimeSampling     | 2.63          |
| Policy-TimeStep         | 4.27          |
| Time                    | 1.09e+03      |
| n_timesteps             | 35000         |
-------------------------------------------

 ---------------- Iteration 35 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 350 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 351 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 352 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 353 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 354 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 355 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 356 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 357 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 358 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 359 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.5           |
| Data-EnvSampler-Poli... | 0.979         |
| Data-EnvTrajs-Averag... | 37.5          |
| Data-EnvTrajs-MaxReturn | 39.5          |
| Data-EnvTrajs-MinReturn | 35.1          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.42          |
| Data-TimeEnvSampleProc  | 0.00118       |
| Data-TimeEnvSampling    | 1.52          |
| Iteration               | 35            |
| ItrTime                 | 38.3          |
| LossAfter               | -0.0012376956 |
| LossBefore              | -9.000705e-06 |
| Model-TimeModelFit      | 34.4          |
| ModelSampler-n_times... | 1440000       |
| Policy-AverageAbsPol... | 1.9809583     |
| Policy-AverageDiscou... | 18            |
| Policy-AveragePolicyStd | 0.5938009     |
| Policy-AverageReturn    | 18.9          |
| Policy-MaxReturn        | 28.4          |
| Policy-MinReturn        | 10.2          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 5.82          |
| Policy-TimeAlgoOpt      | 0.532         |
| Policy-TimeSampleProc   | 0.43          |
| Policy-TimeSampling     | 1.41          |
| Policy-TimeStep         | 2.42          |
| Time                    | 1.13e+03      |
| n_timesteps             | 36000         |
-------------------------------------------

 ---------------- Iteration 36 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 360 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 361 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 362 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 363 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 364 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 365 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 366 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 367 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 368 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 369 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.304         |
| Data-EnvSampler-Poli... | 0.562         |
| Data-EnvTrajs-Averag... | 36.7          |
| Data-EnvTrajs-MaxReturn | 38.1          |
| Data-EnvTrajs-MinReturn | 35.5          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 0.848         |
| Data-TimeEnvSampleProc  | 0.00087       |
| Data-TimeEnvSampling    | 0.895         |
| Iteration               | 36            |
| ItrTime                 | 42.4          |
| LossAfter               | -0.0033366468 |
| LossBefore              | -8.623475e-06 |
| Model-TimeModelFit      | 37.6          |
| ModelSampler-n_times... | 1480000       |
| Policy-AverageAbsPol... | 2.0415795     |
| Policy-AverageDiscou... | 26.2          |
| Policy-AveragePolicyStd | 0.57258826    |
| Policy-AverageReturn    | 36.8          |
| Policy-MaxReturn        | 43.4          |
| Policy-MinReturn        | 31.8          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 3.39          |
| Policy-TimeAlgoOpt      | 0.747         |
| Policy-TimeSampleProc   | 0.768         |
| Policy-TimeSampling     | 2.31          |
| Policy-TimeStep         | 3.87          |
| Time                    | 1.17e+03      |
| n_timesteps             | 37000         |
-------------------------------------------

 ---------------- Iteration 37 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 370 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 371 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 372 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 373 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 374 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 375 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 376 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 377 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 378 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 379 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.448         |
| Data-EnvSampler-Poli... | 0.838         |
| Data-EnvTrajs-Averag... | 37.8          |
| Data-EnvTrajs-MaxReturn | 38.6          |
| Data-EnvTrajs-MinReturn | 36.9          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 0.756         |
| Data-TimeEnvSampleProc  | 0.00117       |
| Data-TimeEnvSampling    | 1.32          |
| Iteration               | 37            |
| ItrTime                 | 37.2          |
| LossAfter               | -0.0030038457 |
| LossBefore              | -8.146694e-06 |
| Model-TimeModelFit      | 33.4          |
| ModelSampler-n_times... | 1520000       |
| Policy-AverageAbsPol... | 2.1338732     |
| Policy-AverageDiscou... | 34.6          |
| Policy-AveragePolicyStd | 0.54702723    |
| Policy-AverageReturn    | 65.8          |
| Policy-MaxReturn        | 81.7          |
| Policy-MinReturn        | 57.2          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 6.56          |
| Policy-TimeAlgoOpt      | 0.561         |
| Policy-TimeSampleProc   | 0.44          |
| Policy-TimeSampling     | 1.45          |
| Policy-TimeStep         | 2.5           |
| Time                    | 1.21e+03      |
| n_timesteps             | 38000         |
-------------------------------------------

 ---------------- Iteration 38 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 380 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 381 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 382 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 383 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 384 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 385 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 386 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 387 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 388 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 389 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.279         |
| Data-EnvSampler-Poli... | 0.514         |
| Data-EnvTrajs-Averag... | 37.5          |
| Data-EnvTrajs-MaxReturn | 38.6          |
| Data-EnvTrajs-MinReturn | 36.3          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 0.913         |
| Data-TimeEnvSampleProc  | 0.000885      |
| Data-TimeEnvSampling    | 0.818         |
| Iteration               | 38            |
| ItrTime                 | 41.9          |
| LossAfter               | -0.0020246021 |
| LossBefore              | -7.646924e-06 |
| Model-TimeModelFit      | 38.1          |
| ModelSampler-n_times... | 1560000       |
| Policy-AverageAbsPol... | 2.1676002     |
| Policy-AverageDiscou... | 30.5          |
| Policy-AveragePolicyStd | 0.5200801     |
| Policy-AverageReturn    | 53.9          |
| Policy-MaxReturn        | 63.7          |
| Policy-MinReturn        | 46.6          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 3.24          |
| Policy-TimeAlgoOpt      | 0.617         |
| Policy-TimeSampleProc   | 0.459         |
| Policy-TimeSampling     | 1.86          |
| Policy-TimeStep         | 2.97          |
| Time                    | 1.25e+03      |
| n_timesteps             | 39000         |
-------------------------------------------

 ---------------- Iteration 39 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 390 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 391 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 392 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 393 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 394 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 395 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 396 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 397 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 398 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 399 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.271          |
| Data-EnvSampler-Poli... | 0.507          |
| Data-EnvTrajs-Averag... | 38.3           |
| Data-EnvTrajs-MaxReturn | 39.5           |
| Data-EnvTrajs-MinReturn | 37.7           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 0.658          |
| Data-TimeEnvSampleProc  | 0.000866       |
| Data-TimeEnvSampling    | 0.804          |
| Iteration               | 39             |
| ItrTime                 | 33.4           |
| LossAfter               | -0.0033033213  |
| LossBefore              | -7.3712763e-06 |
| Model-TimeModelFit      | 28.6           |
| ModelSampler-n_times... | 1600000        |
| Policy-AverageAbsPol... | 1.9720503      |
| Policy-AverageDiscou... | 20.6           |
| Policy-AveragePolicyStd | 0.50550985     |
| Policy-AverageReturn    | 26             |
| Policy-MaxReturn        | 29.9           |
| Policy-MinReturn        | 21.6           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.11           |
| Policy-TimeAlgoOpt      | 0.707          |
| Policy-TimeSampleProc   | 0.923          |
| Policy-TimeSampling     | 2.37           |
| Policy-TimeStep         | 4.02           |
| Time                    | 1.28e+03       |
| n_timesteps             | 40000          |
--------------------------------------------

 ---------------- Iteration 40 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 400 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 401 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 402 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 403 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 404 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 405 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 406 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 407 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 408 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 409 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.471         |
| Data-EnvSampler-Poli... | 0.857         |
| Data-EnvTrajs-Averag... | 37.1          |
| Data-EnvTrajs-MaxReturn | 38.3          |
| Data-EnvTrajs-MinReturn | 35.9          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 0.994         |
| Data-TimeEnvSampleProc  | 0.00115       |
| Data-TimeEnvSampling    | 1.37          |
| Iteration               | 40            |
| ItrTime                 | 41.5          |
| LossAfter               | -0.0036768015 |
| LossBefore              | -7.100998e-06 |
| Model-TimeModelFit      | 37.7          |
| ModelSampler-n_times... | 1640000       |
| Policy-AverageAbsPol... | 1.9222463     |
| Policy-AverageDiscou... | 23.7          |
| Policy-AveragePolicyStd | 0.49353528    |
| Policy-AverageReturn    | 31.1          |
| Policy-MaxReturn        | 33.6          |
| Policy-MinReturn        | 27.9          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.81          |
| Policy-TimeAlgoOpt      | 0.495         |
| Policy-TimeSampleProc   | 0.39          |
| Policy-TimeSampling     | 1.39          |
| Policy-TimeStep         | 2.38          |
| Time                    | 1.32e+03      |
| n_timesteps             | 41000         |
-------------------------------------------

 ---------------- Iteration 41 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 410 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 411 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 412 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 413 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 414 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 415 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 416 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 417 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 418 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 419 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.275         |
| Data-EnvSampler-Poli... | 0.519         |
| Data-EnvTrajs-Averag... | 38.4          |
| Data-EnvTrajs-MaxReturn | 40.4          |
| Data-EnvTrajs-MinReturn | 36.7          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.25          |
| Data-TimeEnvSampleProc  | 0.000866      |
| Data-TimeEnvSampling    | 0.822         |
| Iteration               | 41            |
| ItrTime                 | 41.3          |
| LossAfter               | -0.0043336214 |
| LossBefore              | -6.938505e-06 |
| Model-TimeModelFit      | 36.6          |
| ModelSampler-n_times... | 1680000       |
| Policy-AverageAbsPol... | 2.0274937     |
| Policy-AverageDiscou... | 26.2          |
| Policy-AveragePolicyStd | 0.48534763    |
| Policy-AverageReturn    | 42.6          |
| Policy-MaxReturn        | 51.3          |
| Policy-MinReturn        | 35.4          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 4.25          |
| Policy-TimeAlgoOpt      | 0.829         |
| Policy-TimeSampleProc   | 0.526         |
| Policy-TimeSampling     | 2.48          |
| Policy-TimeStep         | 3.87          |
| Time                    | 1.37e+03      |
| n_timesteps             | 42000         |
-------------------------------------------

 ---------------- Iteration 42 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 420 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 421 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 422 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 423 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 424 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 425 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 426 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 427 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 428 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 429 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.478         |
| Data-EnvSampler-Poli... | 0.851         |
| Data-EnvTrajs-Averag... | 37.5          |
| Data-EnvTrajs-MaxReturn | 38.1          |
| Data-EnvTrajs-MinReturn | 36.6          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 0.533         |
| Data-TimeEnvSampleProc  | 0.00111       |
| Data-TimeEnvSampling    | 1.37          |
| Iteration               | 42            |
| ItrTime                 | 34.6          |
| LossAfter               | -0.0009972717 |
| LossBefore              | -6.592854e-06 |
| Model-TimeModelFit      | 30.7          |
| ModelSampler-n_times... | 1720000       |
| Policy-AverageAbsPol... | 2.0475242     |
| Policy-AverageDiscou... | 27.6          |
| Policy-AveragePolicyStd | 0.46972358    |
| Policy-AverageReturn    | 48.6          |
| Policy-MaxReturn        | 71.2          |
| Policy-MinReturn        | 38.1          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 8.87          |
| Policy-TimeAlgoOpt      | 0.519         |
| Policy-TimeSampleProc   | 0.35          |
| Policy-TimeSampling     | 1.69          |
| Policy-TimeStep         | 2.58          |
| Time                    | 1.4e+03       |
| n_timesteps             | 43000         |
-------------------------------------------

 ---------------- Iteration 43 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 430 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 431 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 432 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 433 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 434 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 435 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 436 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 437 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 438 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 439 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.328          |
| Data-EnvSampler-Poli... | 0.61           |
| Data-EnvTrajs-Averag... | 39.1           |
| Data-EnvTrajs-MaxReturn | 39.7           |
| Data-EnvTrajs-MinReturn | 38.2           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 0.519          |
| Data-TimeEnvSampleProc  | 0.000957       |
| Data-TimeEnvSampling    | 0.966          |
| Iteration               | 43             |
| ItrTime                 | 50.3           |
| LossAfter               | -3.6483805e-05 |
| LossBefore              | -6.3786542e-06 |
| Model-TimeModelFit      | 45.5           |
| ModelSampler-n_times... | 1760000        |
| Policy-AverageAbsPol... | 2.0493963      |
| Policy-AverageDiscou... | 27.9           |
| Policy-AveragePolicyStd | 0.46053204     |
| Policy-AverageReturn    | 45.9           |
| Policy-MaxReturn        | 90             |
| Policy-MinReturn        | 31.5           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 16.5           |
| Policy-TimeAlgoOpt      | 0.666          |
| Policy-TimeSampleProc   | 0.877          |
| Policy-TimeSampling     | 2.18           |
| Policy-TimeStep         | 3.77           |
| Time                    | 1.45e+03       |
| n_timesteps             | 44000          |
--------------------------------------------

 ---------------- Iteration 44 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 440 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 441 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 442 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 443 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 444 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 445 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 446 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 447 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 448 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 449 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.461          |
| Data-EnvSampler-Poli... | 0.905          |
| Data-EnvTrajs-Averag... | 38.5           |
| Data-EnvTrajs-MaxReturn | 39.9           |
| Data-EnvTrajs-MinReturn | 37.8           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 0.743          |
| Data-TimeEnvSampleProc  | 0.00132        |
| Data-TimeEnvSampling    | 1.41           |
| Iteration               | 44             |
| ItrTime                 | 54.5           |
| LossAfter               | -0.0018464996  |
| LossBefore              | -6.1741052e-06 |
| Model-TimeModelFit      | 49.3           |
| ModelSampler-n_times... | 1800000        |
| Policy-AverageAbsPol... | 2.043044       |
| Policy-AverageDiscou... | 30             |
| Policy-AveragePolicyStd | 0.4504235      |
| Policy-AverageReturn    | 64.2           |
| Policy-MaxReturn        | 132            |
| Policy-MinReturn        | 35             |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 29.4           |
| Policy-TimeAlgoOpt      | 0.681          |
| Policy-TimeSampleProc   | 0.883          |
| Policy-TimeSampling     | 2.22           |
| Policy-TimeStep         | 3.8            |
| Time                    | 1.51e+03       |
| n_timesteps             | 45000          |
--------------------------------------------

 ---------------- Iteration 45 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 450 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 451 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 452 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 453 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 454 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 455 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 456 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 457 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 458 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 459 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.465          |
| Data-EnvSampler-Poli... | 0.889          |
| Data-EnvTrajs-Averag... | 38.6           |
| Data-EnvTrajs-MaxReturn | 39.3           |
| Data-EnvTrajs-MinReturn | 38.1           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 0.442          |
| Data-TimeEnvSampleProc  | 0.00116        |
| Data-TimeEnvSampling    | 1.39           |
| Iteration               | 45             |
| ItrTime                 | 42.9           |
| LossAfter               | -0.0009276308  |
| LossBefore              | -5.9345007e-06 |
| Model-TimeModelFit      | 39.1           |
| ModelSampler-n_times... | 1840000        |
| Policy-AverageAbsPol... | 2.1280253      |
| Policy-AverageDiscou... | 36.6           |
| Policy-AveragePolicyStd | 0.44033697     |
| Policy-AverageReturn    | 101            |
| Policy-MaxReturn        | 164            |
| Policy-MinReturn        | 38.2           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 42.2           |
| Policy-TimeAlgoOpt      | 0.503          |
| Policy-TimeSampleProc   | 0.282          |
| Policy-TimeSampling     | 1.61           |
| Policy-TimeStep         | 2.43           |
| Time                    | 1.55e+03       |
| n_timesteps             | 46000          |
--------------------------------------------

 ---------------- Iteration 46 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 460 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 461 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 462 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 463 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 464 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 465 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 466 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 467 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 468 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 469 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.308          |
| Data-EnvSampler-Poli... | 0.605          |
| Data-EnvTrajs-Averag... | 38.8           |
| Data-EnvTrajs-MaxReturn | 39.8           |
| Data-EnvTrajs-MinReturn | 38.2           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 0.534          |
| Data-TimeEnvSampleProc  | 0.000875       |
| Data-TimeEnvSampling    | 0.953          |
| Iteration               | 46             |
| ItrTime                 | 48.6           |
| LossAfter               | -0.005375194   |
| LossBefore              | -5.7611965e-06 |
| Model-TimeModelFit      | 43.7           |
| ModelSampler-n_times... | 1880000        |
| Policy-AverageAbsPol... | 2.0399256      |
| Policy-AverageDiscou... | 28.8           |
| Policy-AveragePolicyStd | 0.4326902      |
| Policy-AverageReturn    | 46             |
| Policy-MaxReturn        | 49.1           |
| Policy-MinReturn        | 40.4           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.19           |
| Policy-TimeAlgoOpt      | 0.758          |
| Policy-TimeSampleProc   | 0.73           |
| Policy-TimeSampling     | 2.4            |
| Policy-TimeStep         | 3.94           |
| Time                    | 1.6e+03        |
| n_timesteps             | 47000          |
--------------------------------------------

 ---------------- Iteration 47 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 470 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 471 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 472 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 473 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 474 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 475 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 476 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 477 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 478 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 479 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.475         |
| Data-EnvSampler-Poli... | 0.97          |
| Data-EnvTrajs-Averag... | 37.7          |
| Data-EnvTrajs-MaxReturn | 39.4          |
| Data-EnvTrajs-MinReturn | 36.3          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.14          |
| Data-TimeEnvSampleProc  | 0.000777      |
| Data-TimeEnvSampling    | 1.49          |
| Iteration               | 47            |
| ItrTime                 | 56.2          |
| LossAfter               | -0.0031433662 |
| LossBefore              | -5.533962e-06 |
| Model-TimeModelFit      | 50.6          |
| ModelSampler-n_times... | 1920000       |
| Policy-AverageAbsPol... | 1.9811968     |
| Policy-AverageDiscou... | 32.9          |
| Policy-AveragePolicyStd | 0.4223744     |
| Policy-AverageReturn    | 72.3          |
| Policy-MaxReturn        | 102           |
| Policy-MinReturn        | 53.6          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 12.9          |
| Policy-TimeAlgoOpt      | 0.684         |
| Policy-TimeSampleProc   | 0.994         |
| Policy-TimeSampling     | 2.38          |
| Policy-TimeStep         | 4.1           |
| Time                    | 1.65e+03      |
| n_timesteps             | 48000         |
-------------------------------------------

 ---------------- Iteration 48 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 480 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 481 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 482 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 483 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 484 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 485 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 486 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 487 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 488 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 489 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.489          |
| Data-EnvSampler-Poli... | 0.976          |
| Data-EnvTrajs-Averag... | 38             |
| Data-EnvTrajs-MaxReturn | 38.9           |
| Data-EnvTrajs-MinReturn | 37.4           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 0.544          |
| Data-TimeEnvSampleProc  | 0.0013         |
| Data-TimeEnvSampling    | 1.51           |
| Iteration               | 48             |
| ItrTime                 | 54             |
| LossAfter               | -0.005858158   |
| LossBefore              | -5.2447626e-06 |
| Model-TimeModelFit      | 48.4           |
| ModelSampler-n_times... | 1960000        |
| Policy-AverageAbsPol... | 2.0728836      |
| Policy-AverageDiscou... | 26             |
| Policy-AveragePolicyStd | 0.40989843     |
| Policy-AverageReturn    | 36.8           |
| Policy-MaxReturn        | 42.1           |
| Policy-MinReturn        | 33.4           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.98           |
| Policy-TimeAlgoOpt      | 0.77           |
| Policy-TimeSampleProc   | 0.913          |
| Policy-TimeSampling     | 2.37           |
| Policy-TimeStep         | 4.09           |
| Time                    | 1.71e+03       |
| n_timesteps             | 49000          |
--------------------------------------------

 ---------------- Iteration 49 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 490 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 491 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 492 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 493 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 494 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 495 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 496 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 497 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 498 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 499 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.474          |
| Data-EnvSampler-Poli... | 0.885          |
| Data-EnvTrajs-Averag... | 38.1           |
| Data-EnvTrajs-MaxReturn | 38.8           |
| Data-EnvTrajs-MinReturn | 36.5           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 0.802          |
| Data-TimeEnvSampleProc  | 0.00142        |
| Data-TimeEnvSampling    | 1.4            |
| Iteration               | 49             |
| ItrTime                 | 36.8           |
| LossAfter               | -0.0033450904  |
| LossBefore              | -5.1170246e-06 |
| Model-TimeModelFit      | 32.7           |
| ModelSampler-n_times... | 2000000        |
| Policy-AverageAbsPol... | 2.1164844      |
| Policy-AverageDiscou... | 25.4           |
| Policy-AveragePolicyStd | 0.40429336     |
| Policy-AverageReturn    | 37.8           |
| Policy-MaxReturn        | 43.4           |
| Policy-MinReturn        | 31.8           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.76           |
| Policy-TimeAlgoOpt      | 0.511          |
| Policy-TimeSampleProc   | 0.518          |
| Policy-TimeSampling     | 1.58           |
| Policy-TimeStep         | 2.64           |
| Time                    | 1.74e+03       |
| n_timesteps             | 50000          |
--------------------------------------------

 ---------------- Iteration 50 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 500 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 501 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 502 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 503 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 504 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 505 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 506 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 507 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 508 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 509 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.414          |
| Data-EnvSampler-Poli... | 0.838          |
| Data-EnvTrajs-Averag... | 38.5           |
| Data-EnvTrajs-MaxReturn | 38.8           |
| Data-EnvTrajs-MinReturn | 38.2           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 0.238          |
| Data-TimeEnvSampleProc  | 0.0014         |
| Data-TimeEnvSampling    | 1.29           |
| Iteration               | 50             |
| ItrTime                 | 48.3           |
| LossAfter               | -0.003406727   |
| LossBefore              | -4.9753817e-06 |
| Model-TimeModelFit      | 43.9           |
| ModelSampler-n_times... | 2040000        |
| Policy-AverageAbsPol... | 2.103393       |
| Policy-AverageDiscou... | 27.5           |
| Policy-AveragePolicyStd | 0.39932397     |
| Policy-AverageReturn    | 42             |
| Policy-MaxReturn        | 47.2           |
| Policy-MinReturn        | 39.3           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.05           |
| Policy-TimeAlgoOpt      | 0.698          |
| Policy-TimeSampleProc   | 0.479          |
| Policy-TimeSampling     | 1.83           |
| Policy-TimeStep         | 3.04           |
| Time                    | 1.79e+03       |
| n_timesteps             | 51000          |
--------------------------------------------
Training finished
