Logging to /home/vincent/workplace/CS_287_-_Advanced_Robotics/homework/hw5/cs287hw5/ppo/run_scripts/data/parallel_mb_ppo/mbppo_Swimmer_l2_no_square//00

 ---------------- Iteration 0 ----------------
Obtaining random samples from the environment...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 0 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 1 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 2 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 3 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 4 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 5 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 6 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 7 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 8 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 9 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.11           |
| Data-EnvSampler-Poli... | 0.0341         |
| Data-EnvTrajs-Averag... | -0.484         |
| Data-EnvTrajs-MaxReturn | 7.44           |
| Data-EnvTrajs-MinReturn | -4.53          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 4.13           |
| Data-TimeEnvSampleProc  | 0.000467       |
| Data-TimeEnvSampling    | 0.154          |
| Iteration               | 0              |
| ItrTime                 | 8.25           |
| LossAfter               | -0.0023865672  |
| LossBefore              | -1.4053011e-05 |
| Model-TimeModelFit      | 2.76           |
| ModelSampler-n_times... | 40000          |
| Policy-AverageAbsPol... | 0.496722       |
| Policy-AverageDiscou... | -13.2          |
| Policy-AveragePolicyStd | 0.98136806     |
| Policy-AverageReturn    | -56.6          |
| Policy-MaxReturn        | 125            |
| Policy-MinReturn        | -382           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 132            |
| Policy-TimeAlgoOpt      | 1.05           |
| Policy-TimeSampleProc   | 0.479          |
| Policy-TimeSampling     | 3.78           |
| Policy-TimeStep         | 5.33           |
| Time                    | 8.25           |
| n_timesteps             | 1000           |
--------------------------------------------

 ---------------- Iteration 1 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 10 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 11 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 12 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 13 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 14 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 15 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 16 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 17 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 18 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 19 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.205          |
| Data-EnvSampler-Poli... | 0.466          |
| Data-EnvTrajs-Averag... | 20.3           |
| Data-EnvTrajs-MaxReturn | 28.3           |
| Data-EnvTrajs-MinReturn | 12.3           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 6.35           |
| Data-TimeEnvSampleProc  | 0.000536       |
| Data-TimeEnvSampling    | 0.691          |
| Iteration               | 1              |
| ItrTime                 | 7.26           |
| LossAfter               | -0.0024275077  |
| LossBefore              | -1.3961418e-05 |
| Model-TimeModelFit      | 4.1            |
| ModelSampler-n_times... | 80000          |
| Policy-AverageAbsPol... | 0.36611804     |
| Policy-AverageDiscou... | -12.6          |
| Policy-AveragePolicyStd | 0.9775633      |
| Policy-AverageReturn    | -40.3          |
| Policy-MaxReturn        | 7.14           |
| Policy-MinReturn        | -77            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 17.5           |
| Policy-TimeAlgoOpt      | 0.481          |
| Policy-TimeSampleProc   | 0.57           |
| Policy-TimeSampling     | 1.39           |
| Policy-TimeStep         | 2.47           |
| Time                    | 15.6           |
| n_timesteps             | 2000           |
--------------------------------------------

 ---------------- Iteration 2 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 20 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 21 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 22 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 23 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 24 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 25 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 26 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 27 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 28 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 29 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.208          |
| Data-EnvSampler-Poli... | 0.377          |
| Data-EnvTrajs-Averag... | 21.8           |
| Data-EnvTrajs-MaxReturn | 27.1           |
| Data-EnvTrajs-MinReturn | 17.7           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 3.66           |
| Data-TimeEnvSampleProc  | 0.000868       |
| Data-TimeEnvSampling    | 0.605          |
| Iteration               | 2              |
| ItrTime                 | 9.28           |
| LossAfter               | -0.0043255566  |
| LossBefore              | -1.3742474e-05 |
| Model-TimeModelFit      | 6.09           |
| ModelSampler-n_times... | 120000         |
| Policy-AverageAbsPol... | 0.50134045     |
| Policy-AverageDiscou... | 10.1           |
| Policy-AveragePolicyStd | 0.957088       |
| Policy-AverageReturn    | -67.1          |
| Policy-MaxReturn        | 105            |
| Policy-MinReturn        | -2.41e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 539            |
| Policy-TimeAlgoOpt      | 0.565          |
| Policy-TimeSampleProc   | 0.348          |
| Policy-TimeSampling     | 1.63           |
| Policy-TimeStep         | 2.59           |
| Time                    | 24.9           |
| n_timesteps             | 3000           |
--------------------------------------------

 ---------------- Iteration 3 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 30 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 31 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 32 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 33 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 34 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 35 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 36 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 37 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 38 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 39 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.232         |
| Data-EnvSampler-Poli... | 0.434         |
| Data-EnvTrajs-Averag... | 21            |
| Data-EnvTrajs-MaxReturn | 29.1          |
| Data-EnvTrajs-MinReturn | 15            |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 5.53          |
| Data-TimeEnvSampleProc  | 0.000589      |
| Data-TimeEnvSampling    | 0.689         |
| Iteration               | 3             |
| ItrTime                 | 14.7          |
| LossAfter               | -0.0048428294 |
| LossBefore              | -1.355806e-05 |
| Model-TimeModelFit      | 10.5          |
| ModelSampler-n_times... | 160000        |
| Policy-AverageAbsPol... | 0.46229437    |
| Policy-AverageDiscou... | 30.8          |
| Policy-AveragePolicyStd | 0.93848807    |
| Policy-AverageReturn    | 99.8          |
| Policy-MaxReturn        | 153           |
| Policy-MinReturn        | 48.6          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 25.8          |
| Policy-TimeAlgoOpt      | 0.692         |
| Policy-TimeSampleProc   | 0.697         |
| Policy-TimeSampling     | 2.08          |
| Policy-TimeStep         | 3.51          |
| Time                    | 39.6          |
| n_timesteps             | 4000          |
-------------------------------------------

 ---------------- Iteration 4 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 40 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 41 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 42 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 43 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 44 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 45 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 46 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 47 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 48 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 49 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.339           |
| Data-EnvSampler-Poli... | 0.593           |
| Data-EnvTrajs-Averag... | 7.33            |
| Data-EnvTrajs-MaxReturn | 18.9            |
| Data-EnvTrajs-MinReturn | 0.59            |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 6.13            |
| Data-TimeEnvSampleProc  | 0.00141         |
| Data-TimeEnvSampling    | 0.962           |
| Iteration               | 4               |
| ItrTime                 | 20              |
| LossAfter               | -0.00255608     |
| LossBefore              | -1.34790625e-05 |
| Model-TimeModelFit      | 15.5            |
| ModelSampler-n_times... | 200000          |
| Policy-AverageAbsPol... | 0.64610255      |
| Policy-AverageDiscou... | -6.27           |
| Policy-AveragePolicyStd | 0.9323772       |
| Policy-AverageReturn    | -14.9           |
| Policy-MaxReturn        | 13.4            |
| Policy-MinReturn        | -92             |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 27.9            |
| Policy-TimeAlgoOpt      | 0.666           |
| Policy-TimeSampleProc   | 0.701           |
| Policy-TimeSampling     | 2.13            |
| Policy-TimeStep         | 3.53            |
| Time                    | 59.6            |
| n_timesteps             | 5000            |
---------------------------------------------

 ---------------- Iteration 5 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 50 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 51 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 52 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 53 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 54 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 55 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 56 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 57 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 58 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 59 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.315          |
| Data-EnvSampler-Poli... | 0.568          |
| Data-EnvTrajs-Averag... | 4.85           |
| Data-EnvTrajs-MaxReturn | 10.1           |
| Data-EnvTrajs-MinReturn | 1.98           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 3.17           |
| Data-TimeEnvSampleProc  | 0.00136        |
| Data-TimeEnvSampling    | 0.912          |
| Iteration               | 5              |
| ItrTime                 | 22.3           |
| LossAfter               | -0.0035848685  |
| LossBefore              | -1.3396855e-05 |
| Model-TimeModelFit      | 17.7           |
| ModelSampler-n_times... | 240000         |
| Policy-AverageAbsPol... | 0.49822628     |
| Policy-AverageDiscou... | -34.7          |
| Policy-AveragePolicyStd | 0.92538255     |
| Policy-AverageReturn    | -246           |
| Policy-MaxReturn        | 17.3           |
| Policy-MinReturn        | -2.65e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 693            |
| Policy-TimeAlgoOpt      | 0.79           |
| Policy-TimeSampleProc   | 0.658          |
| Policy-TimeSampling     | 2.13           |
| Policy-TimeStep         | 3.61           |
| Time                    | 81.9           |
| n_timesteps             | 6000           |
--------------------------------------------

 ---------------- Iteration 6 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 60 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 61 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 62 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 63 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 64 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 65 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 66 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 67 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 68 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 69 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.328          |
| Data-EnvSampler-Poli... | 0.612          |
| Data-EnvTrajs-Averag... | 7.74           |
| Data-EnvTrajs-MaxReturn | 10.7           |
| Data-EnvTrajs-MinReturn | -2.18          |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 4.97           |
| Data-TimeEnvSampleProc  | 0.00348        |
| Data-TimeEnvSampling    | 0.971          |
| Iteration               | 6              |
| ItrTime                 | 21.2           |
| LossAfter               | -0.0076049287  |
| LossBefore              | -1.3182996e-05 |
| Model-TimeModelFit      | 17.8           |
| ModelSampler-n_times... | 280000         |
| Policy-AverageAbsPol... | 0.74257076     |
| Policy-AverageDiscou... | 76.5           |
| Policy-AveragePolicyStd | 0.90596545     |
| Policy-AverageReturn    | 202            |
| Policy-MaxReturn        | 232            |
| Policy-MinReturn        | 169            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 15.2           |
| Policy-TimeAlgoOpt      | 0.609          |
| Policy-TimeSampleProc   | 0.322          |
| Policy-TimeSampling     | 1.44           |
| Policy-TimeStep         | 2.39           |
| Time                    | 103            |
| n_timesteps             | 7000           |
--------------------------------------------

 ---------------- Iteration 7 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 70 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 71 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 72 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 73 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 74 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 75 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 76 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 77 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 78 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 79 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.243          |
| Data-EnvSampler-Poli... | 0.442          |
| Data-EnvTrajs-Averag... | 23.5           |
| Data-EnvTrajs-MaxReturn | 26.4           |
| Data-EnvTrajs-MinReturn | 18.5           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 3.3            |
| Data-TimeEnvSampleProc  | 0.000841       |
| Data-TimeEnvSampling    | 0.707          |
| Iteration               | 7              |
| ItrTime                 | 18.5           |
| LossAfter               | -0.0023224766  |
| LossBefore              | -1.2901553e-05 |
| Model-TimeModelFit      | 15.1           |
| ModelSampler-n_times... | 320000         |
| Policy-AverageAbsPol... | 0.62131965     |
| Policy-AverageDiscou... | 0.682          |
| Policy-AveragePolicyStd | 0.8811848      |
| Policy-AverageReturn    | -11.9          |
| Policy-MaxReturn        | -5.6           |
| Policy-MinReturn        | -21.6          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 4.49           |
| Policy-TimeAlgoOpt      | 0.57           |
| Policy-TimeSampleProc   | 0.53           |
| Policy-TimeSampling     | 1.54           |
| Policy-TimeStep         | 2.68           |
| Time                    | 122            |
| n_timesteps             | 8000           |
--------------------------------------------

 ---------------- Iteration 8 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 80 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 81 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 82 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 83 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 84 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 85 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 86 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 87 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 88 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 89 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.273          |
| Data-EnvSampler-Poli... | 0.5            |
| Data-EnvTrajs-Averag... | 25.9           |
| Data-EnvTrajs-MaxReturn | 30             |
| Data-EnvTrajs-MinReturn | 22.9           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.62           |
| Data-TimeEnvSampleProc  | 0.000938       |
| Data-TimeEnvSampling    | 0.797          |
| Iteration               | 8              |
| ItrTime                 | 31.9           |
| LossAfter               | -0.0044485647  |
| LossBefore              | -1.2767999e-05 |
| Model-TimeModelFit      | 27.4           |
| ModelSampler-n_times... | 360000         |
| Policy-AverageAbsPol... | 0.96161205     |
| Policy-AverageDiscou... | 39.9           |
| Policy-AveragePolicyStd | 0.86862665     |
| Policy-AverageReturn    | 79.7           |
| Policy-MaxReturn        | 93.7           |
| Policy-MinReturn        | 70.1           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 4.8            |
| Policy-TimeAlgoOpt      | 0.82           |
| Policy-TimeSampleProc   | 0.494          |
| Policy-TimeSampling     | 2.4            |
| Policy-TimeStep         | 3.74           |
| Time                    | 153            |
| n_timesteps             | 9000           |
--------------------------------------------

 ---------------- Iteration 9 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 90 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 91 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 92 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 93 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 94 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 95 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 96 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 97 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 98 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 99 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.397          |
| Data-EnvSampler-Poli... | 0.712          |
| Data-EnvTrajs-Averag... | 27.5           |
| Data-EnvTrajs-MaxReturn | 33.2           |
| Data-EnvTrajs-MinReturn | 21             |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 4.6            |
| Data-TimeEnvSampleProc  | 0.00095        |
| Data-TimeEnvSampling    | 1.14           |
| Iteration               | 9              |
| ItrTime                 | 25.6           |
| LossAfter               | -0.0034783925  |
| LossBefore              | -1.2479414e-05 |
| Model-TimeModelFit      | 22             |
| ModelSampler-n_times... | 400000         |
| Policy-AverageAbsPol... | 0.8019438      |
| Policy-AverageDiscou... | 0.234          |
| Policy-AveragePolicyStd | 0.84395695     |
| Policy-AverageReturn    | -27.9          |
| Policy-MaxReturn        | -23.8          |
| Policy-MinReturn        | -31.2          |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.4            |
| Policy-TimeAlgoOpt      | 0.577          |
| Policy-TimeSampleProc   | 0.404          |
| Policy-TimeSampling     | 1.44           |
| Policy-TimeStep         | 2.44           |
| Time                    | 179            |
| n_timesteps             | 10000          |
--------------------------------------------

 ---------------- Iteration 10 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 100 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 101 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 102 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 103 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 104 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 105 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 106 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 107 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 108 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 109 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.302         |
| Data-EnvSampler-Poli... | 0.533         |
| Data-EnvTrajs-Averag... | 24.9          |
| Data-EnvTrajs-MaxReturn | 29.7          |
| Data-EnvTrajs-MinReturn | 19.7          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 3.57          |
| Data-TimeEnvSampleProc  | 0.000563      |
| Data-TimeEnvSampling    | 0.861         |
| Iteration               | 10            |
| ItrTime                 | 31.8          |
| LossAfter               | -0.0062669353 |
| LossBefore              | -1.232931e-05 |
| Model-TimeModelFit      | 26.9          |
| ModelSampler-n_times... | 440000        |
| Policy-AverageAbsPol... | 0.9142279     |
| Policy-AverageDiscou... | 27            |
| Policy-AveragePolicyStd | 0.83072823    |
| Policy-AverageReturn    | 54.3          |
| Policy-MaxReturn        | 64.6          |
| Policy-MinReturn        | 48.6          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 3.84          |
| Policy-TimeAlgoOpt      | 0.768         |
| Policy-TimeSampleProc   | 0.773         |
| Policy-TimeSampling     | 2.42          |
| Policy-TimeStep         | 3.99          |
| Time                    | 211           |
| n_timesteps             | 11000         |
-------------------------------------------

 ---------------- Iteration 11 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 110 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 111 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 112 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 113 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 114 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 115 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 116 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 117 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 118 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 119 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.449          |
| Data-EnvSampler-Poli... | 0.787          |
| Data-EnvTrajs-Averag... | 27.8           |
| Data-EnvTrajs-MaxReturn | 31             |
| Data-EnvTrajs-MinReturn | 24.8           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.99           |
| Data-TimeEnvSampleProc  | 0.000907       |
| Data-TimeEnvSampling    | 1.27           |
| Iteration               | 11             |
| ItrTime                 | 34.8           |
| LossAfter               | -0.0043397467  |
| LossBefore              | -1.2227334e-05 |
| Model-TimeModelFit      | 30.9           |
| ModelSampler-n_times... | 480000         |
| Policy-AverageAbsPol... | 0.63313466     |
| Policy-AverageDiscou... | 70.3           |
| Policy-AveragePolicyStd | 0.8214158      |
| Policy-AverageReturn    | 174            |
| Policy-MaxReturn        | 333            |
| Policy-MinReturn        | 5.36           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 93.6           |
| Policy-TimeAlgoOpt      | 0.524          |
| Policy-TimeSampleProc   | 0.508          |
| Policy-TimeSampling     | 1.53           |
| Policy-TimeStep         | 2.6            |
| Time                    | 246            |
| n_timesteps             | 12000          |
--------------------------------------------

 ---------------- Iteration 12 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 120 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 121 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 122 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 123 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 124 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 125 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 126 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 127 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 128 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 129 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.306          |
| Data-EnvSampler-Poli... | 0.608          |
| Data-EnvTrajs-Averag... | 26.5           |
| Data-EnvTrajs-MaxReturn | 31.4           |
| Data-EnvTrajs-MinReturn | 24.6           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.46           |
| Data-TimeEnvSampleProc  | 0.000631       |
| Data-TimeEnvSampling    | 0.939          |
| Iteration               | 12             |
| ItrTime                 | 32.5           |
| LossAfter               | -0.002199046   |
| LossBefore              | -1.2065967e-05 |
| Model-TimeModelFit      | 27.9           |
| ModelSampler-n_times... | 520000         |
| Policy-AverageAbsPol... | 1.155774       |
| Policy-AverageDiscou... | -35.9          |
| Policy-AveragePolicyStd | 0.8127669      |
| Policy-AverageReturn    | -255           |
| Policy-MaxReturn        | 4.79           |
| Policy-MinReturn        | -4.89e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.06e+03       |
| Policy-TimeAlgoOpt      | 0.845          |
| Policy-TimeSampleProc   | 0.578          |
| Policy-TimeSampling     | 2.16           |
| Policy-TimeStep         | 3.62           |
| Time                    | 278            |
| n_timesteps             | 13000          |
--------------------------------------------

 ---------------- Iteration 13 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 130 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 131 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 132 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 133 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 134 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 135 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 136 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 137 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 138 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 139 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.484          |
| Data-EnvSampler-Poli... | 0.915          |
| Data-EnvTrajs-Averag... | 27.9           |
| Data-EnvTrajs-MaxReturn | 31.2           |
| Data-EnvTrajs-MinReturn | 23.6           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.57           |
| Data-TimeEnvSampleProc  | 0.00108        |
| Data-TimeEnvSampling    | 1.44           |
| Iteration               | 13             |
| ItrTime                 | 41.3           |
| LossAfter               | -0.0024798955  |
| LossBefore              | -1.1976512e-05 |
| Model-TimeModelFit      | 37.4           |
| ModelSampler-n_times... | 560000         |
| Policy-AverageAbsPol... | 0.8543247      |
| Policy-AverageDiscou... | 129            |
| Policy-AveragePolicyStd | 0.80220103     |
| Policy-AverageReturn    | 370            |
| Policy-MaxReturn        | 422            |
| Policy-MinReturn        | 230            |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 42.4           |
| Policy-TimeAlgoOpt      | 0.502          |
| Policy-TimeSampleProc   | 0.559          |
| Policy-TimeSampling     | 1.35           |
| Policy-TimeStep         | 2.45           |
| Time                    | 319            |
| n_timesteps             | 14000          |
--------------------------------------------

 ---------------- Iteration 14 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 140 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 141 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 142 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 143 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 144 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 145 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 146 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 147 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 148 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 149 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.353          |
| Data-EnvSampler-Poli... | 0.724          |
| Data-EnvTrajs-Averag... | 26.1           |
| Data-EnvTrajs-MaxReturn | 28.7           |
| Data-EnvTrajs-MinReturn | 24.5           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.43           |
| Data-TimeEnvSampleProc  | 0.000566       |
| Data-TimeEnvSampling    | 1.1            |
| Iteration               | 14             |
| ItrTime                 | 29.7           |
| LossAfter               | -0.002394294   |
| LossBefore              | -1.1765802e-05 |
| Model-TimeModelFit      | 24.7           |
| ModelSampler-n_times... | 600000         |
| Policy-AverageAbsPol... | 1.1048584      |
| Policy-AverageDiscou... | -193           |
| Policy-AveragePolicyStd | 0.78221685     |
| Policy-AverageReturn    | -1.19e+03      |
| Policy-MaxReturn        | 27.1           |
| Policy-MinReturn        | -6.53e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.88e+03       |
| Policy-TimeAlgoOpt      | 0.858          |
| Policy-TimeSampleProc   | 0.542          |
| Policy-TimeSampling     | 2.44           |
| Policy-TimeStep         | 3.87           |
| Time                    | 349            |
| n_timesteps             | 15000          |
--------------------------------------------

 ---------------- Iteration 15 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 150 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 151 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 152 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 153 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 154 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 155 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 156 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 157 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 158 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 159 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.46           |
| Data-EnvSampler-Poli... | 0.841          |
| Data-EnvTrajs-Averag... | 22.5           |
| Data-EnvTrajs-MaxReturn | 24.6           |
| Data-EnvTrajs-MinReturn | 19.3           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.02           |
| Data-TimeEnvSampleProc  | 0.00105        |
| Data-TimeEnvSampling    | 1.34           |
| Iteration               | 15             |
| ItrTime                 | 44.2           |
| LossAfter               | -0.0040104766  |
| LossBefore              | -1.1508211e-05 |
| Model-TimeModelFit      | 39             |
| ModelSampler-n_times... | 640000         |
| Policy-AverageAbsPol... | 0.7570176      |
| Policy-AverageDiscou... | 30.8           |
| Policy-AveragePolicyStd | 0.7643728      |
| Policy-AverageReturn    | 69.4           |
| Policy-MaxReturn        | 87.8           |
| Policy-MinReturn        | 42.2           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 12.2           |
| Policy-TimeAlgoOpt      | 0.83           |
| Policy-TimeSampleProc   | 0.667          |
| Policy-TimeSampling     | 2.36           |
| Policy-TimeStep         | 3.89           |
| Time                    | 393            |
| n_timesteps             | 16000          |
--------------------------------------------

 ---------------- Iteration 16 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 160 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 161 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 162 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 163 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 164 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 165 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 166 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 167 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 168 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 169 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.489         |
| Data-EnvSampler-Poli... | 0.974         |
| Data-EnvTrajs-Averag... | 26.9          |
| Data-EnvTrajs-MaxReturn | 29.1          |
| Data-EnvTrajs-MinReturn | 24.8          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.44          |
| Data-TimeEnvSampleProc  | 0.00101       |
| Data-TimeEnvSampling    | 1.5           |
| Iteration               | 16            |
| ItrTime                 | 30.6          |
| LossAfter               | -0.0051123654 |
| LossBefore              | -1.10825e-05  |
| Model-TimeModelFit      | 26.7          |
| ModelSampler-n_times... | 680000        |
| Policy-AverageAbsPol... | 0.796692      |
| Policy-AverageDiscou... | -7.24         |
| Policy-AveragePolicyStd | 0.73339844    |
| Policy-AverageReturn    | -33.9         |
| Policy-MaxReturn        | -29.4         |
| Policy-MinReturn        | -40.7         |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 3.42          |
| Policy-TimeAlgoOpt      | 0.539         |
| Policy-TimeSampleProc   | 0.3           |
| Policy-TimeSampling     | 1.58          |
| Policy-TimeStep         | 2.44          |
| Time                    | 424           |
| n_timesteps             | 17000         |
-------------------------------------------

 ---------------- Iteration 17 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 170 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 171 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 172 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 173 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 174 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 175 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 176 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 177 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 178 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 179 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------------
| Data-EnvSampler-EnvE... | 0.365           |
| Data-EnvSampler-Poli... | 0.694           |
| Data-EnvTrajs-Averag... | 28.5            |
| Data-EnvTrajs-MaxReturn | 31.9            |
| Data-EnvTrajs-MinReturn | 24              |
| Data-EnvTrajs-NumTrajs  | 5               |
| Data-EnvTrajs-StdReturn | 3.31            |
| Data-TimeEnvSampleProc  | 0.000834        |
| Data-TimeEnvSampling    | 1.1             |
| Iteration               | 17              |
| ItrTime                 | 41              |
| LossAfter               | -0.0021334335   |
| LossBefore              | -1.08020695e-05 |
| Model-TimeModelFit      | 36              |
| ModelSampler-n_times... | 720000          |
| Policy-AverageAbsPol... | 0.5049002       |
| Policy-AverageDiscou... | 21.3            |
| Policy-AveragePolicyStd | 0.7136617       |
| Policy-AverageReturn    | 34.5            |
| Policy-MaxReturn        | 47              |
| Policy-MinReturn        | 24.5            |
| Policy-NumTrajs         | 20              |
| Policy-StdReturn        | 4.96            |
| Policy-TimeAlgoOpt      | 0.685           |
| Policy-TimeSampleProc   | 0.881           |
| Policy-TimeSampling     | 2.28            |
| Policy-TimeStep         | 3.87            |
| Time                    | 465             |
| n_timesteps             | 18000           |
---------------------------------------------

 ---------------- Iteration 18 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 180 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 181 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 182 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 183 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 184 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 185 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 186 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 187 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 188 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 189 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.512          |
| Data-EnvSampler-Poli... | 1.01           |
| Data-EnvTrajs-Averag... | 23.8           |
| Data-EnvTrajs-MaxReturn | 26.1           |
| Data-EnvTrajs-MinReturn | 20.5           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.03           |
| Data-TimeEnvSampleProc  | 0.00116        |
| Data-TimeEnvSampling    | 1.56           |
| Iteration               | 18             |
| ItrTime                 | 33.8           |
| LossAfter               | -0.0027469853  |
| LossBefore              | -1.0626261e-05 |
| Model-TimeModelFit      | 29.7           |
| ModelSampler-n_times... | 760000         |
| Policy-AverageAbsPol... | 0.5116856      |
| Policy-AverageDiscou... | 30.6           |
| Policy-AveragePolicyStd | 0.7011043      |
| Policy-AverageReturn    | 45             |
| Policy-MaxReturn        | 60.4           |
| Policy-MinReturn        | 32.1           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 6.78           |
| Policy-TimeAlgoOpt      | 0.53           |
| Policy-TimeSampleProc   | 0.351          |
| Policy-TimeSampling     | 1.57           |
| Policy-TimeStep         | 2.49           |
| Time                    | 499            |
| n_timesteps             | 19000          |
--------------------------------------------

 ---------------- Iteration 19 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 190 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 191 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 192 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 193 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 194 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 195 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 196 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 197 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 198 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 199 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.406          |
| Data-EnvSampler-Poli... | 0.94           |
| Data-EnvTrajs-Averag... | 29.3           |
| Data-EnvTrajs-MaxReturn | 32.5           |
| Data-EnvTrajs-MinReturn | 25.5           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.78           |
| Data-TimeEnvSampleProc  | 0.000654       |
| Data-TimeEnvSampling    | 1.39           |
| Iteration               | 19             |
| ItrTime                 | 38.3           |
| LossAfter               | -0.003068255   |
| LossBefore              | -1.0482552e-05 |
| Model-TimeModelFit      | 33.3           |
| ModelSampler-n_times... | 800000         |
| Policy-AverageAbsPol... | 0.62515295     |
| Policy-AverageDiscou... | 25             |
| Policy-AveragePolicyStd | 0.69053465     |
| Policy-AverageReturn    | 32             |
| Policy-MaxReturn        | 43.8           |
| Policy-MinReturn        | 20             |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 4.39           |
| Policy-TimeAlgoOpt      | 0.787          |
| Policy-TimeSampleProc   | 0.554          |
| Policy-TimeSampling     | 2.27           |
| Policy-TimeStep         | 3.63           |
| Time                    | 537            |
| n_timesteps             | 20000          |
--------------------------------------------

 ---------------- Iteration 20 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 200 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 201 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 202 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 203 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 204 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 205 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 206 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 207 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 208 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 209 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.595          |
| Data-EnvSampler-Poli... | 1.12           |
| Data-EnvTrajs-Averag... | 27.7           |
| Data-EnvTrajs-MaxReturn | 32.5           |
| Data-EnvTrajs-MinReturn | 25.3           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.63           |
| Data-TimeEnvSampleProc  | 0.00118        |
| Data-TimeEnvSampling    | 1.77           |
| Iteration               | 20             |
| ItrTime                 | 32.6           |
| LossAfter               | -0.003327843   |
| LossBefore              | -1.0399001e-05 |
| Model-TimeModelFit      | 28.6           |
| ModelSampler-n_times... | 840000         |
| Policy-AverageAbsPol... | 0.6013992      |
| Policy-AverageDiscou... | 23.2           |
| Policy-AveragePolicyStd | 0.68600893     |
| Policy-AverageReturn    | 32.6           |
| Policy-MaxReturn        | 36.3           |
| Policy-MinReturn        | 25.7           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.67           |
| Policy-TimeAlgoOpt      | 0.554          |
| Policy-TimeSampleProc   | 0.328          |
| Policy-TimeSampling     | 1.38           |
| Policy-TimeStep         | 2.29           |
| Time                    | 570            |
| n_timesteps             | 21000          |
--------------------------------------------

 ---------------- Iteration 21 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 210 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 211 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 212 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 213 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 214 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 215 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 216 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 217 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 218 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 219 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.4           |
| Data-EnvSampler-Poli... | 0.809         |
| Data-EnvTrajs-Averag... | 29.8          |
| Data-EnvTrajs-MaxReturn | 32.5          |
| Data-EnvTrajs-MinReturn | 26            |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 2.77          |
| Data-TimeEnvSampleProc  | 0.00105       |
| Data-TimeEnvSampling    | 1.24          |
| Iteration               | 21            |
| ItrTime                 | 40.3          |
| LossAfter               | -0.0047184746 |
| LossBefore              | -1.006511e-05 |
| Model-TimeModelFit      | 35.4          |
| ModelSampler-n_times... | 880000        |
| Policy-AverageAbsPol... | 0.7565827     |
| Policy-AverageDiscou... | 32            |
| Policy-AveragePolicyStd | 0.6634856     |
| Policy-AverageReturn    | 40.9          |
| Policy-MaxReturn        | 52.3          |
| Policy-MinReturn        | 30.3          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 5.73          |
| Policy-TimeAlgoOpt      | 0.717         |
| Policy-TimeSampleProc   | 0.766         |
| Policy-TimeSampling     | 2.21          |
| Policy-TimeStep         | 3.73          |
| Time                    | 610           |
| n_timesteps             | 22000         |
-------------------------------------------

 ---------------- Iteration 22 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 220 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 221 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 222 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 223 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 224 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 225 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 226 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 227 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 228 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 229 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.605         |
| Data-EnvSampler-Poli... | 1.23          |
| Data-EnvTrajs-Averag... | 32.6          |
| Data-EnvTrajs-MaxReturn | 37.3          |
| Data-EnvTrajs-MinReturn | 30.6          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 2.65          |
| Data-TimeEnvSampleProc  | 0.00109       |
| Data-TimeEnvSampling    | 1.89          |
| Iteration               | 22            |
| ItrTime                 | 28.6          |
| LossAfter               | -0.0053012106 |
| LossBefore              | -9.898443e-06 |
| Model-TimeModelFit      | 24.5          |
| ModelSampler-n_times... | 920000        |
| Policy-AverageAbsPol... | 0.710517      |
| Policy-AverageDiscou... | 27.7          |
| Policy-AveragePolicyStd | 0.6532008     |
| Policy-AverageReturn    | 27.8          |
| Policy-MaxReturn        | 35.6          |
| Policy-MinReturn        | 19.5          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 3.79          |
| Policy-TimeAlgoOpt      | 0.455         |
| Policy-TimeSampleProc   | 0.345         |
| Policy-TimeSampling     | 1.38          |
| Policy-TimeStep         | 2.23          |
| Time                    | 639           |
| n_timesteps             | 23000         |
-------------------------------------------

 ---------------- Iteration 23 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 230 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 231 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 232 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 233 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 234 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 235 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 236 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 237 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 238 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 239 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.479         |
| Data-EnvSampler-Poli... | 1.05          |
| Data-EnvTrajs-Averag... | 32.2          |
| Data-EnvTrajs-MaxReturn | 34.4          |
| Data-EnvTrajs-MinReturn | 29.9          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.77          |
| Data-TimeEnvSampleProc  | 0.0017        |
| Data-TimeEnvSampling    | 1.58          |
| Iteration               | 23            |
| ItrTime                 | 40.7          |
| LossAfter               | -0.0024214012 |
| LossBefore              | -9.89519e-06  |
| Model-TimeModelFit      | 36.9          |
| ModelSampler-n_times... | 960000        |
| Policy-AverageAbsPol... | 0.6934555     |
| Policy-AverageDiscou... | 38.6          |
| Policy-AveragePolicyStd | 0.65379953    |
| Policy-AverageReturn    | 67.3          |
| Policy-MaxReturn        | 110           |
| Policy-MinReturn        | 52.8          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 15.9          |
| Policy-TimeAlgoOpt      | 0.483         |
| Policy-TimeSampleProc   | 0.252         |
| Policy-TimeSampling     | 1.39          |
| Policy-TimeStep         | 2.17          |
| Time                    | 679           |
| n_timesteps             | 24000         |
-------------------------------------------

 ---------------- Iteration 24 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 240 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 241 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 242 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 243 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 244 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 245 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 246 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 247 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 248 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 249 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.353         |
| Data-EnvSampler-Poli... | 0.804         |
| Data-EnvTrajs-Averag... | 32.7          |
| Data-EnvTrajs-MaxReturn | 35.6          |
| Data-EnvTrajs-MinReturn | 28.7          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 2.68          |
| Data-TimeEnvSampleProc  | 0.00126       |
| Data-TimeEnvSampling    | 1.19          |
| Iteration               | 24            |
| ItrTime                 | 34.7          |
| LossAfter               | -0.0019763182 |
| LossBefore              | -9.623015e-06 |
| Model-TimeModelFit      | 29.9          |
| ModelSampler-n_times... | 1000000       |
| Policy-AverageAbsPol... | 0.8362167     |
| Policy-AverageDiscou... | 40.6          |
| Policy-AveragePolicyStd | 0.63719803    |
| Policy-AverageReturn    | 76.8          |
| Policy-MaxReturn        | 93.3          |
| Policy-MinReturn        | 52.9          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 12.1          |
| Policy-TimeAlgoOpt      | 0.789         |
| Policy-TimeSampleProc   | 0.599         |
| Policy-TimeSampling     | 2.26          |
| Policy-TimeStep         | 3.67          |
| Time                    | 714           |
| n_timesteps             | 25000         |
-------------------------------------------

 ---------------- Iteration 25 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 250 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 251 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 252 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 253 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 254 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 255 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 256 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 257 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 258 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 259 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.598         |
| Data-EnvSampler-Poli... | 1.24          |
| Data-EnvTrajs-Averag... | 35.1          |
| Data-EnvTrajs-MaxReturn | 36.6          |
| Data-EnvTrajs-MinReturn | 32.9          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.41          |
| Data-TimeEnvSampleProc  | 0.00127       |
| Data-TimeEnvSampling    | 1.89          |
| Iteration               | 25            |
| ItrTime                 | 34.4          |
| LossAfter               | -0.0022171636 |
| LossBefore              | -9.600412e-06 |
| Model-TimeModelFit      | 30.3          |
| ModelSampler-n_times... | 1040000       |
| Policy-AverageAbsPol... | 0.9234434     |
| Policy-AverageDiscou... | 40.2          |
| Policy-AveragePolicyStd | 0.6335326     |
| Policy-AverageReturn    | 59            |
| Policy-MaxReturn        | 68.7          |
| Policy-MinReturn        | 37.1          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 6.62          |
| Policy-TimeAlgoOpt      | 0.526         |
| Policy-TimeSampleProc   | 0.297         |
| Policy-TimeSampling     | 1.32          |
| Policy-TimeStep         | 2.19          |
| Time                    | 749           |
| n_timesteps             | 26000         |
-------------------------------------------

 ---------------- Iteration 26 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 260 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 261 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 262 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 263 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 264 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 265 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 266 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 267 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 268 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 269 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.355         |
| Data-EnvSampler-Poli... | 0.844         |
| Data-EnvTrajs-Averag... | 34.9          |
| Data-EnvTrajs-MaxReturn | 36.8          |
| Data-EnvTrajs-MinReturn | 32.7          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.49          |
| Data-TimeEnvSampleProc  | 0.000971      |
| Data-TimeEnvSampling    | 1.23          |
| Iteration               | 26            |
| ItrTime                 | 41.2          |
| LossAfter               | -0.0024066865 |
| LossBefore              | -9.061265e-06 |
| Model-TimeModelFit      | 36.2          |
| ModelSampler-n_times... | 1080000       |
| Policy-AverageAbsPol... | 0.9802184     |
| Policy-AverageDiscou... | 20.5          |
| Policy-AveragePolicyStd | 0.6009647     |
| Policy-AverageReturn    | 13.1          |
| Policy-MaxReturn        | 27.1          |
| Policy-MinReturn        | 4.52          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 6.26          |
| Policy-TimeAlgoOpt      | 0.746         |
| Policy-TimeSampleProc   | 0.581         |
| Policy-TimeSampling     | 2.41          |
| Policy-TimeStep         | 3.79          |
| Time                    | 790           |
| n_timesteps             | 27000         |
-------------------------------------------

 ---------------- Iteration 27 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 270 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 271 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 272 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 273 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 274 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 275 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 276 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 277 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 278 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 279 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.572         |
| Data-EnvSampler-Poli... | 1.2           |
| Data-EnvTrajs-Averag... | 34.7          |
| Data-EnvTrajs-MaxReturn | 37.3          |
| Data-EnvTrajs-MinReturn | 33.5          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.44          |
| Data-TimeEnvSampleProc  | 0.00143       |
| Data-TimeEnvSampling    | 1.82          |
| Iteration               | 27            |
| ItrTime                 | 29.6          |
| LossAfter               | -0.0031801015 |
| LossBefore              | -8.958205e-06 |
| Model-TimeModelFit      | 25.5          |
| ModelSampler-n_times... | 1120000       |
| Policy-AverageAbsPol... | 0.7473133     |
| Policy-AverageDiscou... | 31.3          |
| Policy-AveragePolicyStd | 0.59520715    |
| Policy-AverageReturn    | 55.1          |
| Policy-MaxReturn        | 59.8          |
| Policy-MinReturn        | 51            |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 2.3           |
| Policy-TimeAlgoOpt      | 0.529         |
| Policy-TimeSampleProc   | 0.28          |
| Policy-TimeSampling     | 1.4           |
| Policy-TimeStep         | 2.24          |
| Time                    | 819           |
| n_timesteps             | 28000         |
-------------------------------------------

 ---------------- Iteration 28 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 280 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 281 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 282 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 283 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 284 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 285 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 286 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 287 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 288 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 289 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.531         |
| Data-EnvSampler-Poli... | 1.09          |
| Data-EnvTrajs-Averag... | 35.4          |
| Data-EnvTrajs-MaxReturn | 37.3          |
| Data-EnvTrajs-MinReturn | 33.9          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.13          |
| Data-TimeEnvSampleProc  | 0.0014        |
| Data-TimeEnvSampling    | 1.67          |
| Iteration               | 28            |
| ItrTime                 | 42.7          |
| LossAfter               | -0.0069723576 |
| LossBefore              | -8.732954e-06 |
| Model-TimeModelFit      | 38.9          |
| ModelSampler-n_times... | 1160000       |
| Policy-AverageAbsPol... | 1.042947      |
| Policy-AverageDiscou... | 20.1          |
| Policy-AveragePolicyStd | 0.5823484     |
| Policy-AverageReturn    | 21.6          |
| Policy-MaxReturn        | 25.9          |
| Policy-MinReturn        | 16.5          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 2.17          |
| Policy-TimeAlgoOpt      | 0.464         |
| Policy-TimeSampleProc   | 0.312         |
| Policy-TimeSampling     | 1.33          |
| Policy-TimeStep         | 2.13          |
| Time                    | 862           |
| n_timesteps             | 29000         |
-------------------------------------------

 ---------------- Iteration 29 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 290 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 291 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 292 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 293 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 294 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 295 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 296 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 297 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 298 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 299 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.34          |
| Data-EnvSampler-Poli... | 0.78          |
| Data-EnvTrajs-Averag... | 36.1          |
| Data-EnvTrajs-MaxReturn | 38.5          |
| Data-EnvTrajs-MinReturn | 34.3          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.58          |
| Data-TimeEnvSampleProc  | 0.000734      |
| Data-TimeEnvSampling    | 1.15          |
| Iteration               | 29            |
| ItrTime                 | 33.9          |
| LossAfter               | -0.0013228562 |
| LossBefore              | -8.360097e-06 |
| Model-TimeModelFit      | 29.1          |
| ModelSampler-n_times... | 1200000       |
| Policy-AverageAbsPol... | 1.0496708     |
| Policy-AverageDiscou... | 30.5          |
| Policy-AveragePolicyStd | 0.56113917    |
| Policy-AverageReturn    | 52.8          |
| Policy-MaxReturn        | 63.6          |
| Policy-MinReturn        | 47.8          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 4.07          |
| Policy-TimeAlgoOpt      | 0.771         |
| Policy-TimeSampleProc   | 0.573         |
| Policy-TimeSampling     | 2.26          |
| Policy-TimeStep         | 3.63          |
| Time                    | 896           |
| n_timesteps             | 30000         |
-------------------------------------------

 ---------------- Iteration 30 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 300 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 301 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 302 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 303 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 304 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 305 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 306 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 307 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 308 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 309 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.549          |
| Data-EnvSampler-Poli... | 1.23           |
| Data-EnvTrajs-Averag... | 36.5           |
| Data-EnvTrajs-MaxReturn | 37.7           |
| Data-EnvTrajs-MinReturn | 34.6           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.12           |
| Data-TimeEnvSampleProc  | 0.00141        |
| Data-TimeEnvSampling    | 1.82           |
| Iteration               | 30             |
| ItrTime                 | 32.1           |
| LossAfter               | -0.00079025404 |
| LossBefore              | -7.989798e-06  |
| Model-TimeModelFit      | 28             |
| ModelSampler-n_times... | 1240000        |
| Policy-AverageAbsPol... | 1.1663228      |
| Policy-AverageDiscou... | 29.4           |
| Policy-AveragePolicyStd | 0.5395358      |
| Policy-AverageReturn    | 42.1           |
| Policy-MaxReturn        | 45.3           |
| Policy-MinReturn        | 40             |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.37           |
| Policy-TimeAlgoOpt      | 0.517          |
| Policy-TimeSampleProc   | 0.422          |
| Policy-TimeSampling     | 1.34           |
| Policy-TimeStep         | 2.31           |
| Time                    | 928            |
| n_timesteps             | 31000          |
--------------------------------------------

 ---------------- Iteration 31 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 310 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 311 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 312 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 313 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 314 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 315 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 316 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 317 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 318 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 319 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.365         |
| Data-EnvSampler-Poli... | 0.817         |
| Data-EnvTrajs-Averag... | 37.3          |
| Data-EnvTrajs-MaxReturn | 39            |
| Data-EnvTrajs-MinReturn | 36.5          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 0.895         |
| Data-TimeEnvSampleProc  | 0.00102       |
| Data-TimeEnvSampling    | 1.22          |
| Iteration               | 31            |
| ItrTime                 | 43.3          |
| LossAfter               | -0.004570511  |
| LossBefore              | -7.653369e-06 |
| Model-TimeModelFit      | 39.9          |
| ModelSampler-n_times... | 1280000       |
| Policy-AverageAbsPol... | 1.1946023     |
| Policy-AverageDiscou... | 24.7          |
| Policy-AveragePolicyStd | 0.52343446    |
| Policy-AverageReturn    | 31.7          |
| Policy-MaxReturn        | 35.4          |
| Policy-MinReturn        | 29.1          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.69          |
| Policy-TimeAlgoOpt      | 0.541         |
| Policy-TimeSampleProc   | 0.29          |
| Policy-TimeSampling     | 1.3           |
| Policy-TimeStep         | 2.18          |
| Time                    | 971           |
| n_timesteps             | 32000         |
-------------------------------------------

 ---------------- Iteration 32 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 320 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 321 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 322 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 323 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 324 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 325 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 326 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 327 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 328 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 329 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.333          |
| Data-EnvSampler-Poli... | 0.761          |
| Data-EnvTrajs-Averag... | 36.7           |
| Data-EnvTrajs-MaxReturn | 38.2           |
| Data-EnvTrajs-MinReturn | 35.5           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 0.909          |
| Data-TimeEnvSampleProc  | 0.000966       |
| Data-TimeEnvSampling    | 1.13           |
| Iteration               | 32             |
| ItrTime                 | 33.8           |
| LossAfter               | -0.0021663788  |
| LossBefore              | -7.3480637e-06 |
| Model-TimeModelFit      | 28.7           |
| ModelSampler-n_times... | 1320000        |
| Policy-AverageAbsPol... | 1.2006407      |
| Policy-AverageDiscou... | 18.1           |
| Policy-AveragePolicyStd | 0.5072958      |
| Policy-AverageReturn    | 13.4           |
| Policy-MaxReturn        | 18             |
| Policy-MinReturn        | 8.86           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.61           |
| Policy-TimeAlgoOpt      | 0.757          |
| Policy-TimeSampleProc   | 0.922          |
| Policy-TimeSampling     | 2.27           |
| Policy-TimeStep         | 3.97           |
| Time                    | 1.01e+03       |
| n_timesteps             | 33000          |
--------------------------------------------

 ---------------- Iteration 33 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 330 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 331 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 332 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 333 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 334 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 335 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 336 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 337 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 338 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 339 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.592         |
| Data-EnvSampler-Poli... | 1.32          |
| Data-EnvTrajs-Averag... | 37.4          |
| Data-EnvTrajs-MaxReturn | 38.4          |
| Data-EnvTrajs-MinReturn | 36.5          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 0.684         |
| Data-TimeEnvSampleProc  | 0.00131       |
| Data-TimeEnvSampling    | 1.98          |
| Iteration               | 33            |
| ItrTime                 | 45.5          |
| LossAfter               | -0.0026020813 |
| LossBefore              | -7.228473e-06 |
| Model-TimeModelFit      | 40.1          |
| ModelSampler-n_times... | 1360000       |
| Policy-AverageAbsPol... | 1.1443398     |
| Policy-AverageDiscou... | 28            |
| Policy-AveragePolicyStd | 0.5032051     |
| Policy-AverageReturn    | 44.6          |
| Policy-MaxReturn        | 47.4          |
| Policy-MinReturn        | 41.9          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.7           |
| Policy-TimeAlgoOpt      | 0.758         |
| Policy-TimeSampleProc   | 0.496         |
| Policy-TimeSampling     | 2.17          |
| Policy-TimeStep         | 3.46          |
| Time                    | 1.05e+03      |
| n_timesteps             | 34000         |
-------------------------------------------

 ---------------- Iteration 34 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 340 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 341 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 342 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 343 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 344 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 345 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 346 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 347 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 348 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 349 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.554          |
| Data-EnvSampler-Poli... | 1.17           |
| Data-EnvTrajs-Averag... | 37             |
| Data-EnvTrajs-MaxReturn | 38.8           |
| Data-EnvTrajs-MinReturn | 35.3           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.33           |
| Data-TimeEnvSampleProc  | 0.000839       |
| Data-TimeEnvSampling    | 1.78           |
| Iteration               | 34             |
| ItrTime                 | 31.5           |
| LossAfter               | 0.011628698    |
| LossBefore              | -7.0232722e-06 |
| Model-TimeModelFit      | 26.1           |
| ModelSampler-n_times... | 1400000        |
| Policy-AverageAbsPol... | 1.3135098      |
| Policy-AverageDiscou... | 36.1           |
| Policy-AveragePolicyStd | 0.49309206     |
| Policy-AverageReturn    | 67.1           |
| Policy-MaxReturn        | 73             |
| Policy-MinReturn        | 58.7           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 3.68           |
| Policy-TimeAlgoOpt      | 0.736          |
| Policy-TimeSampleProc   | 0.62           |
| Policy-TimeSampling     | 2.23           |
| Policy-TimeStep         | 3.63           |
| Time                    | 1.08e+03       |
| n_timesteps             | 35000          |
--------------------------------------------

 ---------------- Iteration 35 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 350 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 351 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 352 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 353 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 354 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 355 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 356 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 357 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 358 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 359 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.579          |
| Data-EnvSampler-Poli... | 1.28           |
| Data-EnvTrajs-Averag... | 36.9           |
| Data-EnvTrajs-MaxReturn | 39.3           |
| Data-EnvTrajs-MinReturn | 35.1           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.75           |
| Data-TimeEnvSampleProc  | 0.00141        |
| Data-TimeEnvSampling    | 1.91           |
| Iteration               | 35             |
| ItrTime                 | 40.7           |
| LossAfter               | -0.0025130927  |
| LossBefore              | -6.6269886e-06 |
| Model-TimeModelFit      | 36.6           |
| ModelSampler-n_times... | 1440000        |
| Policy-AverageAbsPol... | 1.0719575      |
| Policy-AverageDiscou... | 26.3           |
| Policy-AveragePolicyStd | 0.47234097     |
| Policy-AverageReturn    | 35.6           |
| Policy-MaxReturn        | 37.6           |
| Policy-MinReturn        | 30.9           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.79           |
| Policy-TimeAlgoOpt      | 0.516          |
| Policy-TimeSampleProc   | 0.31           |
| Policy-TimeSampling     | 1.33           |
| Policy-TimeStep         | 2.18           |
| Time                    | 1.12e+03       |
| n_timesteps             | 36000          |
--------------------------------------------

 ---------------- Iteration 36 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 360 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 361 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 362 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 363 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 364 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 365 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 366 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 367 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 368 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 369 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.329          |
| Data-EnvSampler-Poli... | 0.763          |
| Data-EnvTrajs-Averag... | 39.6           |
| Data-EnvTrajs-MaxReturn | 42.4           |
| Data-EnvTrajs-MinReturn | 38.1           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.56           |
| Data-TimeEnvSampleProc  | 0.000799       |
| Data-TimeEnvSampling    | 1.12           |
| Iteration               | 36             |
| ItrTime                 | 38.6           |
| LossAfter               | -0.0028091888  |
| LossBefore              | -6.1302194e-06 |
| Model-TimeModelFit      | 33.7           |
| ModelSampler-n_times... | 1480000        |
| Policy-AverageAbsPol... | 1.0166696      |
| Policy-AverageDiscou... | 31.5           |
| Policy-AveragePolicyStd | 0.44969183     |
| Policy-AverageReturn    | 49.7           |
| Policy-MaxReturn        | 54.9           |
| Policy-MinReturn        | 46.4           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.19           |
| Policy-TimeAlgoOpt      | 0.796          |
| Policy-TimeSampleProc   | 0.655          |
| Policy-TimeSampling     | 2.24           |
| Policy-TimeStep         | 3.73           |
| Time                    | 1.16e+03       |
| n_timesteps             | 37000          |
--------------------------------------------

 ---------------- Iteration 37 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 370 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 371 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 372 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 373 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 374 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 375 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 376 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 377 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 378 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 379 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.567         |
| Data-EnvSampler-Poli... | 1.32          |
| Data-EnvTrajs-Averag... | 38.5          |
| Data-EnvTrajs-MaxReturn | 40.5          |
| Data-EnvTrajs-MinReturn | 35.7          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 1.61          |
| Data-TimeEnvSampleProc  | 0.00144       |
| Data-TimeEnvSampling    | 1.94          |
| Iteration               | 37            |
| ItrTime                 | 40.2          |
| LossAfter               | -0.0045761443 |
| LossBefore              | -5.826388e-06 |
| Model-TimeModelFit      | 36            |
| ModelSampler-n_times... | 1520000       |
| Policy-AverageAbsPol... | 1.2284853     |
| Policy-AverageDiscou... | 30.8          |
| Policy-AveragePolicyStd | 0.43554437    |
| Policy-AverageReturn    | 47.1          |
| Policy-MaxReturn        | 51.3          |
| Policy-MinReturn        | 44.3          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.72          |
| Policy-TimeAlgoOpt      | 0.453         |
| Policy-TimeSampleProc   | 0.474         |
| Policy-TimeSampling     | 1.3           |
| Policy-TimeStep         | 2.29          |
| Time                    | 1.2e+03       |
| n_timesteps             | 38000         |
-------------------------------------------

 ---------------- Iteration 38 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 380 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 381 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 382 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 383 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 384 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 385 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 386 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 387 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 388 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 389 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.345         |
| Data-EnvSampler-Poli... | 0.763         |
| Data-EnvTrajs-Averag... | 37.9          |
| Data-EnvTrajs-MaxReturn | 39.1          |
| Data-EnvTrajs-MinReturn | 36.5          |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 0.971         |
| Data-TimeEnvSampleProc  | 0.000531      |
| Data-TimeEnvSampling    | 1.14          |
| Iteration               | 38            |
| ItrTime                 | 37.9          |
| LossAfter               | -0.0026702816 |
| LossBefore              | -5.316776e-06 |
| Model-TimeModelFit      | 33            |
| ModelSampler-n_times... | 1560000       |
| Policy-AverageAbsPol... | 1.1735137     |
| Policy-AverageDiscou... | 24.7          |
| Policy-AveragePolicyStd | 0.41384864    |
| Policy-AverageReturn    | 34.2          |
| Policy-MaxReturn        | 38.9          |
| Policy-MinReturn        | 29.3          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 3.11          |
| Policy-TimeAlgoOpt      | 0.742         |
| Policy-TimeSampleProc   | 0.709         |
| Policy-TimeSampling     | 2.27          |
| Policy-TimeStep         | 3.77          |
| Time                    | 1.24e+03      |
| n_timesteps             | 39000         |
-------------------------------------------

 ---------------- Iteration 39 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 390 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 391 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 392 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 393 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 394 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 395 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 396 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 397 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 398 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 399 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.573          |
| Data-EnvSampler-Poli... | 1.23           |
| Data-EnvTrajs-Averag... | 38.9           |
| Data-EnvTrajs-MaxReturn | 42.1           |
| Data-EnvTrajs-MinReturn | 35.1           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 2.39           |
| Data-TimeEnvSampleProc  | 0.00152        |
| Data-TimeEnvSampling    | 1.85           |
| Iteration               | 39             |
| ItrTime                 | 33.6           |
| LossAfter               | 0.015283901    |
| LossBefore              | -4.8402585e-06 |
| Model-TimeModelFit      | 29.5           |
| ModelSampler-n_times... | 1600000        |
| Policy-AverageAbsPol... | 1.2230778      |
| Policy-AverageDiscou... | 31.2           |
| Policy-AveragePolicyStd | 0.3950896      |
| Policy-AverageReturn    | 47.8           |
| Policy-MaxReturn        | 63.2           |
| Policy-MinReturn        | 41             |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 5.22           |
| Policy-TimeAlgoOpt      | 0.519          |
| Policy-TimeSampleProc   | 0.31           |
| Policy-TimeSampling     | 1.41           |
| Policy-TimeStep         | 2.26           |
| Time                    | 1.27e+03       |
| n_timesteps             | 40000          |
--------------------------------------------

 ---------------- Iteration 40 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 400 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 401 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 402 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 403 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 404 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 405 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 406 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 407 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 408 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 409 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.37           |
| Data-EnvSampler-Poli... | 0.808          |
| Data-EnvTrajs-Averag... | 38.8           |
| Data-EnvTrajs-MaxReturn | 41.2           |
| Data-EnvTrajs-MinReturn | 37.1           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.45           |
| Data-TimeEnvSampleProc  | 0.000964       |
| Data-TimeEnvSampling    | 1.21           |
| Iteration               | 40             |
| ItrTime                 | 44.1           |
| LossAfter               | -0.0011411404  |
| LossBefore              | -4.7466256e-06 |
| Model-TimeModelFit      | 40.7           |
| ModelSampler-n_times... | 1640000        |
| Policy-AverageAbsPol... | 1.2903718      |
| Policy-AverageDiscou... | 28.2           |
| Policy-AveragePolicyStd | 0.39177778     |
| Policy-AverageReturn    | 41             |
| Policy-MaxReturn        | 44.6           |
| Policy-MinReturn        | 35.9           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.21           |
| Policy-TimeAlgoOpt      | 0.526          |
| Policy-TimeSampleProc   | 0.279          |
| Policy-TimeSampling     | 1.33           |
| Policy-TimeStep         | 2.15           |
| Time                    | 1.32e+03       |
| n_timesteps             | 41000          |
--------------------------------------------

 ---------------- Iteration 41 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 410 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 411 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 412 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 413 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 414 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 415 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 416 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 417 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 418 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 419 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.322          |
| Data-EnvSampler-Poli... | 0.74           |
| Data-EnvTrajs-Averag... | 39.2           |
| Data-EnvTrajs-MaxReturn | 41.1           |
| Data-EnvTrajs-MinReturn | 36.7           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.64           |
| Data-TimeEnvSampleProc  | 0.0008         |
| Data-TimeEnvSampling    | 1.09           |
| Iteration               | 41             |
| ItrTime                 | 35.6           |
| LossAfter               | -0.0028002106  |
| LossBefore              | -4.3601967e-06 |
| Model-TimeModelFit      | 30.7           |
| ModelSampler-n_times... | 1680000        |
| Policy-AverageAbsPol... | 1.268094       |
| Policy-AverageDiscou... | 28.4           |
| Policy-AveragePolicyStd | 0.37871546     |
| Policy-AverageReturn    | 33.9           |
| Policy-MaxReturn        | 38.3           |
| Policy-MinReturn        | 26.9           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 3.06           |
| Policy-TimeAlgoOpt      | 0.763          |
| Policy-TimeSampleProc   | 0.69           |
| Policy-TimeSampling     | 2.39           |
| Policy-TimeStep         | 3.87           |
| Time                    | 1.35e+03       |
| n_timesteps             | 42000          |
--------------------------------------------

 ---------------- Iteration 42 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 420 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 421 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 422 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 423 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 424 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 425 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 426 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 427 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 428 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 429 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.566          |
| Data-EnvSampler-Poli... | 1.29           |
| Data-EnvTrajs-Averag... | 38.4           |
| Data-EnvTrajs-MaxReturn | 40             |
| Data-EnvTrajs-MinReturn | 36.6           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.11           |
| Data-TimeEnvSampleProc  | 0.00131        |
| Data-TimeEnvSampling    | 1.91           |
| Iteration               | 42             |
| ItrTime                 | 39.1           |
| LossAfter               | -0.0014639595  |
| LossBefore              | -4.1915164e-06 |
| Model-TimeModelFit      | 34.7           |
| ModelSampler-n_times... | 1720000        |
| Policy-AverageAbsPol... | 1.1085186      |
| Policy-AverageDiscou... | 26.7           |
| Policy-AveragePolicyStd | 0.3736071      |
| Policy-AverageReturn    | 34.9           |
| Policy-MaxReturn        | 37.6           |
| Policy-MinReturn        | 30.2           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.88           |
| Policy-TimeAlgoOpt      | 0.481          |
| Policy-TimeSampleProc   | 0.429          |
| Policy-TimeSampling     | 1.55           |
| Policy-TimeStep         | 2.52           |
| Time                    | 1.39e+03       |
| n_timesteps             | 43000          |
--------------------------------------------

 ---------------- Iteration 43 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 430 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 431 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 432 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 433 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 434 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 435 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 436 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 437 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 438 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 439 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.353          |
| Data-EnvSampler-Poli... | 0.858          |
| Data-EnvTrajs-Averag... | 38.1           |
| Data-EnvTrajs-MaxReturn | 40.8           |
| Data-EnvTrajs-MinReturn | 34.8           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.97           |
| Data-TimeEnvSampleProc  | 0.000918       |
| Data-TimeEnvSampling    | 1.24           |
| Iteration               | 43             |
| ItrTime                 | 44.1           |
| LossAfter               | 0.01655762     |
| LossBefore              | -4.1307317e-06 |
| Model-TimeModelFit      | 39.1           |
| ModelSampler-n_times... | 1760000        |
| Policy-AverageAbsPol... | 1.0205636      |
| Policy-AverageDiscou... | 25.3           |
| Policy-AveragePolicyStd | 0.37006712     |
| Policy-AverageReturn    | 33.2           |
| Policy-MaxReturn        | 42.1           |
| Policy-MinReturn        | 28.2           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 4.09           |
| Policy-TimeAlgoOpt      | 0.823          |
| Policy-TimeSampleProc   | 0.576          |
| Policy-TimeSampling     | 2.36           |
| Policy-TimeStep         | 3.79           |
| Time                    | 1.44e+03       |
| n_timesteps             | 44000          |
--------------------------------------------

 ---------------- Iteration 44 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 440 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 441 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 442 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 443 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 444 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 445 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 446 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 447 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 448 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 449 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.656          |
| Data-EnvSampler-Poli... | 1.36           |
| Data-EnvTrajs-Averag... | 38.5           |
| Data-EnvTrajs-MaxReturn | 39.9           |
| Data-EnvTrajs-MinReturn | 36.5           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.23           |
| Data-TimeEnvSampleProc  | 0.00101        |
| Data-TimeEnvSampling    | 2.07           |
| Iteration               | 44             |
| ItrTime                 | 53.7           |
| LossAfter               | -0.00204093    |
| LossBefore              | -4.1243657e-06 |
| Model-TimeModelFit      | 47.3           |
| ModelSampler-n_times... | 1800000        |
| Policy-AverageAbsPol... | 0.9461042      |
| Policy-AverageDiscou... | 28             |
| Policy-AveragePolicyStd | 0.36912936     |
| Policy-AverageReturn    | 35.6           |
| Policy-MaxReturn        | 40.1           |
| Policy-MinReturn        | 32.7           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.98           |
| Policy-TimeAlgoOpt      | 0.898          |
| Policy-TimeSampleProc   | 0.827          |
| Policy-TimeSampling     | 2.6            |
| Policy-TimeStep         | 4.34           |
| Time                    | 1.49e+03       |
| n_timesteps             | 45000          |
--------------------------------------------

 ---------------- Iteration 45 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 450 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 451 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 452 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 453 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 454 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 455 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 456 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 457 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 458 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 459 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.683          |
| Data-EnvSampler-Poli... | 1.47           |
| Data-EnvTrajs-Averag... | 37.8           |
| Data-EnvTrajs-MaxReturn | 40.7           |
| Data-EnvTrajs-MinReturn | 35.6           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.68           |
| Data-TimeEnvSampleProc  | 0.00148        |
| Data-TimeEnvSampling    | 2.21           |
| Iteration               | 45             |
| ItrTime                 | 48.7           |
| LossAfter               | -0.00067399535 |
| LossBefore              | -4.1771364e-06 |
| Model-TimeModelFit      | 44.2           |
| ModelSampler-n_times... | 1840000        |
| Policy-AverageAbsPol... | 0.84207326     |
| Policy-AverageDiscou... | 32.3           |
| Policy-AveragePolicyStd | 0.37265858     |
| Policy-AverageReturn    | 48.7           |
| Policy-MaxReturn        | 53.8           |
| Policy-MinReturn        | 43.4           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.74           |
| Policy-TimeAlgoOpt      | 0.544          |
| Policy-TimeSampleProc   | 0.323          |
| Policy-TimeSampling     | 1.44           |
| Policy-TimeStep         | 2.32           |
| Time                    | 1.54e+03       |
| n_timesteps             | 46000          |
--------------------------------------------

 ---------------- Iteration 46 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 460 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 461 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 462 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 463 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 464 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 465 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 466 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 467 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 468 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 469 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.365          |
| Data-EnvSampler-Poli... | 0.787          |
| Data-EnvTrajs-Averag... | 38.7           |
| Data-EnvTrajs-MaxReturn | 41.6           |
| Data-EnvTrajs-MinReturn | 36.5           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.68           |
| Data-TimeEnvSampleProc  | 0.00092        |
| Data-TimeEnvSampling    | 1.18           |
| Iteration               | 46             |
| ItrTime                 | 40.2           |
| LossAfter               | -0.0013312444  |
| LossBefore              | -3.8932826e-06 |
| Model-TimeModelFit      | 34.2           |
| ModelSampler-n_times... | 1880000        |
| Policy-AverageAbsPol... | 0.7952325      |
| Policy-AverageDiscou... | 12.8           |
| Policy-AveragePolicyStd | 0.36339098     |
| Policy-AverageReturn    | -69.7          |
| Policy-MaxReturn        | 51.6           |
| Policy-MinReturn        | -2.32e+03      |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 516            |
| Policy-TimeAlgoOpt      | 0.857          |
| Policy-TimeSampleProc   | 1.02           |
| Policy-TimeSampling     | 2.83           |
| Policy-TimeStep         | 4.81           |
| Time                    | 1.58e+03       |
| n_timesteps             | 47000          |
--------------------------------------------

 ---------------- Iteration 47 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 470 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 471 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 472 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 473 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 474 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 475 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 476 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 477 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 478 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 479 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Data-EnvSampler-EnvE... | 0.667        |
| Data-EnvSampler-Poli... | 1.43         |
| Data-EnvTrajs-Averag... | 38.6         |
| Data-EnvTrajs-MaxReturn | 39.5         |
| Data-EnvTrajs-MinReturn | 36.6         |
| Data-EnvTrajs-NumTrajs  | 5            |
| Data-EnvTrajs-StdReturn | 1.02         |
| Data-TimeEnvSampleProc  | 0.00147      |
| Data-TimeEnvSampling    | 2.16         |
| Iteration               | 47           |
| ItrTime                 | 54.8         |
| LossAfter               | -0.002323158 |
| LossBefore              | -4.07148e-06 |
| Model-TimeModelFit      | 48.6         |
| ModelSampler-n_times... | 1920000      |
| Policy-AverageAbsPol... | 0.74157465   |
| Policy-AverageDiscou... | 27.9         |
| Policy-AveragePolicyStd | 0.36941886   |
| Policy-AverageReturn    | 40.1         |
| Policy-MaxReturn        | 46.5         |
| Policy-MinReturn        | 33.8         |
| Policy-NumTrajs         | 20           |
| Policy-StdReturn        | 3.54         |
| Policy-TimeAlgoOpt      | 0.829        |
| Policy-TimeSampleProc   | 0.666        |
| Policy-TimeSampling     | 2.54         |
| Policy-TimeStep         | 4.07         |
| Time                    | 1.63e+03     |
| n_timesteps             | 48000        |
------------------------------------------

 ---------------- Iteration 48 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 480 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 481 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 482 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 483 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 484 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 485 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 486 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 487 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 488 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 489 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Data-EnvSampler-EnvE... | 0.798         |
| Data-EnvSampler-Poli... | 1.73          |
| Data-EnvTrajs-Averag... | 37.2          |
| Data-EnvTrajs-MaxReturn | 38.3          |
| Data-EnvTrajs-MinReturn | 36            |
| Data-EnvTrajs-NumTrajs  | 5             |
| Data-EnvTrajs-StdReturn | 0.894         |
| Data-TimeEnvSampleProc  | 0.00141       |
| Data-TimeEnvSampling    | 2.61          |
| Iteration               | 48            |
| ItrTime                 | 53.7          |
| LossAfter               | -0.002176929  |
| LossBefore              | -3.955078e-06 |
| Model-TimeModelFit      | 47.2          |
| ModelSampler-n_times... | 1960000       |
| Policy-AverageAbsPol... | 0.7089        |
| Policy-AverageDiscou... | 30.7          |
| Policy-AveragePolicyStd | 0.365601      |
| Policy-AverageReturn    | 44.9          |
| Policy-MaxReturn        | 48            |
| Policy-MinReturn        | 41.2          |
| Policy-NumTrajs         | 20            |
| Policy-StdReturn        | 1.71          |
| Policy-TimeAlgoOpt      | 0.808         |
| Policy-TimeSampleProc   | 0.573         |
| Policy-TimeSampling     | 2.5           |
| Policy-TimeStep         | 3.91          |
| Time                    | 1.69e+03      |
| n_timesteps             | 49000         |
-------------------------------------------

 ---------------- Iteration 49 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 490 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 491 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 492 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 493 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 494 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 495 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 496 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 497 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 498 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 499 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.613          |
| Data-EnvSampler-Poli... | 1.36           |
| Data-EnvTrajs-Averag... | 37             |
| Data-EnvTrajs-MaxReturn | 38.5           |
| Data-EnvTrajs-MinReturn | 34.7           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.34           |
| Data-TimeEnvSampleProc  | 0.00155        |
| Data-TimeEnvSampling    | 2.04           |
| Iteration               | 49             |
| ItrTime                 | 43.9           |
| LossAfter               | -0.0041485764  |
| LossBefore              | -3.4620489e-06 |
| Model-TimeModelFit      | 39.4           |
| ModelSampler-n_times... | 2000000        |
| Policy-AverageAbsPol... | 0.7346996      |
| Policy-AverageDiscou... | 30.4           |
| Policy-AveragePolicyStd | 0.34821612     |
| Policy-AverageReturn    | 45.5           |
| Policy-MaxReturn        | 48             |
| Policy-MinReturn        | 42.4           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 1.33           |
| Policy-TimeAlgoOpt      | 0.555          |
| Policy-TimeSampleProc   | 0.327          |
| Policy-TimeSampling     | 1.51           |
| Policy-TimeStep         | 2.42           |
| Time                    | 1.73e+03       |
| n_timesteps             | 50000          |
--------------------------------------------

 ---------------- Iteration 50 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 50 epochs ...

 ---------------- Grad-Step 500 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 501 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 502 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 503 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 504 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 505 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 506 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 507 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 508 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...

 ---------------- Grad-Step 509 ----------------
Obtaining samples from the model...
Processing samples from the model...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Data-EnvSampler-EnvE... | 0.369          |
| Data-EnvSampler-Poli... | 0.809          |
| Data-EnvTrajs-Averag... | 38.4           |
| Data-EnvTrajs-MaxReturn | 39.7           |
| Data-EnvTrajs-MinReturn | 35.5           |
| Data-EnvTrajs-NumTrajs  | 5              |
| Data-EnvTrajs-StdReturn | 1.49           |
| Data-TimeEnvSampleProc  | 0.000938       |
| Data-TimeEnvSampling    | 1.21           |
| Iteration               | 50             |
| ItrTime                 | 46.1           |
| LossAfter               | -0.003478645   |
| LossBefore              | -3.3765168e-06 |
| Model-TimeModelFit      | 40.8           |
| ModelSampler-n_times... | 2040000        |
| Policy-AverageAbsPol... | 0.7681749      |
| Policy-AverageDiscou... | 32.9           |
| Policy-AveragePolicyStd | 0.34399086     |
| Policy-AverageReturn    | 45.2           |
| Policy-MaxReturn        | 51.5           |
| Policy-MinReturn        | 41.5           |
| Policy-NumTrajs         | 20             |
| Policy-StdReturn        | 2.19           |
| Policy-TimeAlgoOpt      | 0.792          |
| Policy-TimeSampleProc   | 0.559          |
| Policy-TimeSampling     | 2.71           |
| Policy-TimeStep         | 4.12           |
| Time                    | 1.78e+03       |
| n_timesteps             | 51000          |
--------------------------------------------
Training finished
