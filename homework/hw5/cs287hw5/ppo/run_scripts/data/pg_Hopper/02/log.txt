Logging to /home/nin/workplace/CS287/cs287hw5/ppo/run_scripts/data/pg_Hopper/02

 ---------------- Iteration 0 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 0            |
| ItrTime                 | 28.5         |
| LossAfter               | -3.312093    |
| LossBefore              | -0.023376636 |
| Time                    | 28.5         |
| Time-Optimization       | 2.19         |
| Time-SampleProc         | 0.0614       |
| Time-Sampling           | 26.2         |
| n_timesteps             | 10000        |
| train-AverageDiscoun... | -15.2        |
| train-AverageReturn     | -41.7        |
| train-EnvExecTime       | 11.1         |
| train-MaxReturn         | 129          |
| train-MinReturn         | -211         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.4         |
| train-StdReturn         | 85.6         |
------------------------------------------

 ---------------- Iteration 1 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 1             |
| ItrTime                 | 27.3          |
| LossAfter               | -5.120926     |
| LossBefore              | -0.0006210205 |
| Time                    | 55.9          |
| Time-Optimization       | 1.59          |
| Time-SampleProc         | 0.0383        |
| Time-Sampling           | 25.6          |
| n_timesteps             | 20000         |
| train-AverageDiscoun... | 68.3          |
| train-AverageReturn     | 104           |
| train-EnvExecTime       | 10.9          |
| train-MaxReturn         | 188           |
| train-MinReturn         | -83.2         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.1          |
| train-StdReturn         | 53.7          |
-------------------------------------------

 ---------------- Iteration 2 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 2           |
| ItrTime                 | 26.8        |
| LossAfter               | -2.0595672  |
| LossBefore              | 0.025072025 |
| Time                    | 82.9        |
| Time-Optimization       | 1.56        |
| Time-SampleProc         | 0.0398      |
| Time-Sampling           | 25.2        |
| n_timesteps             | 30000       |
| train-AverageDiscoun... | 88.5        |
| train-AverageReturn     | 141         |
| train-EnvExecTime       | 10.8        |
| train-MaxReturn         | 175         |
| train-MinReturn         | -144        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 13.8        |
| train-StdReturn         | 41          |
-----------------------------------------

 ---------------- Iteration 3 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 3            |
| ItrTime                 | 26.7         |
| LossAfter               | -3.4977782   |
| LossBefore              | -0.010541421 |
| Time                    | 110          |
| Time-Optimization       | 1.31         |
| Time-SampleProc         | 0.0365       |
| Time-Sampling           | 25.3         |
| n_timesteps             | 40000        |
| train-AverageDiscoun... | 87.4         |
| train-AverageReturn     | 138          |
| train-EnvExecTime       | 10.8         |
| train-MaxReturn         | 178          |
| train-MinReturn         | 67.5         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.8         |
| train-StdReturn         | 17.6         |
------------------------------------------

 ---------------- Iteration 4 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 4           |
| ItrTime                 | 26.6        |
| LossAfter               | -6.1358376  |
| LossBefore              | 0.015854156 |
| Time                    | 136         |
| Time-Optimization       | 1.13        |
| Time-SampleProc         | 0.0366      |
| Time-Sampling           | 25.5        |
| n_timesteps             | 50000       |
| train-AverageDiscoun... | 70.4        |
| train-AverageReturn     | 114         |
| train-EnvExecTime       | 10.8        |
| train-MaxReturn         | 162         |
| train-MinReturn         | 60.2        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14          |
| train-StdReturn         | 28.1        |
-----------------------------------------

 ---------------- Iteration 5 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 5            |
| ItrTime                 | 26.4         |
| LossAfter               | -0.11630326  |
| LossBefore              | -0.004068277 |
| Time                    | 163          |
| Time-Optimization       | 1.13         |
| Time-SampleProc         | 0.0903       |
| Time-Sampling           | 25.2         |
| n_timesteps             | 60000        |
| train-AverageDiscoun... | 45.6         |
| train-AverageReturn     | 76.4         |
| train-EnvExecTime       | 10.5         |
| train-MaxReturn         | 178          |
| train-MinReturn         | -46.3        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14           |
| train-StdReturn         | 50.7         |
------------------------------------------

 ---------------- Iteration 6 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 6           |
| ItrTime                 | 27.2        |
| LossAfter               | -1.6612375  |
| LossBefore              | 0.008558899 |
| Time                    | 190         |
| Time-Optimization       | 1.58        |
| Time-SampleProc         | 0.0624      |
| Time-Sampling           | 25.6        |
| n_timesteps             | 70000       |
| train-AverageDiscoun... | 24.9        |
| train-AverageReturn     | 39.4        |
| train-EnvExecTime       | 10.8        |
| train-MaxReturn         | 138         |
| train-MinReturn         | -329        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 79.6        |
-----------------------------------------

 ---------------- Iteration 7 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 7             |
| ItrTime                 | 26            |
| LossAfter               | -4.867894     |
| LossBefore              | -0.0023641968 |
| Time                    | 216           |
| Time-Optimization       | 1.07          |
| Time-SampleProc         | 0.0455        |
| Time-Sampling           | 24.9          |
| n_timesteps             | 80000         |
| train-AverageDiscoun... | 57.6          |
| train-AverageReturn     | 89.2          |
| train-EnvExecTime       | 10.4          |
| train-MaxReturn         | 145           |
| train-MinReturn         | -15.8         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 13.8          |
| train-StdReturn         | 32.1          |
-------------------------------------------

 ---------------- Iteration 8 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 8             |
| ItrTime                 | 26.2          |
| LossAfter               | -5.7875123    |
| LossBefore              | -0.0075810854 |
| Time                    | 243           |
| Time-Optimization       | 1.05          |
| Time-SampleProc         | 0.0414        |
| Time-Sampling           | 25.1          |
| n_timesteps             | 90000         |
| train-AverageDiscoun... | 69.9          |
| train-AverageReturn     | 114           |
| train-EnvExecTime       | 10.4          |
| train-MaxReturn         | 177           |
| train-MinReturn         | -96.9         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.1          |
| train-StdReturn         | 44.7          |
-------------------------------------------

 ---------------- Iteration 9 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 9            |
| ItrTime                 | 26.7         |
| LossAfter               | -0.3329255   |
| LossBefore              | 0.0021404175 |
| Time                    | 269          |
| Time-Optimization       | 1.07         |
| Time-SampleProc         | 0.0404       |
| Time-Sampling           | 25.6         |
| n_timesteps             | 100000       |
| train-AverageDiscoun... | 7.3          |
| train-AverageReturn     | 1.46         |
| train-EnvExecTime       | 10.7         |
| train-MaxReturn         | 136          |
| train-MinReturn         | -163         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 64.4         |
------------------------------------------

 ---------------- Iteration 10 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 10          |
| ItrTime                 | 26.7        |
| LossAfter               | -3.0784173  |
| LossBefore              | 0.002268251 |
| Time                    | 296         |
| Time-Optimization       | 1.07        |
| Time-SampleProc         | 0.0402      |
| Time-Sampling           | 25.6        |
| n_timesteps             | 110000      |
| train-AverageDiscoun... | -55.8       |
| train-AverageReturn     | -120        |
| train-EnvExecTime       | 10.8        |
| train-MaxReturn         | -30.5       |
| train-MinReturn         | -202        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 22.1        |
-----------------------------------------

 ---------------- Iteration 11 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 11          |
| ItrTime                 | 26.7        |
| LossAfter               | -3.9392335  |
| LossBefore              | 0.011748006 |
| Time                    | 323         |
| Time-Optimization       | 1.09        |
| Time-SampleProc         | 0.0425      |
| Time-Sampling           | 25.6        |
| n_timesteps             | 120000      |
| train-AverageDiscoun... | -52.5       |
| train-AverageReturn     | -112        |
| train-EnvExecTime       | 10.8        |
| train-MaxReturn         | 40.7        |
| train-MinReturn         | -246        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 47.4        |
-----------------------------------------

 ---------------- Iteration 12 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
----------------------------------------
| Itr                     | 12         |
| ItrTime                 | 26.7       |
| LossAfter               | -2.417149  |
| LossBefore              | 0.01565893 |
| Time                    | 350        |
| Time-Optimization       | 1.09       |
| Time-SampleProc         | 0.0456     |
| Time-Sampling           | 25.6       |
| n_timesteps             | 130000     |
| train-AverageDiscoun... | -42.1      |
| train-AverageReturn     | -83.2      |
| train-EnvExecTime       | 10.8       |
| train-MaxReturn         | 99.1       |
| train-MinReturn         | -229       |
| train-NumTrajs          | 100        |
| train-PolicyExecTime    | 14.1       |
| train-StdReturn         | 72         |
----------------------------------------

 ---------------- Iteration 13 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 13          |
| ItrTime                 | 26.9        |
| LossAfter               | -2.0512278  |
| LossBefore              | 0.018980494 |
| Time                    | 377         |
| Time-Optimization       | 1.07        |
| Time-SampleProc         | 0.0475      |
| Time-Sampling           | 25.8        |
| n_timesteps             | 140000      |
| train-AverageDiscoun... | -59.5       |
| train-AverageReturn     | -122        |
| train-EnvExecTime       | 11          |
| train-MaxReturn         | 31.1        |
| train-MinReturn         | -261        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 59.3        |
-----------------------------------------

 ---------------- Iteration 14 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 14          |
| ItrTime                 | 27.2        |
| LossAfter               | -3.7704527  |
| LossBefore              | 0.015326318 |
| Time                    | 404         |
| Time-Optimization       | 1.07        |
| Time-SampleProc         | 0.0378      |
| Time-Sampling           | 26.1        |
| n_timesteps             | 150000      |
| train-AverageDiscoun... | -58.5       |
| train-AverageReturn     | -122        |
| train-EnvExecTime       | 11.3        |
| train-MaxReturn         | -29.2       |
| train-MinReturn         | -180        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 42.8        |
-----------------------------------------

 ---------------- Iteration 15 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 15          |
| ItrTime                 | 27.5        |
| LossAfter               | -6.087751   |
| LossBefore              | 0.022960547 |
| Time                    | 431         |
| Time-Optimization       | 1.08        |
| Time-SampleProc         | 0.046       |
| Time-Sampling           | 26.3        |
| n_timesteps             | 160000      |
| train-AverageDiscoun... | -45.1       |
| train-AverageReturn     | -103        |
| train-EnvExecTime       | 11.5        |
| train-MaxReturn         | -27.8       |
| train-MinReturn         | -200        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.2        |
| train-StdReturn         | 52.5        |
-----------------------------------------

 ---------------- Iteration 16 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
---------------------------------------
| Itr                     | 16        |
| ItrTime                 | 27.4      |
| LossAfter               | 0.5567832 |
| LossBefore              | -0.012322 |
| Time                    | 459       |
| Time-Optimization       | 1.06      |
| Time-SampleProc         | 0.046     |
| Time-Sampling           | 26.3      |
| n_timesteps             | 170000    |
| train-AverageDiscoun... | -11.8     |
| train-AverageReturn     | -41.9     |
| train-EnvExecTime       | 11.4      |
| train-MaxReturn         | -18.1     |
| train-MinReturn         | -89.7     |
| train-NumTrajs          | 100       |
| train-PolicyExecTime    | 14.2      |
| train-StdReturn         | 20.6      |
---------------------------------------

 ---------------- Iteration 17 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 17           |
| ItrTime                 | 27.4         |
| LossAfter               | -0.45261505  |
| LossBefore              | -0.005253641 |
| Time                    | 486          |
| Time-Optimization       | 1.08         |
| Time-SampleProc         | 0.0414       |
| Time-Sampling           | 26.3         |
| n_timesteps             | 180000       |
| train-AverageDiscoun... | -7.66        |
| train-AverageReturn     | -37.6        |
| train-EnvExecTime       | 11.4         |
| train-MaxReturn         | 25.3         |
| train-MinReturn         | -89.9        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 22           |
------------------------------------------

 ---------------- Iteration 18 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
----------------------------------------
| Itr                     | 18         |
| ItrTime                 | 27.4       |
| LossAfter               | -0.5194873 |
| LossBefore              | 0.0124323  |
| Time                    | 514        |
| Time-Optimization       | 1.07       |
| Time-SampleProc         | 0.0407     |
| Time-Sampling           | 26.2       |
| n_timesteps             | 190000     |
| train-AverageDiscoun... | -4.64      |
| train-AverageReturn     | -30.8      |
| train-EnvExecTime       | 11.4       |
| train-MaxReturn         | 42.6       |
| train-MinReturn         | -93        |
| train-NumTrajs          | 100        |
| train-PolicyExecTime    | 14.2       |
| train-StdReturn         | 25.3       |
----------------------------------------

 ---------------- Iteration 19 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 19           |
| ItrTime                 | 27.4         |
| LossAfter               | -0.52703136  |
| LossBefore              | -0.009707654 |
| Time                    | 541          |
| Time-Optimization       | 1.08         |
| Time-SampleProc         | 0.0423       |
| Time-Sampling           | 26.3         |
| n_timesteps             | 200000       |
| train-AverageDiscoun... | 3.1          |
| train-AverageReturn     | -15.6        |
| train-EnvExecTime       | 11.4         |
| train-MaxReturn         | 43.6         |
| train-MinReturn         | -89.4        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 33.3         |
------------------------------------------

 ---------------- Iteration 20 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 20          |
| ItrTime                 | 27.3        |
| LossAfter               | -0.55399406 |
| LossBefore              | 0.007564624 |
| Time                    | 569         |
| Time-Optimization       | 1.06        |
| Time-SampleProc         | 0.0341      |
| Time-Sampling           | 26.2        |
| n_timesteps             | 210000      |
| train-AverageDiscoun... | 6.95        |
| train-AverageReturn     | -6.78       |
| train-EnvExecTime       | 11.4        |
| train-MaxReturn         | 43.7        |
| train-MinReturn         | -90.3       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.2        |
| train-StdReturn         | 35.1        |
-----------------------------------------

 ---------------- Iteration 21 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 21          |
| ItrTime                 | 27.3        |
| LossAfter               | -0.6607336  |
| LossBefore              | 0.008808113 |
| Time                    | 596         |
| Time-Optimization       | 1.06        |
| Time-SampleProc         | 0.0393      |
| Time-Sampling           | 26.2        |
| n_timesteps             | 220000      |
| train-AverageDiscoun... | 9.32        |
| train-AverageReturn     | -0.37       |
| train-EnvExecTime       | 11.3        |
| train-MaxReturn         | 45.7        |
| train-MinReturn         | -89.3       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.3        |
| train-StdReturn         | 38          |
-----------------------------------------

 ---------------- Iteration 22 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 22           |
| ItrTime                 | 27.5         |
| LossAfter               | -0.8801423   |
| LossBefore              | -0.005073392 |
| Time                    | 624          |
| Time-Optimization       | 1.08         |
| Time-SampleProc         | 0.0421       |
| Time-Sampling           | 26.3         |
| n_timesteps             | 230000       |
| train-AverageDiscoun... | 11.7         |
| train-AverageReturn     | 4.08         |
| train-EnvExecTime       | 11.4         |
| train-MaxReturn         | 45.5         |
| train-MinReturn         | -87.5        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.3         |
| train-StdReturn         | 34.5         |
------------------------------------------

 ---------------- Iteration 23 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 23            |
| ItrTime                 | 27.4          |
| LossAfter               | -0.95014405   |
| LossBefore              | -0.0054542967 |
| Time                    | 651           |
| Time-Optimization       | 1.06          |
| Time-SampleProc         | 0.0445        |
| Time-Sampling           | 26.3          |
| n_timesteps             | 240000        |
| train-AverageDiscoun... | 8.05          |
| train-AverageReturn     | -4.41         |
| train-EnvExecTime       | 11.4          |
| train-MaxReturn         | 43.7          |
| train-MinReturn         | -88.2         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.2          |
| train-StdReturn         | 36.1          |
-------------------------------------------

 ---------------- Iteration 24 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 24            |
| ItrTime                 | 27.2          |
| LossAfter               | -1.2552811    |
| LossBefore              | -0.0010082154 |
| Time                    | 678           |
| Time-Optimization       | 1.08          |
| Time-SampleProc         | 0.0383        |
| Time-Sampling           | 26            |
| n_timesteps             | 250000        |
| train-AverageDiscoun... | -10.8         |
| train-AverageReturn     | -46.3         |
| train-EnvExecTime       | 11.2          |
| train-MaxReturn         | 35.8          |
| train-MinReturn         | -102          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.1          |
| train-StdReturn         | 29.4          |
-------------------------------------------

 ---------------- Iteration 25 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 25           |
| ItrTime                 | 27.1         |
| LossAfter               | -1.6885647   |
| LossBefore              | -0.015708834 |
| Time                    | 705          |
| Time-Optimization       | 1.06         |
| Time-SampleProc         | 0.0446       |
| Time-Sampling           | 26           |
| n_timesteps             | 260000       |
| train-AverageDiscoun... | 0.396        |
| train-AverageReturn     | -12.9        |
| train-EnvExecTime       | 11.3         |
| train-MaxReturn         | -2.43        |
| train-MinReturn         | -36.5        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14           |
| train-StdReturn         | 6.81         |
------------------------------------------

 ---------------- Iteration 26 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 26          |
| ItrTime                 | 27.2        |
| LossAfter               | -1.7477914  |
| LossBefore              | 0.024892844 |
| Time                    | 733         |
| Time-Optimization       | 1.07        |
| Time-SampleProc         | 0.0379      |
| Time-Sampling           | 26.1        |
| n_timesteps             | 270000      |
| train-AverageDiscoun... | -0.0364     |
| train-AverageReturn     | -13.2       |
| train-EnvExecTime       | 11.3        |
| train-MaxReturn         | -3.69       |
| train-MinReturn         | -28.6       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 4.52        |
-----------------------------------------

 ---------------- Iteration 27 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 27            |
| ItrTime                 | 27.2          |
| LossAfter               | -1.7077407    |
| LossBefore              | -0.0021836732 |
| Time                    | 760           |
| Time-Optimization       | 1.1           |
| Time-SampleProc         | 0.0358        |
| Time-Sampling           | 26.1          |
| n_timesteps             | 280000        |
| train-AverageDiscoun... | -0.775        |
| train-AverageReturn     | -15           |
| train-EnvExecTime       | 11.3          |
| train-MaxReturn         | -4.22         |
| train-MinReturn         | -61           |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.2          |
| train-StdReturn         | 9.18          |
-------------------------------------------

 ---------------- Iteration 28 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 28           |
| ItrTime                 | 27.4         |
| LossAfter               | -1.8112768   |
| LossBefore              | -0.011192736 |
| Time                    | 787          |
| Time-Optimization       | 1.05         |
| Time-SampleProc         | 0.0427       |
| Time-Sampling           | 26.3         |
| n_timesteps             | 290000       |
| train-AverageDiscoun... | -0.0886      |
| train-AverageReturn     | -13.6        |
| train-EnvExecTime       | 11.4         |
| train-MaxReturn         | -3.35        |
| train-MinReturn         | -33.4        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 4.9          |
------------------------------------------

 ---------------- Iteration 29 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 29            |
| ItrTime                 | 27.3          |
| LossAfter               | -1.9204618    |
| LossBefore              | -0.0013787453 |
| Time                    | 815           |
| Time-Optimization       | 1.1           |
| Time-SampleProc         | 0.0451        |
| Time-Sampling           | 26.1          |
| n_timesteps             | 300000        |
| train-AverageDiscoun... | -1.72         |
| train-AverageReturn     | -17.4         |
| train-EnvExecTime       | 11.3          |
| train-MaxReturn         | -5.11         |
| train-MinReturn         | -73.2         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.1          |
| train-StdReturn         | 14.2          |
-------------------------------------------

 ---------------- Iteration 30 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 30           |
| ItrTime                 | 27.3         |
| LossAfter               | -2.1322436   |
| LossBefore              | -0.017534217 |
| Time                    | 842          |
| Time-Optimization       | 1.08         |
| Time-SampleProc         | 0.0429       |
| Time-Sampling           | 26.1         |
| n_timesteps             | 310000       |
| train-AverageDiscoun... | -0.822       |
| train-AverageReturn     | -15.3        |
| train-EnvExecTime       | 11.3         |
| train-MaxReturn         | -3.73        |
| train-MinReturn         | -71.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 12.8         |
------------------------------------------

 ---------------- Iteration 31 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 31           |
| ItrTime                 | 27.1         |
| LossAfter               | -2.2700417   |
| LossBefore              | 0.0098853875 |
| Time                    | 869          |
| Time-Optimization       | 1.1          |
| Time-SampleProc         | 0.0382       |
| Time-Sampling           | 26           |
| n_timesteps             | 320000       |
| train-AverageDiscoun... | -0.603       |
| train-AverageReturn     | -14.6        |
| train-EnvExecTime       | 11.3         |
| train-MaxReturn         | -4.14        |
| train-MinReturn         | -73.1        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14           |
| train-StdReturn         | 12           |
------------------------------------------

 ---------------- Iteration 32 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 32            |
| ItrTime                 | 27.3          |
| LossAfter               | -2.4618964    |
| LossBefore              | 0.00016509705 |
| Time                    | 897           |
| Time-Optimization       | 1.1           |
| Time-SampleProc         | 0.0344        |
| Time-Sampling           | 26.2          |
| n_timesteps             | 330000        |
| train-AverageDiscoun... | 0.734         |
| train-AverageReturn     | -11.4         |
| train-EnvExecTime       | 11.4          |
| train-MaxReturn         | -3.71         |
| train-MinReturn         | -22.2         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.1          |
| train-StdReturn         | 4.33          |
-------------------------------------------

 ---------------- Iteration 33 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 33            |
| ItrTime                 | 27.3          |
| LossAfter               | -2.5279195    |
| LossBefore              | 0.00072015077 |
| Time                    | 924           |
| Time-Optimization       | 1.1           |
| Time-SampleProc         | 0.041         |
| Time-Sampling           | 26.1          |
| n_timesteps             | 340000        |
| train-AverageDiscoun... | 0.682         |
| train-AverageReturn     | -11.2         |
| train-EnvExecTime       | 11.3          |
| train-MaxReturn         | -4.08         |
| train-MinReturn         | -33           |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.1          |
| train-StdReturn         | 4.59          |
-------------------------------------------

 ---------------- Iteration 34 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 34           |
| ItrTime                 | 27.4         |
| LossAfter               | -2.5054379   |
| LossBefore              | 0.0034144563 |
| Time                    | 951          |
| Time-Optimization       | 1.09         |
| Time-SampleProc         | 0.0416       |
| Time-Sampling           | 26.3         |
| n_timesteps             | 350000       |
| train-AverageDiscoun... | -0.302       |
| train-AverageReturn     | -13.3        |
| train-EnvExecTime       | 11.4         |
| train-MaxReturn         | -3.88        |
| train-MinReturn         | -68.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 11.6         |
------------------------------------------

 ---------------- Iteration 35 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 35          |
| ItrTime                 | 27.2        |
| LossAfter               | -2.714003   |
| LossBefore              | -0.02664818 |
| Time                    | 979         |
| Time-Optimization       | 1.09        |
| Time-SampleProc         | 0.0363      |
| Time-Sampling           | 26.1        |
| n_timesteps             | 360000      |
| train-AverageDiscoun... | 0.366       |
| train-AverageReturn     | -11.8       |
| train-EnvExecTime       | 11.3        |
| train-MaxReturn         | -5.55       |
| train-MinReturn         | -71.8       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 7.03        |
-----------------------------------------

 ---------------- Iteration 36 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 36           |
| ItrTime                 | 27.1         |
| LossAfter               | -2.6169791   |
| LossBefore              | 0.0088096745 |
| Time                    | 1.01e+03     |
| Time-Optimization       | 1.07         |
| Time-SampleProc         | 0.0346       |
| Time-Sampling           | 26           |
| n_timesteps             | 370000       |
| train-AverageDiscoun... | 0.121        |
| train-AverageReturn     | -12.6        |
| train-EnvExecTime       | 11.3         |
| train-MaxReturn         | -5.01        |
| train-MinReturn         | -72.3        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 10.6         |
------------------------------------------

 ---------------- Iteration 37 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 37          |
| ItrTime                 | 27.1        |
| LossAfter               | -2.628338   |
| LossBefore              | 0.004705963 |
| Time                    | 1.03e+03    |
| Time-Optimization       | 1.07        |
| Time-SampleProc         | 0.0364      |
| Time-Sampling           | 26          |
| n_timesteps             | 380000      |
| train-AverageDiscoun... | 0.754       |
| train-AverageReturn     | -10.8       |
| train-EnvExecTime       | 11.2        |
| train-MaxReturn         | -3.41       |
| train-MinReturn         | -48.2       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 5.34        |
-----------------------------------------

 ---------------- Iteration 38 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 38             |
| ItrTime                 | 27.3           |
| LossAfter               | -2.5423536     |
| LossBefore              | -0.00014290161 |
| Time                    | 1.06e+03       |
| Time-Optimization       | 1.09           |
| Time-SampleProc         | 0.0438         |
| Time-Sampling           | 26.2           |
| n_timesteps             | 390000         |
| train-AverageDiscoun... | -0.347         |
| train-AverageReturn     | -13.5          |
| train-EnvExecTime       | 11.3           |
| train-MaxReturn         | -4.29          |
| train-MinReturn         | -72.7          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 14.1           |
| train-StdReturn         | 12.1           |
--------------------------------------------

 ---------------- Iteration 39 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 39           |
| ItrTime                 | 27.4         |
| LossAfter               | -2.5527496   |
| LossBefore              | 0.0050862487 |
| Time                    | 1.09e+03     |
| Time-Optimization       | 1.1          |
| Time-SampleProc         | 0.0352       |
| Time-Sampling           | 26.3         |
| n_timesteps             | 400000       |
| train-AverageDiscoun... | -0.188       |
| train-AverageReturn     | -13.1        |
| train-EnvExecTime       | 11.4         |
| train-MaxReturn         | -4.55        |
| train-MinReturn         | -72.7        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 13.3         |
------------------------------------------

 ---------------- Iteration 40 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 40           |
| ItrTime                 | 27.3         |
| LossAfter               | -2.348265    |
| LossBefore              | 0.0062815812 |
| Time                    | 1.12e+03     |
| Time-Optimization       | 1.07         |
| Time-SampleProc         | 0.0384       |
| Time-Sampling           | 26.2         |
| n_timesteps             | 410000       |
| train-AverageDiscoun... | 0.273        |
| train-AverageReturn     | -11.9        |
| train-EnvExecTime       | 11.3         |
| train-MaxReturn         | -3.45        |
| train-MinReturn         | -68.7        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 10.6         |
------------------------------------------

 ---------------- Iteration 41 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 41            |
| ItrTime                 | 27.3          |
| LossAfter               | -2.3024864    |
| LossBefore              | -0.0010552765 |
| Time                    | 1.14e+03      |
| Time-Optimization       | 1.07          |
| Time-SampleProc         | 0.0421        |
| Time-Sampling           | 26.2          |
| n_timesteps             | 420000        |
| train-AverageDiscoun... | 0.179         |
| train-AverageReturn     | -12.2         |
| train-EnvExecTime       | 11.3          |
| train-MaxReturn         | -4.66         |
| train-MinReturn         | -65.8         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.2          |
| train-StdReturn         | 9.04          |
-------------------------------------------

 ---------------- Iteration 42 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 42           |
| ItrTime                 | 27.3         |
| LossAfter               | -2.1041925   |
| LossBefore              | -0.008712628 |
| Time                    | 1.17e+03     |
| Time-Optimization       | 1.07         |
| Time-SampleProc         | 0.0451       |
| Time-Sampling           | 26.2         |
| n_timesteps             | 430000       |
| train-AverageDiscoun... | -1.25        |
| train-AverageReturn     | -15.5        |
| train-EnvExecTime       | 11.3         |
| train-MaxReturn         | -4.14        |
| train-MinReturn         | -72          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 16.7         |
------------------------------------------

 ---------------- Iteration 43 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 43           |
| ItrTime                 | 27.2         |
| LossAfter               | -2.1164207   |
| LossBefore              | -0.007803446 |
| Time                    | 1.2e+03      |
| Time-Optimization       | 1.06         |
| Time-SampleProc         | 0.0418       |
| Time-Sampling           | 26.1         |
| n_timesteps             | 440000       |
| train-AverageDiscoun... | 0.0404       |
| train-AverageReturn     | -12.3        |
| train-EnvExecTime       | 11.3         |
| train-MaxReturn         | -4.18        |
| train-MinReturn         | -73.4        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 9.91         |
------------------------------------------

 ---------------- Iteration 44 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
----------------------------------------
| Itr                     | 44         |
| ItrTime                 | 27.3       |
| LossAfter               | -1.9463499 |
| LossBefore              | 0.01471452 |
| Time                    | 1.22e+03   |
| Time-Optimization       | 1.06       |
| Time-SampleProc         | 0.0384     |
| Time-Sampling           | 26.2       |
| n_timesteps             | 450000     |
| train-AverageDiscoun... | -0.919     |
| train-AverageReturn     | -14.7      |
| train-EnvExecTime       | 11.3       |
| train-MaxReturn         | -4.7       |
| train-MinReturn         | -72.6      |
| train-NumTrajs          | 100        |
| train-PolicyExecTime    | 14.2       |
| train-StdReturn         | 13.7       |
----------------------------------------

 ---------------- Iteration 45 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 45            |
| ItrTime                 | 27.3          |
| LossAfter               | -1.8953726    |
| LossBefore              | -0.0017118042 |
| Time                    | 1.25e+03      |
| Time-Optimization       | 1.07          |
| Time-SampleProc         | 0.0457        |
| Time-Sampling           | 26.1          |
| n_timesteps             | 460000        |
| train-AverageDiscoun... | -2.13         |
| train-AverageReturn     | -17.6         |
| train-EnvExecTime       | 11.3          |
| train-MaxReturn         | -4.86         |
| train-MinReturn         | -73.1         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.1          |
| train-StdReturn         | 16.7          |
-------------------------------------------

 ---------------- Iteration 46 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 46           |
| ItrTime                 | 27.2         |
| LossAfter               | -1.7642764   |
| LossBefore              | 0.0038608285 |
| Time                    | 1.28e+03     |
| Time-Optimization       | 1.09         |
| Time-SampleProc         | 0.0383       |
| Time-Sampling           | 26.1         |
| n_timesteps             | 470000       |
| train-AverageDiscoun... | -1.67        |
| train-AverageReturn     | -16.3        |
| train-EnvExecTime       | 11.3         |
| train-MaxReturn         | -4.62        |
| train-MinReturn         | -73          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 15.6         |
------------------------------------------

 ---------------- Iteration 47 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 47           |
| ItrTime                 | 27.4         |
| LossAfter               | -1.6912465   |
| LossBefore              | -0.011073724 |
| Time                    | 1.31e+03     |
| Time-Optimization       | 1.09         |
| Time-SampleProc         | 0.0437       |
| Time-Sampling           | 26.2         |
| n_timesteps             | 480000       |
| train-AverageDiscoun... | -2.63        |
| train-AverageReturn     | -18.5        |
| train-EnvExecTime       | 11.4         |
| train-MaxReturn         | -4.24        |
| train-MinReturn         | -72.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 18.5         |
------------------------------------------

 ---------------- Iteration 48 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 48            |
| ItrTime                 | 27.2          |
| LossAfter               | -1.6075779    |
| LossBefore              | -0.0013392945 |
| Time                    | 1.33e+03      |
| Time-Optimization       | 1.07          |
| Time-SampleProc         | 0.0411        |
| Time-Sampling           | 26.1          |
| n_timesteps             | 490000        |
| train-AverageDiscoun... | -2.09         |
| train-AverageReturn     | -17.1         |
| train-EnvExecTime       | 11.3          |
| train-MaxReturn         | -4.31         |
| train-MinReturn         | -72.5         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.1          |
| train-StdReturn         | 14.5          |
-------------------------------------------

 ---------------- Iteration 49 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 49           |
| ItrTime                 | 27.2         |
| LossAfter               | -1.5578523   |
| LossBefore              | -0.004693756 |
| Time                    | 1.36e+03     |
| Time-Optimization       | 1.08         |
| Time-SampleProc         | 0.0442       |
| Time-Sampling           | 26.1         |
| n_timesteps             | 500000       |
| train-AverageDiscoun... | -1.55        |
| train-AverageReturn     | -15.6        |
| train-EnvExecTime       | 11.3         |
| train-MaxReturn         | -4.41        |
| train-MinReturn         | -70.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 14.3         |
------------------------------------------

 ---------------- Iteration 50 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 50            |
| ItrTime                 | 27.3          |
| LossAfter               | -1.5016701    |
| LossBefore              | -0.0057824585 |
| Time                    | 1.39e+03      |
| Time-Optimization       | 1.07          |
| Time-SampleProc         | 0.0354        |
| Time-Sampling           | 26.2          |
| n_timesteps             | 510000        |
| train-AverageDiscoun... | -2.71         |
| train-AverageReturn     | -18.2         |
| train-EnvExecTime       | 11.3          |
| train-MaxReturn         | -4.11         |
| train-MinReturn         | -73.2         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.2          |
| train-StdReturn         | 15.3          |
-------------------------------------------

 ---------------- Iteration 51 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 51          |
| ItrTime                 | 27.2        |
| LossAfter               | -1.5053242  |
| LossBefore              | -0.02673996 |
| Time                    | 1.42e+03    |
| Time-Optimization       | 1.06        |
| Time-SampleProc         | 0.0445      |
| Time-Sampling           | 26.1        |
| n_timesteps             | 520000      |
| train-AverageDiscoun... | -3.01       |
| train-AverageReturn     | -19.1       |
| train-EnvExecTime       | 11.3        |
| train-MaxReturn         | -4.78       |
| train-MinReturn         | -72.9       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 17.4        |
-----------------------------------------

 ---------------- Iteration 52 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 52          |
| ItrTime                 | 27.3        |
| LossAfter               | -1.4527243  |
| LossBefore              | -0.00510437 |
| Time                    | 1.44e+03    |
| Time-Optimization       | 1.05        |
| Time-SampleProc         | 0.0421      |
| Time-Sampling           | 26.2        |
| n_timesteps             | 530000      |
| train-AverageDiscoun... | -3.03       |
| train-AverageReturn     | -19.1       |
| train-EnvExecTime       | 11.3        |
| train-MaxReturn         | -4.45       |
| train-MinReturn         | -72.9       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.2        |
| train-StdReturn         | 16.9        |
-----------------------------------------

 ---------------- Iteration 53 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 53          |
| ItrTime                 | 27.3        |
| LossAfter               | -1.4361682  |
| LossBefore              | 0.015396942 |
| Time                    | 1.47e+03    |
| Time-Optimization       | 1.05        |
| Time-SampleProc         | 0.0395      |
| Time-Sampling           | 26.2        |
| n_timesteps             | 540000      |
| train-AverageDiscoun... | -2.6        |
| train-AverageReturn     | -18.1       |
| train-EnvExecTime       | 11.4        |
| train-MaxReturn         | -4.64       |
| train-MinReturn         | -72.4       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 16.8        |
-----------------------------------------

 ---------------- Iteration 54 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 54            |
| ItrTime                 | 27.3          |
| LossAfter               | -1.4844681    |
| LossBefore              | -0.0016554199 |
| Time                    | 1.5e+03       |
| Time-Optimization       | 1.06          |
| Time-SampleProc         | 0.0413        |
| Time-Sampling           | 26.2          |
| n_timesteps             | 550000        |
| train-AverageDiscoun... | -2.22         |
| train-AverageReturn     | -17           |
| train-EnvExecTime       | 11.3          |
| train-MaxReturn         | -4.67         |
| train-MinReturn         | -68.3         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.2          |
| train-StdReturn         | 12.8          |
-------------------------------------------

 ---------------- Iteration 55 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 55            |
| ItrTime                 | 27.3          |
| LossAfter               | -1.4057908    |
| LossBefore              | -0.0030076797 |
| Time                    | 1.53e+03      |
| Time-Optimization       | 1.06          |
| Time-SampleProc         | 0.038         |
| Time-Sampling           | 26.2          |
| n_timesteps             | 560000        |
| train-AverageDiscoun... | -3.58         |
| train-AverageReturn     | -20.4         |
| train-EnvExecTime       | 11.4          |
| train-MaxReturn         | -4.69         |
| train-MinReturn         | -73.5         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.1          |
| train-StdReturn         | 18.4          |
-------------------------------------------

 ---------------- Iteration 56 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 56           |
| ItrTime                 | 27.5         |
| LossAfter               | -1.487692    |
| LossBefore              | -0.012948262 |
| Time                    | 1.55e+03     |
| Time-Optimization       | 1.2          |
| Time-SampleProc         | 0.0378       |
| Time-Sampling           | 26.3         |
| n_timesteps             | 570000       |
| train-AverageDiscoun... | -3.18        |
| train-AverageReturn     | -19.5        |
| train-EnvExecTime       | 11.3         |
| train-MaxReturn         | -4.5         |
| train-MinReturn         | -73.1        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.3         |
| train-StdReturn         | 18.3         |
------------------------------------------

 ---------------- Iteration 57 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 57          |
| ItrTime                 | 27.3        |
| LossAfter               | -1.3477683  |
| LossBefore              | 0.010096756 |
| Time                    | 1.58e+03    |
| Time-Optimization       | 1.1         |
| Time-SampleProc         | 0.045       |
| Time-Sampling           | 26.2        |
| n_timesteps             | 580000      |
| train-AverageDiscoun... | -4.21       |
| train-AverageReturn     | -21.8       |
| train-EnvExecTime       | 11.3        |
| train-MaxReturn         | -5.44       |
| train-MinReturn         | -72.4       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 19.3        |
-----------------------------------------

 ---------------- Iteration 58 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 58           |
| ItrTime                 | 27.3         |
| LossAfter               | -1.3689916   |
| LossBefore              | -0.021431787 |
| Time                    | 1.61e+03     |
| Time-Optimization       | 1.08         |
| Time-SampleProc         | 0.036        |
| Time-Sampling           | 26.2         |
| n_timesteps             | 590000       |
| train-AverageDiscoun... | -2.97        |
| train-AverageReturn     | -18.8        |
| train-EnvExecTime       | 11.3         |
| train-MaxReturn         | -4.51        |
| train-MinReturn         | -72          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 15.3         |
------------------------------------------

 ---------------- Iteration 59 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 59           |
| ItrTime                 | 27.2         |
| LossAfter               | -1.4335151   |
| LossBefore              | -0.016486328 |
| Time                    | 1.63e+03     |
| Time-Optimization       | 1.07         |
| Time-SampleProc         | 0.0408       |
| Time-Sampling           | 26           |
| n_timesteps             | 600000       |
| train-AverageDiscoun... | -1.91        |
| train-AverageReturn     | -16.5        |
| train-EnvExecTime       | 11.2         |
| train-MaxReturn         | -4.98        |
| train-MinReturn         | -71.3        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 14.6         |
------------------------------------------

 ---------------- Iteration 60 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 60          |
| ItrTime                 | 27.2        |
| LossAfter               | -1.4509146  |
| LossBefore              | 0.009476001 |
| Time                    | 1.66e+03    |
| Time-Optimization       | 1.08        |
| Time-SampleProc         | 0.0367      |
| Time-Sampling           | 26.1        |
| n_timesteps             | 610000      |
| train-AverageDiscoun... | -2.41       |
| train-AverageReturn     | -17.6       |
| train-EnvExecTime       | 11.3        |
| train-MaxReturn         | -3.58       |
| train-MinReturn         | -69         |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 13.7        |
-----------------------------------------

 ---------------- Iteration 61 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 61          |
| ItrTime                 | 27.3        |
| LossAfter               | -1.3700029  |
| LossBefore              | 0.006300293 |
| Time                    | 1.69e+03    |
| Time-Optimization       | 1.07        |
| Time-SampleProc         | 0.0416      |
| Time-Sampling           | 26.1        |
| n_timesteps             | 620000      |
| train-AverageDiscoun... | -3.83       |
| train-AverageReturn     | -21.1       |
| train-EnvExecTime       | 11.3        |
| train-MaxReturn         | -4.58       |
| train-MinReturn         | -73.5       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 19          |
-----------------------------------------

 ---------------- Iteration 62 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 62          |
| ItrTime                 | 27.3        |
| LossAfter               | -1.4474108  |
| LossBefore              | 0.014471446 |
| Time                    | 1.72e+03    |
| Time-Optimization       | 1.07        |
| Time-SampleProc         | 0.0454      |
| Time-Sampling           | 26.2        |
| n_timesteps             | 630000      |
| train-AverageDiscoun... | -2.43       |
| train-AverageReturn     | -17.4       |
| train-EnvExecTime       | 11.4        |
| train-MaxReturn         | -4.94       |
| train-MinReturn         | -74.2       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.2        |
| train-StdReturn         | 14.7        |
-----------------------------------------

 ---------------- Iteration 63 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 63          |
| ItrTime                 | 27.2        |
| LossAfter               | -1.4318035  |
| LossBefore              | -0.01599329 |
| Time                    | 1.74e+03    |
| Time-Optimization       | 1.05        |
| Time-SampleProc         | 0.0403      |
| Time-Sampling           | 26.1        |
| n_timesteps             | 640000      |
| train-AverageDiscoun... | -1.77       |
| train-AverageReturn     | -16         |
| train-EnvExecTime       | 11.3        |
| train-MaxReturn         | -4.52       |
| train-MinReturn         | -70         |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 13.7        |
-----------------------------------------

 ---------------- Iteration 64 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 64          |
| ItrTime                 | 27.2        |
| LossAfter               | -1.4393907  |
| LossBefore              | 0.020478638 |
| Time                    | 1.77e+03    |
| Time-Optimization       | 1.07        |
| Time-SampleProc         | 0.043       |
| Time-Sampling           | 26.1        |
| n_timesteps             | 650000      |
| train-AverageDiscoun... | -2.45       |
| train-AverageReturn     | -17.5       |
| train-EnvExecTime       | 11.3        |
| train-MaxReturn         | -4.14       |
| train-MinReturn         | -72.7       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 14.5        |
-----------------------------------------

 ---------------- Iteration 65 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 65           |
| ItrTime                 | 27.1         |
| LossAfter               | -1.4906722   |
| LossBefore              | 0.0005768799 |
| Time                    | 1.8e+03      |
| Time-Optimization       | 1.04         |
| Time-SampleProc         | 0.0431       |
| Time-Sampling           | 26           |
| n_timesteps             | 660000       |
| train-AverageDiscoun... | -2.64        |
| train-AverageReturn     | -18          |
| train-EnvExecTime       | 11.3         |
| train-MaxReturn         | -4.07        |
| train-MinReturn         | -73.7        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 14.9         |
------------------------------------------

 ---------------- Iteration 66 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 66            |
| ItrTime                 | 27.3          |
| LossAfter               | -1.431424     |
| LossBefore              | -0.0075100036 |
| Time                    | 1.83e+03      |
| Time-Optimization       | 1.06          |
| Time-SampleProc         | 0.0388        |
| Time-Sampling           | 26.2          |
| n_timesteps             | 670000        |
| train-AverageDiscoun... | -3.35         |
| train-AverageReturn     | -20.1         |
| train-EnvExecTime       | 11.3          |
| train-MaxReturn         | -4.71         |
| train-MinReturn         | -72           |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.2          |
| train-StdReturn         | 18.7          |
-------------------------------------------

 ---------------- Iteration 67 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 67           |
| ItrTime                 | 27.2         |
| LossAfter               | -1.5085231   |
| LossBefore              | 0.0028313934 |
| Time                    | 1.85e+03     |
| Time-Optimization       | 1.07         |
| Time-SampleProc         | 0.0387       |
| Time-Sampling           | 26.1         |
| n_timesteps             | 680000       |
| train-AverageDiscoun... | -3.3         |
| train-AverageReturn     | -19.4        |
| train-EnvExecTime       | 11.3         |
| train-MaxReturn         | -5.34        |
| train-MinReturn         | -73          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 16.1         |
------------------------------------------

 ---------------- Iteration 68 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 68          |
| ItrTime                 | 27.2        |
| LossAfter               | -1.5205233  |
| LossBefore              | 0.005626306 |
| Time                    | 1.88e+03    |
| Time-Optimization       | 1.1         |
| Time-SampleProc         | 0.0412      |
| Time-Sampling           | 26.1        |
| n_timesteps             | 690000      |
| train-AverageDiscoun... | -3.47       |
| train-AverageReturn     | -19.8       |
| train-EnvExecTime       | 11.3        |
| train-MaxReturn         | -4.5        |
| train-MinReturn         | -73.9       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 16.6        |
-----------------------------------------

 ---------------- Iteration 69 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 69           |
| ItrTime                 | 27.2         |
| LossAfter               | -1.4977018   |
| LossBefore              | 0.0061598634 |
| Time                    | 1.91e+03     |
| Time-Optimization       | 1.09         |
| Time-SampleProc         | 0.0459       |
| Time-Sampling           | 26.1         |
| n_timesteps             | 700000       |
| train-AverageDiscoun... | -3.46        |
| train-AverageReturn     | -19.9        |
| train-EnvExecTime       | 11.3         |
| train-MaxReturn         | -4.74        |
| train-MinReturn         | -72.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14           |
| train-StdReturn         | 17.9         |
------------------------------------------

 ---------------- Iteration 70 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 70            |
| ItrTime                 | 27.1          |
| LossAfter               | -1.5874579    |
| LossBefore              | -0.0051877564 |
| Time                    | 1.93e+03      |
| Time-Optimization       | 1.05          |
| Time-SampleProc         | 0.0371        |
| Time-Sampling           | 26            |
| n_timesteps             | 710000        |
| train-AverageDiscoun... | -2.69         |
| train-AverageReturn     | -18.1         |
| train-EnvExecTime       | 11.3          |
| train-MaxReturn         | -4.26         |
| train-MinReturn         | -71.4         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.1          |
| train-StdReturn         | 15.7          |
-------------------------------------------

 ---------------- Iteration 71 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 71          |
| ItrTime                 | 27.1        |
| LossAfter               | -1.5343705  |
| LossBefore              | 0.023824262 |
| Time                    | 1.96e+03    |
| Time-Optimization       | 1.05        |
| Time-SampleProc         | 0.0453      |
| Time-Sampling           | 26          |
| n_timesteps             | 720000      |
| train-AverageDiscoun... | -3.43       |
| train-AverageReturn     | -19.9       |
| train-EnvExecTime       | 11.3        |
| train-MaxReturn         | -5.08       |
| train-MinReturn         | -72.4       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 17.5        |
-----------------------------------------

 ---------------- Iteration 72 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 72           |
| ItrTime                 | 27.9         |
| LossAfter               | -1.569159    |
| LossBefore              | 0.0025385406 |
| Time                    | 1.99e+03     |
| Time-Optimization       | 1.09         |
| Time-SampleProc         | 0.0373       |
| Time-Sampling           | 26.7         |
| n_timesteps             | 730000       |
| train-AverageDiscoun... | -1.79        |
| train-AverageReturn     | -16          |
| train-EnvExecTime       | 11.6         |
| train-MaxReturn         | -4.94        |
| train-MinReturn         | -73.1        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.5         |
| train-StdReturn         | 12           |
------------------------------------------

 ---------------- Iteration 73 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 73           |
| ItrTime                 | 27.2         |
| LossAfter               | -1.5914704   |
| LossBefore              | -0.003830887 |
| Time                    | 2.02e+03     |
| Time-Optimization       | 1.06         |
| Time-SampleProc         | 0.0411       |
| Time-Sampling           | 26.1         |
| n_timesteps             | 740000       |
| train-AverageDiscoun... | -1.5         |
| train-AverageReturn     | -15.4        |
| train-EnvExecTime       | 11.3         |
| train-MaxReturn         | -3.67        |
| train-MinReturn         | -73.4        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 12.5         |
------------------------------------------

 ---------------- Iteration 74 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 74          |
| ItrTime                 | 27.1        |
| LossAfter               | -1.6152864  |
| LossBefore              | 0.013017408 |
| Time                    | 2.04e+03    |
| Time-Optimization       | 1.07        |
| Time-SampleProc         | 0.0422      |
| Time-Sampling           | 26          |
| n_timesteps             | 750000      |
| train-AverageDiscoun... | -1.77       |
| train-AverageReturn     | -16         |
| train-EnvExecTime       | 11.3        |
| train-MaxReturn         | -4.98       |
| train-MinReturn         | -74         |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 13.6        |
-----------------------------------------

 ---------------- Iteration 75 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 75            |
| ItrTime                 | 27.3          |
| LossAfter               | -1.7244891    |
| LossBefore              | -0.0018402679 |
| Time                    | 2.07e+03      |
| Time-Optimization       | 1.09          |
| Time-SampleProc         | 0.0394        |
| Time-Sampling           | 26.2          |
| n_timesteps             | 760000        |
| train-AverageDiscoun... | -3.08         |
| train-AverageReturn     | -19.1         |
| train-EnvExecTime       | 11.3          |
| train-MaxReturn         | -4.59         |
| train-MinReturn         | -72.7         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.2          |
| train-StdReturn         | 16.5          |
-------------------------------------------

 ---------------- Iteration 76 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 76           |
| ItrTime                 | 27.1         |
| LossAfter               | -1.6796039   |
| LossBefore              | -0.008238046 |
| Time                    | 2.1e+03      |
| Time-Optimization       | 1.09         |
| Time-SampleProc         | 0.0451       |
| Time-Sampling           | 26           |
| n_timesteps             | 770000       |
| train-AverageDiscoun... | -2.5         |
| train-AverageReturn     | -17.8        |
| train-EnvExecTime       | 11.2         |
| train-MaxReturn         | -4.78        |
| train-MinReturn         | -70.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 16.7         |
------------------------------------------

 ---------------- Iteration 77 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 77           |
| ItrTime                 | 27.2         |
| LossAfter               | -1.721468    |
| LossBefore              | -0.021363495 |
| Time                    | 2.13e+03     |
| Time-Optimization       | 1.08         |
| Time-SampleProc         | 0.0372       |
| Time-Sampling           | 26.1         |
| n_timesteps             | 780000       |
| train-AverageDiscoun... | -2.01        |
| train-AverageReturn     | -16.7        |
| train-EnvExecTime       | 11.3         |
| train-MaxReturn         | -5.78        |
| train-MinReturn         | -72.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 13.4         |
------------------------------------------

 ---------------- Iteration 78 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
----------------------------------------
| Itr                     | 78         |
| ItrTime                 | 27.4       |
| LossAfter               | -1.818713  |
| LossBefore              | 0.00374086 |
| Time                    | 2.15e+03   |
| Time-Optimization       | 1.18       |
| Time-SampleProc         | 0.0457     |
| Time-Sampling           | 26.2       |
| n_timesteps             | 790000     |
| train-AverageDiscoun... | -2.7       |
| train-AverageReturn     | -18        |
| train-EnvExecTime       | 11.3       |
| train-MaxReturn         | -4.45      |
| train-MinReturn         | -72.1      |
| train-NumTrajs          | 100        |
| train-PolicyExecTime    | 14.2       |
| train-StdReturn         | 16.1       |
----------------------------------------

 ---------------- Iteration 79 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 79           |
| ItrTime                 | 27.4         |
| LossAfter               | -1.8144103   |
| LossBefore              | 0.0054260497 |
| Time                    | 2.18e+03     |
| Time-Optimization       | 1.07         |
| Time-SampleProc         | 0.0405       |
| Time-Sampling           | 26.3         |
| n_timesteps             | 800000       |
| train-AverageDiscoun... | -2.28        |
| train-AverageReturn     | -17          |
| train-EnvExecTime       | 11.4         |
| train-MaxReturn         | -5.26        |
| train-MinReturn         | -72.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 13.5         |
------------------------------------------

 ---------------- Iteration 80 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 80          |
| ItrTime                 | 27.2        |
| LossAfter               | -1.8842312  |
| LossBefore              | 0.006430731 |
| Time                    | 2.21e+03    |
| Time-Optimization       | 1.08        |
| Time-SampleProc         | 0.0457      |
| Time-Sampling           | 26.1        |
| n_timesteps             | 810000      |
| train-AverageDiscoun... | -2.22       |
| train-AverageReturn     | -17.2       |
| train-EnvExecTime       | 11.4        |
| train-MaxReturn         | -4.98       |
| train-MinReturn         | -73.8       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 14.8        |
-----------------------------------------

 ---------------- Iteration 81 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 81           |
| ItrTime                 | 27.2         |
| LossAfter               | -2.032598    |
| LossBefore              | -0.001817714 |
| Time                    | 2.24e+03     |
| Time-Optimization       | 1.05         |
| Time-SampleProc         | 0.0383       |
| Time-Sampling           | 26.1         |
| n_timesteps             | 820000       |
| train-AverageDiscoun... | -2.43        |
| train-AverageReturn     | -17.5        |
| train-EnvExecTime       | 11.4         |
| train-MaxReturn         | -5.17        |
| train-MinReturn         | -72.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14           |
| train-StdReturn         | 13.5         |
------------------------------------------

 ---------------- Iteration 82 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 82            |
| ItrTime                 | 27.2          |
| LossAfter               | -2.1041489    |
| LossBefore              | -0.0015351746 |
| Time                    | 2.26e+03      |
| Time-Optimization       | 1.19          |
| Time-SampleProc         | 0.0365        |
| Time-Sampling           | 26            |
| n_timesteps             | 830000        |
| train-AverageDiscoun... | -1.37         |
| train-AverageReturn     | -15.1         |
| train-EnvExecTime       | 11.3          |
| train-MaxReturn         | -4.81         |
| train-MinReturn         | -72.6         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14            |
| train-StdReturn         | 9.88          |
-------------------------------------------

 ---------------- Iteration 83 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 83           |
| ItrTime                 | 27.3         |
| LossAfter               | -2.1645696   |
| LossBefore              | -0.019520245 |
| Time                    | 2.29e+03     |
| Time-Optimization       | 1.08         |
| Time-SampleProc         | 0.0386       |
| Time-Sampling           | 26.2         |
| n_timesteps             | 840000       |
| train-AverageDiscoun... | -1.86        |
| train-AverageReturn     | -16.3        |
| train-EnvExecTime       | 11.3         |
| train-MaxReturn         | -5.24        |
| train-MinReturn         | -71.3        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 13.2         |
------------------------------------------

 ---------------- Iteration 84 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 84           |
| ItrTime                 | 27.4         |
| LossAfter               | -2.0874174   |
| LossBefore              | -0.013922543 |
| Time                    | 2.32e+03     |
| Time-Optimization       | 1.07         |
| Time-SampleProc         | 0.0383       |
| Time-Sampling           | 26.2         |
| n_timesteps             | 850000       |
| train-AverageDiscoun... | -2.11        |
| train-AverageReturn     | -16.9        |
| train-EnvExecTime       | 11.3         |
| train-MaxReturn         | -5           |
| train-MinReturn         | -73.5        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 15.9         |
------------------------------------------

 ---------------- Iteration 85 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 85            |
| ItrTime                 | 27.2          |
| LossAfter               | -2.1581264    |
| LossBefore              | -0.0087563535 |
| Time                    | 2.35e+03      |
| Time-Optimization       | 1.07          |
| Time-SampleProc         | 0.0401        |
| Time-Sampling           | 26.1          |
| n_timesteps             | 860000        |
| train-AverageDiscoun... | -1.87         |
| train-AverageReturn     | -16.2         |
| train-EnvExecTime       | 11.3          |
| train-MaxReturn         | -4.28         |
| train-MinReturn         | -75.5         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.1          |
| train-StdReturn         | 14            |
-------------------------------------------

 ---------------- Iteration 86 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 86            |
| ItrTime                 | 27.3          |
| LossAfter               | -2.190273     |
| LossBefore              | -0.0031154677 |
| Time                    | 2.37e+03      |
| Time-Optimization       | 1.08          |
| Time-SampleProc         | 0.0379        |
| Time-Sampling           | 26.2          |
| n_timesteps             | 870000        |
| train-AverageDiscoun... | -3.1          |
| train-AverageReturn     | -18.9         |
| train-EnvExecTime       | 11.3          |
| train-MaxReturn         | -4.58         |
| train-MinReturn         | -71.7         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.1          |
| train-StdReturn         | 15.5          |
-------------------------------------------

 ---------------- Iteration 87 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 87           |
| ItrTime                 | 27.2         |
| LossAfter               | -2.0892239   |
| LossBefore              | -0.004865588 |
| Time                    | 2.4e+03      |
| Time-Optimization       | 1.05         |
| Time-SampleProc         | 0.0419       |
| Time-Sampling           | 26.1         |
| n_timesteps             | 880000       |
| train-AverageDiscoun... | -3.6         |
| train-AverageReturn     | -20.1        |
| train-EnvExecTime       | 11.3         |
| train-MaxReturn         | -4.49        |
| train-MinReturn         | -75.9        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 17.3         |
------------------------------------------

 ---------------- Iteration 88 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 88          |
| ItrTime                 | 27.3        |
| LossAfter               | -2.163132   |
| LossBefore              | 0.004089831 |
| Time                    | 2.43e+03    |
| Time-Optimization       | 1.05        |
| Time-SampleProc         | 0.0397      |
| Time-Sampling           | 26.2        |
| n_timesteps             | 890000      |
| train-AverageDiscoun... | -3.5        |
| train-AverageReturn     | -19.9       |
| train-EnvExecTime       | 11.3        |
| train-MaxReturn         | -3.91       |
| train-MinReturn         | -74.2       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.2        |
| train-StdReturn         | 16.6        |
-----------------------------------------

 ---------------- Iteration 89 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 89           |
| ItrTime                 | 27.9         |
| LossAfter               | -2.2406356   |
| LossBefore              | -0.008622055 |
| Time                    | 2.46e+03     |
| Time-Optimization       | 1.27         |
| Time-SampleProc         | 0.0537       |
| Time-Sampling           | 26.6         |
| n_timesteps             | 900000       |
| train-AverageDiscoun... | -2.88        |
| train-AverageReturn     | -18.4        |
| train-EnvExecTime       | 11.5         |
| train-MaxReturn         | -5.02        |
| train-MinReturn         | -73.7        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.4         |
| train-StdReturn         | 15.4         |
------------------------------------------

 ---------------- Iteration 90 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 90            |
| ItrTime                 | 27.7          |
| LossAfter               | -2.3579886    |
| LossBefore              | -0.0051962403 |
| Time                    | 2.48e+03      |
| Time-Optimization       | 1.03          |
| Time-SampleProc         | 0.0378        |
| Time-Sampling           | 26.6          |
| n_timesteps             | 910000        |
| train-AverageDiscoun... | -2.11         |
| train-AverageReturn     | -16.6         |
| train-EnvExecTime       | 11.5          |
| train-MaxReturn         | -3.78         |
| train-MinReturn         | -68.3         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.4          |
| train-StdReturn         | 12.6          |
-------------------------------------------

 ---------------- Iteration 91 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 91           |
| ItrTime                 | 27.2         |
| LossAfter               | -2.4042246   |
| LossBefore              | -0.014308294 |
| Time                    | 2.51e+03     |
| Time-Optimization       | 1.05         |
| Time-SampleProc         | 0.0469       |
| Time-Sampling           | 26.1         |
| n_timesteps             | 920000       |
| train-AverageDiscoun... | -2.94        |
| train-AverageReturn     | -18.5        |
| train-EnvExecTime       | 11.3         |
| train-MaxReturn         | -5.14        |
| train-MinReturn         | -73.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 15.7         |
------------------------------------------

 ---------------- Iteration 92 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 92            |
| ItrTime                 | 27.1          |
| LossAfter               | -2.5041041    |
| LossBefore              | -0.0037861145 |
| Time                    | 2.54e+03      |
| Time-Optimization       | 1.07          |
| Time-SampleProc         | 0.038         |
| Time-Sampling           | 26            |
| n_timesteps             | 930000        |
| train-AverageDiscoun... | -3.4          |
| train-AverageReturn     | -19.6         |
| train-EnvExecTime       | 11.3          |
| train-MaxReturn         | -4.71         |
| train-MinReturn         | -75.3         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.1          |
| train-StdReturn         | 16.5          |
-------------------------------------------

 ---------------- Iteration 93 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 93          |
| ItrTime                 | 27.2        |
| LossAfter               | -2.5412252  |
| LossBefore              | 0.013238061 |
| Time                    | 2.56e+03    |
| Time-Optimization       | 1.05        |
| Time-SampleProc         | 0.0416      |
| Time-Sampling           | 26.1        |
| n_timesteps             | 940000      |
| train-AverageDiscoun... | -3.65       |
| train-AverageReturn     | -20.1       |
| train-EnvExecTime       | 11.3        |
| train-MaxReturn         | -4.9        |
| train-MinReturn         | -76.3       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 17.6        |
-----------------------------------------

 ---------------- Iteration 94 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 94          |
| ItrTime                 | 27.3        |
| LossAfter               | -2.6624968  |
| LossBefore              | -0.00925691 |
| Time                    | 2.59e+03    |
| Time-Optimization       | 1.03        |
| Time-SampleProc         | 0.0452      |
| Time-Sampling           | 26.3        |
| n_timesteps             | 950000      |
| train-AverageDiscoun... | -2.84       |
| train-AverageReturn     | -18.2       |
| train-EnvExecTime       | 11.4        |
| train-MaxReturn         | -5.01       |
| train-MinReturn         | -73         |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.2        |
| train-StdReturn         | 14.8        |
-----------------------------------------

 ---------------- Iteration 95 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 95            |
| ItrTime                 | 27.7          |
| LossAfter               | -2.635277     |
| LossBefore              | -0.0015635581 |
| Time                    | 2.62e+03      |
| Time-Optimization       | 1.08          |
| Time-SampleProc         | 0.0372        |
| Time-Sampling           | 26.5          |
| n_timesteps             | 960000        |
| train-AverageDiscoun... | -3.56         |
| train-AverageReturn     | -19.9         |
| train-EnvExecTime       | 11.5          |
| train-MaxReturn         | -5.2          |
| train-MinReturn         | -74.6         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.4          |
| train-StdReturn         | 16.2          |
-------------------------------------------

 ---------------- Iteration 96 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 96           |
| ItrTime                 | 27.2         |
| LossAfter               | -2.6691468   |
| LossBefore              | -0.016998474 |
| Time                    | 2.65e+03     |
| Time-Optimization       | 1.07         |
| Time-SampleProc         | 0.043        |
| Time-Sampling           | 26.1         |
| n_timesteps             | 970000       |
| train-AverageDiscoun... | -3.06        |
| train-AverageReturn     | -18.9        |
| train-EnvExecTime       | 11.2         |
| train-MaxReturn         | -4.47        |
| train-MinReturn         | -67.5        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 15           |
------------------------------------------

 ---------------- Iteration 97 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 97            |
| ItrTime                 | 27.1          |
| LossAfter               | -2.5933065    |
| LossBefore              | -0.0014234955 |
| Time                    | 2.67e+03      |
| Time-Optimization       | 1.07          |
| Time-SampleProc         | 0.0401        |
| Time-Sampling           | 26            |
| n_timesteps             | 980000        |
| train-AverageDiscoun... | -3.67         |
| train-AverageReturn     | -20           |
| train-EnvExecTime       | 11.2          |
| train-MaxReturn         | -4.93         |
| train-MinReturn         | -73.8         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.1          |
| train-StdReturn         | 15.7          |
-------------------------------------------

 ---------------- Iteration 98 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 98           |
| ItrTime                 | 28.3         |
| LossAfter               | -2.7449546   |
| LossBefore              | -0.025110925 |
| Time                    | 2.7e+03      |
| Time-Optimization       | 1.08         |
| Time-SampleProc         | 0.0418       |
| Time-Sampling           | 27.2         |
| n_timesteps             | 990000       |
| train-AverageDiscoun... | -3.29        |
| train-AverageReturn     | -19.3        |
| train-EnvExecTime       | 11.8         |
| train-MaxReturn         | -4.73        |
| train-MinReturn         | -74.5        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.7         |
| train-StdReturn         | 17.9         |
------------------------------------------

 ---------------- Iteration 99 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 99           |
| ItrTime                 | 27.5         |
| LossAfter               | -2.90294     |
| LossBefore              | -0.002119339 |
| Time                    | 2.73e+03     |
| Time-Optimization       | 1.07         |
| Time-SampleProc         | 0.0443       |
| Time-Sampling           | 26.4         |
| n_timesteps             | 1000000      |
| train-AverageDiscoun... | -1.9         |
| train-AverageReturn     | -16.4        |
| train-EnvExecTime       | 11.4         |
| train-MaxReturn         | -5.35        |
| train-MinReturn         | -76.5        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.3         |
| train-StdReturn         | 12.7         |
------------------------------------------

 ---------------- Iteration 100 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 100          |
| ItrTime                 | 27.7         |
| LossAfter               | -3.0172365   |
| LossBefore              | -0.003921884 |
| Time                    | 2.76e+03     |
| Time-Optimization       | 1.25         |
| Time-SampleProc         | 0.0382       |
| Time-Sampling           | 26.4         |
| n_timesteps             | 1010000      |
| train-AverageDiscoun... | -1.88        |
| train-AverageReturn     | -16.1        |
| train-EnvExecTime       | 11.4         |
| train-MaxReturn         | -4.54        |
| train-MinReturn         | -71.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.3         |
| train-StdReturn         | 12.2         |
------------------------------------------

 ---------------- Iteration 101 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 101          |
| ItrTime                 | 27.4         |
| LossAfter               | -3.1443      |
| LossBefore              | -0.014215661 |
| Time                    | 2.79e+03     |
| Time-Optimization       | 1.05         |
| Time-SampleProc         | 0.0393       |
| Time-Sampling           | 26.3         |
| n_timesteps             | 1020000      |
| train-AverageDiscoun... | -1.84        |
| train-AverageReturn     | -16.3        |
| train-EnvExecTime       | 11.3         |
| train-MaxReturn         | -4.72        |
| train-MinReturn         | -71.7        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 13.3         |
------------------------------------------

 ---------------- Iteration 102 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 102         |
| ItrTime                 | 27.3        |
| LossAfter               | -3.3878531  |
| LossBefore              | 0.017050918 |
| Time                    | 2.81e+03    |
| Time-Optimization       | 1.1         |
| Time-SampleProc         | 0.0413      |
| Time-Sampling           | 26.2        |
| n_timesteps             | 1030000     |
| train-AverageDiscoun... | -2.23       |
| train-AverageReturn     | -16.9       |
| train-EnvExecTime       | 11.3        |
| train-MaxReturn         | -4.72       |
| train-MinReturn         | -66.9       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.2        |
| train-StdReturn         | 12.7        |
-----------------------------------------

 ---------------- Iteration 103 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 103           |
| ItrTime                 | 27.2          |
| LossAfter               | -3.5825028    |
| LossBefore              | -0.0031352295 |
| Time                    | 2.84e+03      |
| Time-Optimization       | 1.08          |
| Time-SampleProc         | 0.0399        |
| Time-Sampling           | 26.1          |
| n_timesteps             | 1040000       |
| train-AverageDiscoun... | -1.26         |
| train-AverageReturn     | -15.3         |
| train-EnvExecTime       | 11.2          |
| train-MaxReturn         | -4.33         |
| train-MinReturn         | -65.3         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.1          |
| train-StdReturn         | 10.5          |
-------------------------------------------

 ---------------- Iteration 104 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 104          |
| ItrTime                 | 27.3         |
| LossAfter               | -3.7220204   |
| LossBefore              | -0.015951253 |
| Time                    | 2.87e+03     |
| Time-Optimization       | 1.08         |
| Time-SampleProc         | 0.0367       |
| Time-Sampling           | 26.2         |
| n_timesteps             | 1050000      |
| train-AverageDiscoun... | -2.38        |
| train-AverageReturn     | -17.5        |
| train-EnvExecTime       | 11.3         |
| train-MaxReturn         | -5.2         |
| train-MinReturn         | -63.5        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 12.1         |
------------------------------------------

 ---------------- Iteration 105 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 105         |
| ItrTime                 | 27.2        |
| LossAfter               | -3.9099343  |
| LossBefore              | 0.012513251 |
| Time                    | 2.89e+03    |
| Time-Optimization       | 1.08        |
| Time-SampleProc         | 0.0403      |
| Time-Sampling           | 26.1        |
| n_timesteps             | 1060000     |
| train-AverageDiscoun... | -1.9        |
| train-AverageReturn     | -16.5       |
| train-EnvExecTime       | 11.3        |
| train-MaxReturn         | -3.5        |
| train-MinReturn         | -58.4       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 11.3        |
-----------------------------------------

 ---------------- Iteration 106 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 106         |
| ItrTime                 | 27.3        |
| LossAfter               | -3.9546008  |
| LossBefore              | 0.014312713 |
| Time                    | 2.92e+03    |
| Time-Optimization       | 1.07        |
| Time-SampleProc         | 0.038       |
| Time-Sampling           | 26.2        |
| n_timesteps             | 1070000     |
| train-AverageDiscoun... | -2.16       |
| train-AverageReturn     | -17         |
| train-EnvExecTime       | 11.3        |
| train-MaxReturn         | -5.13       |
| train-MinReturn         | -75.2       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.2        |
| train-StdReturn         | 12.6        |
-----------------------------------------

 ---------------- Iteration 107 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
----------------------------------------
| Itr                     | 107        |
| ItrTime                 | 27.2       |
| LossAfter               | -4.147176  |
| LossBefore              | 0.01019973 |
| Time                    | 2.95e+03   |
| Time-Optimization       | 1.08       |
| Time-SampleProc         | 0.0358     |
| Time-Sampling           | 26.1       |
| n_timesteps             | 1080000    |
| train-AverageDiscoun... | -1.17      |
| train-AverageReturn     | -14.5      |
| train-EnvExecTime       | 11.3       |
| train-MaxReturn         | -4.26      |
| train-MinReturn         | -40        |
| train-NumTrajs          | 100        |
| train-PolicyExecTime    | 14.1       |
| train-StdReturn         | 8.35       |
----------------------------------------

 ---------------- Iteration 108 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 108          |
| ItrTime                 | 27.2         |
| LossAfter               | -4.216788    |
| LossBefore              | -0.016251892 |
| Time                    | 2.98e+03     |
| Time-Optimization       | 1.1          |
| Time-SampleProc         | 0.0572       |
| Time-Sampling           | 26.1         |
| n_timesteps             | 1090000      |
| train-AverageDiscoun... | -2.85        |
| train-AverageReturn     | -18.3        |
| train-EnvExecTime       | 11.3         |
| train-MaxReturn         | -3.52        |
| train-MinReturn         | -73          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 14.3         |
------------------------------------------

 ---------------- Iteration 109 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 109          |
| ItrTime                 | 27.3         |
| LossAfter               | -4.242447    |
| LossBefore              | -0.002573648 |
| Time                    | 3e+03        |
| Time-Optimization       | 1.06         |
| Time-SampleProc         | 0.04         |
| Time-Sampling           | 26.2         |
| n_timesteps             | 1100000      |
| train-AverageDiscoun... | -2.28        |
| train-AverageReturn     | -17          |
| train-EnvExecTime       | 11.3         |
| train-MaxReturn         | -4.66        |
| train-MinReturn         | -77.5        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 13.3         |
------------------------------------------

 ---------------- Iteration 110 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 110          |
| ItrTime                 | 27.3         |
| LossAfter               | -4.29099     |
| LossBefore              | -0.004566037 |
| Time                    | 3.03e+03     |
| Time-Optimization       | 1.06         |
| Time-SampleProc         | 0.0396       |
| Time-Sampling           | 26.2         |
| n_timesteps             | 1110000      |
| train-AverageDiscoun... | -1.47        |
| train-AverageReturn     | -15.6        |
| train-EnvExecTime       | 11.3         |
| train-MaxReturn         | -4.17        |
| train-MinReturn         | -75.9        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 10.1         |
------------------------------------------

 ---------------- Iteration 111 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 111          |
| ItrTime                 | 27.1         |
| LossAfter               | -4.2922196   |
| LossBefore              | -0.020452505 |
| Time                    | 3.06e+03     |
| Time-Optimization       | 1.05         |
| Time-SampleProc         | 0.0444       |
| Time-Sampling           | 26           |
| n_timesteps             | 1120000      |
| train-AverageDiscoun... | -1.29        |
| train-AverageReturn     | -15.1        |
| train-EnvExecTime       | 11.3         |
| train-MaxReturn         | -4.66        |
| train-MinReturn         | -73.5        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 10.9         |
------------------------------------------

 ---------------- Iteration 112 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 112          |
| ItrTime                 | 27.1         |
| LossAfter               | -4.2351103   |
| LossBefore              | -0.016904468 |
| Time                    | 3.09e+03     |
| Time-Optimization       | 1.06         |
| Time-SampleProc         | 0.0444       |
| Time-Sampling           | 26           |
| n_timesteps             | 1130000      |
| train-AverageDiscoun... | -1.94        |
| train-AverageReturn     | -16.4        |
| train-EnvExecTime       | 11.3         |
| train-MaxReturn         | -5.11        |
| train-MinReturn         | -73.4        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 12.7         |
------------------------------------------

 ---------------- Iteration 113 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 113         |
| ItrTime                 | 27.2        |
| LossAfter               | -4.1320434  |
| LossBefore              | 0.014224051 |
| Time                    | 3.11e+03    |
| Time-Optimization       | 1.09        |
| Time-SampleProc         | 0.0387      |
| Time-Sampling           | 26          |
| n_timesteps             | 1140000     |
| train-AverageDiscoun... | -2.36       |
| train-AverageReturn     | -17.9       |
| train-EnvExecTime       | 11.2        |
| train-MaxReturn         | -3.89       |
| train-MinReturn         | -68.3       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 13.1        |
-----------------------------------------

 ---------------- Iteration 114 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
----------------------------------------
| Itr                     | 114        |
| ItrTime                 | 27.4       |
| LossAfter               | -7.4040055 |
| LossBefore              | 0.01239151 |
| Time                    | 3.14e+03   |
| Time-Optimization       | 1.33       |
| Time-SampleProc         | 0.0659     |
| Time-Sampling           | 26         |
| n_timesteps             | 1150000    |
| train-AverageDiscoun... | -3.36      |
| train-AverageReturn     | -21.6      |
| train-EnvExecTime       | 11.3       |
| train-MaxReturn         | -4.67      |
| train-MinReturn         | -72.7      |
| train-NumTrajs          | 100        |
| train-PolicyExecTime    | 14         |
| train-StdReturn         | 11.7       |
----------------------------------------

 ---------------- Iteration 115 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 115          |
| ItrTime                 | 27.4         |
| LossAfter               | -10.544781   |
| LossBefore              | -0.018085442 |
| Time                    | 3.17e+03     |
| Time-Optimization       | 1.48         |
| Time-SampleProc         | 0.0608       |
| Time-Sampling           | 25.8         |
| n_timesteps             | 1160000      |
| train-AverageDiscoun... | -5.03        |
| train-AverageReturn     | -26.7        |
| train-EnvExecTime       | 11.2         |
| train-MaxReturn         | -4.61        |
| train-MinReturn         | -52.3        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14           |
| train-StdReturn         | 13           |
------------------------------------------

 ---------------- Iteration 116 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 116         |
| ItrTime                 | 27.3        |
| LossAfter               | -4.3580694  |
| LossBefore              | 0.012518601 |
| Time                    | 3.2e+03     |
| Time-Optimization       | 1.66        |
| Time-SampleProc         | 0.0344      |
| Time-Sampling           | 25.6        |
| n_timesteps             | 1170000     |
| train-AverageDiscoun... | -6.72       |
| train-AverageReturn     | -31.5       |
| train-EnvExecTime       | 11.1        |
| train-MaxReturn         | -5.69       |
| train-MinReturn         | -50.9       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 13.8        |
| train-StdReturn         | 12.7        |
-----------------------------------------

 ---------------- Iteration 117 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 117           |
| ItrTime                 | 27.2          |
| LossAfter               | -239.6509     |
| LossBefore              | -0.0033314575 |
| Time                    | 3.22e+03      |
| Time-Optimization       | 1.45          |
| Time-SampleProc         | 0.0422        |
| Time-Sampling           | 25.7          |
| n_timesteps             | 1180000       |
| train-AverageDiscoun... | -9.31         |
| train-AverageReturn     | -38.5         |
| train-EnvExecTime       | 11.2          |
| train-MaxReturn         | -4.95         |
| train-MinReturn         | -53.9         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 13.9          |
| train-StdReturn         | 11.8          |
-------------------------------------------

 ---------------- Iteration 118 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 118           |
| ItrTime                 | 27.1          |
| LossAfter               | -7418.7983    |
| LossBefore              | -0.0046641333 |
| Time                    | 3.25e+03      |
| Time-Optimization       | 1.3           |
| Time-SampleProc         | 0.0398        |
| Time-Sampling           | 25.7          |
| n_timesteps             | 1190000       |
| train-AverageDiscoun... | -9.18         |
| train-AverageReturn     | -38.2         |
| train-EnvExecTime       | 11.2          |
| train-MaxReturn         | -5.36         |
| train-MinReturn         | -51.6         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 13.9          |
| train-StdReturn         | 12.2          |
-------------------------------------------

 ---------------- Iteration 119 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 119          |
| ItrTime                 | 27           |
| LossAfter               | -2725.4414   |
| LossBefore              | -0.005658389 |
| Time                    | 3.28e+03     |
| Time-Optimization       | 1.06         |
| Time-SampleProc         | 0.0407       |
| Time-Sampling           | 25.9         |
| n_timesteps             | 1200000      |
| train-AverageDiscoun... | -9.8         |
| train-AverageReturn     | -39.7        |
| train-EnvExecTime       | 11.2         |
| train-MaxReturn         | -4.98        |
| train-MinReturn         | -53.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14           |
| train-StdReturn         | 12.1         |
------------------------------------------

 ---------------- Iteration 120 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 120         |
| ItrTime                 | 27.2        |
| LossAfter               | -2339.3386  |
| LossBefore              | 0.003647577 |
| Time                    | 3.3e+03     |
| Time-Optimization       | 1.1         |
| Time-SampleProc         | 0.0378      |
| Time-Sampling           | 26          |
| n_timesteps             | 1210000     |
| train-AverageDiscoun... | -8.85       |
| train-AverageReturn     | -37.4       |
| train-EnvExecTime       | 11.2        |
| train-MaxReturn         | -4.35       |
| train-MinReturn         | -53.2       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 14.2        |
-----------------------------------------

 ---------------- Iteration 121 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
----------------------------------------
| Itr                     | 121        |
| ItrTime                 | 27.2       |
| LossAfter               | -1752.8308 |
| LossBefore              | -0.0045218 |
| Time                    | 3.33e+03   |
| Time-Optimization       | 1.07       |
| Time-SampleProc         | 0.0477     |
| Time-Sampling           | 26.1       |
| n_timesteps             | 1220000    |
| train-AverageDiscoun... | -3.82      |
| train-AverageReturn     | -24.7      |
| train-EnvExecTime       | 11.2       |
| train-MaxReturn         | -5.19      |
| train-MinReturn         | -48.4      |
| train-NumTrajs          | 100        |
| train-PolicyExecTime    | 14.1       |
| train-StdReturn         | 10.1       |
----------------------------------------

 ---------------- Iteration 122 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 122         |
| ItrTime                 | 26.8        |
| LossAfter               | -422.75894  |
| LossBefore              | 0.009906994 |
| Time                    | 3.36e+03    |
| Time-Optimization       | 1.07        |
| Time-SampleProc         | 0.0443      |
| Time-Sampling           | 25.7        |
| n_timesteps             | 1230000     |
| train-AverageDiscoun... | 17.9        |
| train-AverageReturn     | 11.2        |
| train-EnvExecTime       | 10.8        |
| train-MaxReturn         | 101         |
| train-MinReturn         | -95.4       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.2        |
| train-StdReturn         | 38.9        |
-----------------------------------------

 ---------------- Iteration 123 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 123           |
| ItrTime                 | 26.7          |
| LossAfter               | -1345.9624    |
| LossBefore              | -0.0042134095 |
| Time                    | 3.38e+03      |
| Time-Optimization       | 1.09          |
| Time-SampleProc         | 0.0375        |
| Time-Sampling           | 25.6          |
| n_timesteps             | 1240000       |
| train-AverageDiscoun... | 21.4          |
| train-AverageReturn     | 23            |
| train-EnvExecTime       | 10.7          |
| train-MaxReturn         | 101           |
| train-MinReturn         | -24.6         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.2          |
| train-StdReturn         | 33.8          |
-------------------------------------------

 ---------------- Iteration 124 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 124           |
| ItrTime                 | 26.5          |
| LossAfter               | -1006.1708    |
| LossBefore              | -0.0036951904 |
| Time                    | 3.41e+03      |
| Time-Optimization       | 1.07          |
| Time-SampleProc         | 0.0377        |
| Time-Sampling           | 25.4          |
| n_timesteps             | 1250000       |
| train-AverageDiscoun... | 23.6          |
| train-AverageReturn     | 28.5          |
| train-EnvExecTime       | 10.7          |
| train-MaxReturn         | 105           |
| train-MinReturn         | -28.2         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.1          |
| train-StdReturn         | 35.4          |
-------------------------------------------

 ---------------- Iteration 125 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 125           |
| ItrTime                 | 26.6          |
| LossAfter               | -138.47018    |
| LossBefore              | -0.0073971925 |
| Time                    | 3.44e+03      |
| Time-Optimization       | 1.08          |
| Time-SampleProc         | 0.0391        |
| Time-Sampling           | 25.5          |
| n_timesteps             | 1260000       |
| train-AverageDiscoun... | 23.1          |
| train-AverageReturn     | 27.7          |
| train-EnvExecTime       | 10.6          |
| train-MaxReturn         | 105           |
| train-MinReturn         | -24.8         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.2          |
| train-StdReturn         | 38            |
-------------------------------------------

 ---------------- Iteration 126 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 126            |
| ItrTime                 | 27.3           |
| LossAfter               | -100.31597     |
| LossBefore              | -0.00085455325 |
| Time                    | 3.47e+03       |
| Time-Optimization       | 1.2            |
| Time-SampleProc         | 0.05           |
| Time-Sampling           | 26.1           |
| n_timesteps             | 1270000        |
| train-AverageDiscoun... | 25.7           |
| train-AverageReturn     | 33.3           |
| train-EnvExecTime       | 10.9           |
| train-MaxReturn         | 103            |
| train-MinReturn         | -16.9          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 14.5           |
| train-StdReturn         | 36.1           |
--------------------------------------------

 ---------------- Iteration 127 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 127          |
| ItrTime                 | 28.5         |
| LossAfter               | -108.5599    |
| LossBefore              | -0.014459758 |
| Time                    | 3.49e+03     |
| Time-Optimization       | 1.21         |
| Time-SampleProc         | 0.0552       |
| Time-Sampling           | 27.2         |
| n_timesteps             | 1280000      |
| train-AverageDiscoun... | 14.6         |
| train-AverageReturn     | -0.695       |
| train-EnvExecTime       | 11.3         |
| train-MaxReturn         | 106          |
| train-MinReturn         | -14.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 15.2         |
| train-StdReturn         | 15.4         |
------------------------------------------

 ---------------- Iteration 128 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 128          |
| ItrTime                 | 28.1         |
| LossAfter               | -839.5454    |
| LossBefore              | -0.016085453 |
| Time                    | 3.52e+03     |
| Time-Optimization       | 1.06         |
| Time-SampleProc         | 0.0446       |
| Time-Sampling           | 27           |
| n_timesteps             | 1290000      |
| train-AverageDiscoun... | 15.4         |
| train-AverageReturn     | 1.06         |
| train-EnvExecTime       | 11.3         |
| train-MaxReturn         | 111          |
| train-MinReturn         | -16.3        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 15           |
| train-StdReturn         | 16.8         |
------------------------------------------

 ---------------- Iteration 129 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 129           |
| ItrTime                 | 26.5          |
| LossAfter               | -4181.8247    |
| LossBefore              | -0.0026417023 |
| Time                    | 3.55e+03      |
| Time-Optimization       | 1.09          |
| Time-SampleProc         | 0.0439        |
| Time-Sampling           | 25.3          |
| n_timesteps             | 1300000       |
| train-AverageDiscoun... | 15            |
| train-AverageReturn     | 0.138         |
| train-EnvExecTime       | 10.6          |
| train-MaxReturn         | 101           |
| train-MinReturn         | -12.6         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14            |
| train-StdReturn         | 17            |
-------------------------------------------

 ---------------- Iteration 130 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 130         |
| ItrTime                 | 26.6        |
| LossAfter               | -2006.0978  |
| LossBefore              | 0.005584717 |
| Time                    | 3.58e+03    |
| Time-Optimization       | 1.05        |
| Time-SampleProc         | 0.0351      |
| Time-Sampling           | 25.6        |
| n_timesteps             | 1310000     |
| train-AverageDiscoun... | 16.5        |
| train-AverageReturn     | 4.26        |
| train-EnvExecTime       | 10.7        |
| train-MaxReturn         | 112         |
| train-MinReturn         | -11.3       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.2        |
| train-StdReturn         | 25.5        |
-----------------------------------------

 ---------------- Iteration 131 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 131          |
| ItrTime                 | 26.6         |
| LossAfter               | -671.604     |
| LossBefore              | 0.0019462837 |
| Time                    | 3.6e+03      |
| Time-Optimization       | 1.11         |
| Time-SampleProc         | 0.0433       |
| Time-Sampling           | 25.5         |
| n_timesteps             | 1320000      |
| train-AverageDiscoun... | 15           |
| train-AverageReturn     | 0.438        |
| train-EnvExecTime       | 10.7         |
| train-MaxReturn         | 104          |
| train-MinReturn         | -16.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 19.3         |
------------------------------------------

 ---------------- Iteration 132 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 132          |
| ItrTime                 | 26.3         |
| LossAfter               | -697.1077    |
| LossBefore              | 0.0027528168 |
| Time                    | 3.63e+03     |
| Time-Optimization       | 1.08         |
| Time-SampleProc         | 0.037        |
| Time-Sampling           | 25.2         |
| n_timesteps             | 1330000      |
| train-AverageDiscoun... | 94.8         |
| train-AverageReturn     | 164          |
| train-EnvExecTime       | 10.4         |
| train-MaxReturn         | 178          |
| train-MinReturn         | 144          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 7.34         |
------------------------------------------

 ---------------- Iteration 133 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 133          |
| ItrTime                 | 26.5         |
| LossAfter               | -326.45407   |
| LossBefore              | -0.006480583 |
| Time                    | 3.66e+03     |
| Time-Optimization       | 1.06         |
| Time-SampleProc         | 0.0344       |
| Time-Sampling           | 25.4         |
| n_timesteps             | 1340000      |
| train-AverageDiscoun... | 74           |
| train-AverageReturn     | 122          |
| train-EnvExecTime       | 10.5         |
| train-MaxReturn         | 154          |
| train-MinReturn         | 106          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 10.1         |
------------------------------------------

 ---------------- Iteration 134 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 134          |
| ItrTime                 | 26.7         |
| LossAfter               | -3.2710915   |
| LossBefore              | 0.0069663497 |
| Time                    | 3.68e+03     |
| Time-Optimization       | 1.64         |
| Time-SampleProc         | 0.0641       |
| Time-Sampling           | 25           |
| n_timesteps             | 1350000      |
| train-AverageDiscoun... | 73.1         |
| train-AverageReturn     | 112          |
| train-EnvExecTime       | 10.5         |
| train-MaxReturn         | 156          |
| train-MinReturn         | 63           |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.9         |
| train-StdReturn         | 14.3         |
------------------------------------------

 ---------------- Iteration 135 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 135         |
| ItrTime                 | 26.4        |
| LossAfter               | -104.53677  |
| LossBefore              | 0.001668225 |
| Time                    | 3.71e+03    |
| Time-Optimization       | 1.16        |
| Time-SampleProc         | 0.0402      |
| Time-Sampling           | 25.2        |
| n_timesteps             | 1360000     |
| train-AverageDiscoun... | 84.2        |
| train-AverageReturn     | 134         |
| train-EnvExecTime       | 10.7        |
| train-MaxReturn         | 162         |
| train-MinReturn         | 73          |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 13.8        |
| train-StdReturn         | 22.7        |
-----------------------------------------

 ---------------- Iteration 136 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 136         |
| ItrTime                 | 26.8        |
| LossAfter               | -1387.8804  |
| LossBefore              | 0.019340295 |
| Time                    | 3.74e+03    |
| Time-Optimization       | 1.08        |
| Time-SampleProc         | 0.0358      |
| Time-Sampling           | 25.7        |
| n_timesteps             | 1370000     |
| train-AverageDiscoun... | 85.6        |
| train-AverageReturn     | 145         |
| train-EnvExecTime       | 10.9        |
| train-MaxReturn         | 159         |
| train-MinReturn         | 109         |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 6.25        |
-----------------------------------------

 ---------------- Iteration 137 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 137          |
| ItrTime                 | 26.9         |
| LossAfter               | -4297.6367   |
| LossBefore              | -0.002119687 |
| Time                    | 3.76e+03     |
| Time-Optimization       | 1.08         |
| Time-SampleProc         | 0.0398       |
| Time-Sampling           | 25.8         |
| n_timesteps             | 1380000      |
| train-AverageDiscoun... | 79.5         |
| train-AverageReturn     | 135          |
| train-EnvExecTime       | 11           |
| train-MaxReturn         | 147          |
| train-MinReturn         | 117          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 4.71         |
------------------------------------------

 ---------------- Iteration 138 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 138          |
| ItrTime                 | 27.8         |
| LossAfter               | -3122.5498   |
| LossBefore              | 0.0018728699 |
| Time                    | 3.79e+03     |
| Time-Optimization       | 1.13         |
| Time-SampleProc         | 0.0332       |
| Time-Sampling           | 26.6         |
| n_timesteps             | 1390000      |
| train-AverageDiscoun... | 46           |
| train-AverageReturn     | 55.5         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 73.2         |
| train-MinReturn         | 40.1         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 7.9          |
------------------------------------------

 ---------------- Iteration 139 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 139          |
| ItrTime                 | 28.1         |
| LossAfter               | -7.312486    |
| LossBefore              | 0.0047369744 |
| Time                    | 3.82e+03     |
| Time-Optimization       | 1.06         |
| Time-SampleProc         | 0.0397       |
| Time-Sampling           | 27           |
| n_timesteps             | 1400000      |
| train-AverageDiscoun... | 45.5         |
| train-AverageReturn     | 54.5         |
| train-EnvExecTime       | 11.8         |
| train-MaxReturn         | 75.9         |
| train-MinReturn         | 41.7         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.5         |
| train-StdReturn         | 7.48         |
------------------------------------------

 ---------------- Iteration 140 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 140          |
| ItrTime                 | 27.6         |
| LossAfter               | -1.161693    |
| LossBefore              | 0.0048377533 |
| Time                    | 3.85e+03     |
| Time-Optimization       | 1.06         |
| Time-SampleProc         | 0.0415       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 1410000      |
| train-AverageDiscoun... | 43.8         |
| train-AverageReturn     | 50.6         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 76           |
| train-MinReturn         | 37.7         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 7.45         |
------------------------------------------

 ---------------- Iteration 141 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 141           |
| ItrTime                 | 27.7          |
| LossAfter               | -0.9375       |
| LossBefore              | -0.0032189179 |
| Time                    | 3.87e+03      |
| Time-Optimization       | 1.22          |
| Time-SampleProc         | 0.0377        |
| Time-Sampling           | 26.5          |
| n_timesteps             | 1420000       |
| train-AverageDiscoun... | 43.5          |
| train-AverageReturn     | 49.7          |
| train-EnvExecTime       | 11.7          |
| train-MaxReturn         | 59.5          |
| train-MinReturn         | 33.8          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.1          |
| train-StdReturn         | 5.94          |
-------------------------------------------

 ---------------- Iteration 142 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 142           |
| ItrTime                 | 27.9          |
| LossAfter               | -0.26600474   |
| LossBefore              | -0.0028088656 |
| Time                    | 3.9e+03       |
| Time-Optimization       | 1.49          |
| Time-SampleProc         | 0.0391        |
| Time-Sampling           | 26.3          |
| n_timesteps             | 1430000       |
| train-AverageDiscoun... | 42.7          |
| train-AverageReturn     | 47.8          |
| train-EnvExecTime       | 11.6          |
| train-MaxReturn         | 63.7          |
| train-MinReturn         | 31.8          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14            |
| train-StdReturn         | 6.82          |
-------------------------------------------

 ---------------- Iteration 143 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 143          |
| ItrTime                 | 27.9         |
| LossAfter               | -0.12789138  |
| LossBefore              | -0.010146523 |
| Time                    | 3.93e+03     |
| Time-Optimization       | 1.7          |
| Time-SampleProc         | 0.0428       |
| Time-Sampling           | 26.1         |
| n_timesteps             | 1440000      |
| train-AverageDiscoun... | 42.4         |
| train-AverageReturn     | 47           |
| train-EnvExecTime       | 11.5         |
| train-MaxReturn         | 59.2         |
| train-MinReturn         | 33.9         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.9         |
| train-StdReturn         | 6.65         |
------------------------------------------

 ---------------- Iteration 144 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 144           |
| ItrTime                 | 27.7          |
| LossAfter               | -0.06448813   |
| LossBefore              | 0.00058222807 |
| Time                    | 3.96e+03      |
| Time-Optimization       | 1.46          |
| Time-SampleProc         | 0.066         |
| Time-Sampling           | 26.2          |
| n_timesteps             | 1450000       |
| train-AverageDiscoun... | 41.7          |
| train-AverageReturn     | 45.5          |
| train-EnvExecTime       | 11.6          |
| train-MaxReturn         | 61.3          |
| train-MinReturn         | 32.5          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 13.9          |
| train-StdReturn         | 6.2           |
-------------------------------------------

 ---------------- Iteration 145 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 145          |
| ItrTime                 | 28           |
| LossAfter               | -0.025893731 |
| LossBefore              | 0.0077679153 |
| Time                    | 3.99e+03     |
| Time-Optimization       | 1.09         |
| Time-SampleProc         | 0.0419       |
| Time-Sampling           | 26.9         |
| n_timesteps             | 1460000      |
| train-AverageDiscoun... | 42.2         |
| train-AverageReturn     | 46.7         |
| train-EnvExecTime       | 11.9         |
| train-MaxReturn         | 59.4         |
| train-MinReturn         | 32.4         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.3         |
| train-StdReturn         | 6.5          |
------------------------------------------

 ---------------- Iteration 146 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 146          |
| ItrTime                 | 27.5         |
| LossAfter               | -0.030719575 |
| LossBefore              | -0.014914262 |
| Time                    | 4.01e+03     |
| Time-Optimization       | 1.06         |
| Time-SampleProc         | 0.0417       |
| Time-Sampling           | 26.4         |
| n_timesteps             | 1470000      |
| train-AverageDiscoun... | 41.9         |
| train-AverageReturn     | 46           |
| train-EnvExecTime       | 11.6         |
| train-MaxReturn         | 59.3         |
| train-MinReturn         | 33.2         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 6.32         |
------------------------------------------

 ---------------- Iteration 147 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 147          |
| ItrTime                 | 27.6         |
| LossAfter               | -0.029900031 |
| LossBefore              | -0.023684565 |
| Time                    | 4.04e+03     |
| Time-Optimization       | 1.05         |
| Time-SampleProc         | 0.0487       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 1480000      |
| train-AverageDiscoun... | 42           |
| train-AverageReturn     | 46.4         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 62.7         |
| train-MinReturn         | 33.2         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 7.01         |
------------------------------------------

 ---------------- Iteration 148 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 148         |
| ItrTime                 | 27.5        |
| LossAfter               | 0.012219004 |
| LossBefore              | 0.013834234 |
| Time                    | 4.07e+03    |
| Time-Optimization       | 1.06        |
| Time-SampleProc         | 0.0398      |
| Time-Sampling           | 26.4        |
| n_timesteps             | 1490000     |
| train-AverageDiscoun... | 42.5        |
| train-AverageReturn     | 47.4        |
| train-EnvExecTime       | 11.6        |
| train-MaxReturn         | 63          |
| train-MinReturn         | 34.4        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 6.16        |
-----------------------------------------

 ---------------- Iteration 149 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 149         |
| ItrTime                 | 27.5        |
| LossAfter               | -0.03009604 |
| LossBefore              | -0.02844428 |
| Time                    | 4.1e+03     |
| Time-Optimization       | 1.09        |
| Time-SampleProc         | 0.0437      |
| Time-Sampling           | 26.4        |
| n_timesteps             | 1500000     |
| train-AverageDiscoun... | 42.2        |
| train-AverageReturn     | 46.8        |
| train-EnvExecTime       | 11.6        |
| train-MaxReturn         | 59.9        |
| train-MinReturn         | 32.2        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14          |
| train-StdReturn         | 6.72        |
-----------------------------------------

 ---------------- Iteration 150 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 150          |
| ItrTime                 | 27.6         |
| LossAfter               | -0.015807837 |
| LossBefore              | -0.014957013 |
| Time                    | 4.12e+03     |
| Time-Optimization       | 1.08         |
| Time-SampleProc         | 0.0458       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 1510000      |
| train-AverageDiscoun... | 41.9         |
| train-AverageReturn     | 46           |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 58.8         |
| train-MinReturn         | 33           |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 6.49         |
------------------------------------------

 ---------------- Iteration 151 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 151          |
| ItrTime                 | 27.5         |
| LossAfter               | -0.008408557 |
| LossBefore              | -0.007921487 |
| Time                    | 4.15e+03     |
| Time-Optimization       | 1.09         |
| Time-SampleProc         | 0.0409       |
| Time-Sampling           | 26.3         |
| n_timesteps             | 1520000      |
| train-AverageDiscoun... | 42.1         |
| train-AverageReturn     | 46.3         |
| train-EnvExecTime       | 11.6         |
| train-MaxReturn         | 58.5         |
| train-MinReturn         | 36.5         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14           |
| train-StdReturn         | 5.69         |
------------------------------------------

 ---------------- Iteration 152 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 152          |
| ItrTime                 | 27.6         |
| LossAfter               | -0.015389999 |
| LossBefore              | -0.014801154 |
| Time                    | 4.18e+03     |
| Time-Optimization       | 1.07         |
| Time-SampleProc         | 0.0342       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 1530000      |
| train-AverageDiscoun... | 42.4         |
| train-AverageReturn     | 47.2         |
| train-EnvExecTime       | 11.6         |
| train-MaxReturn         | 59           |
| train-MinReturn         | 34.9         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 6.42         |
------------------------------------------

 ---------------- Iteration 153 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 153          |
| ItrTime                 | 27.6         |
| LossAfter               | -0.011727113 |
| LossBefore              | -0.01142221  |
| Time                    | 4.21e+03     |
| Time-Optimization       | 1.06         |
| Time-SampleProc         | 0.0439       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 1540000      |
| train-AverageDiscoun... | 42           |
| train-AverageReturn     | 46.2         |
| train-EnvExecTime       | 11.6         |
| train-MaxReturn         | 60.6         |
| train-MinReturn         | 35.2         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 6.33         |
------------------------------------------

 ---------------- Iteration 154 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 154         |
| ItrTime                 | 27.6        |
| LossAfter               | 0.006290403 |
| LossBefore              | 0.00667478  |
| Time                    | 4.23e+03    |
| Time-Optimization       | 1.07        |
| Time-SampleProc         | 0.0374      |
| Time-Sampling           | 26.5        |
| n_timesteps             | 1550000     |
| train-AverageDiscoun... | 42.1        |
| train-AverageReturn     | 46.5        |
| train-EnvExecTime       | 11.6        |
| train-MaxReturn         | 59.3        |
| train-MinReturn         | 36.2        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 6.52        |
-----------------------------------------

 ---------------- Iteration 155 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 155          |
| ItrTime                 | 27.5         |
| LossAfter               | 0.0010867988 |
| LossBefore              | 0.001450665  |
| Time                    | 4.26e+03     |
| Time-Optimization       | 1.05         |
| Time-SampleProc         | 0.0467       |
| Time-Sampling           | 26.4         |
| n_timesteps             | 1560000      |
| train-AverageDiscoun... | 42.4         |
| train-AverageReturn     | 47.2         |
| train-EnvExecTime       | 11.6         |
| train-MaxReturn         | 61.1         |
| train-MinReturn         | 34.9         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 6.33         |
------------------------------------------

 ---------------- Iteration 156 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 156          |
| ItrTime                 | 27.6         |
| LossAfter               | 0.001737912  |
| LossBefore              | 0.0019328797 |
| Time                    | 4.29e+03     |
| Time-Optimization       | 1.06         |
| Time-SampleProc         | 0.0475       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 1570000      |
| train-AverageDiscoun... | 42.1         |
| train-AverageReturn     | 46.5         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 60.5         |
| train-MinReturn         | 35.5         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 6.19         |
------------------------------------------

 ---------------- Iteration 157 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 157         |
| ItrTime                 | 27.4        |
| LossAfter               | 0.012965811 |
| LossBefore              | 0.013431215 |
| Time                    | 4.32e+03    |
| Time-Optimization       | 1.06        |
| Time-SampleProc         | 0.0427      |
| Time-Sampling           | 26.3        |
| n_timesteps             | 1580000     |
| train-AverageDiscoun... | 42.6        |
| train-AverageReturn     | 47.7        |
| train-EnvExecTime       | 11.6        |
| train-MaxReturn         | 71.5        |
| train-MinReturn         | 32.7        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14          |
| train-StdReturn         | 7.1         |
-----------------------------------------

 ---------------- Iteration 158 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 158          |
| ItrTime                 | 27.6         |
| LossAfter               | 0.002275305  |
| LossBefore              | 0.0028612243 |
| Time                    | 4.34e+03     |
| Time-Optimization       | 1.07         |
| Time-SampleProc         | 0.0364       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 1590000      |
| train-AverageDiscoun... | 42           |
| train-AverageReturn     | 46.2         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 60.5         |
| train-MinReturn         | 33.8         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 6.48         |
------------------------------------------

 ---------------- Iteration 159 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 159          |
| ItrTime                 | 27.6         |
| LossAfter               | -0.01181987  |
| LossBefore              | -0.011544431 |
| Time                    | 4.37e+03     |
| Time-Optimization       | 1.05         |
| Time-SampleProc         | 0.0413       |
| Time-Sampling           | 26.6         |
| n_timesteps             | 1600000      |
| train-AverageDiscoun... | 42.2         |
| train-AverageReturn     | 46.8         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 59.9         |
| train-MinReturn         | 34.6         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 6            |
------------------------------------------

 ---------------- Iteration 160 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 160          |
| ItrTime                 | 27.6         |
| LossAfter               | 0.0013583862 |
| LossBefore              | 0.0014605857 |
| Time                    | 4.4e+03      |
| Time-Optimization       | 1.08         |
| Time-SampleProc         | 0.0399       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 1610000      |
| train-AverageDiscoun... | 42.7         |
| train-AverageReturn     | 47.8         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 61.7         |
| train-MinReturn         | 34.7         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 6.79         |
------------------------------------------

 ---------------- Iteration 161 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 161          |
| ItrTime                 | 28.1         |
| LossAfter               | 0.0065832557 |
| LossBefore              | 0.0069942162 |
| Time                    | 4.43e+03     |
| Time-Optimization       | 1.03         |
| Time-SampleProc         | 0.0385       |
| Time-Sampling           | 27           |
| n_timesteps             | 1620000      |
| train-AverageDiscoun... | 42.4         |
| train-AverageReturn     | 47.1         |
| train-EnvExecTime       | 11.8         |
| train-MaxReturn         | 67.6         |
| train-MinReturn         | 33.1         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.5         |
| train-StdReturn         | 6.29         |
------------------------------------------

 ---------------- Iteration 162 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 162          |
| ItrTime                 | 27.6         |
| LossAfter               | -0.017072117 |
| LossBefore              | -0.016859895 |
| Time                    | 4.46e+03     |
| Time-Optimization       | 1.06         |
| Time-SampleProc         | 0.0402       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 1630000      |
| train-AverageDiscoun... | 42.3         |
| train-AverageReturn     | 47           |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 61.8         |
| train-MinReturn         | 34.5         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 6.63         |
------------------------------------------

 ---------------- Iteration 163 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 163          |
| ItrTime                 | 27.5         |
| LossAfter               | -0.02212493  |
| LossBefore              | -0.021340674 |
| Time                    | 4.48e+03     |
| Time-Optimization       | 1.07         |
| Time-SampleProc         | 0.043        |
| Time-Sampling           | 26.4         |
| n_timesteps             | 1640000      |
| train-AverageDiscoun... | 41.7         |
| train-AverageReturn     | 45.7         |
| train-EnvExecTime       | 11.6         |
| train-MaxReturn         | 58.3         |
| train-MinReturn         | 33.4         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 6.47         |
------------------------------------------

 ---------------- Iteration 164 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 164           |
| ItrTime                 | 27.5          |
| LossAfter               | -0.0029132874 |
| LossBefore              | -0.0027417908 |
| Time                    | 4.51e+03      |
| Time-Optimization       | 1.1           |
| Time-SampleProc         | 0.0383        |
| Time-Sampling           | 26.3          |
| n_timesteps             | 1650000       |
| train-AverageDiscoun... | 42.1          |
| train-AverageReturn     | 46.6          |
| train-EnvExecTime       | 11.6          |
| train-MaxReturn         | 59.5          |
| train-MinReturn         | 36.6          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.1          |
| train-StdReturn         | 6.33          |
-------------------------------------------

 ---------------- Iteration 165 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 165          |
| ItrTime                 | 27.6         |
| LossAfter               | -0.012463433 |
| LossBefore              | -0.012364139 |
| Time                    | 4.54e+03     |
| Time-Optimization       | 1.06         |
| Time-SampleProc         | 0.0355       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 1660000      |
| train-AverageDiscoun... | 42.5         |
| train-AverageReturn     | 47.4         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 71.7         |
| train-MinReturn         | 32.4         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14           |
| train-StdReturn         | 7.14         |
------------------------------------------

 ---------------- Iteration 166 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 166          |
| ItrTime                 | 27.8         |
| LossAfter               | 0.002580197  |
| LossBefore              | 0.0030327302 |
| Time                    | 4.57e+03     |
| Time-Optimization       | 1.07         |
| Time-SampleProc         | 0.0435       |
| Time-Sampling           | 26.6         |
| n_timesteps             | 1670000      |
| train-AverageDiscoun... | 42.2         |
| train-AverageReturn     | 46.6         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 59.1         |
| train-MinReturn         | 32.9         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.3         |
| train-StdReturn         | 6.56         |
------------------------------------------

 ---------------- Iteration 167 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 167          |
| ItrTime                 | 27.7         |
| LossAfter               | 0.0077657173 |
| LossBefore              | 0.008008647  |
| Time                    | 4.59e+03     |
| Time-Optimization       | 1.08         |
| Time-SampleProc         | 0.0407       |
| Time-Sampling           | 26.6         |
| n_timesteps             | 1680000      |
| train-AverageDiscoun... | 41.9         |
| train-AverageReturn     | 46           |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 59           |
| train-MinReturn         | 35           |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 6.32         |
------------------------------------------

 ---------------- Iteration 168 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 168           |
| ItrTime                 | 27.6          |
| LossAfter               | -0.0030858596 |
| LossBefore              | -0.0028608185 |
| Time                    | 4.62e+03      |
| Time-Optimization       | 1.07          |
| Time-SampleProc         | 0.036         |
| Time-Sampling           | 26.5          |
| n_timesteps             | 1690000       |
| train-AverageDiscoun... | 42.5          |
| train-AverageReturn     | 47.4          |
| train-EnvExecTime       | 11.7          |
| train-MaxReturn         | 68.9          |
| train-MinReturn         | 32.5          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.1          |
| train-StdReturn         | 6.46          |
-------------------------------------------

 ---------------- Iteration 169 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 169          |
| ItrTime                 | 27.6         |
| LossAfter               | -0.01523544  |
| LossBefore              | -0.015029245 |
| Time                    | 4.65e+03     |
| Time-Optimization       | 1.09         |
| Time-SampleProc         | 0.0341       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 1700000      |
| train-AverageDiscoun... | 42.1         |
| train-AverageReturn     | 46.6         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 58.9         |
| train-MinReturn         | 33           |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 6.22         |
------------------------------------------

 ---------------- Iteration 170 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 170           |
| ItrTime                 | 27.5          |
| LossAfter               | -0.0058144927 |
| LossBefore              | -0.005235648  |
| Time                    | 4.68e+03      |
| Time-Optimization       | 1.09          |
| Time-SampleProc         | 0.0444        |
| Time-Sampling           | 26.3          |
| n_timesteps             | 1710000       |
| train-AverageDiscoun... | 41.5          |
| train-AverageReturn     | 45.2          |
| train-EnvExecTime       | 11.6          |
| train-MaxReturn         | 60.3          |
| train-MinReturn         | 34.6          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.1          |
| train-StdReturn         | 6.39          |
-------------------------------------------

 ---------------- Iteration 171 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 171          |
| ItrTime                 | 27.6         |
| LossAfter               | 0.0012345428 |
| LossBefore              | 0.0013471802 |
| Time                    | 4.7e+03      |
| Time-Optimization       | 1.07         |
| Time-SampleProc         | 0.0423       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 1720000      |
| train-AverageDiscoun... | 42.1         |
| train-AverageReturn     | 46.5         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 59.8         |
| train-MinReturn         | 33.9         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14           |
| train-StdReturn         | 6.9          |
------------------------------------------

 ---------------- Iteration 172 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 172          |
| ItrTime                 | 27.6         |
| LossAfter               | -0.009179055 |
| LossBefore              | -0.008959211 |
| Time                    | 4.73e+03     |
| Time-Optimization       | 1.06         |
| Time-SampleProc         | 0.0441       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 1730000      |
| train-AverageDiscoun... | 42.1         |
| train-AverageReturn     | 46.5         |
| train-EnvExecTime       | 11.6         |
| train-MaxReturn         | 60.3         |
| train-MinReturn         | 34.5         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 5.89         |
------------------------------------------

 ---------------- Iteration 173 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 173         |
| ItrTime                 | 27.6        |
| LossAfter               | 0.015395922 |
| LossBefore              | 0.015726907 |
| Time                    | 4.76e+03    |
| Time-Optimization       | 1.09        |
| Time-SampleProc         | 0.0382      |
| Time-Sampling           | 26.5        |
| n_timesteps             | 1740000     |
| train-AverageDiscoun... | 42.4        |
| train-AverageReturn     | 47.1        |
| train-EnvExecTime       | 11.7        |
| train-MaxReturn         | 60.9        |
| train-MinReturn         | 35.5        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 6.23        |
-----------------------------------------

 ---------------- Iteration 174 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 174          |
| ItrTime                 | 27.5         |
| LossAfter               | -0.011003433 |
| LossBefore              | -0.010771577 |
| Time                    | 4.79e+03     |
| Time-Optimization       | 1.06         |
| Time-SampleProc         | 0.0397       |
| Time-Sampling           | 26.4         |
| n_timesteps             | 1750000      |
| train-AverageDiscoun... | 41.9         |
| train-AverageReturn     | 46.1         |
| train-EnvExecTime       | 11.6         |
| train-MaxReturn         | 58.3         |
| train-MinReturn         | 34.7         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 5.97         |
------------------------------------------

 ---------------- Iteration 175 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 175          |
| ItrTime                 | 27.7         |
| LossAfter               | -0.021614127 |
| LossBefore              | -0.021383744 |
| Time                    | 4.81e+03     |
| Time-Optimization       | 1.08         |
| Time-SampleProc         | 0.0421       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 1760000      |
| train-AverageDiscoun... | 42.1         |
| train-AverageReturn     | 46.5         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 59.8         |
| train-MinReturn         | 33.7         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 6.35         |
------------------------------------------

 ---------------- Iteration 176 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 176          |
| ItrTime                 | 27.6         |
| LossAfter               | 0.0111813275 |
| LossBefore              | 0.011625143  |
| Time                    | 4.84e+03     |
| Time-Optimization       | 1.08         |
| Time-SampleProc         | 0.0386       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 1770000      |
| train-AverageDiscoun... | 41.8         |
| train-AverageReturn     | 45.7         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 58.7         |
| train-MinReturn         | 34.7         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 5.78         |
------------------------------------------

 ---------------- Iteration 177 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 177         |
| ItrTime                 | 27.5        |
| LossAfter               | 0.037324987 |
| LossBefore              | 0.037616644 |
| Time                    | 4.87e+03    |
| Time-Optimization       | 1.08        |
| Time-SampleProc         | 0.0431      |
| Time-Sampling           | 26.4        |
| n_timesteps             | 1780000     |
| train-AverageDiscoun... | 41.9        |
| train-AverageReturn     | 45.9        |
| train-EnvExecTime       | 11.6        |
| train-MaxReturn         | 59.6        |
| train-MinReturn         | 35.9        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 6.15        |
-----------------------------------------

 ---------------- Iteration 178 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 178         |
| ItrTime                 | 27.6        |
| LossAfter               | 0.016818963 |
| LossBefore              | 0.017002152 |
| Time                    | 4.9e+03     |
| Time-Optimization       | 1.07        |
| Time-SampleProc         | 0.0358      |
| Time-Sampling           | 26.5        |
| n_timesteps             | 1790000     |
| train-AverageDiscoun... | 41.9        |
| train-AverageReturn     | 46.1        |
| train-EnvExecTime       | 11.7        |
| train-MaxReturn         | 61.4        |
| train-MinReturn         | 32.9        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.2        |
| train-StdReturn         | 6.35        |
-----------------------------------------

 ---------------- Iteration 179 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 179          |
| ItrTime                 | 27.6         |
| LossAfter               | -0.012699294 |
| LossBefore              | -0.012526493 |
| Time                    | 4.93e+03     |
| Time-Optimization       | 1.07         |
| Time-SampleProc         | 0.042        |
| Time-Sampling           | 26.5         |
| n_timesteps             | 1800000      |
| train-AverageDiscoun... | 42.3         |
| train-AverageReturn     | 47           |
| train-EnvExecTime       | 11.6         |
| train-MaxReturn         | 66.3         |
| train-MinReturn         | 35.2         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 6.3          |
------------------------------------------

 ---------------- Iteration 180 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 180         |
| ItrTime                 | 27.6        |
| LossAfter               | 0.010897646 |
| LossBefore              | 0.011355129 |
| Time                    | 4.95e+03    |
| Time-Optimization       | 1.11        |
| Time-SampleProc         | 0.0432      |
| Time-Sampling           | 26.5        |
| n_timesteps             | 1810000     |
| train-AverageDiscoun... | 42.1        |
| train-AverageReturn     | 46.4        |
| train-EnvExecTime       | 11.6        |
| train-MaxReturn         | 57.6        |
| train-MinReturn         | 34.2        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 5.93        |
-----------------------------------------

 ---------------- Iteration 181 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 181          |
| ItrTime                 | 27.5         |
| LossAfter               | -0.005133041 |
| LossBefore              | -0.004998355 |
| Time                    | 4.98e+03     |
| Time-Optimization       | 1.08         |
| Time-SampleProc         | 0.0425       |
| Time-Sampling           | 26.4         |
| n_timesteps             | 1820000      |
| train-AverageDiscoun... | 41.9         |
| train-AverageReturn     | 45.9         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 60.7         |
| train-MinReturn         | 33.5         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 6.13         |
------------------------------------------

 ---------------- Iteration 182 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 182          |
| ItrTime                 | 27.6         |
| LossAfter               | -0.006474237 |
| LossBefore              | -0.006112033 |
| Time                    | 5.01e+03     |
| Time-Optimization       | 1.06         |
| Time-SampleProc         | 0.0413       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 1830000      |
| train-AverageDiscoun... | 42.5         |
| train-AverageReturn     | 47.3         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 60.3         |
| train-MinReturn         | 32.8         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 6.65         |
------------------------------------------

 ---------------- Iteration 183 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 183          |
| ItrTime                 | 27.7         |
| LossAfter               | -0.009521231 |
| LossBefore              | -0.009083369 |
| Time                    | 5.04e+03     |
| Time-Optimization       | 1.1          |
| Time-SampleProc         | 0.0425       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 1840000      |
| train-AverageDiscoun... | 41.7         |
| train-AverageReturn     | 45.6         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 58.5         |
| train-MinReturn         | 30.7         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 6.21         |
------------------------------------------

 ---------------- Iteration 184 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 184          |
| ItrTime                 | 27.7         |
| LossAfter               | -0.007986427 |
| LossBefore              | -0.007854488 |
| Time                    | 5.06e+03     |
| Time-Optimization       | 1.08         |
| Time-SampleProc         | 0.0429       |
| Time-Sampling           | 26.6         |
| n_timesteps             | 1850000      |
| train-AverageDiscoun... | 42.3         |
| train-AverageReturn     | 46.9         |
| train-EnvExecTime       | 11.6         |
| train-MaxReturn         | 67.5         |
| train-MinReturn         | 36.5         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 6.92         |
------------------------------------------

 ---------------- Iteration 185 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 185          |
| ItrTime                 | 27.6         |
| LossAfter               | -0.008200255 |
| LossBefore              | -0.007893118 |
| Time                    | 5.09e+03     |
| Time-Optimization       | 1.06         |
| Time-SampleProc         | 0.0394       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 1860000      |
| train-AverageDiscoun... | 41.9         |
| train-AverageReturn     | 46           |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 60.2         |
| train-MinReturn         | 30.3         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 6.23         |
------------------------------------------

 ---------------- Iteration 186 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 186          |
| ItrTime                 | 27.5         |
| LossAfter               | 0.0048347837 |
| LossBefore              | 0.0049320403 |
| Time                    | 5.12e+03     |
| Time-Optimization       | 1.08         |
| Time-SampleProc         | 0.045        |
| Time-Sampling           | 26.4         |
| n_timesteps             | 1870000      |
| train-AverageDiscoun... | 42           |
| train-AverageReturn     | 46.3         |
| train-EnvExecTime       | 11.6         |
| train-MaxReturn         | 59.3         |
| train-MinReturn         | 33.1         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14           |
| train-StdReturn         | 6.42         |
------------------------------------------

 ---------------- Iteration 187 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 187          |
| ItrTime                 | 27.5         |
| LossAfter               | -0.008623039 |
| LossBefore              | -0.008112424 |
| Time                    | 5.15e+03     |
| Time-Optimization       | 1.07         |
| Time-SampleProc         | 0.0434       |
| Time-Sampling           | 26.4         |
| n_timesteps             | 1880000      |
| train-AverageDiscoun... | 42.1         |
| train-AverageReturn     | 46.6         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 60.4         |
| train-MinReturn         | 34.2         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14           |
| train-StdReturn         | 6.29         |
------------------------------------------

 ---------------- Iteration 188 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 188          |
| ItrTime                 | 27.8         |
| LossAfter               | -0.009715576 |
| LossBefore              | -0.009483594 |
| Time                    | 5.17e+03     |
| Time-Optimization       | 1.06         |
| Time-SampleProc         | 0.0435       |
| Time-Sampling           | 26.7         |
| n_timesteps             | 1890000      |
| train-AverageDiscoun... | 42.1         |
| train-AverageReturn     | 46.6         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 60.4         |
| train-MinReturn         | 36.4         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 6.41         |
------------------------------------------

 ---------------- Iteration 189 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 189          |
| ItrTime                 | 27.6         |
| LossAfter               | -0.013457559 |
| LossBefore              | -0.012898906 |
| Time                    | 5.2e+03      |
| Time-Optimization       | 1.07         |
| Time-SampleProc         | 0.0406       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 1900000      |
| train-AverageDiscoun... | 42.2         |
| train-AverageReturn     | 46.7         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 59.9         |
| train-MinReturn         | 32.3         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 6.41         |
------------------------------------------

 ---------------- Iteration 190 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 190           |
| ItrTime                 | 27.6          |
| LossAfter               | -0.009735275  |
| LossBefore              | -0.0094872555 |
| Time                    | 5.23e+03      |
| Time-Optimization       | 1.06          |
| Time-SampleProc         | 0.0387        |
| Time-Sampling           | 26.5          |
| n_timesteps             | 1910000       |
| train-AverageDiscoun... | 41.6          |
| train-AverageReturn     | 45.5          |
| train-EnvExecTime       | 11.7          |
| train-MaxReturn         | 59.3          |
| train-MinReturn         | 34.7          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.1          |
| train-StdReturn         | 5.69          |
-------------------------------------------

 ---------------- Iteration 191 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 191         |
| ItrTime                 | 27.6        |
| LossAfter               | 0.005483014 |
| LossBefore              | 0.005684149 |
| Time                    | 5.26e+03    |
| Time-Optimization       | 1.09        |
| Time-SampleProc         | 0.0385      |
| Time-Sampling           | 26.5        |
| n_timesteps             | 1920000     |
| train-AverageDiscoun... | 42          |
| train-AverageReturn     | 46.2        |
| train-EnvExecTime       | 11.7        |
| train-MaxReturn         | 60.1        |
| train-MinReturn         | 34.7        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 6.56        |
-----------------------------------------

 ---------------- Iteration 192 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 192         |
| ItrTime                 | 27.5        |
| LossAfter               | 0.023229554 |
| LossBefore              | 0.023600033 |
| Time                    | 5.28e+03    |
| Time-Optimization       | 1.07        |
| Time-SampleProc         | 0.042       |
| Time-Sampling           | 26.4        |
| n_timesteps             | 1930000     |
| train-AverageDiscoun... | 41.9        |
| train-AverageReturn     | 46.1        |
| train-EnvExecTime       | 11.6        |
| train-MaxReturn         | 59          |
| train-MinReturn         | 30.9        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 6.56        |
-----------------------------------------

 ---------------- Iteration 193 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 193           |
| ItrTime                 | 27.5          |
| LossAfter               | -0.003000441  |
| LossBefore              | -0.0028163728 |
| Time                    | 5.31e+03      |
| Time-Optimization       | 1.09          |
| Time-SampleProc         | 0.0375        |
| Time-Sampling           | 26.4          |
| n_timesteps             | 1940000       |
| train-AverageDiscoun... | 41.8          |
| train-AverageReturn     | 45.7          |
| train-EnvExecTime       | 11.7          |
| train-MaxReturn         | 59.4          |
| train-MinReturn         | 33.4          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.1          |
| train-StdReturn         | 6.81          |
-------------------------------------------

 ---------------- Iteration 194 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 194         |
| ItrTime                 | 27.6        |
| LossAfter               | 0.026456766 |
| LossBefore              | 0.026668385 |
| Time                    | 5.34e+03    |
| Time-Optimization       | 1.05        |
| Time-SampleProc         | 0.0362      |
| Time-Sampling           | 26.5        |
| n_timesteps             | 1950000     |
| train-AverageDiscoun... | 42.2        |
| train-AverageReturn     | 46.7        |
| train-EnvExecTime       | 11.6        |
| train-MaxReturn         | 61.7        |
| train-MinReturn         | 32.4        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 6.56        |
-----------------------------------------

 ---------------- Iteration 195 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 195           |
| ItrTime                 | 27.5          |
| LossAfter               | -0.0022539764 |
| LossBefore              | -0.001590715  |
| Time                    | 5.37e+03      |
| Time-Optimization       | 1.06          |
| Time-SampleProc         | 0.0372        |
| Time-Sampling           | 26.4          |
| n_timesteps             | 1960000       |
| train-AverageDiscoun... | 41.9          |
| train-AverageReturn     | 46            |
| train-EnvExecTime       | 11.6          |
| train-MaxReturn         | 64.2          |
| train-MinReturn         | 33.4          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.1          |
| train-StdReturn         | 6.7           |
-------------------------------------------

 ---------------- Iteration 196 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 196         |
| ItrTime                 | 27.5        |
| LossAfter               | 0.006536915 |
| LossBefore              | 0.006737113 |
| Time                    | 5.4e+03     |
| Time-Optimization       | 1.07        |
| Time-SampleProc         | 0.0456      |
| Time-Sampling           | 26.4        |
| n_timesteps             | 1970000     |
| train-AverageDiscoun... | 42.3        |
| train-AverageReturn     | 46.9        |
| train-EnvExecTime       | 11.6        |
| train-MaxReturn         | 60.3        |
| train-MinReturn         | 33.6        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 6.73        |
-----------------------------------------

 ---------------- Iteration 197 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 197           |
| ItrTime                 | 27.6          |
| LossAfter               | -0.0029016717 |
| LossBefore              | -0.0024795167 |
| Time                    | 5.42e+03      |
| Time-Optimization       | 1.09          |
| Time-SampleProc         | 0.0433        |
| Time-Sampling           | 26.5          |
| n_timesteps             | 1980000       |
| train-AverageDiscoun... | 42.4          |
| train-AverageReturn     | 47.2          |
| train-EnvExecTime       | 11.6          |
| train-MaxReturn         | 58.9          |
| train-MinReturn         | 32.6          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.2          |
| train-StdReturn         | 6.65          |
-------------------------------------------

 ---------------- Iteration 198 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 198         |
| ItrTime                 | 27.5        |
| LossAfter               | 0.016223093 |
| LossBefore              | 0.016404489 |
| Time                    | 5.45e+03    |
| Time-Optimization       | 1.07        |
| Time-SampleProc         | 0.0401      |
| Time-Sampling           | 26.4        |
| n_timesteps             | 1990000     |
| train-AverageDiscoun... | 41.9        |
| train-AverageReturn     | 46          |
| train-EnvExecTime       | 11.7        |
| train-MaxReturn         | 61.3        |
| train-MinReturn         | 34.8        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14          |
| train-StdReturn         | 6.7         |
-----------------------------------------

 ---------------- Iteration 199 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 199          |
| ItrTime                 | 27.5         |
| LossAfter               | -0.016381158 |
| LossBefore              | -0.015613971 |
| Time                    | 5.48e+03     |
| Time-Optimization       | 1.08         |
| Time-SampleProc         | 0.0391       |
| Time-Sampling           | 26.4         |
| n_timesteps             | 2000000      |
| train-AverageDiscoun... | 42.2         |
| train-AverageReturn     | 46.6         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 59.2         |
| train-MinReturn         | 34.8         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14           |
| train-StdReturn         | 6.41         |
------------------------------------------

 ---------------- Iteration 200 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 200         |
| ItrTime                 | 27.5        |
| LossAfter               | 0.017110687 |
| LossBefore              | 0.017321164 |
| Time                    | 5.51e+03    |
| Time-Optimization       | 1.05        |
| Time-SampleProc         | 0.0446      |
| Time-Sampling           | 26.4        |
| n_timesteps             | 2010000     |
| train-AverageDiscoun... | 42.1        |
| train-AverageReturn     | 46.4        |
| train-EnvExecTime       | 11.6        |
| train-MaxReturn         | 60.4        |
| train-MinReturn         | 32.5        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 6.68        |
-----------------------------------------

 ---------------- Iteration 201 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 201          |
| ItrTime                 | 27.5         |
| LossAfter               | -0.018828304 |
| LossBefore              | -0.018530434 |
| Time                    | 5.53e+03     |
| Time-Optimization       | 1.08         |
| Time-SampleProc         | 0.0478       |
| Time-Sampling           | 26.4         |
| n_timesteps             | 2020000      |
| train-AverageDiscoun... | 42.2         |
| train-AverageReturn     | 46.6         |
| train-EnvExecTime       | 11.6         |
| train-MaxReturn         | 64.6         |
| train-MinReturn         | 34.2         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 6.91         |
------------------------------------------

 ---------------- Iteration 202 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 202         |
| ItrTime                 | 27.7        |
| LossAfter               | 0.022471795 |
| LossBefore              | 0.022769148 |
| Time                    | 5.56e+03    |
| Time-Optimization       | 1.08        |
| Time-SampleProc         | 0.0382      |
| Time-Sampling           | 26.5        |
| n_timesteps             | 2030000     |
| train-AverageDiscoun... | 41.9        |
| train-AverageReturn     | 46.1        |
| train-EnvExecTime       | 11.7        |
| train-MaxReturn         | 59.9        |
| train-MinReturn         | 35.1        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 6.21        |
-----------------------------------------

 ---------------- Iteration 203 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 203          |
| ItrTime                 | 27.4         |
| LossAfter               | 0.007210513  |
| LossBefore              | 0.0072902436 |
| Time                    | 5.59e+03     |
| Time-Optimization       | 1.03         |
| Time-SampleProc         | 0.0378       |
| Time-Sampling           | 26.4         |
| n_timesteps             | 2040000      |
| train-AverageDiscoun... | 41.9         |
| train-AverageReturn     | 46           |
| train-EnvExecTime       | 11.6         |
| train-MaxReturn         | 58.7         |
| train-MinReturn         | 32.5         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 6.47         |
------------------------------------------

 ---------------- Iteration 204 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 204         |
| ItrTime                 | 27.6        |
| LossAfter               | 0.005717447 |
| LossBefore              | 0.005941858 |
| Time                    | 5.62e+03    |
| Time-Optimization       | 1.07        |
| Time-SampleProc         | 0.0422      |
| Time-Sampling           | 26.5        |
| n_timesteps             | 2050000     |
| train-AverageDiscoun... | 41.9        |
| train-AverageReturn     | 46.1        |
| train-EnvExecTime       | 11.7        |
| train-MaxReturn         | 58.3        |
| train-MinReturn         | 35.4        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 5.86        |
-----------------------------------------

 ---------------- Iteration 205 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 205           |
| ItrTime                 | 28.1          |
| LossAfter               | -0.0047095064 |
| LossBefore              | -0.0042490102 |
| Time                    | 5.64e+03      |
| Time-Optimization       | 1.07          |
| Time-SampleProc         | 0.0375        |
| Time-Sampling           | 27            |
| n_timesteps             | 2060000       |
| train-AverageDiscoun... | 42            |
| train-AverageReturn     | 46.3          |
| train-EnvExecTime       | 11.9          |
| train-MaxReturn         | 59.4          |
| train-MinReturn         | 34.1          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.4          |
| train-StdReturn         | 5.92          |
-------------------------------------------

 ---------------- Iteration 206 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 206          |
| ItrTime                 | 27.6         |
| LossAfter               | -0.023960426 |
| LossBefore              | -0.023335626 |
| Time                    | 5.67e+03     |
| Time-Optimization       | 1.07         |
| Time-SampleProc         | 0.04         |
| Time-Sampling           | 26.5         |
| n_timesteps             | 2070000      |
| train-AverageDiscoun... | 41.9         |
| train-AverageReturn     | 46.1         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 60.3         |
| train-MinReturn         | 33.3         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 6.01         |
------------------------------------------

 ---------------- Iteration 207 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 207         |
| ItrTime                 | 27.6        |
| LossAfter               | 0.003777462 |
| LossBefore              | 0.004227201 |
| Time                    | 5.7e+03     |
| Time-Optimization       | 1.08        |
| Time-SampleProc         | 0.0369      |
| Time-Sampling           | 26.5        |
| n_timesteps             | 2080000     |
| train-AverageDiscoun... | 41.9        |
| train-AverageReturn     | 46.1        |
| train-EnvExecTime       | 11.7        |
| train-MaxReturn         | 59.7        |
| train-MinReturn         | 34.8        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 6.31        |
-----------------------------------------

 ---------------- Iteration 208 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 208          |
| ItrTime                 | 27.6         |
| LossAfter               | -0.013723413 |
| LossBefore              | -0.0134384   |
| Time                    | 5.73e+03     |
| Time-Optimization       | 1.1          |
| Time-SampleProc         | 0.0383       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 2090000      |
| train-AverageDiscoun... | 41.6         |
| train-AverageReturn     | 45.4         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 59.4         |
| train-MinReturn         | 32.2         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 6.1          |
------------------------------------------

 ---------------- Iteration 209 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 209         |
| ItrTime                 | 27.6        |
| LossAfter               | 0.008300315 |
| LossBefore              | 0.008665735 |
| Time                    | 5.75e+03    |
| Time-Optimization       | 1.03        |
| Time-SampleProc         | 0.0379      |
| Time-Sampling           | 26.5        |
| n_timesteps             | 2100000     |
| train-AverageDiscoun... | 42          |
| train-AverageReturn     | 46.1        |
| train-EnvExecTime       | 11.7        |
| train-MaxReturn         | 60.4        |
| train-MinReturn         | 33.8        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.2        |
| train-StdReturn         | 6.18        |
-----------------------------------------

 ---------------- Iteration 210 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
----------------------------------------
| Itr                     | 210        |
| ItrTime                 | 27.7       |
| LossAfter               | 0.0343698  |
| LossBefore              | 0.03473673 |
| Time                    | 5.78e+03   |
| Time-Optimization       | 1.1        |
| Time-SampleProc         | 0.0484     |
| Time-Sampling           | 26.6       |
| n_timesteps             | 2110000    |
| train-AverageDiscoun... | 42.2       |
| train-AverageReturn     | 46.7       |
| train-EnvExecTime       | 11.7       |
| train-MaxReturn         | 61.6       |
| train-MinReturn         | 33.6       |
| train-NumTrajs          | 100        |
| train-PolicyExecTime    | 14.2       |
| train-StdReturn         | 6.4        |
----------------------------------------

 ---------------- Iteration 211 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 211         |
| ItrTime                 | 27.6        |
| LossAfter               | 0.011899739 |
| LossBefore              | 0.012104108 |
| Time                    | 5.81e+03    |
| Time-Optimization       | 1.08        |
| Time-SampleProc         | 0.0357      |
| Time-Sampling           | 26.5        |
| n_timesteps             | 2120000     |
| train-AverageDiscoun... | 41.7        |
| train-AverageReturn     | 45.6        |
| train-EnvExecTime       | 11.7        |
| train-MaxReturn         | 58.3        |
| train-MinReturn         | 34          |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 6.05        |
-----------------------------------------

 ---------------- Iteration 212 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 212           |
| ItrTime                 | 27.6          |
| LossAfter               | -0.0046996796 |
| LossBefore              | -0.0044209594 |
| Time                    | 5.84e+03      |
| Time-Optimization       | 1.08          |
| Time-SampleProc         | 0.039         |
| Time-Sampling           | 26.5          |
| n_timesteps             | 2130000       |
| train-AverageDiscoun... | 42.5          |
| train-AverageReturn     | 47.5          |
| train-EnvExecTime       | 11.7          |
| train-MaxReturn         | 61.9          |
| train-MinReturn         | 33.8          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.1          |
| train-StdReturn         | 6.63          |
-------------------------------------------

 ---------------- Iteration 213 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 213           |
| ItrTime                 | 27.7          |
| LossAfter               | -0.0026892063 |
| LossBefore              | -0.0022256884 |
| Time                    | 5.87e+03      |
| Time-Optimization       | 1.09          |
| Time-SampleProc         | 0.0362        |
| Time-Sampling           | 26.5          |
| n_timesteps             | 2140000       |
| train-AverageDiscoun... | 42            |
| train-AverageReturn     | 46.3          |
| train-EnvExecTime       | 11.6          |
| train-MaxReturn         | 60.2          |
| train-MinReturn         | 35.8          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.2          |
| train-StdReturn         | 6.5           |
-------------------------------------------

 ---------------- Iteration 214 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 214         |
| ItrTime                 | 27.6        |
| LossAfter               | 0.016693374 |
| LossBefore              | 0.017010687 |
| Time                    | 5.89e+03    |
| Time-Optimization       | 1.07        |
| Time-SampleProc         | 0.0353      |
| Time-Sampling           | 26.5        |
| n_timesteps             | 2150000     |
| train-AverageDiscoun... | 42.4        |
| train-AverageReturn     | 47          |
| train-EnvExecTime       | 11.6        |
| train-MaxReturn         | 59.2        |
| train-MinReturn         | 32.7        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.2        |
| train-StdReturn         | 6.46        |
-----------------------------------------

 ---------------- Iteration 215 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 215          |
| ItrTime                 | 27.6         |
| LossAfter               | -0.013711468 |
| LossBefore              | -0.013481068 |
| Time                    | 5.92e+03     |
| Time-Optimization       | 1.08         |
| Time-SampleProc         | 0.0361       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 2160000      |
| train-AverageDiscoun... | 42.3         |
| train-AverageReturn     | 46.8         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 58.6         |
| train-MinReturn         | 34.8         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14           |
| train-StdReturn         | 5.99         |
------------------------------------------

 ---------------- Iteration 216 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 216          |
| ItrTime                 | 27.6         |
| LossAfter               | -0.012025714 |
| LossBefore              | -0.011381238 |
| Time                    | 5.95e+03     |
| Time-Optimization       | 1.06         |
| Time-SampleProc         | 0.0419       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 2170000      |
| train-AverageDiscoun... | 41.4         |
| train-AverageReturn     | 45           |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 60.2         |
| train-MinReturn         | 32           |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 6.99         |
------------------------------------------

 ---------------- Iteration 217 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 217          |
| ItrTime                 | 27.7         |
| LossAfter               | -0.023750212 |
| LossBefore              | -0.02349668  |
| Time                    | 5.98e+03     |
| Time-Optimization       | 1.07         |
| Time-SampleProc         | 0.0407       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 2180000      |
| train-AverageDiscoun... | 41.9         |
| train-AverageReturn     | 46.1         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 72.5         |
| train-MinReturn         | 31.3         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 7.43         |
------------------------------------------

 ---------------- Iteration 218 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 218           |
| ItrTime                 | 27.7          |
| LossAfter               | -0.0058904085 |
| LossBefore              | -0.0056205336 |
| Time                    | 6e+03         |
| Time-Optimization       | 1.07          |
| Time-SampleProc         | 0.0438        |
| Time-Sampling           | 26.6          |
| n_timesteps             | 2190000       |
| train-AverageDiscoun... | 42.4          |
| train-AverageReturn     | 47.3          |
| train-EnvExecTime       | 11.7          |
| train-MaxReturn         | 59.8          |
| train-MinReturn         | 33.6          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.2          |
| train-StdReturn         | 6.52          |
-------------------------------------------

 ---------------- Iteration 219 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 219           |
| ItrTime                 | 27.6          |
| LossAfter               | 0.00021912232 |
| LossBefore              | 0.0004673584  |
| Time                    | 6.03e+03      |
| Time-Optimization       | 1.03          |
| Time-SampleProc         | 0.04          |
| Time-Sampling           | 26.5          |
| n_timesteps             | 2200000       |
| train-AverageDiscoun... | 42.6          |
| train-AverageReturn     | 47.6          |
| train-EnvExecTime       | 11.7          |
| train-MaxReturn         | 59.9          |
| train-MinReturn         | 32.5          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.1          |
| train-StdReturn         | 6.57          |
-------------------------------------------

 ---------------- Iteration 220 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 220          |
| ItrTime                 | 27.6         |
| LossAfter               | -0.016122852 |
| LossBefore              | -0.015659843 |
| Time                    | 6.06e+03     |
| Time-Optimization       | 1.05         |
| Time-SampleProc         | 0.0419       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 2210000      |
| train-AverageDiscoun... | 41.9         |
| train-AverageReturn     | 46           |
| train-EnvExecTime       | 11.6         |
| train-MaxReturn         | 60.6         |
| train-MinReturn         | 33.1         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 6.53         |
------------------------------------------

 ---------------- Iteration 221 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 221          |
| ItrTime                 | 27.6         |
| LossAfter               | 0.0024242834 |
| LossBefore              | 0.0029040773 |
| Time                    | 6.09e+03     |
| Time-Optimization       | 1.08         |
| Time-SampleProc         | 0.0497       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 2220000      |
| train-AverageDiscoun... | 41.5         |
| train-AverageReturn     | 45.2         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 59.7         |
| train-MinReturn         | 30.3         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 6.24         |
------------------------------------------

 ---------------- Iteration 222 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 222         |
| ItrTime                 | 27.5        |
| LossAfter               | 0.008293231 |
| LossBefore              | 0.008559047 |
| Time                    | 6.11e+03    |
| Time-Optimization       | 1.05        |
| Time-SampleProc         | 0.0357      |
| Time-Sampling           | 26.4        |
| n_timesteps             | 2230000     |
| train-AverageDiscoun... | 42.1        |
| train-AverageReturn     | 46.4        |
| train-EnvExecTime       | 11.6        |
| train-MaxReturn         | 60.6        |
| train-MinReturn         | 38.6        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 5.76        |
-----------------------------------------

 ---------------- Iteration 223 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 223          |
| ItrTime                 | 27.6         |
| LossAfter               | -0.017561425 |
| LossBefore              | -0.017361468 |
| Time                    | 6.14e+03     |
| Time-Optimization       | 1.07         |
| Time-SampleProc         | 0.0377       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 2240000      |
| train-AverageDiscoun... | 42           |
| train-AverageReturn     | 46.2         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 58.9         |
| train-MinReturn         | 33.7         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 6.43         |
------------------------------------------

 ---------------- Iteration 224 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 224          |
| ItrTime                 | 27.8         |
| LossAfter               | -0.019467577 |
| LossBefore              | -0.019191358 |
| Time                    | 6.17e+03     |
| Time-Optimization       | 1.06         |
| Time-SampleProc         | 0.0375       |
| Time-Sampling           | 26.7         |
| n_timesteps             | 2250000      |
| train-AverageDiscoun... | 41.9         |
| train-AverageReturn     | 46.1         |
| train-EnvExecTime       | 11.8         |
| train-MaxReturn         | 64.4         |
| train-MinReturn         | 32.4         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 6.31         |
------------------------------------------

 ---------------- Iteration 225 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 225         |
| ItrTime                 | 27.5        |
| LossAfter               | 0.004494232 |
| LossBefore              | 0.005022081 |
| Time                    | 6.2e+03     |
| Time-Optimization       | 1.05        |
| Time-SampleProc         | 0.0429      |
| Time-Sampling           | 26.4        |
| n_timesteps             | 2260000     |
| train-AverageDiscoun... | 41.8        |
| train-AverageReturn     | 46          |
| train-EnvExecTime       | 11.7        |
| train-MaxReturn         | 61.7        |
| train-MinReturn         | 34.4        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 6.15        |
-----------------------------------------

 ---------------- Iteration 226 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 226          |
| ItrTime                 | 27.7         |
| LossAfter               | -0.013567279 |
| LossBefore              | -0.013043152 |
| Time                    | 6.23e+03     |
| Time-Optimization       | 1.09         |
| Time-SampleProc         | 0.0519       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 2270000      |
| train-AverageDiscoun... | 41.3         |
| train-AverageReturn     | 44.6         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 58.7         |
| train-MinReturn         | 33.5         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 6.17         |
------------------------------------------

 ---------------- Iteration 227 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 227          |
| ItrTime                 | 27.6         |
| LossAfter               | -0.010096966 |
| LossBefore              | -0.009689484 |
| Time                    | 6.25e+03     |
| Time-Optimization       | 1.05         |
| Time-SampleProc         | 0.0419       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 2280000      |
| train-AverageDiscoun... | 42.2         |
| train-AverageReturn     | 46.8         |
| train-EnvExecTime       | 11.6         |
| train-MaxReturn         | 58.8         |
| train-MinReturn         | 33.5         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 6.49         |
------------------------------------------

 ---------------- Iteration 228 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 228          |
| ItrTime                 | 27.7         |
| LossAfter               | 0.0028118042 |
| LossBefore              | 0.003409681  |
| Time                    | 6.28e+03     |
| Time-Optimization       | 1.1          |
| Time-SampleProc         | 0.0403       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 2290000      |
| train-AverageDiscoun... | 42.2         |
| train-AverageReturn     | 46.9         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 62.4         |
| train-MinReturn         | 33.6         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 7.06         |
------------------------------------------

 ---------------- Iteration 229 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 229            |
| ItrTime                 | 27.6           |
| LossAfter               | -0.00023972016 |
| LossBefore              | 0.00011260834  |
| Time                    | 6.31e+03       |
| Time-Optimization       | 1.07           |
| Time-SampleProc         | 0.041          |
| Time-Sampling           | 26.5           |
| n_timesteps             | 2300000        |
| train-AverageDiscoun... | 42             |
| train-AverageReturn     | 46.4           |
| train-EnvExecTime       | 11.7           |
| train-MaxReturn         | 59             |
| train-MinReturn         | 34.1           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 14.1           |
| train-StdReturn         | 6.56           |
--------------------------------------------

 ---------------- Iteration 230 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 230          |
| ItrTime                 | 27.6         |
| LossAfter               | 0.0030257667 |
| LossBefore              | 0.003431524  |
| Time                    | 6.34e+03     |
| Time-Optimization       | 1.1          |
| Time-SampleProc         | 0.0364       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 2310000      |
| train-AverageDiscoun... | 41.6         |
| train-AverageReturn     | 45.3         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 58.6         |
| train-MinReturn         | 33           |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 6.25         |
------------------------------------------

 ---------------- Iteration 231 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 231          |
| ItrTime                 | 27.6         |
| LossAfter               | 0.0009814773 |
| LossBefore              | 0.0011425248 |
| Time                    | 6.36e+03     |
| Time-Optimization       | 1.09         |
| Time-SampleProc         | 0.036        |
| Time-Sampling           | 26.4         |
| n_timesteps             | 2320000      |
| train-AverageDiscoun... | 41.8         |
| train-AverageReturn     | 45.9         |
| train-EnvExecTime       | 11.6         |
| train-MaxReturn         | 58.6         |
| train-MinReturn         | 34.4         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 5.97         |
------------------------------------------

 ---------------- Iteration 232 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 232          |
| ItrTime                 | 27.6         |
| LossAfter               | -0.02340852  |
| LossBefore              | -0.023172565 |
| Time                    | 6.39e+03     |
| Time-Optimization       | 1.08         |
| Time-SampleProc         | 0.0376       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 2330000      |
| train-AverageDiscoun... | 42           |
| train-AverageReturn     | 46.3         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 61.7         |
| train-MinReturn         | 34.5         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 6.3          |
------------------------------------------

 ---------------- Iteration 233 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 233           |
| ItrTime                 | 27.5          |
| LossAfter               | -0.0046304455 |
| LossBefore              | -0.0040652757 |
| Time                    | 6.42e+03      |
| Time-Optimization       | 1.04          |
| Time-SampleProc         | 0.044         |
| Time-Sampling           | 26.4          |
| n_timesteps             | 2340000       |
| train-AverageDiscoun... | 42            |
| train-AverageReturn     | 46.3          |
| train-EnvExecTime       | 11.6          |
| train-MaxReturn         | 60.7          |
| train-MinReturn         | 33.9          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.1          |
| train-StdReturn         | 7.12          |
-------------------------------------------

 ---------------- Iteration 234 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 234         |
| ItrTime                 | 27.5        |
| LossAfter               | 0.02367339  |
| LossBefore              | 0.023921164 |
| Time                    | 6.45e+03    |
| Time-Optimization       | 1.08        |
| Time-SampleProc         | 0.0378      |
| Time-Sampling           | 26.4        |
| n_timesteps             | 2350000     |
| train-AverageDiscoun... | 41.9        |
| train-AverageReturn     | 46.1        |
| train-EnvExecTime       | 11.7        |
| train-MaxReturn         | 58.9        |
| train-MinReturn         | 36          |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 6           |
-----------------------------------------

 ---------------- Iteration 235 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 235          |
| ItrTime                 | 27.6         |
| LossAfter               | -0.011344883 |
| LossBefore              | -0.010725577 |
| Time                    | 6.47e+03     |
| Time-Optimization       | 1.09         |
| Time-SampleProc         | 0.0398       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 2360000      |
| train-AverageDiscoun... | 42.1         |
| train-AverageReturn     | 46.4         |
| train-EnvExecTime       | 11.6         |
| train-MaxReturn         | 57.1         |
| train-MinReturn         | 35.2         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 5.97         |
------------------------------------------

 ---------------- Iteration 236 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 236          |
| ItrTime                 | 27.7         |
| LossAfter               | -0.009893001 |
| LossBefore              | -0.00975044  |
| Time                    | 6.5e+03      |
| Time-Optimization       | 1.27         |
| Time-SampleProc         | 0.0378       |
| Time-Sampling           | 26.4         |
| n_timesteps             | 2370000      |
| train-AverageDiscoun... | 41.9         |
| train-AverageReturn     | 46.1         |
| train-EnvExecTime       | 11.6         |
| train-MaxReturn         | 61.4         |
| train-MinReturn         | 32.5         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 6.73         |
------------------------------------------

 ---------------- Iteration 237 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 237          |
| ItrTime                 | 28           |
| LossAfter               | 0.0027509788 |
| LossBefore              | 0.0030542305 |
| Time                    | 6.53e+03     |
| Time-Optimization       | 1.65         |
| Time-SampleProc         | 0.0562       |
| Time-Sampling           | 26.2         |
| n_timesteps             | 2380000      |
| train-AverageDiscoun... | 41.8         |
| train-AverageReturn     | 45.9         |
| train-EnvExecTime       | 11.6         |
| train-MaxReturn         | 58.4         |
| train-MinReturn         | 35.3         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14           |
| train-StdReturn         | 5.9          |
------------------------------------------

 ---------------- Iteration 238 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 238           |
| ItrTime                 | 27.6          |
| LossAfter               | -0.0050052637 |
| LossBefore              | -0.0044151116 |
| Time                    | 6.56e+03      |
| Time-Optimization       | 1.32          |
| Time-SampleProc         | 0.0607        |
| Time-Sampling           | 26.2          |
| n_timesteps             | 2390000       |
| train-AverageDiscoun... | 41.9          |
| train-AverageReturn     | 46            |
| train-EnvExecTime       | 11.6          |
| train-MaxReturn         | 58.1          |
| train-MinReturn         | 33.2          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14            |
| train-StdReturn         | 5.9           |
-------------------------------------------

 ---------------- Iteration 239 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 239           |
| ItrTime                 | 27.6          |
| LossAfter               | 9.2306516e-05 |
| LossBefore              | 0.0004937302  |
| Time                    | 6.59e+03      |
| Time-Optimization       | 1.09          |
| Time-SampleProc         | 0.066         |
| Time-Sampling           | 26.4          |
| n_timesteps             | 2400000       |
| train-AverageDiscoun... | 41.8          |
| train-AverageReturn     | 45.7          |
| train-EnvExecTime       | 11.6          |
| train-MaxReturn         | 60            |
| train-MinReturn         | 35.6          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.1          |
| train-StdReturn         | 5.83          |
-------------------------------------------

 ---------------- Iteration 240 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 240         |
| ItrTime                 | 27.5        |
| LossAfter               | 0.007442117 |
| LossBefore              | 0.008012408 |
| Time                    | 6.61e+03    |
| Time-Optimization       | 1.08        |
| Time-SampleProc         | 0.0404      |
| Time-Sampling           | 26.4        |
| n_timesteps             | 2410000     |
| train-AverageDiscoun... | 42.3        |
| train-AverageReturn     | 47          |
| train-EnvExecTime       | 11.6        |
| train-MaxReturn         | 59.8        |
| train-MinReturn         | 33.6        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 6.45        |
-----------------------------------------

 ---------------- Iteration 241 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 241           |
| ItrTime                 | 27.6          |
| LossAfter               | -0.005376187  |
| LossBefore              | -0.0052226135 |
| Time                    | 6.64e+03      |
| Time-Optimization       | 1.08          |
| Time-SampleProc         | 0.0375        |
| Time-Sampling           | 26.5          |
| n_timesteps             | 2420000       |
| train-AverageDiscoun... | 42.1          |
| train-AverageReturn     | 46.5          |
| train-EnvExecTime       | 11.7          |
| train-MaxReturn         | 58.4          |
| train-MinReturn         | 34.6          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.1          |
| train-StdReturn         | 5.86          |
-------------------------------------------

 ---------------- Iteration 242 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 242          |
| ItrTime                 | 27.5         |
| LossAfter               | 0.001590741  |
| LossBefore              | 0.0019437592 |
| Time                    | 6.67e+03     |
| Time-Optimization       | 1.06         |
| Time-SampleProc         | 0.0416       |
| Time-Sampling           | 26.4         |
| n_timesteps             | 2430000      |
| train-AverageDiscoun... | 42           |
| train-AverageReturn     | 46.4         |
| train-EnvExecTime       | 11.6         |
| train-MaxReturn         | 58.7         |
| train-MinReturn         | 31.6         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 6.39         |
------------------------------------------

 ---------------- Iteration 243 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 243           |
| ItrTime                 | 27.6          |
| LossAfter               | -0.009731765  |
| LossBefore              | -0.0088536255 |
| Time                    | 6.7e+03       |
| Time-Optimization       | 1.06          |
| Time-SampleProc         | 0.038         |
| Time-Sampling           | 26.5          |
| n_timesteps             | 2440000       |
| train-AverageDiscoun... | 41.9          |
| train-AverageReturn     | 46.1          |
| train-EnvExecTime       | 11.7          |
| train-MaxReturn         | 60.2          |
| train-MinReturn         | 36.1          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.1          |
| train-StdReturn         | 6.4           |
-------------------------------------------

 ---------------- Iteration 244 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 244         |
| ItrTime                 | 27.5        |
| LossAfter               | 0.006310101 |
| LossBefore              | 0.006305739 |
| Time                    | 6.72e+03    |
| Time-Optimization       | 1.05        |
| Time-SampleProc         | 0.0433      |
| Time-Sampling           | 26.4        |
| n_timesteps             | 2450000     |
| train-AverageDiscoun... | 42.5        |
| train-AverageReturn     | 47.4        |
| train-EnvExecTime       | 11.7        |
| train-MaxReturn         | 60.9        |
| train-MinReturn         | 30.8        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14          |
| train-StdReturn         | 6.48        |
-----------------------------------------

 ---------------- Iteration 245 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 245          |
| ItrTime                 | 27.6         |
| LossAfter               | 0.0077220122 |
| LossBefore              | 0.008334677  |
| Time                    | 6.75e+03     |
| Time-Optimization       | 1.09         |
| Time-SampleProc         | 0.0401       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 2460000      |
| train-AverageDiscoun... | 41.9         |
| train-AverageReturn     | 46           |
| train-EnvExecTime       | 11.6         |
| train-MaxReturn         | 58.1         |
| train-MinReturn         | 34           |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 6.6          |
------------------------------------------

 ---------------- Iteration 246 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 246          |
| ItrTime                 | 27.7         |
| LossAfter               | 0.0062383506 |
| LossBefore              | 0.006855617  |
| Time                    | 6.78e+03     |
| Time-Optimization       | 1.08         |
| Time-SampleProc         | 0.0371       |
| Time-Sampling           | 26.6         |
| n_timesteps             | 2470000      |
| train-AverageDiscoun... | 42.5         |
| train-AverageReturn     | 47.4         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 60.8         |
| train-MinReturn         | 33.3         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 7.02         |
------------------------------------------

 ---------------- Iteration 247 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 247         |
| ItrTime                 | 27.6        |
| LossAfter               | 0.023726087 |
| LossBefore              | 0.024325684 |
| Time                    | 6.81e+03    |
| Time-Optimization       | 1.07        |
| Time-SampleProc         | 0.0374      |
| Time-Sampling           | 26.5        |
| n_timesteps             | 2480000     |
| train-AverageDiscoun... | 42.2        |
| train-AverageReturn     | 46.8        |
| train-EnvExecTime       | 11.8        |
| train-MaxReturn         | 58.7        |
| train-MinReturn         | 34.2        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14          |
| train-StdReturn         | 6.35        |
-----------------------------------------

 ---------------- Iteration 248 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 248           |
| ItrTime                 | 27.6          |
| LossAfter               | 0.00077648927 |
| LossBefore              | 0.001462603   |
| Time                    | 6.83e+03      |
| Time-Optimization       | 1.07          |
| Time-SampleProc         | 0.0377        |
| Time-Sampling           | 26.5          |
| n_timesteps             | 2490000       |
| train-AverageDiscoun... | 42.2          |
| train-AverageReturn     | 46.8          |
| train-EnvExecTime       | 11.7          |
| train-MaxReturn         | 59.8          |
| train-MinReturn         | 34.3          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.1          |
| train-StdReturn         | 6.32          |
-------------------------------------------

 ---------------- Iteration 249 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 249          |
| ItrTime                 | 27.5         |
| LossAfter               | -0.01120776  |
| LossBefore              | -0.010569284 |
| Time                    | 6.86e+03     |
| Time-Optimization       | 1.07         |
| Time-SampleProc         | 0.0394       |
| Time-Sampling           | 26.4         |
| n_timesteps             | 2500000      |
| train-AverageDiscoun... | 42.3         |
| train-AverageReturn     | 47           |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 59.4         |
| train-MinReturn         | 35.8         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14           |
| train-StdReturn         | 6.04         |
------------------------------------------

 ---------------- Iteration 250 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 250           |
| ItrTime                 | 28.1          |
| LossAfter               | -0.0018463669 |
| LossBefore              | -0.0012086487 |
| Time                    | 6.89e+03      |
| Time-Optimization       | 1.47          |
| Time-SampleProc         | 0.0354        |
| Time-Sampling           | 26.6          |
| n_timesteps             | 2510000       |
| train-AverageDiscoun... | 42.1          |
| train-AverageReturn     | 46.5          |
| train-EnvExecTime       | 11.7          |
| train-MaxReturn         | 59.7          |
| train-MinReturn         | 34.7          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.2          |
| train-StdReturn         | 6.65          |
-------------------------------------------

 ---------------- Iteration 251 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 251         |
| ItrTime                 | 27.7        |
| LossAfter               | 0.007831729 |
| LossBefore              | 0.008323608 |
| Time                    | 6.92e+03    |
| Time-Optimization       | 1.06        |
| Time-SampleProc         | 0.0377      |
| Time-Sampling           | 26.6        |
| n_timesteps             | 2520000     |
| train-AverageDiscoun... | 42.2        |
| train-AverageReturn     | 46.8        |
| train-EnvExecTime       | 11.7        |
| train-MaxReturn         | 62.4        |
| train-MinReturn         | 32.4        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.2        |
| train-StdReturn         | 6.7         |
-----------------------------------------

 ---------------- Iteration 252 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 252           |
| ItrTime                 | 27.7          |
| LossAfter               | -0.0057799867 |
| LossBefore              | -0.005416312  |
| Time                    | 6.95e+03      |
| Time-Optimization       | 1.09          |
| Time-SampleProc         | 0.0454        |
| Time-Sampling           | 26.6          |
| n_timesteps             | 2530000       |
| train-AverageDiscoun... | 42.1          |
| train-AverageReturn     | 46.6          |
| train-EnvExecTime       | 11.7          |
| train-MaxReturn         | 58.6          |
| train-MinReturn         | 32.7          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.2          |
| train-StdReturn         | 6.95          |
-------------------------------------------

 ---------------- Iteration 253 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 253          |
| ItrTime                 | 27.7         |
| LossAfter               | -0.014121233 |
| LossBefore              | -0.013915924 |
| Time                    | 6.97e+03     |
| Time-Optimization       | 1.09         |
| Time-SampleProc         | 0.0378       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 2540000      |
| train-AverageDiscoun... | 42.2         |
| train-AverageReturn     | 46.7         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 61           |
| train-MinReturn         | 33.1         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 6.86         |
------------------------------------------

 ---------------- Iteration 254 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 254         |
| ItrTime                 | 27.6        |
| LossAfter               | 0.013493738 |
| LossBefore              | 0.014404103 |
| Time                    | 7e+03       |
| Time-Optimization       | 1.06        |
| Time-SampleProc         | 0.0378      |
| Time-Sampling           | 26.5        |
| n_timesteps             | 2550000     |
| train-AverageDiscoun... | 41.7        |
| train-AverageReturn     | 45.6        |
| train-EnvExecTime       | 11.7        |
| train-MaxReturn         | 59.4        |
| train-MinReturn         | 32          |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 6.85        |
-----------------------------------------

 ---------------- Iteration 255 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 255          |
| ItrTime                 | 27.6         |
| LossAfter               | -0.01634739  |
| LossBefore              | -0.015959268 |
| Time                    | 7.03e+03     |
| Time-Optimization       | 1.08         |
| Time-SampleProc         | 0.0433       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 2560000      |
| train-AverageDiscoun... | 41.9         |
| train-AverageReturn     | 46.2         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 58.7         |
| train-MinReturn         | 33.1         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 6.67         |
------------------------------------------

 ---------------- Iteration 256 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 256          |
| ItrTime                 | 27.5         |
| LossAfter               | 0.0029169815 |
| LossBefore              | 0.0033645246 |
| Time                    | 7.06e+03     |
| Time-Optimization       | 1.06         |
| Time-SampleProc         | 0.0379       |
| Time-Sampling           | 26.4         |
| n_timesteps             | 2570000      |
| train-AverageDiscoun... | 42.3         |
| train-AverageReturn     | 46.8         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 59.3         |
| train-MinReturn         | 34.3         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 6            |
------------------------------------------

 ---------------- Iteration 257 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 257           |
| ItrTime                 | 27.7          |
| LossAfter               | -0.0107805645 |
| LossBefore              | -0.010604354  |
| Time                    | 7.08e+03      |
| Time-Optimization       | 1.05          |
| Time-SampleProc         | 0.0373        |
| Time-Sampling           | 26.6          |
| n_timesteps             | 2580000       |
| train-AverageDiscoun... | 42.2          |
| train-AverageReturn     | 46.7          |
| train-EnvExecTime       | 11.7          |
| train-MaxReturn         | 60.1          |
| train-MinReturn         | 33.4          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.3          |
| train-StdReturn         | 6.51          |
-------------------------------------------

 ---------------- Iteration 258 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 258          |
| ItrTime                 | 27.7         |
| LossAfter               | -0.019096041 |
| LossBefore              | -0.01881199  |
| Time                    | 7.11e+03     |
| Time-Optimization       | 1.1          |
| Time-SampleProc         | 0.0411       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 2590000      |
| train-AverageDiscoun... | 42.2         |
| train-AverageReturn     | 46.6         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 60.3         |
| train-MinReturn         | 34.5         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 6.62         |
------------------------------------------

 ---------------- Iteration 259 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 259          |
| ItrTime                 | 27.6         |
| LossAfter               | 0.0028266876 |
| LossBefore              | 0.003007814  |
| Time                    | 7.14e+03     |
| Time-Optimization       | 1.07         |
| Time-SampleProc         | 0.0397       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 2600000      |
| train-AverageDiscoun... | 42           |
| train-AverageReturn     | 46.4         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 60.1         |
| train-MinReturn         | 33.4         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 6.76         |
------------------------------------------

 ---------------- Iteration 260 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 260         |
| ItrTime                 | 27.7        |
| LossAfter               | 0.019223725 |
| LossBefore              | 0.019732349 |
| Time                    | 7.17e+03    |
| Time-Optimization       | 1.09        |
| Time-SampleProc         | 0.0416      |
| Time-Sampling           | 26.6        |
| n_timesteps             | 2610000     |
| train-AverageDiscoun... | 42.2        |
| train-AverageReturn     | 46.7        |
| train-EnvExecTime       | 11.7        |
| train-MaxReturn         | 59.1        |
| train-MinReturn         | 34.4        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.2        |
| train-StdReturn         | 6.18        |
-----------------------------------------

 ---------------- Iteration 261 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 261          |
| ItrTime                 | 27.5         |
| LossAfter               | 0.0015855698 |
| LossBefore              | 0.0015082458 |
| Time                    | 7.19e+03     |
| Time-Optimization       | 1.08         |
| Time-SampleProc         | 0.0354       |
| Time-Sampling           | 26.4         |
| n_timesteps             | 2620000      |
| train-AverageDiscoun... | 42.4         |
| train-AverageReturn     | 47.1         |
| train-EnvExecTime       | 11.6         |
| train-MaxReturn         | 60.3         |
| train-MinReturn         | 34.3         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 6.53         |
------------------------------------------

 ---------------- Iteration 262 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 262          |
| ItrTime                 | 27.6         |
| LossAfter               | -0.019662853 |
| LossBefore              | -0.019396346 |
| Time                    | 7.22e+03     |
| Time-Optimization       | 1.09         |
| Time-SampleProc         | 0.0404       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 2630000      |
| train-AverageDiscoun... | 42.2         |
| train-AverageReturn     | 46.7         |
| train-EnvExecTime       | 11.6         |
| train-MaxReturn         | 60.9         |
| train-MinReturn         | 33.3         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 7.06         |
------------------------------------------

 ---------------- Iteration 263 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 263         |
| ItrTime                 | 27.6        |
| LossAfter               | 0.010101661 |
| LossBefore              | 0.010577813 |
| Time                    | 7.25e+03    |
| Time-Optimization       | 1.09        |
| Time-SampleProc         | 0.039       |
| Time-Sampling           | 26.5        |
| n_timesteps             | 2640000     |
| train-AverageDiscoun... | 41.8        |
| train-AverageReturn     | 45.8        |
| train-EnvExecTime       | 11.7        |
| train-MaxReturn         | 61.1        |
| train-MinReturn         | 34.9        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 6.93        |
-----------------------------------------

 ---------------- Iteration 264 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 264          |
| ItrTime                 | 27.6         |
| LossAfter               | -0.020855844 |
| LossBefore              | -0.020765744 |
| Time                    | 7.28e+03     |
| Time-Optimization       | 1.18         |
| Time-SampleProc         | 0.039        |
| Time-Sampling           | 26.4         |
| n_timesteps             | 2650000      |
| train-AverageDiscoun... | 42.2         |
| train-AverageReturn     | 46.8         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 60.2         |
| train-MinReturn         | 34.2         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14           |
| train-StdReturn         | 7.24         |
------------------------------------------

 ---------------- Iteration 265 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 265           |
| ItrTime                 | 27.7          |
| LossAfter               | -0.0016733521 |
| LossBefore              | -0.001194049  |
| Time                    | 7.31e+03      |
| Time-Optimization       | 1.07          |
| Time-SampleProc         | 0.0416        |
| Time-Sampling           | 26.6          |
| n_timesteps             | 2660000       |
| train-AverageDiscoun... | 42.2          |
| train-AverageReturn     | 46.7          |
| train-EnvExecTime       | 11.7          |
| train-MaxReturn         | 59.9          |
| train-MinReturn         | 32.1          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.1          |
| train-StdReturn         | 6.49          |
-------------------------------------------

 ---------------- Iteration 266 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 266         |
| ItrTime                 | 27.5        |
| LossAfter               | 0.008561677 |
| LossBefore              | 0.008833017 |
| Time                    | 7.33e+03    |
| Time-Optimization       | 1.07        |
| Time-SampleProc         | 0.0384      |
| Time-Sampling           | 26.4        |
| n_timesteps             | 2670000     |
| train-AverageDiscoun... | 42.1        |
| train-AverageReturn     | 46.4        |
| train-EnvExecTime       | 11.6        |
| train-MaxReturn         | 60          |
| train-MinReturn         | 35.1        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14          |
| train-StdReturn         | 6.08        |
-----------------------------------------

 ---------------- Iteration 267 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 267          |
| ItrTime                 | 27.6         |
| LossAfter               | 0.0016907761 |
| LossBefore              | 0.0022862458 |
| Time                    | 7.36e+03     |
| Time-Optimization       | 1.1          |
| Time-SampleProc         | 0.0424       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 2680000      |
| train-AverageDiscoun... | 41.9         |
| train-AverageReturn     | 46           |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 60.1         |
| train-MinReturn         | 31.7         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 6.66         |
------------------------------------------

 ---------------- Iteration 268 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 268          |
| ItrTime                 | 27.6         |
| LossAfter               | -0.005799382 |
| LossBefore              | -0.005836998 |
| Time                    | 7.39e+03     |
| Time-Optimization       | 1.07         |
| Time-SampleProc         | 0.0443       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 2690000      |
| train-AverageDiscoun... | 42.1         |
| train-AverageReturn     | 46.6         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 59.8         |
| train-MinReturn         | 33.3         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 6.52         |
------------------------------------------

 ---------------- Iteration 269 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 269         |
| ItrTime                 | 27.6        |
| LossAfter               | 0.012444408 |
| LossBefore              | 0.012786483 |
| Time                    | 7.42e+03    |
| Time-Optimization       | 1.05        |
| Time-SampleProc         | 0.039       |
| Time-Sampling           | 26.5        |
| n_timesteps             | 2700000     |
| train-AverageDiscoun... | 41.8        |
| train-AverageReturn     | 45.8        |
| train-EnvExecTime       | 11.7        |
| train-MaxReturn         | 59.7        |
| train-MinReturn         | 32.8        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 6.82        |
-----------------------------------------

 ---------------- Iteration 270 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 270         |
| ItrTime                 | 27.8        |
| LossAfter               | 0.01182144  |
| LossBefore              | 0.012248513 |
| Time                    | 7.44e+03    |
| Time-Optimization       | 1.06        |
| Time-SampleProc         | 0.0449      |
| Time-Sampling           | 26.6        |
| n_timesteps             | 2710000     |
| train-AverageDiscoun... | 42.2        |
| train-AverageReturn     | 46.7        |
| train-EnvExecTime       | 11.8        |
| train-MaxReturn         | 57.9        |
| train-MinReturn         | 35.2        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.2        |
| train-StdReturn         | 5.94        |
-----------------------------------------

 ---------------- Iteration 271 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 271         |
| ItrTime                 | 28.3        |
| LossAfter               | 0.003930229 |
| LossBefore              | 0.004313966 |
| Time                    | 7.47e+03    |
| Time-Optimization       | 1.08        |
| Time-SampleProc         | 0.038       |
| Time-Sampling           | 27.2        |
| n_timesteps             | 2720000     |
| train-AverageDiscoun... | 42          |
| train-AverageReturn     | 46.3        |
| train-EnvExecTime       | 12          |
| train-MaxReturn         | 58.2        |
| train-MinReturn         | 34.8        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.5        |
| train-StdReturn         | 6.19        |
-----------------------------------------

 ---------------- Iteration 272 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 272           |
| ItrTime                 | 27.6          |
| LossAfter               | 0.0003408951  |
| LossBefore              | 0.00058863295 |
| Time                    | 7.5e+03       |
| Time-Optimization       | 1.05          |
| Time-SampleProc         | 0.0452        |
| Time-Sampling           | 26.5          |
| n_timesteps             | 2730000       |
| train-AverageDiscoun... | 42.2          |
| train-AverageReturn     | 46.6          |
| train-EnvExecTime       | 11.6          |
| train-MaxReturn         | 59.9          |
| train-MinReturn         | 33.3          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.2          |
| train-StdReturn         | 6.8           |
-------------------------------------------

 ---------------- Iteration 273 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 273          |
| ItrTime                 | 27.6         |
| LossAfter               | 0.001994699  |
| LossBefore              | 0.0023254326 |
| Time                    | 7.53e+03     |
| Time-Optimization       | 1.09         |
| Time-SampleProc         | 0.0413       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 2740000      |
| train-AverageDiscoun... | 41.8         |
| train-AverageReturn     | 45.8         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 58.3         |
| train-MinReturn         | 33.1         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 6.24         |
------------------------------------------

 ---------------- Iteration 274 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 274         |
| ItrTime                 | 27.5        |
| LossAfter               | 0.024885722 |
| LossBefore              | 0.025400132 |
| Time                    | 7.56e+03    |
| Time-Optimization       | 1.06        |
| Time-SampleProc         | 0.0371      |
| Time-Sampling           | 26.4        |
| n_timesteps             | 2750000     |
| train-AverageDiscoun... | 41.8        |
| train-AverageReturn     | 45.9        |
| train-EnvExecTime       | 11.6        |
| train-MaxReturn         | 60.7        |
| train-MinReturn         | 34.1        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 6.85        |
-----------------------------------------

 ---------------- Iteration 275 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 275          |
| ItrTime                 | 29.2         |
| LossAfter               | -0.013637607 |
| LossBefore              | -0.013141028 |
| Time                    | 7.58e+03     |
| Time-Optimization       | 1.63         |
| Time-SampleProc         | 0.0387       |
| Time-Sampling           | 27.5         |
| n_timesteps             | 2760000      |
| train-AverageDiscoun... | 41.9         |
| train-AverageReturn     | 46.1         |
| train-EnvExecTime       | 12.1         |
| train-MaxReturn         | 60.2         |
| train-MinReturn         | 32.8         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.7         |
| train-StdReturn         | 6.42         |
------------------------------------------

 ---------------- Iteration 276 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 276         |
| ItrTime                 | 27.6        |
| LossAfter               | 0.016561875 |
| LossBefore              | 0.017260699 |
| Time                    | 7.61e+03    |
| Time-Optimization       | 1.04        |
| Time-SampleProc         | 0.0384      |
| Time-Sampling           | 26.5        |
| n_timesteps             | 2770000     |
| train-AverageDiscoun... | 42.1        |
| train-AverageReturn     | 46.6        |
| train-EnvExecTime       | 11.7        |
| train-MaxReturn         | 59.6        |
| train-MinReturn         | 33.5        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 6.64        |
-----------------------------------------

 ---------------- Iteration 277 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 277         |
| ItrTime                 | 27.5        |
| LossAfter               | 0.013697975 |
| LossBefore              | 0.01407283  |
| Time                    | 7.64e+03    |
| Time-Optimization       | 1.17        |
| Time-SampleProc         | 0.057       |
| Time-Sampling           | 26.3        |
| n_timesteps             | 2780000     |
| train-AverageDiscoun... | 42.4        |
| train-AverageReturn     | 47.1        |
| train-EnvExecTime       | 11.6        |
| train-MaxReturn         | 59.6        |
| train-MinReturn         | 32.4        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14          |
| train-StdReturn         | 6.34        |
-----------------------------------------

 ---------------- Iteration 278 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 278          |
| ItrTime                 | 28           |
| LossAfter               | -0.024309402 |
| LossBefore              | -0.023740552 |
| Time                    | 7.67e+03     |
| Time-Optimization       | 1.09         |
| Time-SampleProc         | 0.0444       |
| Time-Sampling           | 26.9         |
| n_timesteps             | 2790000      |
| train-AverageDiscoun... | 41.8         |
| train-AverageReturn     | 45.8         |
| train-EnvExecTime       | 11.9         |
| train-MaxReturn         | 59.3         |
| train-MinReturn         | 33.4         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.3         |
| train-StdReturn         | 6.87         |
------------------------------------------

 ---------------- Iteration 279 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 279         |
| ItrTime                 | 28          |
| LossAfter               | 0.008818047 |
| LossBefore              | 0.008907862 |
| Time                    | 7.7e+03     |
| Time-Optimization       | 1.11        |
| Time-SampleProc         | 0.0417      |
| Time-Sampling           | 26.9        |
| n_timesteps             | 2800000     |
| train-AverageDiscoun... | 42.1        |
| train-AverageReturn     | 46.5        |
| train-EnvExecTime       | 11.9        |
| train-MaxReturn         | 60.2        |
| train-MinReturn         | 35.8        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.2        |
| train-StdReturn         | 6.03        |
-----------------------------------------

 ---------------- Iteration 280 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 280          |
| ItrTime                 | 28.2         |
| LossAfter               | -0.00778199  |
| LossBefore              | -0.007618651 |
| Time                    | 7.72e+03     |
| Time-Optimization       | 1.08         |
| Time-SampleProc         | 0.0382       |
| Time-Sampling           | 27           |
| n_timesteps             | 2810000      |
| train-AverageDiscoun... | 42.4         |
| train-AverageReturn     | 47.3         |
| train-EnvExecTime       | 12           |
| train-MaxReturn         | 59.8         |
| train-MinReturn         | 34.8         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.3         |
| train-StdReturn         | 6.15         |
------------------------------------------

 ---------------- Iteration 281 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 281          |
| ItrTime                 | 28           |
| LossAfter               | 0.0026411705 |
| LossBefore              | 0.00299713   |
| Time                    | 7.75e+03     |
| Time-Optimization       | 1.07         |
| Time-SampleProc         | 0.0392       |
| Time-Sampling           | 26.9         |
| n_timesteps             | 2820000      |
| train-AverageDiscoun... | 42.3         |
| train-AverageReturn     | 46.9         |
| train-EnvExecTime       | 11.9         |
| train-MaxReturn         | 59.8         |
| train-MinReturn         | 32.3         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.3         |
| train-StdReturn         | 6.89         |
------------------------------------------

 ---------------- Iteration 282 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 282         |
| ItrTime                 | 27.9        |
| LossAfter               | 0.012750805 |
| LossBefore              | 0.013496296 |
| Time                    | 7.78e+03    |
| Time-Optimization       | 1.05        |
| Time-SampleProc         | 0.0472      |
| Time-Sampling           | 26.9        |
| n_timesteps             | 2830000     |
| train-AverageDiscoun... | 42.3        |
| train-AverageReturn     | 47          |
| train-EnvExecTime       | 11.8        |
| train-MaxReturn         | 59.7        |
| train-MinReturn         | 34.6        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.3        |
| train-StdReturn         | 6.19        |
-----------------------------------------

 ---------------- Iteration 283 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 283           |
| ItrTime                 | 27.6          |
| LossAfter               | -0.0018050186 |
| LossBefore              | -0.001490155  |
| Time                    | 7.81e+03      |
| Time-Optimization       | 1.06          |
| Time-SampleProc         | 0.0416        |
| Time-Sampling           | 26.5          |
| n_timesteps             | 2840000       |
| train-AverageDiscoun... | 42.1          |
| train-AverageReturn     | 46.5          |
| train-EnvExecTime       | 11.7          |
| train-MaxReturn         | 59.9          |
| train-MinReturn         | 36.1          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.1          |
| train-StdReturn         | 6.37          |
-------------------------------------------

 ---------------- Iteration 284 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 284           |
| ItrTime                 | 27.6          |
| LossAfter               | -0.005233743  |
| LossBefore              | -0.0044998145 |
| Time                    | 7.84e+03      |
| Time-Optimization       | 1.05          |
| Time-SampleProc         | 0.0449        |
| Time-Sampling           | 26.5          |
| n_timesteps             | 2850000       |
| train-AverageDiscoun... | 42.4          |
| train-AverageReturn     | 47.1          |
| train-EnvExecTime       | 11.6          |
| train-MaxReturn         | 61.2          |
| train-MinReturn         | 32.6          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.2          |
| train-StdReturn         | 6.06          |
-------------------------------------------

 ---------------- Iteration 285 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 285           |
| ItrTime                 | 27.6          |
| LossAfter               | -0.000920063  |
| LossBefore              | -0.0007506077 |
| Time                    | 7.86e+03      |
| Time-Optimization       | 1.08          |
| Time-SampleProc         | 0.0361        |
| Time-Sampling           | 26.5          |
| n_timesteps             | 2860000       |
| train-AverageDiscoun... | 41.8          |
| train-AverageReturn     | 45.6          |
| train-EnvExecTime       | 11.7          |
| train-MaxReturn         | 59            |
| train-MinReturn         | 34.6          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.2          |
| train-StdReturn         | 5.54          |
-------------------------------------------

 ---------------- Iteration 286 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 286          |
| ItrTime                 | 27.6         |
| LossAfter               | 0.0041205217 |
| LossBefore              | 0.0045545623 |
| Time                    | 7.89e+03     |
| Time-Optimization       | 1.08         |
| Time-SampleProc         | 0.0424       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 2870000      |
| train-AverageDiscoun... | 42.4         |
| train-AverageReturn     | 47.3         |
| train-EnvExecTime       | 11.6         |
| train-MaxReturn         | 59.9         |
| train-MinReturn         | 32.9         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 6.95         |
------------------------------------------

 ---------------- Iteration 287 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 287         |
| ItrTime                 | 27.5        |
| LossAfter               | 0.003732386 |
| LossBefore              | 0.004295944 |
| Time                    | 7.92e+03    |
| Time-Optimization       | 1.07        |
| Time-SampleProc         | 0.0407      |
| Time-Sampling           | 26.4        |
| n_timesteps             | 2880000     |
| train-AverageDiscoun... | 41.9        |
| train-AverageReturn     | 46          |
| train-EnvExecTime       | 11.6        |
| train-MaxReturn         | 59.6        |
| train-MinReturn         | 32.8        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 6.74        |
-----------------------------------------

 ---------------- Iteration 288 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 288         |
| ItrTime                 | 27.7        |
| LossAfter               | 0.016578956 |
| LossBefore              | 0.01702352  |
| Time                    | 7.95e+03    |
| Time-Optimization       | 1.08        |
| Time-SampleProc         | 0.0419      |
| Time-Sampling           | 26.6        |
| n_timesteps             | 2890000     |
| train-AverageDiscoun... | 41.9        |
| train-AverageReturn     | 46.2        |
| train-EnvExecTime       | 11.7        |
| train-MaxReturn         | 61.1        |
| train-MinReturn         | 31.7        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.2        |
| train-StdReturn         | 6.76        |
-----------------------------------------

 ---------------- Iteration 289 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 289          |
| ItrTime                 | 27.8         |
| LossAfter               | -0.014477429 |
| LossBefore              | -0.014120893 |
| Time                    | 7.97e+03     |
| Time-Optimization       | 1.05         |
| Time-SampleProc         | 0.0485       |
| Time-Sampling           | 26.7         |
| n_timesteps             | 2900000      |
| train-AverageDiscoun... | 42.4         |
| train-AverageReturn     | 47.1         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 57.8         |
| train-MinReturn         | 33.4         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.3         |
| train-StdReturn         | 6.59         |
------------------------------------------

 ---------------- Iteration 290 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 290           |
| ItrTime                 | 27.7          |
| LossAfter               | -0.001993621  |
| LossBefore              | -0.0016086036 |
| Time                    | 8e+03         |
| Time-Optimization       | 1.05          |
| Time-SampleProc         | 0.0396        |
| Time-Sampling           | 26.6          |
| n_timesteps             | 2910000       |
| train-AverageDiscoun... | 42.4          |
| train-AverageReturn     | 47.2          |
| train-EnvExecTime       | 11.8          |
| train-MaxReturn         | 62.7          |
| train-MinReturn         | 32.8          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.1          |
| train-StdReturn         | 6.4           |
-------------------------------------------

 ---------------- Iteration 291 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 291         |
| ItrTime                 | 27.7        |
| LossAfter               | 0.017317891 |
| LossBefore              | 0.017801264 |
| Time                    | 8.03e+03    |
| Time-Optimization       | 1.06        |
| Time-SampleProc         | 0.0393      |
| Time-Sampling           | 26.6        |
| n_timesteps             | 2920000     |
| train-AverageDiscoun... | 41.9        |
| train-AverageReturn     | 46.1        |
| train-EnvExecTime       | 11.7        |
| train-MaxReturn         | 59.4        |
| train-MinReturn         | 32.7        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.2        |
| train-StdReturn         | 7.1         |
-----------------------------------------

 ---------------- Iteration 292 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 292         |
| ItrTime                 | 27.6        |
| LossAfter               | 0.010390034 |
| LossBefore              | 0.011151046 |
| Time                    | 8.06e+03    |
| Time-Optimization       | 1.08        |
| Time-SampleProc         | 0.033       |
| Time-Sampling           | 26.5        |
| n_timesteps             | 2930000     |
| train-AverageDiscoun... | 42          |
| train-AverageReturn     | 46.3        |
| train-EnvExecTime       | 11.7        |
| train-MaxReturn         | 58.7        |
| train-MinReturn         | 33.6        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 6.74        |
-----------------------------------------

 ---------------- Iteration 293 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 293          |
| ItrTime                 | 27.7         |
| LossAfter               | -0.014544527 |
| LossBefore              | -0.014465024 |
| Time                    | 8.08e+03     |
| Time-Optimization       | 1.06         |
| Time-SampleProc         | 0.0483       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 2940000      |
| train-AverageDiscoun... | 42.4         |
| train-AverageReturn     | 47.2         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 60.7         |
| train-MinReturn         | 35.2         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 6.88         |
------------------------------------------

 ---------------- Iteration 294 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 294         |
| ItrTime                 | 27.7        |
| LossAfter               | 0.020782629 |
| LossBefore              | 0.021390803 |
| Time                    | 8.11e+03    |
| Time-Optimization       | 1.07        |
| Time-SampleProc         | 0.0397      |
| Time-Sampling           | 26.6        |
| n_timesteps             | 2950000     |
| train-AverageDiscoun... | 42.6        |
| train-AverageReturn     | 47.5        |
| train-EnvExecTime       | 11.7        |
| train-MaxReturn         | 61.1        |
| train-MinReturn         | 35.4        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 6.58        |
-----------------------------------------

 ---------------- Iteration 295 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 295          |
| ItrTime                 | 27.7         |
| LossAfter               | -0.024565373 |
| LossBefore              | -0.024005057 |
| Time                    | 8.14e+03     |
| Time-Optimization       | 1.07         |
| Time-SampleProc         | 0.0374       |
| Time-Sampling           | 26.6         |
| n_timesteps             | 2960000      |
| train-AverageDiscoun... | 42.5         |
| train-AverageReturn     | 47.3         |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 60.4         |
| train-MinReturn         | 33.3         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 6.75         |
------------------------------------------

 ---------------- Iteration 296 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 296         |
| ItrTime                 | 27.7        |
| LossAfter               | 0.005006332 |
| LossBefore              | 0.005317259 |
| Time                    | 8.17e+03    |
| Time-Optimization       | 1.07        |
| Time-SampleProc         | 0.0438      |
| Time-Sampling           | 26.6        |
| n_timesteps             | 2970000     |
| train-AverageDiscoun... | 42.5        |
| train-AverageReturn     | 47.3        |
| train-EnvExecTime       | 11.7        |
| train-MaxReturn         | 58          |
| train-MinReturn         | 34.2        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.3        |
| train-StdReturn         | 6.87        |
-----------------------------------------

 ---------------- Iteration 297 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 297           |
| ItrTime                 | 27.7          |
| LossAfter               | -0.004185568  |
| LossBefore              | -0.0038206878 |
| Time                    | 8.2e+03       |
| Time-Optimization       | 1.06          |
| Time-SampleProc         | 0.0365        |
| Time-Sampling           | 26.6          |
| n_timesteps             | 2980000       |
| train-AverageDiscoun... | 42.1          |
| train-AverageReturn     | 46.4          |
| train-EnvExecTime       | 11.7          |
| train-MaxReturn         | 61            |
| train-MinReturn         | 34.2          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.2          |
| train-StdReturn         | 6.87          |
-------------------------------------------

 ---------------- Iteration 298 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 298          |
| ItrTime                 | 27.6         |
| LossAfter               | -0.007360494 |
| LossBefore              | -0.006693466 |
| Time                    | 8.22e+03     |
| Time-Optimization       | 1.06         |
| Time-SampleProc         | 0.0396       |
| Time-Sampling           | 26.5         |
| n_timesteps             | 2990000      |
| train-AverageDiscoun... | 41.9         |
| train-AverageReturn     | 46           |
| train-EnvExecTime       | 11.7         |
| train-MaxReturn         | 58           |
| train-MinReturn         | 32           |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 6.52         |
------------------------------------------

 ---------------- Iteration 299 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 299          |
| ItrTime                 | 24.4         |
| LossAfter               | 0.0010545639 |
| LossBefore              | 0.0012773583 |
| Time                    | 8.25e+03     |
| Time-Optimization       | 0.857        |
| Time-SampleProc         | 0.0346       |
| Time-Sampling           | 23.5         |
| n_timesteps             | 3000000      |
| train-AverageDiscoun... | 41.9         |
| train-AverageReturn     | 46.1         |
| train-EnvExecTime       | 9.87         |
| train-MaxReturn         | 58           |
| train-MinReturn         | 32.9         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13           |
| train-StdReturn         | 6.13         |
------------------------------------------
Training finished
