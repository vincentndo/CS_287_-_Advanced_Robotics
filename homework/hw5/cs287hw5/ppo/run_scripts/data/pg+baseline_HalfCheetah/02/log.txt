Logging to /home/nin/workplace/CS287/cs287hw5/ppo/run_scripts/data/pg+baseline_HalfCheetah/02

 ---------------- Iteration 0 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 0           |
| ItrTime                 | 6.1         |
| LossAfter               | -0.51898235 |
| LossBefore              | 0.015627638 |
| Time                    | 6.1         |
| Time-Optimization       | 1.25        |
| Time-SampleProc         | 0.0617      |
| Time-Sampling           | 4.79        |
| n_timesteps             | 10000       |
| train-AverageDiscoun... | -20.2       |
| train-AverageReturn     | -31.3       |
| train-EnvExecTime       | 1.76        |
| train-MaxReturn         | 47.2        |
| train-MinReturn         | -120        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 2.87        |
| train-StdReturn         | 35.2        |
-----------------------------------------

 ---------------- Iteration 1 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 1             |
| ItrTime                 | 6.89          |
| LossAfter               | -0.23461416   |
| LossBefore              | -0.0016315674 |
| Time                    | 13            |
| Time-Optimization       | 1.13          |
| Time-SampleProc         | 0.0351        |
| Time-Sampling           | 5.72          |
| n_timesteps             | 20000         |
| train-AverageDiscoun... | -16.7         |
| train-AverageReturn     | -26.4         |
| train-EnvExecTime       | 2.13          |
| train-MaxReturn         | 50.3          |
| train-MinReturn         | -129          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 3.4           |
| train-StdReturn         | 34.5          |
-------------------------------------------

 ---------------- Iteration 2 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 2           |
| ItrTime                 | 15.2        |
| LossAfter               | -0.17522751 |
| LossBefore              | 0.002131604 |
| Time                    | 28.3        |
| Time-Optimization       | 1.89        |
| Time-SampleProc         | 0.123       |
| Time-Sampling           | 13.2        |
| n_timesteps             | 30000       |
| train-AverageDiscoun... | -20.9       |
| train-AverageReturn     | -32.8       |
| train-EnvExecTime       | 4.87        |
| train-MaxReturn         | 60.2        |
| train-MinReturn         | -198        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 7.91        |
| train-StdReturn         | 40.3        |
-----------------------------------------

 ---------------- Iteration 3 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 3           |
| ItrTime                 | 25          |
| LossAfter               | -0.15334262 |
| LossBefore              | 0.00718479  |
| Time                    | 53.5        |
| Time-Optimization       | 1.73        |
| Time-SampleProc         | 0.144       |
| Time-Sampling           | 23.2        |
| n_timesteps             | 40000       |
| train-AverageDiscoun... | -17.2       |
| train-AverageReturn     | -25.6       |
| train-EnvExecTime       | 8.43        |
| train-MaxReturn         | 67.6        |
| train-MinReturn         | -132        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14          |
| train-StdReturn         | 38.9        |
-----------------------------------------

 ---------------- Iteration 4 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 4            |
| ItrTime                 | 24.7         |
| LossAfter               | -0.2240877   |
| LossBefore              | -0.015886713 |
| Time                    | 78.3         |
| Time-Optimization       | 1.38         |
| Time-SampleProc         | 0.116        |
| Time-Sampling           | 23.2         |
| n_timesteps             | 50000        |
| train-AverageDiscoun... | 12           |
| train-AverageReturn     | 26           |
| train-EnvExecTime       | 8.36         |
| train-MaxReturn         | 122          |
| train-MinReturn         | -62.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 45.4         |
------------------------------------------

 ---------------- Iteration 5 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 5            |
| ItrTime                 | 24.7         |
| LossAfter               | 0.0049959472 |
| LossBefore              | 0.03668518   |
| Time                    | 103          |
| Time-Optimization       | 1.11         |
| Time-SampleProc         | 0.127        |
| Time-Sampling           | 23.4         |
| n_timesteps             | 60000        |
| train-AverageDiscoun... | 39.5         |
| train-AverageReturn     | 71.9         |
| train-EnvExecTime       | 8.38         |
| train-MaxReturn         | 108          |
| train-MinReturn         | -50.9        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.3         |
| train-StdReturn         | 28.1         |
------------------------------------------

 ---------------- Iteration 6 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 6            |
| ItrTime                 | 24.9         |
| LossAfter               | -0.041799244 |
| LossBefore              | 0.035344884  |
| Time                    | 128          |
| Time-Optimization       | 1.14         |
| Time-SampleProc         | 0.152        |
| Time-Sampling           | 23.6         |
| n_timesteps             | 70000        |
| train-AverageDiscoun... | 44.8         |
| train-AverageReturn     | 80           |
| train-EnvExecTime       | 8.36         |
| train-MaxReturn         | 121          |
| train-MinReturn         | -5.6         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.5         |
| train-StdReturn         | 17.7         |
------------------------------------------

 ---------------- Iteration 7 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 7            |
| ItrTime                 | 24.9         |
| LossAfter               | -0.018687304 |
| LossBefore              | 0.0078505855 |
| Time                    | 153          |
| Time-Optimization       | 1.15         |
| Time-SampleProc         | 0.129        |
| Time-Sampling           | 23.6         |
| n_timesteps             | 80000        |
| train-AverageDiscoun... | 44           |
| train-AverageReturn     | 78.8         |
| train-EnvExecTime       | 8.34         |
| train-MaxReturn         | 110          |
| train-MinReturn         | -46          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.5         |
| train-StdReturn         | 21.8         |
------------------------------------------

 ---------------- Iteration 8 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 8            |
| ItrTime                 | 24.9         |
| LossAfter               | -0.06477058  |
| LossBefore              | -0.005259204 |
| Time                    | 178          |
| Time-Optimization       | 1.12         |
| Time-SampleProc         | 0.144        |
| Time-Sampling           | 23.7         |
| n_timesteps             | 90000        |
| train-AverageDiscoun... | 40.9         |
| train-AverageReturn     | 74.7         |
| train-EnvExecTime       | 8.31         |
| train-MaxReturn         | 112          |
| train-MinReturn         | -43.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.6         |
| train-StdReturn         | 24.7         |
------------------------------------------

 ---------------- Iteration 9 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 9            |
| ItrTime                 | 24.7         |
| LossAfter               | -0.08228862  |
| LossBefore              | -0.008064538 |
| Time                    | 203          |
| Time-Optimization       | 1.13         |
| Time-SampleProc         | 0.148        |
| Time-Sampling           | 23.5         |
| n_timesteps             | 100000       |
| train-AverageDiscoun... | 39.2         |
| train-AverageReturn     | 71.5         |
| train-EnvExecTime       | 8.34         |
| train-MaxReturn         | 101          |
| train-MinReturn         | -92.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.4         |
| train-StdReturn         | 33.7         |
------------------------------------------

 ---------------- Iteration 10 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 10           |
| ItrTime                 | 24.8         |
| LossAfter               | -0.009046094 |
| LossBefore              | 0.025342846  |
| Time                    | 228          |
| Time-Optimization       | 1.1          |
| Time-SampleProc         | 0.117        |
| Time-Sampling           | 23.6         |
| n_timesteps             | 110000       |
| train-AverageDiscoun... | 45.5         |
| train-AverageReturn     | 81           |
| train-EnvExecTime       | 8.38         |
| train-MaxReturn         | 109          |
| train-MinReturn         | -49.1        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.4         |
| train-StdReturn         | 22.5         |
------------------------------------------

 ---------------- Iteration 11 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 11           |
| ItrTime                 | 24.9         |
| LossAfter               | -0.052266333 |
| LossBefore              | -0.014252399 |
| Time                    | 253          |
| Time-Optimization       | 1.12         |
| Time-SampleProc         | 0.118        |
| Time-Sampling           | 23.7         |
| n_timesteps             | 120000       |
| train-AverageDiscoun... | 38.8         |
| train-AverageReturn     | 71.9         |
| train-EnvExecTime       | 8.36         |
| train-MaxReturn         | 113          |
| train-MinReturn         | -19.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.6         |
| train-StdReturn         | 27.2         |
------------------------------------------

 ---------------- Iteration 12 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 12            |
| ItrTime                 | 24.8          |
| LossAfter               | -0.08290958   |
| LossBefore              | 0.00029002686 |
| Time                    | 277           |
| Time-Optimization       | 1.13          |
| Time-SampleProc         | 0.124         |
| Time-Sampling           | 23.5          |
| n_timesteps             | 130000        |
| train-AverageDiscoun... | 42.5          |
| train-AverageReturn     | 77.6          |
| train-EnvExecTime       | 8.31          |
| train-MaxReturn         | 113           |
| train-MinReturn         | -14.5         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.5          |
| train-StdReturn         | 24.4          |
-------------------------------------------

 ---------------- Iteration 13 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 13           |
| ItrTime                 | 24.9         |
| LossAfter               | -0.005102539 |
| LossBefore              | 0.00919707   |
| Time                    | 302          |
| Time-Optimization       | 1.12         |
| Time-SampleProc         | 0.118        |
| Time-Sampling           | 23.7         |
| n_timesteps             | 140000       |
| train-AverageDiscoun... | 46.6         |
| train-AverageReturn     | 82.1         |
| train-EnvExecTime       | 8.36         |
| train-MaxReturn         | 109          |
| train-MinReturn         | 0.517        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.6         |
| train-StdReturn         | 16.9         |
------------------------------------------

 ---------------- Iteration 14 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 14           |
| ItrTime                 | 24.9         |
| LossAfter               | -0.048083667 |
| LossBefore              | -0.03124707  |
| Time                    | 327          |
| Time-Optimization       | 1.14         |
| Time-SampleProc         | 0.13         |
| Time-Sampling           | 23.6         |
| n_timesteps             | 150000       |
| train-AverageDiscoun... | 42.9         |
| train-AverageReturn     | 76.4         |
| train-EnvExecTime       | 8.33         |
| train-MaxReturn         | 110          |
| train-MinReturn         | -47.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.6         |
| train-StdReturn         | 26.9         |
------------------------------------------

 ---------------- Iteration 15 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 15           |
| ItrTime                 | 24.9         |
| LossAfter               | -0.057978857 |
| LossBefore              | 0.0066918214 |
| Time                    | 352          |
| Time-Optimization       | 1.18         |
| Time-SampleProc         | 0.134        |
| Time-Sampling           | 23.6         |
| n_timesteps             | 160000       |
| train-AverageDiscoun... | 45.4         |
| train-AverageReturn     | 81           |
| train-EnvExecTime       | 8.32         |
| train-MaxReturn         | 109          |
| train-MinReturn         | -24.9        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.5         |
| train-StdReturn         | 21           |
------------------------------------------

 ---------------- Iteration 16 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 16           |
| ItrTime                 | 25           |
| LossAfter               | -0.06472551  |
| LossBefore              | -0.019778077 |
| Time                    | 377          |
| Time-Optimization       | 1.11         |
| Time-SampleProc         | 0.12         |
| Time-Sampling           | 23.8         |
| n_timesteps             | 170000       |
| train-AverageDiscoun... | 47.1         |
| train-AverageReturn     | 84.4         |
| train-EnvExecTime       | 8.42         |
| train-MaxReturn         | 121          |
| train-MinReturn         | -10.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.6         |
| train-StdReturn         | 23.7         |
------------------------------------------

 ---------------- Iteration 17 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 17           |
| ItrTime                 | 25           |
| LossAfter               | -0.053337988 |
| LossBefore              | -0.032898046 |
| Time                    | 402          |
| Time-Optimization       | 1.1          |
| Time-SampleProc         | 0.147        |
| Time-Sampling           | 23.7         |
| n_timesteps             | 180000       |
| train-AverageDiscoun... | 30.7         |
| train-AverageReturn     | 56.8         |
| train-EnvExecTime       | 8.55         |
| train-MaxReturn         | 113          |
| train-MinReturn         | -32          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.4         |
| train-StdReturn         | 26.5         |
------------------------------------------

 ---------------- Iteration 18 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 18           |
| ItrTime                 | 25           |
| LossAfter               | -0.118651025 |
| LossBefore              | -0.045605958 |
| Time                    | 427          |
| Time-Optimization       | 1.13         |
| Time-SampleProc         | 0.12         |
| Time-Sampling           | 23.7         |
| n_timesteps             | 190000       |
| train-AverageDiscoun... | 18.3         |
| train-AverageReturn     | 35.3         |
| train-EnvExecTime       | 8.48         |
| train-MaxReturn         | 89.7         |
| train-MinReturn         | -19.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.5         |
| train-StdReturn         | 23           |
------------------------------------------

 ---------------- Iteration 19 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 19           |
| ItrTime                 | 24.8         |
| LossAfter               | -0.123100534 |
| LossBefore              | -0.02483562  |
| Time                    | 452          |
| Time-Optimization       | 1.1          |
| Time-SampleProc         | 0.118        |
| Time-Sampling           | 23.6         |
| n_timesteps             | 200000       |
| train-AverageDiscoun... | 37.7         |
| train-AverageReturn     | 68.8         |
| train-EnvExecTime       | 8.42         |
| train-MaxReturn         | 104          |
| train-MinReturn         | -23          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.4         |
| train-StdReturn         | 22           |
------------------------------------------

 ---------------- Iteration 20 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 20           |
| ItrTime                 | 25.2         |
| LossAfter               | -0.07043029  |
| LossBefore              | -0.017580926 |
| Time                    | 478          |
| Time-Optimization       | 1.12         |
| Time-SampleProc         | 0.124        |
| Time-Sampling           | 23.9         |
| n_timesteps             | 210000       |
| train-AverageDiscoun... | 45.9         |
| train-AverageReturn     | 81.8         |
| train-EnvExecTime       | 8.44         |
| train-MaxReturn         | 112          |
| train-MinReturn         | -49.9        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.7         |
| train-StdReturn         | 23.1         |
------------------------------------------

 ---------------- Iteration 21 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 21            |
| ItrTime                 | 25.2          |
| LossAfter               | -0.04597361   |
| LossBefore              | -0.0010606934 |
| Time                    | 503           |
| Time-Optimization       | 1.15          |
| Time-SampleProc         | 0.115         |
| Time-Sampling           | 23.9          |
| n_timesteps             | 220000        |
| train-AverageDiscoun... | 43.8          |
| train-AverageReturn     | 77.5          |
| train-EnvExecTime       | 8.48          |
| train-MaxReturn         | 108           |
| train-MinReturn         | -48.2         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.7          |
| train-StdReturn         | 28.6          |
-------------------------------------------

 ---------------- Iteration 22 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 22           |
| ItrTime                 | 25.3         |
| LossAfter               | 0.0012534179 |
| LossBefore              | 0.016668506  |
| Time                    | 528          |
| Time-Optimization       | 1.11         |
| Time-SampleProc         | 0.12         |
| Time-Sampling           | 24.1         |
| n_timesteps             | 230000       |
| train-AverageDiscoun... | 42.7         |
| train-AverageReturn     | 76.3         |
| train-EnvExecTime       | 8.52         |
| train-MaxReturn         | 114          |
| train-MinReturn         | -42.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.8         |
| train-StdReturn         | 29.8         |
------------------------------------------

 ---------------- Iteration 23 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 23          |
| ItrTime                 | 25.3        |
| LossAfter               | -0.0210485  |
| LossBefore              | 0.006101221 |
| Time                    | 554         |
| Time-Optimization       | 1.1         |
| Time-SampleProc         | 0.126       |
| Time-Sampling           | 24.1        |
| n_timesteps             | 240000      |
| train-AverageDiscoun... | 46.3        |
| train-AverageReturn     | 81.2        |
| train-EnvExecTime       | 8.47        |
| train-MaxReturn         | 111         |
| train-MinReturn         | -13.8       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.9        |
| train-StdReturn         | 18.9        |
-----------------------------------------

 ---------------- Iteration 24 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 24           |
| ItrTime                 | 24.5         |
| LossAfter               | -0.0713147   |
| LossBefore              | -0.005336157 |
| Time                    | 578          |
| Time-Optimization       | 1.09         |
| Time-SampleProc         | 0.139        |
| Time-Sampling           | 23.2         |
| n_timesteps             | 250000       |
| train-AverageDiscoun... | 45.3         |
| train-AverageReturn     | 80.7         |
| train-EnvExecTime       | 8.27         |
| train-MaxReturn         | 110          |
| train-MinReturn         | -19.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 22.3         |
------------------------------------------

 ---------------- Iteration 25 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 25           |
| ItrTime                 | 24.2         |
| LossAfter               | -0.007466455 |
| LossBefore              | 0.04162063   |
| Time                    | 602          |
| Time-Optimization       | 1.1          |
| Time-SampleProc         | 0.116        |
| Time-Sampling           | 23           |
| n_timesteps             | 260000       |
| train-AverageDiscoun... | 48.5         |
| train-AverageReturn     | 85.4         |
| train-EnvExecTime       | 8.19         |
| train-MaxReturn         | 108          |
| train-MinReturn         | 12.5         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 15.6         |
------------------------------------------

 ---------------- Iteration 26 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 26            |
| ItrTime                 | 24.9          |
| LossAfter               | -0.036964674  |
| LossBefore              | -0.0038946776 |
| Time                    | 627           |
| Time-Optimization       | 1.25          |
| Time-SampleProc         | 0.125         |
| Time-Sampling           | 23.5          |
| n_timesteps             | 270000        |
| train-AverageDiscoun... | 45.8          |
| train-AverageReturn     | 81.4          |
| train-EnvExecTime       | 8.39          |
| train-MaxReturn         | 112           |
| train-MinReturn         | -13.3         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.4          |
| train-StdReturn         | 17.9          |
-------------------------------------------

 ---------------- Iteration 27 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 27           |
| ItrTime                 | 27.1         |
| LossAfter               | -0.02600222  |
| LossBefore              | -0.014704883 |
| Time                    | 654          |
| Time-Optimization       | 1.18         |
| Time-SampleProc         | 0.152        |
| Time-Sampling           | 25.8         |
| n_timesteps             | 280000       |
| train-AverageDiscoun... | 47.3         |
| train-AverageReturn     | 83.4         |
| train-EnvExecTime       | 9            |
| train-MaxReturn         | 109          |
| train-MinReturn         | -26.1        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 16           |
| train-StdReturn         | 19.3         |
------------------------------------------

 ---------------- Iteration 28 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 28            |
| ItrTime                 | 24.4          |
| LossAfter               | -0.056133326  |
| LossBefore              | -0.0112496335 |
| Time                    | 679           |
| Time-Optimization       | 1.05          |
| Time-SampleProc         | 0.118         |
| Time-Sampling           | 23.2          |
| n_timesteps             | 290000        |
| train-AverageDiscoun... | 48.2          |
| train-AverageReturn     | 84.6          |
| train-EnvExecTime       | 8.26          |
| train-MaxReturn         | 103           |
| train-MinReturn         | 36.1          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.2          |
| train-StdReturn         | 12.6          |
-------------------------------------------

 ---------------- Iteration 29 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 29           |
| ItrTime                 | 24.3         |
| LossAfter               | -0.022884862 |
| LossBefore              | 0.016122265  |
| Time                    | 703          |
| Time-Optimization       | 1.1          |
| Time-SampleProc         | 0.143        |
| Time-Sampling           | 23.1         |
| n_timesteps             | 300000       |
| train-AverageDiscoun... | 46.9         |
| train-AverageReturn     | 82.8         |
| train-EnvExecTime       | 8.2          |
| train-MaxReturn         | 120          |
| train-MinReturn         | -0.808       |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 16.7         |
------------------------------------------

 ---------------- Iteration 30 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 30           |
| ItrTime                 | 28           |
| LossAfter               | -0.018050501 |
| LossBefore              | 0.0058456054 |
| Time                    | 731          |
| Time-Optimization       | 1.48         |
| Time-SampleProc         | 0.135        |
| Time-Sampling           | 26.4         |
| n_timesteps             | 310000       |
| train-AverageDiscoun... | 47.3         |
| train-AverageReturn     | 83.2         |
| train-EnvExecTime       | 9.17         |
| train-MaxReturn         | 105          |
| train-MinReturn         | 0.999        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 16.4         |
| train-StdReturn         | 17.4         |
------------------------------------------

 ---------------- Iteration 31 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 31             |
| ItrTime                 | 33.4           |
| LossAfter               | -0.00017758789 |
| LossBefore              | 0.029566552    |
| Time                    | 765            |
| Time-Optimization       | 1.76           |
| Time-SampleProc         | 0.158          |
| Time-Sampling           | 31.5           |
| n_timesteps             | 320000         |
| train-AverageDiscoun... | 47.8           |
| train-AverageReturn     | 82.6           |
| train-EnvExecTime       | 10.5           |
| train-MaxReturn         | 113            |
| train-MinReturn         | -11            |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 20             |
| train-StdReturn         | 19.6           |
--------------------------------------------

 ---------------- Iteration 32 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 32           |
| ItrTime                 | 39.9         |
| LossAfter               | -0.049922753 |
| LossBefore              | -0.009385095 |
| Time                    | 805          |
| Time-Optimization       | 1.64         |
| Time-SampleProc         | 0.146        |
| Time-Sampling           | 38.1         |
| n_timesteps             | 330000       |
| train-AverageDiscoun... | 49.1         |
| train-AverageReturn     | 86           |
| train-EnvExecTime       | 12.3         |
| train-MaxReturn         | 109          |
| train-MinReturn         | -4.85        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 24.6         |
| train-StdReturn         | 16.5         |
------------------------------------------

 ---------------- Iteration 33 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 33           |
| ItrTime                 | 33.4         |
| LossAfter               | -0.0656169   |
| LossBefore              | -0.014440893 |
| Time                    | 838          |
| Time-Optimization       | 1.48         |
| Time-SampleProc         | 0.124        |
| Time-Sampling           | 31.8         |
| n_timesteps             | 340000       |
| train-AverageDiscoun... | 48           |
| train-AverageReturn     | 83.8         |
| train-EnvExecTime       | 10.5         |
| train-MaxReturn         | 113          |
| train-MinReturn         | 17.3         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 20.3         |
| train-StdReturn         | 14.1         |
------------------------------------------

 ---------------- Iteration 34 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 34           |
| ItrTime                 | 32.2         |
| LossAfter               | -0.009960254 |
| LossBefore              | 0.004226709  |
| Time                    | 871          |
| Time-Optimization       | 1.53         |
| Time-SampleProc         | 0.14         |
| Time-Sampling           | 30.5         |
| n_timesteps             | 350000       |
| train-AverageDiscoun... | 48.4         |
| train-AverageReturn     | 84.9         |
| train-EnvExecTime       | 10.3         |
| train-MaxReturn         | 116          |
| train-MinReturn         | 20.8         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 19.3         |
| train-StdReturn         | 13.1         |
------------------------------------------

 ---------------- Iteration 35 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 35           |
| ItrTime                 | 33.7         |
| LossAfter               | -0.05233645  |
| LossBefore              | -0.023949586 |
| Time                    | 904          |
| Time-Optimization       | 1.72         |
| Time-SampleProc         | 0.13         |
| Time-Sampling           | 31.8         |
| n_timesteps             | 360000       |
| train-AverageDiscoun... | 47.4         |
| train-AverageReturn     | 83.1         |
| train-EnvExecTime       | 10.7         |
| train-MaxReturn         | 105          |
| train-MinReturn         | -13.9        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 20.2         |
| train-StdReturn         | 17.5         |
------------------------------------------

 ---------------- Iteration 36 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 36           |
| ItrTime                 | 33.2         |
| LossAfter               | -0.03358814  |
| LossBefore              | -0.024379648 |
| Time                    | 938          |
| Time-Optimization       | 1.61         |
| Time-SampleProc         | 0.16         |
| Time-Sampling           | 31.4         |
| n_timesteps             | 370000       |
| train-AverageDiscoun... | 48.4         |
| train-AverageReturn     | 84.9         |
| train-EnvExecTime       | 10.6         |
| train-MaxReturn         | 111          |
| train-MinReturn         | 22.5         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 19.9         |
| train-StdReturn         | 13.6         |
------------------------------------------

 ---------------- Iteration 37 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 37            |
| ItrTime                 | 34.4          |
| LossAfter               | -0.0029257813 |
| LossBefore              | 0.006305664   |
| Time                    | 972           |
| Time-Optimization       | 1.63          |
| Time-SampleProc         | 0.197         |
| Time-Sampling           | 32.5          |
| n_timesteps             | 380000        |
| train-AverageDiscoun... | 46            |
| train-AverageReturn     | 80.5          |
| train-EnvExecTime       | 10.9          |
| train-MaxReturn         | 107           |
| train-MinReturn         | -9.19         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 20.6          |
| train-StdReturn         | 21.2          |
-------------------------------------------

 ---------------- Iteration 38 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 38           |
| ItrTime                 | 36           |
| LossAfter               | -0.053124756 |
| LossBefore              | -0.008987183 |
| Time                    | 1.01e+03     |
| Time-Optimization       | 1.52         |
| Time-SampleProc         | 0.159        |
| Time-Sampling           | 34.3         |
| n_timesteps             | 390000       |
| train-AverageDiscoun... | 48.8         |
| train-AverageReturn     | 85.7         |
| train-EnvExecTime       | 11.4         |
| train-MaxReturn         | 109          |
| train-MinReturn         | 30.1         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 21.9         |
| train-StdReturn         | 13.8         |
------------------------------------------

 ---------------- Iteration 39 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 39           |
| ItrTime                 | 35.8         |
| LossAfter               | -0.055124193 |
| LossBefore              | -0.038787648 |
| Time                    | 1.04e+03     |
| Time-Optimization       | 1.68         |
| Time-SampleProc         | 0.188        |
| Time-Sampling           | 34           |
| n_timesteps             | 400000       |
| train-AverageDiscoun... | 47.5         |
| train-AverageReturn     | 82.8         |
| train-EnvExecTime       | 11.3         |
| train-MaxReturn         | 118          |
| train-MinReturn         | 3.22         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 21.6         |
| train-StdReturn         | 17.2         |
------------------------------------------

 ---------------- Iteration 40 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 40            |
| ItrTime                 | 36.3          |
| LossAfter               | 0.00027270507 |
| LossBefore              | 0.013932006   |
| Time                    | 1.08e+03      |
| Time-Optimization       | 1.79          |
| Time-SampleProc         | 0.191         |
| Time-Sampling           | 34.3          |
| n_timesteps             | 410000        |
| train-AverageDiscoun... | 48.9          |
| train-AverageReturn     | 86            |
| train-EnvExecTime       | 11.1          |
| train-MaxReturn         | 108           |
| train-MinReturn         | 25.1          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 22.1          |
| train-StdReturn         | 12.2          |
-------------------------------------------

 ---------------- Iteration 41 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 41           |
| ItrTime                 | 41.4         |
| LossAfter               | -0.051393703 |
| LossBefore              | -0.021164257 |
| Time                    | 1.12e+03     |
| Time-Optimization       | 1.81         |
| Time-SampleProc         | 0.19         |
| Time-Sampling           | 39.4         |
| n_timesteps             | 420000       |
| train-AverageDiscoun... | 46.8         |
| train-AverageReturn     | 81.9         |
| train-EnvExecTime       | 12.5         |
| train-MaxReturn         | 106          |
| train-MinReturn         | 7.18         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 25.7         |
| train-StdReturn         | 18.1         |
------------------------------------------

 ---------------- Iteration 42 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 42           |
| ItrTime                 | 42.3         |
| LossAfter               | -0.039544336 |
| LossBefore              | -0.017965795 |
| Time                    | 1.16e+03     |
| Time-Optimization       | 1.81         |
| Time-SampleProc         | 0.185        |
| Time-Sampling           | 40.3         |
| n_timesteps             | 430000       |
| train-AverageDiscoun... | 47.3         |
| train-AverageReturn     | 82.4         |
| train-EnvExecTime       | 12.7         |
| train-MaxReturn         | 109          |
| train-MinReturn         | 17.6         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 26.3         |
| train-StdReturn         | 14.6         |
------------------------------------------

 ---------------- Iteration 43 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 43           |
| ItrTime                 | 40.5         |
| LossAfter               | -0.05046118  |
| LossBefore              | -0.022226758 |
| Time                    | 1.2e+03      |
| Time-Optimization       | 1.93         |
| Time-SampleProc         | 0.197        |
| Time-Sampling           | 38.4         |
| n_timesteps             | 440000       |
| train-AverageDiscoun... | 47.6         |
| train-AverageReturn     | 83           |
| train-EnvExecTime       | 12.3         |
| train-MaxReturn         | 116          |
| train-MinReturn         | 6.23         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 24.9         |
| train-StdReturn         | 16.9         |
------------------------------------------

 ---------------- Iteration 44 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 44          |
| ItrTime                 | 39.4        |
| LossAfter               | 0.014391162 |
| LossBefore              | 0.029756676 |
| Time                    | 1.24e+03    |
| Time-Optimization       | 1.44        |
| Time-SampleProc         | 0.135       |
| Time-Sampling           | 37.8        |
| n_timesteps             | 450000      |
| train-AverageDiscoun... | 48.5        |
| train-AverageReturn     | 85          |
| train-EnvExecTime       | 12.3        |
| train-MaxReturn         | 115         |
| train-MinReturn         | 30.4        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 24.4        |
| train-StdReturn         | 13.3        |
-----------------------------------------

 ---------------- Iteration 45 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 45           |
| ItrTime                 | 36.7         |
| LossAfter               | -0.010265699 |
| LossBefore              | 0.0005624878 |
| Time                    | 1.28e+03     |
| Time-Optimization       | 1.82         |
| Time-SampleProc         | 0.142        |
| Time-Sampling           | 34.7         |
| n_timesteps             | 460000       |
| train-AverageDiscoun... | 47.8         |
| train-AverageReturn     | 83.7         |
| train-EnvExecTime       | 11.3         |
| train-MaxReturn         | 111          |
| train-MinReturn         | -30.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 22.3         |
| train-StdReturn         | 15           |
------------------------------------------

 ---------------- Iteration 46 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 46          |
| ItrTime                 | 38          |
| LossAfter               | -0.02926333 |
| LossBefore              | -0.01101941 |
| Time                    | 1.32e+03    |
| Time-Optimization       | 1.57        |
| Time-SampleProc         | 0.201       |
| Time-Sampling           | 36.2        |
| n_timesteps             | 470000      |
| train-AverageDiscoun... | 48.6        |
| train-AverageReturn     | 85.1        |
| train-EnvExecTime       | 11.8        |
| train-MaxReturn         | 110         |
| train-MinReturn         | 2.76        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 23.4        |
| train-StdReturn         | 17.4        |
-----------------------------------------

 ---------------- Iteration 47 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 47          |
| ItrTime                 | 34.4        |
| LossAfter               | 0.002841797 |
| LossBefore              | 0.030755859 |
| Time                    | 1.35e+03    |
| Time-Optimization       | 1.73        |
| Time-SampleProc         | 0.191       |
| Time-Sampling           | 32.5        |
| n_timesteps             | 480000      |
| train-AverageDiscoun... | 46.1        |
| train-AverageReturn     | 80.4        |
| train-EnvExecTime       | 10.7        |
| train-MaxReturn         | 111         |
| train-MinReturn         | 16.5        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 20.7        |
| train-StdReturn         | 19.5        |
-----------------------------------------

 ---------------- Iteration 48 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 48          |
| ItrTime                 | 37.5        |
| LossAfter               | -0.07889595 |
| LossBefore              | -0.04632617 |
| Time                    | 1.39e+03    |
| Time-Optimization       | 1.83        |
| Time-SampleProc         | 0.217       |
| Time-Sampling           | 35.5        |
| n_timesteps             | 490000      |
| train-AverageDiscoun... | 48.3        |
| train-AverageReturn     | 84.2        |
| train-EnvExecTime       | 11.7        |
| train-MaxReturn         | 110         |
| train-MinReturn         | -20.4       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 22.7        |
| train-StdReturn         | 17.7        |
-----------------------------------------

 ---------------- Iteration 49 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 49           |
| ItrTime                 | 39.4         |
| LossAfter               | -0.033534717 |
| LossBefore              | -0.015954297 |
| Time                    | 1.43e+03     |
| Time-Optimization       | 1.62         |
| Time-SampleProc         | 0.194        |
| Time-Sampling           | 37.6         |
| n_timesteps             | 500000       |
| train-AverageDiscoun... | 49.9         |
| train-AverageReturn     | 87.5         |
| train-EnvExecTime       | 12.2         |
| train-MaxReturn         | 116          |
| train-MinReturn         | 36.7         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 24.2         |
| train-StdReturn         | 12.7         |
------------------------------------------

 ---------------- Iteration 50 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 50            |
| ItrTime                 | 36.5          |
| LossAfter               | -0.0123042725 |
| LossBefore              | 0.030744385   |
| Time                    | 1.47e+03      |
| Time-Optimization       | 1.54          |
| Time-SampleProc         | 0.141         |
| Time-Sampling           | 34.8          |
| n_timesteps             | 510000        |
| train-AverageDiscoun... | 48.3          |
| train-AverageReturn     | 85            |
| train-EnvExecTime       | 11.5          |
| train-MaxReturn         | 108           |
| train-MinReturn         | 10.5          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 22.2          |
| train-StdReturn         | 15            |
-------------------------------------------

 ---------------- Iteration 51 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 51            |
| ItrTime                 | 37.1          |
| LossAfter               | 0.00045306396 |
| LossBefore              | 0.016874572   |
| Time                    | 1.5e+03       |
| Time-Optimization       | 1.65          |
| Time-SampleProc         | 0.155         |
| Time-Sampling           | 35.3          |
| n_timesteps             | 520000        |
| train-AverageDiscoun... | 48.9          |
| train-AverageReturn     | 85.6          |
| train-EnvExecTime       | 11.5          |
| train-MaxReturn         | 119           |
| train-MinReturn         | -11.4         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 22.7          |
| train-StdReturn         | 17.6          |
-------------------------------------------

 ---------------- Iteration 52 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 52            |
| ItrTime                 | 35.3          |
| LossAfter               | -0.02027647   |
| LossBefore              | -0.0051748534 |
| Time                    | 1.54e+03      |
| Time-Optimization       | 1.82          |
| Time-SampleProc         | 0.181         |
| Time-Sampling           | 33.3          |
| n_timesteps             | 530000        |
| train-AverageDiscoun... | 49.5          |
| train-AverageReturn     | 86.6          |
| train-EnvExecTime       | 11            |
| train-MaxReturn         | 115           |
| train-MinReturn         | 54.6          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 21.3          |
| train-StdReturn         | 10.3          |
-------------------------------------------

 ---------------- Iteration 53 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 53           |
| ItrTime                 | 38.2         |
| LossAfter               | -0.027651709 |
| LossBefore              | -0.010570899 |
| Time                    | 1.58e+03     |
| Time-Optimization       | 1.82         |
| Time-SampleProc         | 0.163        |
| Time-Sampling           | 36.3         |
| n_timesteps             | 540000       |
| train-AverageDiscoun... | 47.5         |
| train-AverageReturn     | 83.3         |
| train-EnvExecTime       | 11.8         |
| train-MaxReturn         | 112          |
| train-MinReturn         | 28.7         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 23.4         |
| train-StdReturn         | 14.6         |
------------------------------------------

 ---------------- Iteration 54 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 54          |
| ItrTime                 | 36          |
| LossAfter               | -0.03464617 |
| LossBefore              | 0.021309057 |
| Time                    | 1.61e+03    |
| Time-Optimization       | 1.72        |
| Time-SampleProc         | 0.175       |
| Time-Sampling           | 34.1        |
| n_timesteps             | 550000      |
| train-AverageDiscoun... | 47.8        |
| train-AverageReturn     | 83.4        |
| train-EnvExecTime       | 11.2        |
| train-MaxReturn         | 108         |
| train-MinReturn         | 15          |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 21.8        |
| train-StdReturn         | 16.3        |
-----------------------------------------

 ---------------- Iteration 55 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 55            |
| ItrTime                 | 34.5          |
| LossAfter               | -0.08621304   |
| LossBefore              | -0.0028408936 |
| Time                    | 1.65e+03      |
| Time-Optimization       | 1.64          |
| Time-SampleProc         | 0.207         |
| Time-Sampling           | 32.7          |
| n_timesteps             | 560000        |
| train-AverageDiscoun... | 47.4          |
| train-AverageReturn     | 83.8          |
| train-EnvExecTime       | 11            |
| train-MaxReturn         | 109           |
| train-MinReturn         | -5.4          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 20.7          |
| train-StdReturn         | 17.5          |
-------------------------------------------

 ---------------- Iteration 56 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 56           |
| ItrTime                 | 35.3         |
| LossAfter               | -0.0669958   |
| LossBefore              | -0.014880811 |
| Time                    | 1.68e+03     |
| Time-Optimization       | 1.54         |
| Time-SampleProc         | 0.186        |
| Time-Sampling           | 33.5         |
| n_timesteps             | 570000       |
| train-AverageDiscoun... | 42.9         |
| train-AverageReturn     | 76.3         |
| train-EnvExecTime       | 11           |
| train-MaxReturn         | 113          |
| train-MinReturn         | 19.9         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 21.5         |
| train-StdReturn         | 16.6         |
------------------------------------------

 ---------------- Iteration 57 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 57           |
| ItrTime                 | 34.7         |
| LossAfter               | -0.07851387  |
| LossBefore              | -0.013830591 |
| Time                    | 1.72e+03     |
| Time-Optimization       | 1.72         |
| Time-SampleProc         | 0.19         |
| Time-Sampling           | 32.8         |
| n_timesteps             | 580000       |
| train-AverageDiscoun... | 45.9         |
| train-AverageReturn     | 81.5         |
| train-EnvExecTime       | 11           |
| train-MaxReturn         | 114          |
| train-MinReturn         | 10.6         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 20.8         |
| train-StdReturn         | 17.4         |
------------------------------------------

 ---------------- Iteration 58 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 58            |
| ItrTime                 | 35.8          |
| LossAfter               | -0.0017635132 |
| LossBefore              | -0.0123083675 |
| Time                    | 1.75e+03      |
| Time-Optimization       | 1.57          |
| Time-SampleProc         | 0.174         |
| Time-Sampling           | 34.1          |
| n_timesteps             | 590000        |
| train-AverageDiscoun... | 47.6          |
| train-AverageReturn     | 83.3          |
| train-EnvExecTime       | 11.3          |
| train-MaxReturn         | 117           |
| train-MinReturn         | -1.65         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 21.8          |
| train-StdReturn         | 20            |
-------------------------------------------

 ---------------- Iteration 59 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 59           |
| ItrTime                 | 35.5         |
| LossAfter               | -0.06364146  |
| LossBefore              | -0.014932666 |
| Time                    | 1.79e+03     |
| Time-Optimization       | 1.64         |
| Time-SampleProc         | 0.19         |
| Time-Sampling           | 33.7         |
| n_timesteps             | 600000       |
| train-AverageDiscoun... | 49.4         |
| train-AverageReturn     | 86.4         |
| train-EnvExecTime       | 11.2         |
| train-MaxReturn         | 108          |
| train-MinReturn         | 57.2         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 21.4         |
| train-StdReturn         | 10.1         |
------------------------------------------

 ---------------- Iteration 60 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 60           |
| ItrTime                 | 34.8         |
| LossAfter               | -0.017889453 |
| LossBefore              | 0.011399927  |
| Time                    | 1.83e+03     |
| Time-Optimization       | 1.57         |
| Time-SampleProc         | 0.16         |
| Time-Sampling           | 33.1         |
| n_timesteps             | 610000       |
| train-AverageDiscoun... | 47.9         |
| train-AverageReturn     | 83.4         |
| train-EnvExecTime       | 11           |
| train-MaxReturn         | 106          |
| train-MinReturn         | 16.9         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 21           |
| train-StdReturn         | 16.1         |
------------------------------------------

 ---------------- Iteration 61 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 61           |
| ItrTime                 | 33.9         |
| LossAfter               | -0.06894224  |
| LossBefore              | -0.044513613 |
| Time                    | 1.86e+03     |
| Time-Optimization       | 1.51         |
| Time-SampleProc         | 0.194        |
| Time-Sampling           | 32.2         |
| n_timesteps             | 620000       |
| train-AverageDiscoun... | 48.7         |
| train-AverageReturn     | 84.9         |
| train-EnvExecTime       | 10.7         |
| train-MaxReturn         | 108          |
| train-MinReturn         | -30.5        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 20.5         |
| train-StdReturn         | 15.3         |
------------------------------------------

 ---------------- Iteration 62 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 62           |
| ItrTime                 | 34.1         |
| LossAfter               | -0.027813502 |
| LossBefore              | 0.011455371  |
| Time                    | 1.89e+03     |
| Time-Optimization       | 1.67         |
| Time-SampleProc         | 0.138        |
| Time-Sampling           | 32.3         |
| n_timesteps             | 630000       |
| train-AverageDiscoun... | 46.4         |
| train-AverageReturn     | 81.4         |
| train-EnvExecTime       | 10.8         |
| train-MaxReturn         | 103          |
| train-MinReturn         | 11.6         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 20.5         |
| train-StdReturn         | 18.7         |
------------------------------------------

 ---------------- Iteration 63 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 63           |
| ItrTime                 | 35.6         |
| LossAfter               | -0.023627369 |
| LossBefore              | 0.001772168  |
| Time                    | 1.93e+03     |
| Time-Optimization       | 1.7          |
| Time-SampleProc         | 0.165        |
| Time-Sampling           | 33.7         |
| n_timesteps             | 640000       |
| train-AverageDiscoun... | 47.9         |
| train-AverageReturn     | 84.2         |
| train-EnvExecTime       | 11.1         |
| train-MaxReturn         | 107          |
| train-MinReturn         | 5.55         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 21.5         |
| train-StdReturn         | 14.7         |
------------------------------------------

 ---------------- Iteration 64 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 64           |
| ItrTime                 | 35.1         |
| LossAfter               | -0.09137339  |
| LossBefore              | 0.0073494385 |
| Time                    | 1.96e+03     |
| Time-Optimization       | 1.6          |
| Time-SampleProc         | 0.149        |
| Time-Sampling           | 33.4         |
| n_timesteps             | 650000       |
| train-AverageDiscoun... | 48.1         |
| train-AverageReturn     | 85           |
| train-EnvExecTime       | 11           |
| train-MaxReturn         | 116          |
| train-MinReturn         | -26.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 21.3         |
| train-StdReturn         | 17.9         |
------------------------------------------

 ---------------- Iteration 65 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 65           |
| ItrTime                 | 34.7         |
| LossAfter               | -0.0422854   |
| LossBefore              | -0.012513746 |
| Time                    | 2e+03        |
| Time-Optimization       | 1.55         |
| Time-SampleProc         | 0.144        |
| Time-Sampling           | 33           |
| n_timesteps             | 660000       |
| train-AverageDiscoun... | 47.3         |
| train-AverageReturn     | 82.9         |
| train-EnvExecTime       | 10.9         |
| train-MaxReturn         | 108          |
| train-MinReturn         | -4.28        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 21.1         |
| train-StdReturn         | 19           |
------------------------------------------

 ---------------- Iteration 66 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 66            |
| ItrTime                 | 34.1          |
| LossAfter               | -0.053770375  |
| LossBefore              | -0.0015474121 |
| Time                    | 2.03e+03      |
| Time-Optimization       | 1.68          |
| Time-SampleProc         | 0.19          |
| Time-Sampling           | 32.2          |
| n_timesteps             | 670000        |
| train-AverageDiscoun... | 46.1          |
| train-AverageReturn     | 81            |
| train-EnvExecTime       | 10.8          |
| train-MaxReturn         | 107           |
| train-MinReturn         | -4.68         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 20.4          |
| train-StdReturn         | 20.5          |
-------------------------------------------

 ---------------- Iteration 67 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 67           |
| ItrTime                 | 35.2         |
| LossAfter               | -0.06634155  |
| LossBefore              | -0.027108252 |
| Time                    | 2.07e+03     |
| Time-Optimization       | 1.41         |
| Time-SampleProc         | 0.183        |
| Time-Sampling           | 33.6         |
| n_timesteps             | 680000       |
| train-AverageDiscoun... | 48           |
| train-AverageReturn     | 83.7         |
| train-EnvExecTime       | 11.1         |
| train-MaxReturn         | 111          |
| train-MinReturn         | -13.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 21.4         |
| train-StdReturn         | 20.4         |
------------------------------------------

 ---------------- Iteration 68 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 68           |
| ItrTime                 | 34.9         |
| LossAfter               | -0.030841846 |
| LossBefore              | -0.016164063 |
| Time                    | 2.1e+03      |
| Time-Optimization       | 1.69         |
| Time-SampleProc         | 0.197        |
| Time-Sampling           | 33           |
| n_timesteps             | 690000       |
| train-AverageDiscoun... | 47.2         |
| train-AverageReturn     | 83           |
| train-EnvExecTime       | 11           |
| train-MaxReturn         | 105          |
| train-MinReturn         | 13.7         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 21           |
| train-StdReturn         | 14.5         |
------------------------------------------

 ---------------- Iteration 69 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 69          |
| ItrTime                 | 34.8        |
| LossAfter               | -0.06709375 |
| LossBefore              | 0.007628906 |
| Time                    | 2.14e+03    |
| Time-Optimization       | 1.75        |
| Time-SampleProc         | 0.176       |
| Time-Sampling           | 32.8        |
| n_timesteps             | 700000      |
| train-AverageDiscoun... | 49.7        |
| train-AverageReturn     | 87          |
| train-EnvExecTime       | 11          |
| train-MaxReturn         | 111         |
| train-MinReturn         | 13.7        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 20.8        |
| train-StdReturn         | 11.8        |
-----------------------------------------

 ---------------- Iteration 70 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 70           |
| ItrTime                 | 34.6         |
| LossAfter               | -0.07348174  |
| LossBefore              | -0.025170568 |
| Time                    | 2.17e+03     |
| Time-Optimization       | 1.63         |
| Time-SampleProc         | 0.15         |
| Time-Sampling           | 32.8         |
| n_timesteps             | 710000       |
| train-AverageDiscoun... | 49.5         |
| train-AverageReturn     | 86.5         |
| train-EnvExecTime       | 10.9         |
| train-MaxReturn         | 117          |
| train-MinReturn         | 24.9         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 20.8         |
| train-StdReturn         | 12.6         |
------------------------------------------

 ---------------- Iteration 71 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 71            |
| ItrTime                 | 35.6          |
| LossAfter               | -0.04131056   |
| LossBefore              | -0.0032406738 |
| Time                    | 2.21e+03      |
| Time-Optimization       | 1.57          |
| Time-SampleProc         | 0.158         |
| Time-Sampling           | 33.9          |
| n_timesteps             | 720000        |
| train-AverageDiscoun... | 49.1          |
| train-AverageReturn     | 86.3          |
| train-EnvExecTime       | 11.2          |
| train-MaxReturn         | 110           |
| train-MinReturn         | 5.14          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 21.6          |
| train-StdReturn         | 15.7          |
-------------------------------------------

 ---------------- Iteration 72 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 72           |
| ItrTime                 | 35           |
| LossAfter               | -0.045756616 |
| LossBefore              | 0.0022208618 |
| Time                    | 2.24e+03     |
| Time-Optimization       | 1.56         |
| Time-SampleProc         | 0.137        |
| Time-Sampling           | 33.3         |
| n_timesteps             | 730000       |
| train-AverageDiscoun... | 48.3         |
| train-AverageReturn     | 84.3         |
| train-EnvExecTime       | 11           |
| train-MaxReturn         | 116          |
| train-MinReturn         | -4.63        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 21.2         |
| train-StdReturn         | 16.9         |
------------------------------------------

 ---------------- Iteration 73 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 73           |
| ItrTime                 | 34.1         |
| LossAfter               | -0.03413071  |
| LossBefore              | 0.0014488769 |
| Time                    | 2.28e+03     |
| Time-Optimization       | 1.76         |
| Time-SampleProc         | 0.212        |
| Time-Sampling           | 32.2         |
| n_timesteps             | 740000       |
| train-AverageDiscoun... | 47.2         |
| train-AverageReturn     | 83.1         |
| train-EnvExecTime       | 10.7         |
| train-MaxReturn         | 116          |
| train-MinReturn         | -5.67        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 20.4         |
| train-StdReturn         | 19.2         |
------------------------------------------

 ---------------- Iteration 74 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 74           |
| ItrTime                 | 33.6         |
| LossAfter               | -0.048271436 |
| LossBefore              | -0.015468433 |
| Time                    | 2.31e+03     |
| Time-Optimization       | 1.48         |
| Time-SampleProc         | 0.167        |
| Time-Sampling           | 32           |
| n_timesteps             | 750000       |
| train-AverageDiscoun... | 46.9         |
| train-AverageReturn     | 81.4         |
| train-EnvExecTime       | 10.8         |
| train-MaxReturn         | 117          |
| train-MinReturn         | -8.5         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 20.2         |
| train-StdReturn         | 22.9         |
------------------------------------------

 ---------------- Iteration 75 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 75           |
| ItrTime                 | 34.4         |
| LossAfter               | -0.11702573  |
| LossBefore              | -0.012277417 |
| Time                    | 2.35e+03     |
| Time-Optimization       | 1.48         |
| Time-SampleProc         | 0.179        |
| Time-Sampling           | 32.7         |
| n_timesteps             | 760000       |
| train-AverageDiscoun... | 47.3         |
| train-AverageReturn     | 82.7         |
| train-EnvExecTime       | 10.8         |
| train-MaxReturn         | 116          |
| train-MinReturn         | 26.3         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 20.9         |
| train-StdReturn         | 15.8         |
------------------------------------------

 ---------------- Iteration 76 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 76           |
| ItrTime                 | 34.6         |
| LossAfter               | -0.059000317 |
| LossBefore              | 0.009136353  |
| Time                    | 2.38e+03     |
| Time-Optimization       | 1.66         |
| Time-SampleProc         | 0.147        |
| Time-Sampling           | 32.7         |
| n_timesteps             | 770000       |
| train-AverageDiscoun... | 47.5         |
| train-AverageReturn     | 82.9         |
| train-EnvExecTime       | 10.8         |
| train-MaxReturn         | 109          |
| train-MinReturn         | 8.86         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 20.9         |
| train-StdReturn         | 19.7         |
------------------------------------------

 ---------------- Iteration 77 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 77           |
| ItrTime                 | 34.8         |
| LossAfter               | -0.07284463  |
| LossBefore              | -0.020263953 |
| Time                    | 2.42e+03     |
| Time-Optimization       | 1.61         |
| Time-SampleProc         | 0.196        |
| Time-Sampling           | 33           |
| n_timesteps             | 780000       |
| train-AverageDiscoun... | 48.2         |
| train-AverageReturn     | 84.4         |
| train-EnvExecTime       | 11.1         |
| train-MaxReturn         | 108          |
| train-MinReturn         | 17.5         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 20.9         |
| train-StdReturn         | 14.3         |
------------------------------------------

 ---------------- Iteration 78 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 78          |
| ItrTime                 | 34.2        |
| LossAfter               | 0.020073438 |
| LossBefore              | 0.012706152 |
| Time                    | 2.45e+03    |
| Time-Optimization       | 1.66        |
| Time-SampleProc         | 0.204       |
| Time-Sampling           | 32.4        |
| n_timesteps             | 790000      |
| train-AverageDiscoun... | 48.1        |
| train-AverageReturn     | 83.7        |
| train-EnvExecTime       | 10.7        |
| train-MaxReturn         | 108         |
| train-MinReturn         | -28.2       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 20.7        |
| train-StdReturn         | 17.6        |
-----------------------------------------

 ---------------- Iteration 79 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 79           |
| ItrTime                 | 34.2         |
| LossAfter               | -0.017154858 |
| LossBefore              | 0.0050497805 |
| Time                    | 2.48e+03     |
| Time-Optimization       | 1.56         |
| Time-SampleProc         | 0.177        |
| Time-Sampling           | 32.5         |
| n_timesteps             | 800000       |
| train-AverageDiscoun... | 48.2         |
| train-AverageReturn     | 84.4         |
| train-EnvExecTime       | 10.8         |
| train-MaxReturn         | 109          |
| train-MinReturn         | 29.7         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 20.7         |
| train-StdReturn         | 14.2         |
------------------------------------------

 ---------------- Iteration 80 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 80           |
| ItrTime                 | 34.5         |
| LossAfter               | -0.017381568 |
| LossBefore              | 0.0025907836 |
| Time                    | 2.52e+03     |
| Time-Optimization       | 1.55         |
| Time-SampleProc         | 0.168        |
| Time-Sampling           | 32.8         |
| n_timesteps             | 810000       |
| train-AverageDiscoun... | 47.2         |
| train-AverageReturn     | 82.4         |
| train-EnvExecTime       | 10.9         |
| train-MaxReturn         | 122          |
| train-MinReturn         | -14.1        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 20.9         |
| train-StdReturn         | 20           |
------------------------------------------

 ---------------- Iteration 81 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 81           |
| ItrTime                 | 34.1         |
| LossAfter               | -0.010450806 |
| LossBefore              | 0.002343164  |
| Time                    | 2.55e+03     |
| Time-Optimization       | 1.5          |
| Time-SampleProc         | 0.146        |
| Time-Sampling           | 32.4         |
| n_timesteps             | 820000       |
| train-AverageDiscoun... | 47.1         |
| train-AverageReturn     | 82.8         |
| train-EnvExecTime       | 10.7         |
| train-MaxReturn         | 108          |
| train-MinReturn         | 4.15         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 20.7         |
| train-StdReturn         | 17.9         |
------------------------------------------

 ---------------- Iteration 82 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 82          |
| ItrTime                 | 37.1        |
| LossAfter               | 0.02024878  |
| LossBefore              | 0.023800086 |
| Time                    | 2.59e+03    |
| Time-Optimization       | 1.86        |
| Time-SampleProc         | 0.183       |
| Time-Sampling           | 35.1        |
| n_timesteps             | 830000      |
| train-AverageDiscoun... | 48          |
| train-AverageReturn     | 84.6        |
| train-EnvExecTime       | 11.4        |
| train-MaxReturn         | 114         |
| train-MinReturn         | 14.9        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 22.6        |
| train-StdReturn         | 12.9        |
-----------------------------------------

 ---------------- Iteration 83 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 83          |
| ItrTime                 | 40          |
| LossAfter               | -0.0362564  |
| LossBefore              | -0.03153566 |
| Time                    | 2.63e+03    |
| Time-Optimization       | 1.82        |
| Time-SampleProc         | 0.154       |
| Time-Sampling           | 38          |
| n_timesteps             | 840000      |
| train-AverageDiscoun... | 49.1        |
| train-AverageReturn     | 85.7        |
| train-EnvExecTime       | 12.2        |
| train-MaxReturn         | 111         |
| train-MinReturn         | 16.4        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 24.6        |
| train-StdReturn         | 12.8        |
-----------------------------------------

 ---------------- Iteration 84 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 84           |
| ItrTime                 | 42.3         |
| LossAfter               | -0.035142276 |
| LossBefore              | -0.012647973 |
| Time                    | 2.67e+03     |
| Time-Optimization       | 1.85         |
| Time-SampleProc         | 0.174        |
| Time-Sampling           | 40.3         |
| n_timesteps             | 850000       |
| train-AverageDiscoun... | 47.8         |
| train-AverageReturn     | 83.8         |
| train-EnvExecTime       | 12.9         |
| train-MaxReturn         | 115          |
| train-MinReturn         | 12.1         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 26.2         |
| train-StdReturn         | 17.3         |
------------------------------------------

 ---------------- Iteration 85 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 85            |
| ItrTime                 | 41.1          |
| LossAfter               | -0.012295264  |
| LossBefore              | -0.0017411865 |
| Time                    | 2.71e+03      |
| Time-Optimization       | 1.94          |
| Time-SampleProc         | 0.242         |
| Time-Sampling           | 38.9          |
| n_timesteps             | 860000        |
| train-AverageDiscoun... | 48.1          |
| train-AverageReturn     | 84.2          |
| train-EnvExecTime       | 12.5          |
| train-MaxReturn         | 122           |
| train-MinReturn         | 14.4          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 25.3          |
| train-StdReturn         | 16.1          |
-------------------------------------------

 ---------------- Iteration 86 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 86           |
| ItrTime                 | 35.9         |
| LossAfter               | -0.036002442 |
| LossBefore              | 0.013718579  |
| Time                    | 2.75e+03     |
| Time-Optimization       | 1.6          |
| Time-SampleProc         | 0.144        |
| Time-Sampling           | 34.2         |
| n_timesteps             | 870000       |
| train-AverageDiscoun... | 47.9         |
| train-AverageReturn     | 84.2         |
| train-EnvExecTime       | 11.3         |
| train-MaxReturn         | 107          |
| train-MinReturn         | 41.9         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 21.9         |
| train-StdReturn         | 12.6         |
------------------------------------------

 ---------------- Iteration 87 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 87           |
| ItrTime                 | 35.1         |
| LossAfter               | -0.017354907 |
| LossBefore              | -0.003436737 |
| Time                    | 2.79e+03     |
| Time-Optimization       | 1.77         |
| Time-SampleProc         | 0.166        |
| Time-Sampling           | 33.2         |
| n_timesteps             | 880000       |
| train-AverageDiscoun... | 48.8         |
| train-AverageReturn     | 85.4         |
| train-EnvExecTime       | 10.9         |
| train-MaxReturn         | 105          |
| train-MinReturn         | 7.33         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 21.2         |
| train-StdReturn         | 14.4         |
------------------------------------------

 ---------------- Iteration 88 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 88          |
| ItrTime                 | 34.7        |
| LossAfter               | -0.02747412 |
| LossBefore              | 0.008455102 |
| Time                    | 2.82e+03    |
| Time-Optimization       | 1.57        |
| Time-SampleProc         | 0.159       |
| Time-Sampling           | 33          |
| n_timesteps             | 890000      |
| train-AverageDiscoun... | 48.5        |
| train-AverageReturn     | 85.8        |
| train-EnvExecTime       | 11          |
| train-MaxReturn         | 110         |
| train-MinReturn         | 25.1        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 21          |
| train-StdReturn         | 14.9        |
-----------------------------------------

 ---------------- Iteration 89 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 89           |
| ItrTime                 | 34.6         |
| LossAfter               | -0.06224238  |
| LossBefore              | -0.043304786 |
| Time                    | 2.85e+03     |
| Time-Optimization       | 1.83         |
| Time-SampleProc         | 0.13         |
| Time-Sampling           | 32.6         |
| n_timesteps             | 900000       |
| train-AverageDiscoun... | 34.7         |
| train-AverageReturn     | 63.5         |
| train-EnvExecTime       | 10.8         |
| train-MaxReturn         | 96.6         |
| train-MinReturn         | -15          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 20.8         |
| train-StdReturn         | 19.9         |
------------------------------------------

 ---------------- Iteration 90 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 90           |
| ItrTime                 | 31.5         |
| LossAfter               | -0.17051782  |
| LossBefore              | -0.038900975 |
| Time                    | 2.89e+03     |
| Time-Optimization       | 1.49         |
| Time-SampleProc         | 0.152        |
| Time-Sampling           | 29.8         |
| n_timesteps             | 910000       |
| train-AverageDiscoun... | 36.9         |
| train-AverageReturn     | 67           |
| train-EnvExecTime       | 10.1         |
| train-MaxReturn         | 110          |
| train-MinReturn         | 8.23         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 18.8         |
| train-StdReturn         | 19.7         |
------------------------------------------

 ---------------- Iteration 91 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 91           |
| ItrTime                 | 34.3         |
| LossAfter               | -0.115146436 |
| LossBefore              | -0.009241025 |
| Time                    | 2.92e+03     |
| Time-Optimization       | 1.65         |
| Time-SampleProc         | 0.185        |
| Time-Sampling           | 32.5         |
| n_timesteps             | 920000       |
| train-AverageDiscoun... | 47.7         |
| train-AverageReturn     | 83.8         |
| train-EnvExecTime       | 10.8         |
| train-MaxReturn         | 109          |
| train-MinReturn         | -23.4        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 20.6         |
| train-StdReturn         | 18.5         |
------------------------------------------

 ---------------- Iteration 92 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 92           |
| ItrTime                 | 36.7         |
| LossAfter               | -0.012751587 |
| LossBefore              | 0.015451269  |
| Time                    | 2.96e+03     |
| Time-Optimization       | 1.51         |
| Time-SampleProc         | 0.128        |
| Time-Sampling           | 35.1         |
| n_timesteps             | 930000       |
| train-AverageDiscoun... | 48.5         |
| train-AverageReturn     | 84.7         |
| train-EnvExecTime       | 11.5         |
| train-MaxReturn         | 114          |
| train-MinReturn         | 1.37         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 22.5         |
| train-StdReturn         | 14.9         |
------------------------------------------

 ---------------- Iteration 93 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 93          |
| ItrTime                 | 33.6        |
| LossAfter               | 0.048338197 |
| LossBefore              | 0.042020597 |
| Time                    | 2.99e+03    |
| Time-Optimization       | 1.7         |
| Time-SampleProc         | 0.165       |
| Time-Sampling           | 31.8        |
| n_timesteps             | 940000      |
| train-AverageDiscoun... | 48.9        |
| train-AverageReturn     | 85.2        |
| train-EnvExecTime       | 10.6        |
| train-MaxReturn         | 111         |
| train-MinReturn         | 16.6        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 20.2        |
| train-StdReturn         | 14.5        |
-----------------------------------------

 ---------------- Iteration 94 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 94            |
| ItrTime                 | 34.1          |
| LossAfter               | -0.020199634  |
| LossBefore              | -0.0037335937 |
| Time                    | 3.03e+03      |
| Time-Optimization       | 1.61          |
| Time-SampleProc         | 0.127         |
| Time-Sampling           | 32.3          |
| n_timesteps             | 950000        |
| train-AverageDiscoun... | 47.3          |
| train-AverageReturn     | 83.2          |
| train-EnvExecTime       | 10.8          |
| train-MaxReturn         | 116           |
| train-MinReturn         | -5.37         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 20.5          |
| train-StdReturn         | 17.2          |
-------------------------------------------

 ---------------- Iteration 95 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 95           |
| ItrTime                 | 34.5         |
| LossAfter               | -0.04678098  |
| LossBefore              | -0.025805457 |
| Time                    | 3.06e+03     |
| Time-Optimization       | 1.73         |
| Time-SampleProc         | 0.19         |
| Time-Sampling           | 32.6         |
| n_timesteps             | 960000       |
| train-AverageDiscoun... | 47.8         |
| train-AverageReturn     | 83.3         |
| train-EnvExecTime       | 10.8         |
| train-MaxReturn         | 108          |
| train-MinReturn         | 3.32         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 20.8         |
| train-StdReturn         | 14.4         |
------------------------------------------

 ---------------- Iteration 96 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 96           |
| ItrTime                 | 33.3         |
| LossAfter               | -0.017050976 |
| LossBefore              | -0.010258728 |
| Time                    | 3.09e+03     |
| Time-Optimization       | 1.42         |
| Time-SampleProc         | 0.127        |
| Time-Sampling           | 31.7         |
| n_timesteps             | 970000       |
| train-AverageDiscoun... | 47.3         |
| train-AverageReturn     | 82.9         |
| train-EnvExecTime       | 10.6         |
| train-MaxReturn         | 108          |
| train-MinReturn         | 33.4         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 20.1         |
| train-StdReturn         | 15.1         |
------------------------------------------

 ---------------- Iteration 97 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 97           |
| ItrTime                 | 36.1         |
| LossAfter               | -0.037768457 |
| LossBefore              | -0.011439307 |
| Time                    | 3.13e+03     |
| Time-Optimization       | 1.53         |
| Time-SampleProc         | 0.186        |
| Time-Sampling           | 34.4         |
| n_timesteps             | 980000       |
| train-AverageDiscoun... | 47.4         |
| train-AverageReturn     | 83.6         |
| train-EnvExecTime       | 11.3         |
| train-MaxReturn         | 109          |
| train-MinReturn         | 0.926        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 22           |
| train-StdReturn         | 14.2         |
------------------------------------------

 ---------------- Iteration 98 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 98           |
| ItrTime                 | 33.5         |
| LossAfter               | -0.011532275 |
| LossBefore              | 0.006726172  |
| Time                    | 3.16e+03     |
| Time-Optimization       | 1.55         |
| Time-SampleProc         | 0.152        |
| Time-Sampling           | 31.8         |
| n_timesteps             | 990000       |
| train-AverageDiscoun... | 50.6         |
| train-AverageReturn     | 87.8         |
| train-EnvExecTime       | 10.6         |
| train-MaxReturn         | 109          |
| train-MinReturn         | 6.26         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 20.2         |
| train-StdReturn         | 13.9         |
------------------------------------------

 ---------------- Iteration 99 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 99          |
| ItrTime                 | 33.1        |
| LossAfter               | -0.07409618 |
| LossBefore              | -0.01519776 |
| Time                    | 3.2e+03     |
| Time-Optimization       | 1.63        |
| Time-SampleProc         | 0.19        |
| Time-Sampling           | 31.3        |
| n_timesteps             | 1000000     |
| train-AverageDiscoun... | 48.1        |
| train-AverageReturn     | 84.3        |
| train-EnvExecTime       | 10.5        |
| train-MaxReturn         | 109         |
| train-MinReturn         | -0.363      |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 19.7        |
| train-StdReturn         | 14.4        |
-----------------------------------------

 ---------------- Iteration 100 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 100          |
| ItrTime                 | 33.9         |
| LossAfter               | -0.049340233 |
| LossBefore              | -0.028237598 |
| Time                    | 3.23e+03     |
| Time-Optimization       | 1.68         |
| Time-SampleProc         | 0.155        |
| Time-Sampling           | 32.1         |
| n_timesteps             | 1010000      |
| train-AverageDiscoun... | 48           |
| train-AverageReturn     | 84           |
| train-EnvExecTime       | 10.8         |
| train-MaxReturn         | 111          |
| train-MinReturn         | -34.9        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 20.3         |
| train-StdReturn         | 19.2         |
------------------------------------------

 ---------------- Iteration 101 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 101           |
| ItrTime                 | 34.3          |
| LossAfter               | -0.0070797973 |
| LossBefore              | 0.015091211   |
| Time                    | 3.26e+03      |
| Time-Optimization       | 1.42          |
| Time-SampleProc         | 0.147         |
| Time-Sampling           | 32.8          |
| n_timesteps             | 1020000       |
| train-AverageDiscoun... | 48.7          |
| train-AverageReturn     | 85.2          |
| train-EnvExecTime       | 10.8          |
| train-MaxReturn         | 109           |
| train-MinReturn         | 0.795         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 20.9          |
| train-StdReturn         | 18.1          |
-------------------------------------------

 ---------------- Iteration 102 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 102          |
| ItrTime                 | 34.1         |
| LossAfter               | -0.025376245 |
| LossBefore              | 0.013267969  |
| Time                    | 3.3e+03      |
| Time-Optimization       | 1.56         |
| Time-SampleProc         | 0.146        |
| Time-Sampling           | 32.4         |
| n_timesteps             | 1030000      |
| train-AverageDiscoun... | 49.9         |
| train-AverageReturn     | 86.9         |
| train-EnvExecTime       | 10.9         |
| train-MaxReturn         | 114          |
| train-MinReturn         | 26.4         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 20.5         |
| train-StdReturn         | 11           |
------------------------------------------

 ---------------- Iteration 103 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 103         |
| ItrTime                 | 34.7        |
| LossAfter               | -0.03133009 |
| LossBefore              | -0.01470426 |
| Time                    | 3.33e+03    |
| Time-Optimization       | 1.76        |
| Time-SampleProc         | 0.19        |
| Time-Sampling           | 32.7        |
| n_timesteps             | 1040000     |
| train-AverageDiscoun... | 47.7        |
| train-AverageReturn     | 83.2        |
| train-EnvExecTime       | 10.9        |
| train-MaxReturn         | 112         |
| train-MinReturn         | -3.72       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 20.8        |
| train-StdReturn         | 18.4        |
-----------------------------------------

 ---------------- Iteration 104 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 104          |
| ItrTime                 | 33.8         |
| LossAfter               | -0.03943197  |
| LossBefore              | 0.0031483276 |
| Time                    | 3.37e+03     |
| Time-Optimization       | 1.68         |
| Time-SampleProc         | 0.168        |
| Time-Sampling           | 32           |
| n_timesteps             | 1050000      |
| train-AverageDiscoun... | 46.5         |
| train-AverageReturn     | 80.8         |
| train-EnvExecTime       | 10.7         |
| train-MaxReturn         | 107          |
| train-MinReturn         | -14.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 20.3         |
| train-StdReturn         | 21.6         |
------------------------------------------

 ---------------- Iteration 105 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 105          |
| ItrTime                 | 34.9         |
| LossAfter               | 0.0064130127 |
| LossBefore              | 0.020108862  |
| Time                    | 3.4e+03      |
| Time-Optimization       | 1.45         |
| Time-SampleProc         | 0.124        |
| Time-Sampling           | 33.3         |
| n_timesteps             | 1060000      |
| train-AverageDiscoun... | 48.4         |
| train-AverageReturn     | 84.8         |
| train-EnvExecTime       | 11.1         |
| train-MaxReturn         | 110          |
| train-MinReturn         | 14.2         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 21.2         |
| train-StdReturn         | 15.3         |
------------------------------------------

 ---------------- Iteration 106 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 106          |
| ItrTime                 | 32.1         |
| LossAfter               | -0.042937916 |
| LossBefore              | 0.023376074  |
| Time                    | 3.43e+03     |
| Time-Optimization       | 1.47         |
| Time-SampleProc         | 0.144        |
| Time-Sampling           | 30.5         |
| n_timesteps             | 1070000      |
| train-AverageDiscoun... | 47.9         |
| train-AverageReturn     | 83.6         |
| train-EnvExecTime       | 10.3         |
| train-MaxReturn         | 117          |
| train-MinReturn         | -23.5        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 19.3         |
| train-StdReturn         | 17           |
------------------------------------------

 ---------------- Iteration 107 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 107          |
| ItrTime                 | 33.4         |
| LossAfter               | -0.031855885 |
| LossBefore              | -0.02127157  |
| Time                    | 3.47e+03     |
| Time-Optimization       | 1.61         |
| Time-SampleProc         | 0.13         |
| Time-Sampling           | 31.7         |
| n_timesteps             | 1080000      |
| train-AverageDiscoun... | 48           |
| train-AverageReturn     | 84.2         |
| train-EnvExecTime       | 10.6         |
| train-MaxReturn         | 109          |
| train-MinReturn         | 7.01         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 20.1         |
| train-StdReturn         | 14.9         |
------------------------------------------

 ---------------- Iteration 108 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 108          |
| ItrTime                 | 34.7         |
| LossAfter               | -0.03263996  |
| LossBefore              | -0.011561299 |
| Time                    | 3.5e+03      |
| Time-Optimization       | 1.81         |
| Time-SampleProc         | 0.141        |
| Time-Sampling           | 32.8         |
| n_timesteps             | 1090000      |
| train-AverageDiscoun... | 47.3         |
| train-AverageReturn     | 82.9         |
| train-EnvExecTime       | 10.9         |
| train-MaxReturn         | 108          |
| train-MinReturn         | -7.94        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 20.9         |
| train-StdReturn         | 18.8         |
------------------------------------------

 ---------------- Iteration 109 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 109          |
| ItrTime                 | 34.4         |
| LossAfter               | -0.020783935 |
| LossBefore              | 0.0009262085 |
| Time                    | 3.54e+03     |
| Time-Optimization       | 1.78         |
| Time-SampleProc         | 0.17         |
| Time-Sampling           | 32.5         |
| n_timesteps             | 1100000      |
| train-AverageDiscoun... | 46.9         |
| train-AverageReturn     | 82.2         |
| train-EnvExecTime       | 10.8         |
| train-MaxReturn         | 103          |
| train-MinReturn         | 4.53         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 20.6         |
| train-StdReturn         | 15.3         |
------------------------------------------

 ---------------- Iteration 110 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 110          |
| ItrTime                 | 34.4         |
| LossAfter               | -0.009516406 |
| LossBefore              | 0.004306836  |
| Time                    | 3.57e+03     |
| Time-Optimization       | 1.52         |
| Time-SampleProc         | 0.126        |
| Time-Sampling           | 32.7         |
| n_timesteps             | 1110000      |
| train-AverageDiscoun... | 48.7         |
| train-AverageReturn     | 85.5         |
| train-EnvExecTime       | 10.8         |
| train-MaxReturn         | 113          |
| train-MinReturn         | 11.3         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 20.8         |
| train-StdReturn         | 14.5         |
------------------------------------------

 ---------------- Iteration 111 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 111          |
| ItrTime                 | 35           |
| LossAfter               | -0.025479468 |
| LossBefore              | 0.014726587  |
| Time                    | 3.61e+03     |
| Time-Optimization       | 1.57         |
| Time-SampleProc         | 0.141        |
| Time-Sampling           | 33.3         |
| n_timesteps             | 1120000      |
| train-AverageDiscoun... | 48.6         |
| train-AverageReturn     | 84.6         |
| train-EnvExecTime       | 11           |
| train-MaxReturn         | 112          |
| train-MinReturn         | 10.8         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 21.2         |
| train-StdReturn         | 16           |
------------------------------------------

 ---------------- Iteration 112 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 112          |
| ItrTime                 | 34.1         |
| LossAfter               | -0.05216526  |
| LossBefore              | -0.023866601 |
| Time                    | 3.64e+03     |
| Time-Optimization       | 1.65         |
| Time-SampleProc         | 0.15         |
| Time-Sampling           | 32.3         |
| n_timesteps             | 1130000      |
| train-AverageDiscoun... | 48.8         |
| train-AverageReturn     | 85           |
| train-EnvExecTime       | 10.7         |
| train-MaxReturn         | 109          |
| train-MinReturn         | -31.7        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 20.5         |
| train-StdReturn         | 16.5         |
------------------------------------------

 ---------------- Iteration 113 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 113          |
| ItrTime                 | 34.7         |
| LossAfter               | -0.017099127 |
| LossBefore              | -0.012857941 |
| Time                    | 3.68e+03     |
| Time-Optimization       | 1.72         |
| Time-SampleProc         | 0.176        |
| Time-Sampling           | 32.8         |
| n_timesteps             | 1140000      |
| train-AverageDiscoun... | 46.9         |
| train-AverageReturn     | 81.9         |
| train-EnvExecTime       | 10.9         |
| train-MaxReturn         | 107          |
| train-MinReturn         | 8.52         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 20.9         |
| train-StdReturn         | 15.1         |
------------------------------------------

 ---------------- Iteration 114 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 114          |
| ItrTime                 | 32.9         |
| LossAfter               | -0.018941931 |
| LossBefore              | 0.0041911867 |
| Time                    | 3.71e+03     |
| Time-Optimization       | 1.58         |
| Time-SampleProc         | 0.18         |
| Time-Sampling           | 31.1         |
| n_timesteps             | 1150000      |
| train-AverageDiscoun... | 48.4         |
| train-AverageReturn     | 84.7         |
| train-EnvExecTime       | 10.4         |
| train-MaxReturn         | 114          |
| train-MinReturn         | 7.46         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 19.8         |
| train-StdReturn         | 15.4         |
------------------------------------------

 ---------------- Iteration 115 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 115          |
| ItrTime                 | 32.9         |
| LossAfter               | -0.051974352 |
| LossBefore              | -0.014844238 |
| Time                    | 3.74e+03     |
| Time-Optimization       | 1.58         |
| Time-SampleProc         | 0.148        |
| Time-Sampling           | 31.1         |
| n_timesteps             | 1160000      |
| train-AverageDiscoun... | 48.1         |
| train-AverageReturn     | 84.2         |
| train-EnvExecTime       | 10.4         |
| train-MaxReturn         | 111          |
| train-MinReturn         | -19.3        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 19.7         |
| train-StdReturn         | 15.4         |
------------------------------------------

 ---------------- Iteration 116 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 116          |
| ItrTime                 | 33.2         |
| LossAfter               | -0.032937806 |
| LossBefore              | 0.013029871  |
| Time                    | 3.77e+03     |
| Time-Optimization       | 1.61         |
| Time-SampleProc         | 0.172        |
| Time-Sampling           | 31.4         |
| n_timesteps             | 1170000      |
| train-AverageDiscoun... | 48.2         |
| train-AverageReturn     | 84.5         |
| train-EnvExecTime       | 10.5         |
| train-MaxReturn         | 114          |
| train-MinReturn         | 24.4         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 19.9         |
| train-StdReturn         | 13.7         |
------------------------------------------

 ---------------- Iteration 117 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 117          |
| ItrTime                 | 33.4         |
| LossAfter               | -0.014654147 |
| LossBefore              | 0.032985974  |
| Time                    | 3.81e+03     |
| Time-Optimization       | 1.59         |
| Time-SampleProc         | 0.203        |
| Time-Sampling           | 31.6         |
| n_timesteps             | 1180000      |
| train-AverageDiscoun... | 48.8         |
| train-AverageReturn     | 85.5         |
| train-EnvExecTime       | 10.6         |
| train-MaxReturn         | 116          |
| train-MinReturn         | -24.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 20           |
| train-StdReturn         | 18.5         |
------------------------------------------

 ---------------- Iteration 118 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 118          |
| ItrTime                 | 32.6         |
| LossAfter               | -0.06613985  |
| LossBefore              | -0.013475781 |
| Time                    | 3.84e+03     |
| Time-Optimization       | 1.48         |
| Time-SampleProc         | 0.128        |
| Time-Sampling           | 31           |
| n_timesteps             | 1190000      |
| train-AverageDiscoun... | 46.2         |
| train-AverageReturn     | 80.7         |
| train-EnvExecTime       | 10.5         |
| train-MaxReturn         | 105          |
| train-MinReturn         | -26.1        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 19.6         |
| train-StdReturn         | 20.9         |
------------------------------------------

 ---------------- Iteration 119 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 119         |
| ItrTime                 | 33.3        |
| LossAfter               | 0.015041089 |
| LossBefore              | 0.02433231  |
| Time                    | 3.87e+03    |
| Time-Optimization       | 1.51        |
| Time-SampleProc         | 0.131       |
| Time-Sampling           | 31.7        |
| n_timesteps             | 1200000     |
| train-AverageDiscoun... | 49          |
| train-AverageReturn     | 85          |
| train-EnvExecTime       | 10.6        |
| train-MaxReturn         | 110         |
| train-MinReturn         | 21.1        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 20.1        |
| train-StdReturn         | 13.7        |
-----------------------------------------

 ---------------- Iteration 120 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 120          |
| ItrTime                 | 32.6         |
| LossAfter               | -0.03485     |
| LossBefore              | -0.006127417 |
| Time                    | 3.91e+03     |
| Time-Optimization       | 1.5          |
| Time-SampleProc         | 0.17         |
| Time-Sampling           | 30.9         |
| n_timesteps             | 1210000      |
| train-AverageDiscoun... | 49.4         |
| train-AverageReturn     | 85.5         |
| train-EnvExecTime       | 10.4         |
| train-MaxReturn         | 111          |
| train-MinReturn         | -6.13        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 19.6         |
| train-StdReturn         | 16.7         |
------------------------------------------

 ---------------- Iteration 121 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 121         |
| ItrTime                 | 32.8        |
| LossAfter               | 0.015617249 |
| LossBefore              | 0.019685706 |
| Time                    | 3.94e+03    |
| Time-Optimization       | 1.61        |
| Time-SampleProc         | 0.139       |
| Time-Sampling           | 31.1        |
| n_timesteps             | 1220000     |
| train-AverageDiscoun... | 48.7        |
| train-AverageReturn     | 85.5        |
| train-EnvExecTime       | 10.4        |
| train-MaxReturn         | 109         |
| train-MinReturn         | 8.89        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 19.7        |
| train-StdReturn         | 15.4        |
-----------------------------------------

 ---------------- Iteration 122 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 122          |
| ItrTime                 | 33.2         |
| LossAfter               | -0.022433141 |
| LossBefore              | 0.0026234984 |
| Time                    | 3.97e+03     |
| Time-Optimization       | 1.48         |
| Time-SampleProc         | 0.15         |
| Time-Sampling           | 31.6         |
| n_timesteps             | 1230000      |
| train-AverageDiscoun... | 48.5         |
| train-AverageReturn     | 84.6         |
| train-EnvExecTime       | 10.6         |
| train-MaxReturn         | 105          |
| train-MinReturn         | -30.5        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 20           |
| train-StdReturn         | 19.5         |
------------------------------------------

 ---------------- Iteration 123 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 123          |
| ItrTime                 | 32.9         |
| LossAfter               | -0.013940442 |
| LossBefore              | 0.016382996  |
| Time                    | 4.01e+03     |
| Time-Optimization       | 1.61         |
| Time-SampleProc         | 0.182        |
| Time-Sampling           | 31.1         |
| n_timesteps             | 1240000      |
| train-AverageDiscoun... | 47           |
| train-AverageReturn     | 82.7         |
| train-EnvExecTime       | 10.5         |
| train-MaxReturn         | 109          |
| train-MinReturn         | -1.47        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 19.7         |
| train-StdReturn         | 17.6         |
------------------------------------------

 ---------------- Iteration 124 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 124          |
| ItrTime                 | 32.8         |
| LossAfter               | -0.01852266  |
| LossBefore              | -0.009534323 |
| Time                    | 4.04e+03     |
| Time-Optimization       | 1.51         |
| Time-SampleProc         | 0.14         |
| Time-Sampling           | 31.1         |
| n_timesteps             | 1250000      |
| train-AverageDiscoun... | 48.8         |
| train-AverageReturn     | 85.5         |
| train-EnvExecTime       | 10.4         |
| train-MaxReturn         | 107          |
| train-MinReturn         | 27.5         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 19.7         |
| train-StdReturn         | 12.2         |
------------------------------------------

 ---------------- Iteration 125 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 125          |
| ItrTime                 | 33.3         |
| LossAfter               | 0.0012302246 |
| LossBefore              | 0.009181799  |
| Time                    | 4.07e+03     |
| Time-Optimization       | 1.45         |
| Time-SampleProc         | 0.164        |
| Time-Sampling           | 31.6         |
| n_timesteps             | 1260000      |
| train-AverageDiscoun... | 47.7         |
| train-AverageReturn     | 83.4         |
| train-EnvExecTime       | 10.6         |
| train-MaxReturn         | 106          |
| train-MinReturn         | -30.4        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 20.1         |
| train-StdReturn         | 20.6         |
------------------------------------------

 ---------------- Iteration 126 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 126          |
| ItrTime                 | 32.8         |
| LossAfter               | -0.03839336  |
| LossBefore              | -0.011408447 |
| Time                    | 4.11e+03     |
| Time-Optimization       | 1.55         |
| Time-SampleProc         | 0.162        |
| Time-Sampling           | 31.1         |
| n_timesteps             | 1270000      |
| train-AverageDiscoun... | 47.6         |
| train-AverageReturn     | 82.9         |
| train-EnvExecTime       | 10.4         |
| train-MaxReturn         | 112          |
| train-MinReturn         | -30          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 19.6         |
| train-StdReturn         | 19           |
------------------------------------------

 ---------------- Iteration 127 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 127         |
| ItrTime                 | 32.4        |
| LossAfter               | -0.0304927  |
| LossBefore              | 0.019676758 |
| Time                    | 4.14e+03    |
| Time-Optimization       | 1.48        |
| Time-SampleProc         | 0.154       |
| Time-Sampling           | 30.8        |
| n_timesteps             | 1280000     |
| train-AverageDiscoun... | 48.2        |
| train-AverageReturn     | 84          |
| train-EnvExecTime       | 10.3        |
| train-MaxReturn         | 111         |
| train-MinReturn         | -10.3       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 19.5        |
| train-StdReturn         | 19.2        |
-----------------------------------------

 ---------------- Iteration 128 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 128           |
| ItrTime                 | 32.8          |
| LossAfter               | -0.025278613  |
| LossBefore              | -0.0069711427 |
| Time                    | 4.17e+03      |
| Time-Optimization       | 1.61          |
| Time-SampleProc         | 0.143         |
| Time-Sampling           | 31.1          |
| n_timesteps             | 1290000       |
| train-AverageDiscoun... | 48.2          |
| train-AverageReturn     | 83.7          |
| train-EnvExecTime       | 10.4          |
| train-MaxReturn         | 115           |
| train-MinReturn         | 1.32          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 19.7          |
| train-StdReturn         | 18.9          |
-------------------------------------------

 ---------------- Iteration 129 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 129          |
| ItrTime                 | 32.9         |
| LossAfter               | -0.033869725 |
| LossBefore              | 0.012332691  |
| Time                    | 4.2e+03      |
| Time-Optimization       | 1.61         |
| Time-SampleProc         | 0.163        |
| Time-Sampling           | 31.1         |
| n_timesteps             | 1300000      |
| train-AverageDiscoun... | 48.1         |
| train-AverageReturn     | 84           |
| train-EnvExecTime       | 10.5         |
| train-MaxReturn         | 105          |
| train-MinReturn         | -2.91        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 19.6         |
| train-StdReturn         | 17.9         |
------------------------------------------

 ---------------- Iteration 130 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 130           |
| ItrTime                 | 33.1          |
| LossAfter               | -0.0030502076 |
| LossBefore              | 0.008661963   |
| Time                    | 4.24e+03      |
| Time-Optimization       | 1.53          |
| Time-SampleProc         | 0.134         |
| Time-Sampling           | 31.4          |
| n_timesteps             | 1310000       |
| train-AverageDiscoun... | 47.5          |
| train-AverageReturn     | 83.2          |
| train-EnvExecTime       | 10.5          |
| train-MaxReturn         | 105           |
| train-MinReturn         | -14.9         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 19.9          |
| train-StdReturn         | 18.8          |
-------------------------------------------

 ---------------- Iteration 131 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 131          |
| ItrTime                 | 31.9         |
| LossAfter               | -0.036580637 |
| LossBefore              | -0.0227628   |
| Time                    | 4.27e+03     |
| Time-Optimization       | 1.56         |
| Time-SampleProc         | 0.182        |
| Time-Sampling           | 30.1         |
| n_timesteps             | 1320000      |
| train-AverageDiscoun... | 47.2         |
| train-AverageReturn     | 82.3         |
| train-EnvExecTime       | 10.1         |
| train-MaxReturn         | 111          |
| train-MinReturn         | 3.78         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 19.1         |
| train-StdReturn         | 16.8         |
------------------------------------------

 ---------------- Iteration 132 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 132          |
| ItrTime                 | 33.3         |
| LossAfter               | -0.013568995 |
| LossBefore              | 0.004308984  |
| Time                    | 4.3e+03      |
| Time-Optimization       | 1.56         |
| Time-SampleProc         | 0.185        |
| Time-Sampling           | 31.5         |
| n_timesteps             | 1330000      |
| train-AverageDiscoun... | 46.2         |
| train-AverageReturn     | 80.9         |
| train-EnvExecTime       | 10.6         |
| train-MaxReturn         | 113          |
| train-MinReturn         | -25.9        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 19.9         |
| train-StdReturn         | 21           |
------------------------------------------

 ---------------- Iteration 133 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 133          |
| ItrTime                 | 32.2         |
| LossAfter               | -0.059318382 |
| LossBefore              | -0.010167163 |
| Time                    | 4.33e+03     |
| Time-Optimization       | 1.61         |
| Time-SampleProc         | 0.171        |
| Time-Sampling           | 30.4         |
| n_timesteps             | 1340000      |
| train-AverageDiscoun... | 46.8         |
| train-AverageReturn     | 81.8         |
| train-EnvExecTime       | 10.2         |
| train-MaxReturn         | 106          |
| train-MinReturn         | 24.9         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 19.3         |
| train-StdReturn         | 17.9         |
------------------------------------------

 ---------------- Iteration 134 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 134            |
| ItrTime                 | 32.7           |
| LossAfter               | 0.0035959962   |
| LossBefore              | -0.00042609865 |
| Time                    | 4.37e+03       |
| Time-Optimization       | 1.47           |
| Time-SampleProc         | 0.164          |
| Time-Sampling           | 31             |
| n_timesteps             | 1350000        |
| train-AverageDiscoun... | 47.7           |
| train-AverageReturn     | 84             |
| train-EnvExecTime       | 10.5           |
| train-MaxReturn         | 105            |
| train-MinReturn         | 7.9            |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 19.6           |
| train-StdReturn         | 14.3           |
--------------------------------------------

 ---------------- Iteration 135 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 135           |
| ItrTime                 | 33.5          |
| LossAfter               | -0.0051234374 |
| LossBefore              | 0.01656687    |
| Time                    | 4.4e+03       |
| Time-Optimization       | 1.66          |
| Time-SampleProc         | 0.172         |
| Time-Sampling           | 31.7          |
| n_timesteps             | 1360000       |
| train-AverageDiscoun... | 47.7          |
| train-AverageReturn     | 83.5          |
| train-EnvExecTime       | 10.6          |
| train-MaxReturn         | 106           |
| train-MinReturn         | 0.506         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 20.1          |
| train-StdReturn         | 14.6          |
-------------------------------------------

 ---------------- Iteration 136 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 136          |
| ItrTime                 | 32.5         |
| LossAfter               | -0.021888379 |
| LossBefore              | 0.02135542   |
| Time                    | 4.43e+03     |
| Time-Optimization       | 1.66         |
| Time-SampleProc         | 0.188        |
| Time-Sampling           | 30.7         |
| n_timesteps             | 1370000      |
| train-AverageDiscoun... | 47.7         |
| train-AverageReturn     | 83.7         |
| train-EnvExecTime       | 10.3         |
| train-MaxReturn         | 107          |
| train-MinReturn         | -1.9         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 19.5         |
| train-StdReturn         | 18.9         |
------------------------------------------

 ---------------- Iteration 137 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 137          |
| ItrTime                 | 31.9         |
| LossAfter               | -0.015558563 |
| LossBefore              | 0.0006813843 |
| Time                    | 4.47e+03     |
| Time-Optimization       | 1.55         |
| Time-SampleProc         | 0.204        |
| Time-Sampling           | 30.2         |
| n_timesteps             | 1380000      |
| train-AverageDiscoun... | 48.3         |
| train-AverageReturn     | 84.5         |
| train-EnvExecTime       | 10.3         |
| train-MaxReturn         | 107          |
| train-MinReturn         | 13.9         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 18.9         |
| train-StdReturn         | 14.4         |
------------------------------------------

 ---------------- Iteration 138 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 138          |
| ItrTime                 | 32.6         |
| LossAfter               | -0.029653808 |
| LossBefore              | -0.013883032 |
| Time                    | 4.5e+03      |
| Time-Optimization       | 1.49         |
| Time-SampleProc         | 0.162        |
| Time-Sampling           | 31           |
| n_timesteps             | 1390000      |
| train-AverageDiscoun... | 47.5         |
| train-AverageReturn     | 84.1         |
| train-EnvExecTime       | 10.4         |
| train-MaxReturn         | 108          |
| train-MinReturn         | 48.3         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 19.7         |
| train-StdReturn         | 12.7         |
------------------------------------------

 ---------------- Iteration 139 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 139          |
| ItrTime                 | 34.2         |
| LossAfter               | -0.03440337  |
| LossBefore              | -0.023114782 |
| Time                    | 4.53e+03     |
| Time-Optimization       | 1.66         |
| Time-SampleProc         | 0.217        |
| Time-Sampling           | 32.3         |
| n_timesteps             | 1400000      |
| train-AverageDiscoun... | 48.5         |
| train-AverageReturn     | 85.4         |
| train-EnvExecTime       | 10.8         |
| train-MaxReturn         | 108          |
| train-MinReturn         | 48.1         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 20.6         |
| train-StdReturn         | 9.44         |
------------------------------------------

 ---------------- Iteration 140 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 140          |
| ItrTime                 | 34.7         |
| LossAfter               | -0.05416206  |
| LossBefore              | -0.011608551 |
| Time                    | 4.57e+03     |
| Time-Optimization       | 1.49         |
| Time-SampleProc         | 0.182        |
| Time-Sampling           | 33           |
| n_timesteps             | 1410000      |
| train-AverageDiscoun... | 48.8         |
| train-AverageReturn     | 85.8         |
| train-EnvExecTime       | 10.8         |
| train-MaxReturn         | 121          |
| train-MinReturn         | 31.9         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 21.2         |
| train-StdReturn         | 13.9         |
------------------------------------------

 ---------------- Iteration 141 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 141          |
| ItrTime                 | 33           |
| LossAfter               | -0.011580737 |
| LossBefore              | -0.015985856 |
| Time                    | 4.6e+03      |
| Time-Optimization       | 1.56         |
| Time-SampleProc         | 0.145        |
| Time-Sampling           | 31.3         |
| n_timesteps             | 1420000      |
| train-AverageDiscoun... | 47.2         |
| train-AverageReturn     | 82.7         |
| train-EnvExecTime       | 10.4         |
| train-MaxReturn         | 105          |
| train-MinReturn         | 12.1         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 19.9         |
| train-StdReturn         | 14.9         |
------------------------------------------

 ---------------- Iteration 142 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 142         |
| ItrTime                 | 32.4        |
| LossAfter               | -0.03823279 |
| LossBefore              | 0.013713134 |
| Time                    | 4.63e+03    |
| Time-Optimization       | 1.6         |
| Time-SampleProc         | 0.165       |
| Time-Sampling           | 30.6        |
| n_timesteps             | 1430000     |
| train-AverageDiscoun... | 49          |
| train-AverageReturn     | 85.9        |
| train-EnvExecTime       | 10.3        |
| train-MaxReturn         | 113         |
| train-MinReturn         | 21.1        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 19.4        |
| train-StdReturn         | 14.2        |
-----------------------------------------

 ---------------- Iteration 143 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 143          |
| ItrTime                 | 33.9         |
| LossAfter               | -0.027946534 |
| LossBefore              | -0.015289551 |
| Time                    | 4.67e+03     |
| Time-Optimization       | 1.56         |
| Time-SampleProc         | 0.144        |
| Time-Sampling           | 32.2         |
| n_timesteps             | 1440000      |
| train-AverageDiscoun... | 49.1         |
| train-AverageReturn     | 85.8         |
| train-EnvExecTime       | 10.7         |
| train-MaxReturn         | 108          |
| train-MinReturn         | 13.1         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 20.5         |
| train-StdReturn         | 14.7         |
------------------------------------------

 ---------------- Iteration 144 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 144          |
| ItrTime                 | 32.2         |
| LossAfter               | -0.015580041 |
| LossBefore              | 0.028565979  |
| Time                    | 4.7e+03      |
| Time-Optimization       | 1.57         |
| Time-SampleProc         | 0.164        |
| Time-Sampling           | 30.4         |
| n_timesteps             | 1450000      |
| train-AverageDiscoun... | 48.5         |
| train-AverageReturn     | 84.3         |
| train-EnvExecTime       | 10.2         |
| train-MaxReturn         | 109          |
| train-MinReturn         | 1.3          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 19.3         |
| train-StdReturn         | 15.9         |
------------------------------------------

 ---------------- Iteration 145 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 145          |
| ItrTime                 | 31.6         |
| LossAfter               | -0.066946045 |
| LossBefore              | -0.035948683 |
| Time                    | 4.73e+03     |
| Time-Optimization       | 1.57         |
| Time-SampleProc         | 0.17         |
| Time-Sampling           | 29.9         |
| n_timesteps             | 1460000      |
| train-AverageDiscoun... | 48.2         |
| train-AverageReturn     | 84.6         |
| train-EnvExecTime       | 10.2         |
| train-MaxReturn         | 113          |
| train-MinReturn         | 0.505        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 18.8         |
| train-StdReturn         | 18           |
------------------------------------------

 ---------------- Iteration 146 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 146          |
| ItrTime                 | 32.4         |
| LossAfter               | -0.05295945  |
| LossBefore              | -0.009362012 |
| Time                    | 4.76e+03     |
| Time-Optimization       | 1.5          |
| Time-SampleProc         | 0.169        |
| Time-Sampling           | 30.8         |
| n_timesteps             | 1470000      |
| train-AverageDiscoun... | 49.5         |
| train-AverageReturn     | 86.5         |
| train-EnvExecTime       | 10.3         |
| train-MaxReturn         | 116          |
| train-MinReturn         | 15.8         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 19.5         |
| train-StdReturn         | 15.6         |
------------------------------------------

 ---------------- Iteration 147 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 147          |
| ItrTime                 | 31.4         |
| LossAfter               | -0.005131247 |
| LossBefore              | 0.012110514  |
| Time                    | 4.79e+03     |
| Time-Optimization       | 1.51         |
| Time-SampleProc         | 0.171        |
| Time-Sampling           | 29.7         |
| n_timesteps             | 1480000      |
| train-AverageDiscoun... | 46.8         |
| train-AverageReturn     | 81.9         |
| train-EnvExecTime       | 10           |
| train-MaxReturn         | 105          |
| train-MinReturn         | -26.1        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 18.8         |
| train-StdReturn         | 17.4         |
------------------------------------------

 ---------------- Iteration 148 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 148          |
| ItrTime                 | 31           |
| LossAfter               | -0.009515076 |
| LossBefore              | 0.01797359   |
| Time                    | 4.83e+03     |
| Time-Optimization       | 1.77         |
| Time-SampleProc         | 0.23         |
| Time-Sampling           | 29           |
| n_timesteps             | 1490000      |
| train-AverageDiscoun... | 50.1         |
| train-AverageReturn     | 88           |
| train-EnvExecTime       | 9.85         |
| train-MaxReturn         | 114          |
| train-MinReturn         | 34.3         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 18.2         |
| train-StdReturn         | 12.6         |
------------------------------------------

 ---------------- Iteration 149 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 149          |
| ItrTime                 | 31.5         |
| LossAfter               | -0.04707908  |
| LossBefore              | 0.0150784915 |
| Time                    | 4.86e+03     |
| Time-Optimization       | 2.14         |
| Time-SampleProc         | 0.123        |
| Time-Sampling           | 29.3         |
| n_timesteps             | 1500000      |
| train-AverageDiscoun... | 47.4         |
| train-AverageReturn     | 83           |
| train-EnvExecTime       | 9.97         |
| train-MaxReturn         | 113          |
| train-MinReturn         | -31.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 18.4         |
| train-StdReturn         | 20.7         |
------------------------------------------

 ---------------- Iteration 150 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 150          |
| ItrTime                 | 32.2         |
| LossAfter               | -0.011137415 |
| LossBefore              | 0.021279508  |
| Time                    | 4.89e+03     |
| Time-Optimization       | 1.66         |
| Time-SampleProc         | 0.175        |
| Time-Sampling           | 30.4         |
| n_timesteps             | 1510000      |
| train-AverageDiscoun... | 47.8         |
| train-AverageReturn     | 84.2         |
| train-EnvExecTime       | 10.3         |
| train-MaxReturn         | 109          |
| train-MinReturn         | 25.1         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 19.1         |
| train-StdReturn         | 12.9         |
------------------------------------------

 ---------------- Iteration 151 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 151           |
| ItrTime                 | 31.8          |
| LossAfter               | -0.022604797  |
| LossBefore              | 0.00070013426 |
| Time                    | 4.92e+03      |
| Time-Optimization       | 1.76          |
| Time-SampleProc         | 0.149         |
| Time-Sampling           | 29.9          |
| n_timesteps             | 1520000       |
| train-AverageDiscoun... | 49.6          |
| train-AverageReturn     | 86.6          |
| train-EnvExecTime       | 10.2          |
| train-MaxReturn         | 110           |
| train-MinReturn         | 5.22          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 18.8          |
| train-StdReturn         | 14.2          |
-------------------------------------------

 ---------------- Iteration 152 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 152          |
| ItrTime                 | 32.3         |
| LossAfter               | -0.056077246 |
| LossBefore              | -0.023475366 |
| Time                    | 4.95e+03     |
| Time-Optimization       | 1.54         |
| Time-SampleProc         | 0.134        |
| Time-Sampling           | 30.6         |
| n_timesteps             | 1530000      |
| train-AverageDiscoun... | 48.3         |
| train-AverageReturn     | 84.2         |
| train-EnvExecTime       | 10.3         |
| train-MaxReturn         | 112          |
| train-MinReturn         | 28.9         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 19.4         |
| train-StdReturn         | 14.4         |
------------------------------------------

 ---------------- Iteration 153 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 153          |
| ItrTime                 | 32.9         |
| LossAfter               | -0.024116503 |
| LossBefore              | 0.009845947  |
| Time                    | 4.99e+03     |
| Time-Optimization       | 1.57         |
| Time-SampleProc         | 0.162        |
| Time-Sampling           | 31.1         |
| n_timesteps             | 1540000      |
| train-AverageDiscoun... | 47.9         |
| train-AverageReturn     | 84.5         |
| train-EnvExecTime       | 10.4         |
| train-MaxReturn         | 112          |
| train-MinReturn         | -3.6         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 19.8         |
| train-StdReturn         | 18.4         |
------------------------------------------

 ---------------- Iteration 154 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 154          |
| ItrTime                 | 33.1         |
| LossAfter               | -0.04912827  |
| LossBefore              | -0.019023877 |
| Time                    | 5.02e+03     |
| Time-Optimization       | 1.63         |
| Time-SampleProc         | 0.195        |
| Time-Sampling           | 31.3         |
| n_timesteps             | 1550000      |
| train-AverageDiscoun... | 49.6         |
| train-AverageReturn     | 86.4         |
| train-EnvExecTime       | 10.5         |
| train-MaxReturn         | 109          |
| train-MinReturn         | 50.2         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 19.9         |
| train-StdReturn         | 11.4         |
------------------------------------------

 ---------------- Iteration 155 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 155          |
| ItrTime                 | 32.6         |
| LossAfter               | -0.13907526  |
| LossBefore              | -0.012769531 |
| Time                    | 5.05e+03     |
| Time-Optimization       | 1.58         |
| Time-SampleProc         | 0.176        |
| Time-Sampling           | 30.9         |
| n_timesteps             | 1560000      |
| train-AverageDiscoun... | 47.9         |
| train-AverageReturn     | 83.3         |
| train-EnvExecTime       | 10.4         |
| train-MaxReturn         | 110          |
| train-MinReturn         | 5.94         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 19.6         |
| train-StdReturn         | 14.5         |
------------------------------------------

 ---------------- Iteration 156 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 156          |
| ItrTime                 | 32.7         |
| LossAfter               | -0.054525685 |
| LossBefore              | 0.0175825    |
| Time                    | 5.09e+03     |
| Time-Optimization       | 1.58         |
| Time-SampleProc         | 0.167        |
| Time-Sampling           | 30.9         |
| n_timesteps             | 1570000      |
| train-AverageDiscoun... | 49.3         |
| train-AverageReturn     | 85.6         |
| train-EnvExecTime       | 10.4         |
| train-MaxReturn         | 109          |
| train-MinReturn         | 41.4         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 19.5         |
| train-StdReturn         | 11.6         |
------------------------------------------

 ---------------- Iteration 157 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 157          |
| ItrTime                 | 32.6         |
| LossAfter               | -0.055914357 |
| LossBefore              | -0.018182177 |
| Time                    | 5.12e+03     |
| Time-Optimization       | 1.57         |
| Time-SampleProc         | 0.196        |
| Time-Sampling           | 30.8         |
| n_timesteps             | 1580000      |
| train-AverageDiscoun... | 48           |
| train-AverageReturn     | 83.8         |
| train-EnvExecTime       | 10.3         |
| train-MaxReturn         | 103          |
| train-MinReturn         | 18           |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 19.6         |
| train-StdReturn         | 15.9         |
------------------------------------------

 ---------------- Iteration 158 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 158           |
| ItrTime                 | 32.4          |
| LossAfter               | -0.0007706543 |
| LossBefore              | -0.0012164307 |
| Time                    | 5.15e+03      |
| Time-Optimization       | 1.52          |
| Time-SampleProc         | 0.162         |
| Time-Sampling           | 30.7          |
| n_timesteps             | 1590000       |
| train-AverageDiscoun... | 47.6          |
| train-AverageReturn     | 83.7          |
| train-EnvExecTime       | 10.4          |
| train-MaxReturn         | 116           |
| train-MinReturn         | 23.7          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 19.3          |
| train-StdReturn         | 14.5          |
-------------------------------------------

 ---------------- Iteration 159 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 159         |
| ItrTime                 | 32.7        |
| LossAfter               | 0.011165174 |
| LossBefore              | 0.03874801  |
| Time                    | 5.18e+03    |
| Time-Optimization       | 1.71        |
| Time-SampleProc         | 0.163       |
| Time-Sampling           | 30.8        |
| n_timesteps             | 1600000     |
| train-AverageDiscoun... | 46.1        |
| train-AverageReturn     | 80.1        |
| train-EnvExecTime       | 10.4        |
| train-MaxReturn         | 105         |
| train-MinReturn         | -32.5       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 19.5        |
| train-StdReturn         | 21.3        |
-----------------------------------------

 ---------------- Iteration 160 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 160          |
| ItrTime                 | 32.6         |
| LossAfter               | -0.045311928 |
| LossBefore              | -0.03151825  |
| Time                    | 5.22e+03     |
| Time-Optimization       | 1.73         |
| Time-SampleProc         | 0.141        |
| Time-Sampling           | 30.7         |
| n_timesteps             | 1610000      |
| train-AverageDiscoun... | 48           |
| train-AverageReturn     | 84.1         |
| train-EnvExecTime       | 10.3         |
| train-MaxReturn         | 107          |
| train-MinReturn         | 27           |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 19.5         |
| train-StdReturn         | 14.5         |
------------------------------------------

 ---------------- Iteration 161 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 161          |
| ItrTime                 | 32.8         |
| LossAfter               | -0.024220899 |
| LossBefore              | -0.01378894  |
| Time                    | 5.25e+03     |
| Time-Optimization       | 1.57         |
| Time-SampleProc         | 0.144        |
| Time-Sampling           | 31.1         |
| n_timesteps             | 1620000      |
| train-AverageDiscoun... | 47.7         |
| train-AverageReturn     | 83.8         |
| train-EnvExecTime       | 10.4         |
| train-MaxReturn         | 115          |
| train-MinReturn         | -7.69        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 19.6         |
| train-StdReturn         | 17.5         |
------------------------------------------

 ---------------- Iteration 162 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 162          |
| ItrTime                 | 33.1         |
| LossAfter               | -0.022847584 |
| LossBefore              | -0.008778711 |
| Time                    | 5.28e+03     |
| Time-Optimization       | 1.6          |
| Time-SampleProc         | 0.18         |
| Time-Sampling           | 31.3         |
| n_timesteps             | 1630000      |
| train-AverageDiscoun... | 48.8         |
| train-AverageReturn     | 84.8         |
| train-EnvExecTime       | 10.5         |
| train-MaxReturn         | 112          |
| train-MinReturn         | -4.68        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 19.9         |
| train-StdReturn         | 15.4         |
------------------------------------------

 ---------------- Iteration 163 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 163          |
| ItrTime                 | 33.6         |
| LossAfter               | -0.004121997 |
| LossBefore              | 0.011684888  |
| Time                    | 5.32e+03     |
| Time-Optimization       | 1.49         |
| Time-SampleProc         | 0.159        |
| Time-Sampling           | 31.9         |
| n_timesteps             | 1640000      |
| train-AverageDiscoun... | 49.3         |
| train-AverageReturn     | 86           |
| train-EnvExecTime       | 10.8         |
| train-MaxReturn         | 108          |
| train-MinReturn         | 31           |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 20.2         |
| train-StdReturn         | 12.1         |
------------------------------------------

 ---------------- Iteration 164 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 164          |
| ItrTime                 | 31.9         |
| LossAfter               | -0.017386597 |
| LossBefore              | 0.0042534303 |
| Time                    | 5.35e+03     |
| Time-Optimization       | 1.54         |
| Time-SampleProc         | 0.147        |
| Time-Sampling           | 30.2         |
| n_timesteps             | 1650000      |
| train-AverageDiscoun... | 48.5         |
| train-AverageReturn     | 85           |
| train-EnvExecTime       | 10.1         |
| train-MaxReturn         | 123          |
| train-MinReturn         | 4.66         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 19.1         |
| train-StdReturn         | 17.4         |
------------------------------------------

 ---------------- Iteration 165 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 165          |
| ItrTime                 | 33.9         |
| LossAfter               | -0.017607471 |
| LossBefore              | 0.011350195  |
| Time                    | 5.38e+03     |
| Time-Optimization       | 1.48         |
| Time-SampleProc         | 0.162        |
| Time-Sampling           | 32.2         |
| n_timesteps             | 1660000      |
| train-AverageDiscoun... | 48.4         |
| train-AverageReturn     | 84.3         |
| train-EnvExecTime       | 10.7         |
| train-MaxReturn         | 121          |
| train-MinReturn         | 15.9         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 20.5         |
| train-StdReturn         | 14.6         |
------------------------------------------

 ---------------- Iteration 166 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 166           |
| ItrTime                 | 33.3          |
| LossAfter               | -0.06764827   |
| LossBefore              | -0.0054953857 |
| Time                    | 5.41e+03      |
| Time-Optimization       | 1.58          |
| Time-SampleProc         | 0.166         |
| Time-Sampling           | 31.5          |
| n_timesteps             | 1670000       |
| train-AverageDiscoun... | 49.1          |
| train-AverageReturn     | 85.3          |
| train-EnvExecTime       | 10.6          |
| train-MaxReturn         | 115           |
| train-MinReturn         | 17.2          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 20            |
| train-StdReturn         | 14.5          |
-------------------------------------------

 ---------------- Iteration 167 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 167          |
| ItrTime                 | 33.2         |
| LossAfter               | -0.012201758 |
| LossBefore              | 0.002976953  |
| Time                    | 5.45e+03     |
| Time-Optimization       | 1.57         |
| Time-SampleProc         | 0.168        |
| Time-Sampling           | 31.5         |
| n_timesteps             | 1680000      |
| train-AverageDiscoun... | 48.4         |
| train-AverageReturn     | 84.7         |
| train-EnvExecTime       | 10.5         |
| train-MaxReturn         | 111          |
| train-MinReturn         | 0.936        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 20           |
| train-StdReturn         | 15.6         |
------------------------------------------

 ---------------- Iteration 168 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 168          |
| ItrTime                 | 33.8         |
| LossAfter               | -0.031278625 |
| LossBefore              | -0.028714105 |
| Time                    | 5.48e+03     |
| Time-Optimization       | 1.67         |
| Time-SampleProc         | 0.176        |
| Time-Sampling           | 32           |
| n_timesteps             | 1690000      |
| train-AverageDiscoun... | 47.9         |
| train-AverageReturn     | 83           |
| train-EnvExecTime       | 10.7         |
| train-MaxReturn         | 108          |
| train-MinReturn         | 18.8         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 20.3         |
| train-StdReturn         | 17.2         |
------------------------------------------

 ---------------- Iteration 169 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 169           |
| ItrTime                 | 34.5          |
| LossAfter               | -0.046978466  |
| LossBefore              | -0.0004390503 |
| Time                    | 5.52e+03      |
| Time-Optimization       | 1.56          |
| Time-SampleProc         | 0.137         |
| Time-Sampling           | 32.8          |
| n_timesteps             | 1700000       |
| train-AverageDiscoun... | 48.5          |
| train-AverageReturn     | 84.4          |
| train-EnvExecTime       | 10.8          |
| train-MaxReturn         | 110           |
| train-MinReturn         | -13.3         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 20.9          |
| train-StdReturn         | 20.2          |
-------------------------------------------

 ---------------- Iteration 170 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 170         |
| ItrTime                 | 34.5        |
| LossAfter               | -0.01213263 |
| LossBefore              | 0.039683912 |
| Time                    | 5.55e+03    |
| Time-Optimization       | 1.51        |
| Time-SampleProc         | 0.134       |
| Time-Sampling           | 32.9        |
| n_timesteps             | 1710000     |
| train-AverageDiscoun... | 45.8        |
| train-AverageReturn     | 79.8        |
| train-EnvExecTime       | 10.9        |
| train-MaxReturn         | 107         |
| train-MinReturn         | -28.8       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 21          |
| train-StdReturn         | 19.9        |
-----------------------------------------

 ---------------- Iteration 171 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 171           |
| ItrTime                 | 31.1          |
| LossAfter               | -0.07533579   |
| LossBefore              | -0.0024727539 |
| Time                    | 5.58e+03      |
| Time-Optimization       | 1.49          |
| Time-SampleProc         | 0.152         |
| Time-Sampling           | 29.4          |
| n_timesteps             | 1720000       |
| train-AverageDiscoun... | 46.5          |
| train-AverageReturn     | 80.7          |
| train-EnvExecTime       | 9.96          |
| train-MaxReturn         | 121           |
| train-MinReturn         | 10.1          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 18.5          |
| train-StdReturn         | 18.2          |
-------------------------------------------

 ---------------- Iteration 172 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 172           |
| ItrTime                 | 30            |
| LossAfter               | -0.51514846   |
| LossBefore              | -0.0089406315 |
| Time                    | 5.61e+03      |
| Time-Optimization       | 1.5           |
| Time-SampleProc         | 0.127         |
| Time-Sampling           | 28.4          |
| n_timesteps             | 1730000       |
| train-AverageDiscoun... | 42.5          |
| train-AverageReturn     | 74.1          |
| train-EnvExecTime       | 9.76          |
| train-MaxReturn         | 102           |
| train-MinReturn         | -21.2         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 17.7          |
| train-StdReturn         | 17            |
-------------------------------------------

 ---------------- Iteration 173 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 173          |
| ItrTime                 | 31.8         |
| LossAfter               | -1.2266527   |
| LossBefore              | 0.0024620362 |
| Time                    | 5.64e+03     |
| Time-Optimization       | 1.61         |
| Time-SampleProc         | 0.183        |
| Time-Sampling           | 30           |
| n_timesteps             | 1740000      |
| train-AverageDiscoun... | 46.4         |
| train-AverageReturn     | 81           |
| train-EnvExecTime       | 10.1         |
| train-MaxReturn         | 101          |
| train-MinReturn         | 5.31         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 18.9         |
| train-StdReturn         | 16.1         |
------------------------------------------

 ---------------- Iteration 174 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 174         |
| ItrTime                 | 28.2        |
| LossAfter               | -1.2941225  |
| LossBefore              | -0.02757417 |
| Time                    | 5.67e+03    |
| Time-Optimization       | 1.27        |
| Time-SampleProc         | 0.139       |
| Time-Sampling           | 26.8        |
| n_timesteps             | 1750000     |
| train-AverageDiscoun... | 41.7        |
| train-AverageReturn     | 73.8        |
| train-EnvExecTime       | 9.22        |
| train-MaxReturn         | 113         |
| train-MinReturn         | -1.25       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 16.7        |
| train-StdReturn         | 23.3        |
-----------------------------------------

 ---------------- Iteration 175 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 175          |
| ItrTime                 | 27.7         |
| LossAfter               | -1.2982213   |
| LossBefore              | 0.0061457274 |
| Time                    | 5.7e+03      |
| Time-Optimization       | 1.25         |
| Time-SampleProc         | 0.129        |
| Time-Sampling           | 26.3         |
| n_timesteps             | 1760000      |
| train-AverageDiscoun... | 40.9         |
| train-AverageReturn     | 74.2         |
| train-EnvExecTime       | 9.15         |
| train-MaxReturn         | 114          |
| train-MinReturn         | -43.1        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 16.3         |
| train-StdReturn         | 33.2         |
------------------------------------------

 ---------------- Iteration 176 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 176          |
| ItrTime                 | 27.8         |
| LossAfter               | -0.9920875   |
| LossBefore              | 0.0005482422 |
| Time                    | 5.73e+03     |
| Time-Optimization       | 1.38         |
| Time-SampleProc         | 0.149        |
| Time-Sampling           | 26.3         |
| n_timesteps             | 1770000      |
| train-AverageDiscoun... | 44.3         |
| train-AverageReturn     | 76.6         |
| train-EnvExecTime       | 9.17         |
| train-MaxReturn         | 136          |
| train-MinReturn         | -39.5        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 16.3         |
| train-StdReturn         | 40.2         |
------------------------------------------

 ---------------- Iteration 177 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 177         |
| ItrTime                 | 28.8        |
| LossAfter               | -0.4070088  |
| LossBefore              | 0.031711865 |
| Time                    | 5.76e+03    |
| Time-Optimization       | 1.36        |
| Time-SampleProc         | 0.124       |
| Time-Sampling           | 27.3        |
| n_timesteps             | 1780000     |
| train-AverageDiscoun... | 37.9        |
| train-AverageReturn     | 67          |
| train-EnvExecTime       | 9.33        |
| train-MaxReturn         | 136         |
| train-MinReturn         | -63.8       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 17.2        |
| train-StdReturn         | 47.3        |
-----------------------------------------

 ---------------- Iteration 178 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 178          |
| ItrTime                 | 28.7         |
| LossAfter               | -0.9515693   |
| LossBefore              | 0.0031422607 |
| Time                    | 5.79e+03     |
| Time-Optimization       | 1.3          |
| Time-SampleProc         | 0.173        |
| Time-Sampling           | 27.3         |
| n_timesteps             | 1790000      |
| train-AverageDiscoun... | 38           |
| train-AverageReturn     | 66.4         |
| train-EnvExecTime       | 9.45         |
| train-MaxReturn         | 126          |
| train-MinReturn         | -78.1        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 17           |
| train-StdReturn         | 51.4         |
------------------------------------------

 ---------------- Iteration 179 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 179         |
| ItrTime                 | 27.8        |
| LossAfter               | -3.7949808  |
| LossBefore              | 0.008095093 |
| Time                    | 5.81e+03    |
| Time-Optimization       | 1.39        |
| Time-SampleProc         | 0.158       |
| Time-Sampling           | 26.3        |
| n_timesteps             | 1800000     |
| train-AverageDiscoun... | 43.8        |
| train-AverageReturn     | 76          |
| train-EnvExecTime       | 9.12        |
| train-MaxReturn         | 123         |
| train-MinReturn         | -37.6       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 16.3        |
| train-StdReturn         | 39.7        |
-----------------------------------------

 ---------------- Iteration 180 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 180         |
| ItrTime                 | 27.9        |
| LossAfter               | -1.4348053  |
| LossBefore              | 0.020348258 |
| Time                    | 5.84e+03    |
| Time-Optimization       | 1.35        |
| Time-SampleProc         | 0.136       |
| Time-Sampling           | 26.4        |
| n_timesteps             | 1810000     |
| train-AverageDiscoun... | 39.2        |
| train-AverageReturn     | 67.6        |
| train-EnvExecTime       | 9.17        |
| train-MaxReturn         | 135         |
| train-MinReturn         | -55.6       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 16.4        |
| train-StdReturn         | 49.8        |
-----------------------------------------

 ---------------- Iteration 181 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 181         |
| ItrTime                 | 28.5        |
| LossAfter               | -5.2815175  |
| LossBefore              | 0.022128735 |
| Time                    | 5.87e+03    |
| Time-Optimization       | 1.39        |
| Time-SampleProc         | 0.155       |
| Time-Sampling           | 27          |
| n_timesteps             | 1820000     |
| train-AverageDiscoun... | 28.6        |
| train-AverageReturn     | 47.2        |
| train-EnvExecTime       | 9.29        |
| train-MaxReturn         | 130         |
| train-MinReturn         | -102        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 16.8        |
| train-StdReturn         | 51.4        |
-----------------------------------------

 ---------------- Iteration 182 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 182         |
| ItrTime                 | 28          |
| LossAfter               | -1.9241524  |
| LossBefore              | -0.03060067 |
| Time                    | 5.9e+03     |
| Time-Optimization       | 1.28        |
| Time-SampleProc         | 0.118       |
| Time-Sampling           | 26.6        |
| n_timesteps             | 1830000     |
| train-AverageDiscoun... | 46.1        |
| train-AverageReturn     | 81.2        |
| train-EnvExecTime       | 9.23        |
| train-MaxReturn         | 117         |
| train-MinReturn         | -70.8       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 16.5        |
| train-StdReturn         | 22.6        |
-----------------------------------------

 ---------------- Iteration 183 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 183          |
| ItrTime                 | 28.2         |
| LossAfter               | -0.40138778  |
| LossBefore              | -0.004714331 |
| Time                    | 5.93e+03     |
| Time-Optimization       | 1.27         |
| Time-SampleProc         | 0.144        |
| Time-Sampling           | 26.8         |
| n_timesteps             | 1840000      |
| train-AverageDiscoun... | 45.8         |
| train-AverageReturn     | 80.2         |
| train-EnvExecTime       | 9.25         |
| train-MaxReturn         | 108          |
| train-MinReturn         | -10.3        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 16.7         |
| train-StdReturn         | 19.5         |
------------------------------------------

 ---------------- Iteration 184 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 184          |
| ItrTime                 | 28.2         |
| LossAfter               | -0.18969986  |
| LossBefore              | 0.0067415526 |
| Time                    | 5.96e+03     |
| Time-Optimization       | 1.29         |
| Time-SampleProc         | 0.129        |
| Time-Sampling           | 26.7         |
| n_timesteps             | 1850000      |
| train-AverageDiscoun... | 47.9         |
| train-AverageReturn     | 84.6         |
| train-EnvExecTime       | 9.22         |
| train-MaxReturn         | 105          |
| train-MinReturn         | -4.7         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 16.7         |
| train-StdReturn         | 14.7         |
------------------------------------------

 ---------------- Iteration 185 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 185          |
| ItrTime                 | 27.9         |
| LossAfter               | -0.06570754  |
| LossBefore              | -0.009520557 |
| Time                    | 5.98e+03     |
| Time-Optimization       | 1.25         |
| Time-SampleProc         | 0.122        |
| Time-Sampling           | 26.5         |
| n_timesteps             | 1860000      |
| train-AverageDiscoun... | 46.9         |
| train-AverageReturn     | 82.6         |
| train-EnvExecTime       | 9.19         |
| train-MaxReturn         | 119          |
| train-MinReturn         | 15.2         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 16.5         |
| train-StdReturn         | 17.3         |
------------------------------------------

 ---------------- Iteration 186 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 186           |
| ItrTime                 | 27.6          |
| LossAfter               | -0.028106665  |
| LossBefore              | -0.0061638914 |
| Time                    | 6.01e+03      |
| Time-Optimization       | 1.28          |
| Time-SampleProc         | 0.127         |
| Time-Sampling           | 26.2          |
| n_timesteps             | 1870000       |
| train-AverageDiscoun... | 48.3          |
| train-AverageReturn     | 85.2          |
| train-EnvExecTime       | 9.11          |
| train-MaxReturn         | 109           |
| train-MinReturn         | 30.6          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 16.2          |
| train-StdReturn         | 13.6          |
-------------------------------------------

 ---------------- Iteration 187 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 187          |
| ItrTime                 | 27.6         |
| LossAfter               | -0.02936573  |
| LossBefore              | -0.030852875 |
| Time                    | 6.04e+03     |
| Time-Optimization       | 1.32         |
| Time-SampleProc         | 0.137        |
| Time-Sampling           | 26.1         |
| n_timesteps             | 1880000      |
| train-AverageDiscoun... | 48.6         |
| train-AverageReturn     | 85.6         |
| train-EnvExecTime       | 9.08         |
| train-MaxReturn         | 104          |
| train-MinReturn         | 35.2         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 16.2         |
| train-StdReturn         | 10.6         |
------------------------------------------

 ---------------- Iteration 188 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 188          |
| ItrTime                 | 28.7         |
| LossAfter               | -0.010802276 |
| LossBefore              | 0.005136493  |
| Time                    | 6.07e+03     |
| Time-Optimization       | 1.37         |
| Time-SampleProc         | 0.133        |
| Time-Sampling           | 27.2         |
| n_timesteps             | 1890000      |
| train-AverageDiscoun... | 47.3         |
| train-AverageReturn     | 83.1         |
| train-EnvExecTime       | 9.38         |
| train-MaxReturn         | 108          |
| train-MinReturn         | -32          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 16.9         |
| train-StdReturn         | 18.9         |
------------------------------------------

 ---------------- Iteration 189 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 189         |
| ItrTime                 | 27.4        |
| LossAfter               | -0.05940126 |
| LossBefore              | 0.017194886 |
| Time                    | 6.09e+03    |
| Time-Optimization       | 1.31        |
| Time-SampleProc         | 0.122       |
| Time-Sampling           | 26          |
| n_timesteps             | 1900000     |
| train-AverageDiscoun... | 46.6        |
| train-AverageReturn     | 82.1        |
| train-EnvExecTime       | 9.05        |
| train-MaxReturn         | 115         |
| train-MinReturn         | 12.6        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 16.1        |
| train-StdReturn         | 18.4        |
-----------------------------------------

 ---------------- Iteration 190 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 190          |
| ItrTime                 | 28.1         |
| LossAfter               | -0.032684375 |
| LossBefore              | 0.017055029  |
| Time                    | 6.12e+03     |
| Time-Optimization       | 1.24         |
| Time-SampleProc         | 0.157        |
| Time-Sampling           | 26.7         |
| n_timesteps             | 1910000      |
| train-AverageDiscoun... | 47.9         |
| train-AverageReturn     | 83.8         |
| train-EnvExecTime       | 9.22         |
| train-MaxReturn         | 109          |
| train-MinReturn         | 3.02         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 16.6         |
| train-StdReturn         | 16.2         |
------------------------------------------

 ---------------- Iteration 191 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 191          |
| ItrTime                 | 28.1         |
| LossAfter               | -0.097491525 |
| LossBefore              | -0.043413002 |
| Time                    | 6.15e+03     |
| Time-Optimization       | 1.4          |
| Time-SampleProc         | 0.2          |
| Time-Sampling           | 26.5         |
| n_timesteps             | 1920000      |
| train-AverageDiscoun... | 48.1         |
| train-AverageReturn     | 83.9         |
| train-EnvExecTime       | 9.16         |
| train-MaxReturn         | 116          |
| train-MinReturn         | -29.7        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 16.5         |
| train-StdReturn         | 19.2         |
------------------------------------------

 ---------------- Iteration 192 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 192          |
| ItrTime                 | 27.7         |
| LossAfter               | -0.09074767  |
| LossBefore              | -0.013934876 |
| Time                    | 6.18e+03     |
| Time-Optimization       | 1.3          |
| Time-SampleProc         | 0.126        |
| Time-Sampling           | 26.3         |
| n_timesteps             | 1930000      |
| train-AverageDiscoun... | 47.5         |
| train-AverageReturn     | 83.2         |
| train-EnvExecTime       | 9.17         |
| train-MaxReturn         | 106          |
| train-MinReturn         | 11.9         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 16.3         |
| train-StdReturn         | 17.1         |
------------------------------------------

 ---------------- Iteration 193 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 193          |
| ItrTime                 | 28.4         |
| LossAfter               | -0.030400086 |
| LossBefore              | 0.019961182  |
| Time                    | 6.21e+03     |
| Time-Optimization       | 1.26         |
| Time-SampleProc         | 0.128        |
| Time-Sampling           | 27.1         |
| n_timesteps             | 1940000      |
| train-AverageDiscoun... | 48.1         |
| train-AverageReturn     | 84.5         |
| train-EnvExecTime       | 9.34         |
| train-MaxReturn         | 104          |
| train-MinReturn         | -17.4        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 16.9         |
| train-StdReturn         | 17.4         |
------------------------------------------

 ---------------- Iteration 194 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 194          |
| ItrTime                 | 27.7         |
| LossAfter               | -0.073231384 |
| LossBefore              | -0.007549808 |
| Time                    | 6.23e+03     |
| Time-Optimization       | 1.24         |
| Time-SampleProc         | 0.148        |
| Time-Sampling           | 26.3         |
| n_timesteps             | 1950000      |
| train-AverageDiscoun... | 49.6         |
| train-AverageReturn     | 86.2         |
| train-EnvExecTime       | 9.11         |
| train-MaxReturn         | 112          |
| train-MinReturn         | 26.4         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 16.4         |
| train-StdReturn         | 12.1         |
------------------------------------------

 ---------------- Iteration 195 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 195          |
| ItrTime                 | 27.7         |
| LossAfter               | -0.049144898 |
| LossBefore              | -0.006545068 |
| Time                    | 6.26e+03     |
| Time-Optimization       | 1.23         |
| Time-SampleProc         | 0.174        |
| Time-Sampling           | 26.3         |
| n_timesteps             | 1960000      |
| train-AverageDiscoun... | 49.9         |
| train-AverageReturn     | 87.1         |
| train-EnvExecTime       | 9.16         |
| train-MaxReturn         | 116          |
| train-MinReturn         | 40.3         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 16.3         |
| train-StdReturn         | 11.6         |
------------------------------------------

 ---------------- Iteration 196 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 196          |
| ItrTime                 | 27.8         |
| LossAfter               | -0.046948437 |
| LossBefore              | 0.019341968  |
| Time                    | 6.29e+03     |
| Time-Optimization       | 1.39         |
| Time-SampleProc         | 0.165        |
| Time-Sampling           | 26.3         |
| n_timesteps             | 1970000      |
| train-AverageDiscoun... | 47.7         |
| train-AverageReturn     | 83.6         |
| train-EnvExecTime       | 9.17         |
| train-MaxReturn         | 108          |
| train-MinReturn         | 10.6         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 16.3         |
| train-StdReturn         | 14.1         |
------------------------------------------

 ---------------- Iteration 197 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 197           |
| ItrTime                 | 27.5          |
| LossAfter               | -0.01883535   |
| LossBefore              | -0.0039786743 |
| Time                    | 6.32e+03      |
| Time-Optimization       | 1.27          |
| Time-SampleProc         | 0.125         |
| Time-Sampling           | 26.1          |
| n_timesteps             | 1980000       |
| train-AverageDiscoun... | 48.7          |
| train-AverageReturn     | 84.6          |
| train-EnvExecTime       | 9.09          |
| train-MaxReturn         | 114           |
| train-MinReturn         | 9             |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 16.2          |
| train-StdReturn         | 15            |
-------------------------------------------

 ---------------- Iteration 198 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 198          |
| ItrTime                 | 29.8         |
| LossAfter               | -0.011355022 |
| LossBefore              | 0.0009840893 |
| Time                    | 6.35e+03     |
| Time-Optimization       | 1.35         |
| Time-SampleProc         | 0.126        |
| Time-Sampling           | 28.3         |
| n_timesteps             | 1990000      |
| train-AverageDiscoun... | 47.9         |
| train-AverageReturn     | 84           |
| train-EnvExecTime       | 9.67         |
| train-MaxReturn         | 109          |
| train-MinReturn         | 12.3         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 17.8         |
| train-StdReturn         | 16.4         |
------------------------------------------

 ---------------- Iteration 199 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 199         |
| ItrTime                 | 30.8        |
| LossAfter               | 0.031502392 |
| LossBefore              | 0.034716066 |
| Time                    | 6.38e+03    |
| Time-Optimization       | 1.61        |
| Time-SampleProc         | 0.231       |
| Time-Sampling           | 28.9        |
| n_timesteps             | 2000000     |
| train-AverageDiscoun... | 47          |
| train-AverageReturn     | 81.8        |
| train-EnvExecTime       | 9.79        |
| train-MaxReturn         | 109         |
| train-MinReturn         | 8.82        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 18.2        |
| train-StdReturn         | 17          |
-----------------------------------------

 ---------------- Iteration 200 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 200          |
| ItrTime                 | 30           |
| LossAfter               | -0.03640791  |
| LossBefore              | 0.0092093265 |
| Time                    | 6.41e+03     |
| Time-Optimization       | 1.81         |
| Time-SampleProc         | 0.122        |
| Time-Sampling           | 28.1         |
| n_timesteps             | 2010000      |
| train-AverageDiscoun... | 48.7         |
| train-AverageReturn     | 85.8         |
| train-EnvExecTime       | 9.66         |
| train-MaxReturn         | 107          |
| train-MinReturn         | 15.2         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 17.5         |
| train-StdReturn         | 14           |
------------------------------------------

 ---------------- Iteration 201 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 201          |
| ItrTime                 | 26.4         |
| LossAfter               | -0.02263706  |
| LossBefore              | -0.014068006 |
| Time                    | 6.44e+03     |
| Time-Optimization       | 1.32         |
| Time-SampleProc         | 0.142        |
| Time-Sampling           | 25           |
| n_timesteps             | 2020000      |
| train-AverageDiscoun... | 45.7         |
| train-AverageReturn     | 80.4         |
| train-EnvExecTime       | 8.79         |
| train-MaxReturn         | 111          |
| train-MinReturn         | 4.71         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 15.4         |
| train-StdReturn         | 19           |
------------------------------------------

 ---------------- Iteration 202 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 202         |
| ItrTime                 | 26.2        |
| LossAfter               | 0.015930492 |
| LossBefore              | 0.030239014 |
| Time                    | 6.46e+03    |
| Time-Optimization       | 1.24        |
| Time-SampleProc         | 0.119       |
| Time-Sampling           | 24.8        |
| n_timesteps             | 2030000     |
| train-AverageDiscoun... | 47.7        |
| train-AverageReturn     | 83.8        |
| train-EnvExecTime       | 8.72        |
| train-MaxReturn         | 115         |
| train-MinReturn         | 5.99        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 15.3        |
| train-StdReturn         | 17.4        |
-----------------------------------------

 ---------------- Iteration 203 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 203          |
| ItrTime                 | 26.6         |
| LossAfter               | -0.017597329 |
| LossBefore              | 0.0045374725 |
| Time                    | 6.49e+03     |
| Time-Optimization       | 1.32         |
| Time-SampleProc         | 0.121        |
| Time-Sampling           | 25.2         |
| n_timesteps             | 2040000      |
| train-AverageDiscoun... | 48.2         |
| train-AverageReturn     | 84.3         |
| train-EnvExecTime       | 8.81         |
| train-MaxReturn         | 110          |
| train-MinReturn         | 9.87         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 15.6         |
| train-StdReturn         | 18.5         |
------------------------------------------

 ---------------- Iteration 204 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 204          |
| ItrTime                 | 27.8         |
| LossAfter               | -0.042413145 |
| LossBefore              | -0.024634149 |
| Time                    | 6.52e+03     |
| Time-Optimization       | 1.24         |
| Time-SampleProc         | 0.123        |
| Time-Sampling           | 26.5         |
| n_timesteps             | 2050000      |
| train-AverageDiscoun... | 48.7         |
| train-AverageReturn     | 85.3         |
| train-EnvExecTime       | 9.16         |
| train-MaxReturn         | 112          |
| train-MinReturn         | 14.2         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 16.5         |
| train-StdReturn         | 13.9         |
------------------------------------------

 ---------------- Iteration 205 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 205          |
| ItrTime                 | 29.2         |
| LossAfter               | -0.036063526 |
| LossBefore              | 0.0014922363 |
| Time                    | 6.55e+03     |
| Time-Optimization       | 1.31         |
| Time-SampleProc         | 0.142        |
| Time-Sampling           | 27.7         |
| n_timesteps             | 2060000      |
| train-AverageDiscoun... | 48.1         |
| train-AverageReturn     | 84.4         |
| train-EnvExecTime       | 9.51         |
| train-MaxReturn         | 116          |
| train-MinReturn         | 36           |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 17.3         |
| train-StdReturn         | 13.3         |
------------------------------------------

 ---------------- Iteration 206 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 206          |
| ItrTime                 | 30.4         |
| LossAfter               | -0.068825394 |
| LossBefore              | -0.016682958 |
| Time                    | 6.58e+03     |
| Time-Optimization       | 1.26         |
| Time-SampleProc         | 0.127        |
| Time-Sampling           | 29           |
| n_timesteps             | 2070000      |
| train-AverageDiscoun... | 48.2         |
| train-AverageReturn     | 84.3         |
| train-EnvExecTime       | 9.81         |
| train-MaxReturn         | 105          |
| train-MinReturn         | 16.8         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 18.3         |
| train-StdReturn         | 14.3         |
------------------------------------------

 ---------------- Iteration 207 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 207          |
| ItrTime                 | 29.4         |
| LossAfter               | -0.010164624 |
| LossBefore              | 0.0019350097 |
| Time                    | 6.61e+03     |
| Time-Optimization       | 1.62         |
| Time-SampleProc         | 0.153        |
| Time-Sampling           | 27.6         |
| n_timesteps             | 2080000      |
| train-AverageDiscoun... | 47.8         |
| train-AverageReturn     | 83.4         |
| train-EnvExecTime       | 9.51         |
| train-MaxReturn         | 108          |
| train-MinReturn         | 27.3         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 17.2         |
| train-StdReturn         | 11.8         |
------------------------------------------

 ---------------- Iteration 208 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 208          |
| ItrTime                 | 30.4         |
| LossAfter               | -0.028179174 |
| LossBefore              | -0.003349707 |
| Time                    | 6.64e+03     |
| Time-Optimization       | 1.41         |
| Time-SampleProc         | 0.126        |
| Time-Sampling           | 28.8         |
| n_timesteps             | 2090000      |
| train-AverageDiscoun... | 48           |
| train-AverageReturn     | 84.4         |
| train-EnvExecTime       | 9.74         |
| train-MaxReturn         | 106          |
| train-MinReturn         | 14.9         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 18.2         |
| train-StdReturn         | 12.8         |
------------------------------------------

 ---------------- Iteration 209 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 209           |
| ItrTime                 | 29            |
| LossAfter               | -0.020626465  |
| LossBefore              | 0.00034084474 |
| Time                    | 6.67e+03      |
| Time-Optimization       | 1.34          |
| Time-SampleProc         | 0.147         |
| Time-Sampling           | 27.5          |
| n_timesteps             | 2100000       |
| train-AverageDiscoun... | 46.7          |
| train-AverageReturn     | 81.9          |
| train-EnvExecTime       | 9.45          |
| train-MaxReturn         | 110           |
| train-MinReturn         | -26           |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 17.1          |
| train-StdReturn         | 17.4          |
-------------------------------------------

 ---------------- Iteration 210 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 210          |
| ItrTime                 | 31.6         |
| LossAfter               | -0.013352246 |
| LossBefore              | 0.024037939  |
| Time                    | 6.7e+03      |
| Time-Optimization       | 1.44         |
| Time-SampleProc         | 0.143        |
| Time-Sampling           | 30           |
| n_timesteps             | 2110000      |
| train-AverageDiscoun... | 48.7         |
| train-AverageReturn     | 85.8         |
| train-EnvExecTime       | 10.2         |
| train-MaxReturn         | 106          |
| train-MinReturn         | 41.3         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 18.9         |
| train-StdReturn         | 10.2         |
------------------------------------------

 ---------------- Iteration 211 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 211          |
| ItrTime                 | 28.5         |
| LossAfter               | -0.040945604 |
| LossBefore              | 0.0010032714 |
| Time                    | 6.73e+03     |
| Time-Optimization       | 1.29         |
| Time-SampleProc         | 0.136        |
| Time-Sampling           | 27.1         |
| n_timesteps             | 2120000      |
| train-AverageDiscoun... | 47           |
| train-AverageReturn     | 82.7         |
| train-EnvExecTime       | 9.34         |
| train-MaxReturn         | 107          |
| train-MinReturn         | -25.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 16.9         |
| train-StdReturn         | 17.1         |
------------------------------------------

 ---------------- Iteration 212 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 212         |
| ItrTime                 | 26.5        |
| LossAfter               | 0.0261693   |
| LossBefore              | 0.027346442 |
| Time                    | 6.75e+03    |
| Time-Optimization       | 1.16        |
| Time-SampleProc         | 0.129       |
| Time-Sampling           | 25.2        |
| n_timesteps             | 2130000     |
| train-AverageDiscoun... | 48.6        |
| train-AverageReturn     | 85          |
| train-EnvExecTime       | 8.85        |
| train-MaxReturn         | 109         |
| train-MinReturn         | -41.7       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 15.6        |
| train-StdReturn         | 17.3        |
-----------------------------------------

 ---------------- Iteration 213 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 213          |
| ItrTime                 | 28.7         |
| LossAfter               | -0.021529488 |
| LossBefore              | 0.0024096146 |
| Time                    | 6.78e+03     |
| Time-Optimization       | 1.35         |
| Time-SampleProc         | 0.149        |
| Time-Sampling           | 27.2         |
| n_timesteps             | 2140000      |
| train-AverageDiscoun... | 47.6         |
| train-AverageReturn     | 83.3         |
| train-EnvExecTime       | 9.33         |
| train-MaxReturn         | 109          |
| train-MinReturn         | 7.22         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 17           |
| train-StdReturn         | 18.1         |
------------------------------------------

 ---------------- Iteration 214 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 214          |
| ItrTime                 | 27.8         |
| LossAfter               | -0.030838769 |
| LossBefore              | -0.016403075 |
| Time                    | 6.81e+03     |
| Time-Optimization       | 1.38         |
| Time-SampleProc         | 0.222        |
| Time-Sampling           | 26.2         |
| n_timesteps             | 2150000      |
| train-AverageDiscoun... | 48           |
| train-AverageReturn     | 83.6         |
| train-EnvExecTime       | 9.14         |
| train-MaxReturn         | 111          |
| train-MinReturn         | 0.63         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 16.2         |
| train-StdReturn         | 17.8         |
------------------------------------------

 ---------------- Iteration 215 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 215          |
| ItrTime                 | 28.8         |
| LossAfter               | -0.035148803 |
| LossBefore              | 0.0015616578 |
| Time                    | 6.84e+03     |
| Time-Optimization       | 1.84         |
| Time-SampleProc         | 0.171        |
| Time-Sampling           | 26.7         |
| n_timesteps             | 2160000      |
| train-AverageDiscoun... | 48.1         |
| train-AverageReturn     | 84.5         |
| train-EnvExecTime       | 9.26         |
| train-MaxReturn         | 106          |
| train-MinReturn         | 13.7         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 16.6         |
| train-StdReturn         | 14.2         |
------------------------------------------

 ---------------- Iteration 216 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 216          |
| ItrTime                 | 28.7         |
| LossAfter               | -0.018041003 |
| LossBefore              | -0.005792914 |
| Time                    | 6.87e+03     |
| Time-Optimization       | 1.81         |
| Time-SampleProc         | 0.148        |
| Time-Sampling           | 26.7         |
| n_timesteps             | 2170000      |
| train-AverageDiscoun... | 46.8         |
| train-AverageReturn     | 82.5         |
| train-EnvExecTime       | 9.37         |
| train-MaxReturn         | 103          |
| train-MinReturn         | 19.9         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 16.5         |
| train-StdReturn         | 15.3         |
------------------------------------------

 ---------------- Iteration 217 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 217          |
| ItrTime                 | 28           |
| LossAfter               | -0.026927685 |
| LossBefore              | -0.017764745 |
| Time                    | 6.89e+03     |
| Time-Optimization       | 1.68         |
| Time-SampleProc         | 0.123        |
| Time-Sampling           | 26.2         |
| n_timesteps             | 2180000      |
| train-AverageDiscoun... | 47.9         |
| train-AverageReturn     | 83.7         |
| train-EnvExecTime       | 9.07         |
| train-MaxReturn         | 126          |
| train-MinReturn         | -28.4        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 16.2         |
| train-StdReturn         | 20.1         |
------------------------------------------

 ---------------- Iteration 218 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 218            |
| ItrTime                 | 28.6           |
| LossAfter               | -0.00074575195 |
| LossBefore              | 0.008852417    |
| Time                    | 6.92e+03       |
| Time-Optimization       | 1.48           |
| Time-SampleProc         | 0.176          |
| Time-Sampling           | 26.9           |
| n_timesteps             | 2190000        |
| train-AverageDiscoun... | 49.3           |
| train-AverageReturn     | 85.9           |
| train-EnvExecTime       | 9.31           |
| train-MaxReturn         | 108            |
| train-MinReturn         | 2.88           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 16.8           |
| train-StdReturn         | 14.9           |
--------------------------------------------

 ---------------- Iteration 219 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 219          |
| ItrTime                 | 29           |
| LossAfter               | -0.009282654 |
| LossBefore              | 0.006379191  |
| Time                    | 6.95e+03     |
| Time-Optimization       | 1.35         |
| Time-SampleProc         | 0.128        |
| Time-Sampling           | 27.6         |
| n_timesteps             | 2200000      |
| train-AverageDiscoun... | 48.7         |
| train-AverageReturn     | 84.9         |
| train-EnvExecTime       | 9.51         |
| train-MaxReturn         | 109          |
| train-MinReturn         | -7.84        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 17.2         |
| train-StdReturn         | 14.5         |
------------------------------------------

 ---------------- Iteration 220 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 220           |
| ItrTime                 | 28.3          |
| LossAfter               | -0.033990644  |
| LossBefore              | -0.0040348936 |
| Time                    | 6.98e+03      |
| Time-Optimization       | 1.44          |
| Time-SampleProc         | 0.159         |
| Time-Sampling           | 26.7          |
| n_timesteps             | 2210000       |
| train-AverageDiscoun... | 47.9          |
| train-AverageReturn     | 83.5          |
| train-EnvExecTime       | 9.21          |
| train-MaxReturn         | 108           |
| train-MinReturn         | 9.33          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 16.7          |
| train-StdReturn         | 14.9          |
-------------------------------------------

 ---------------- Iteration 221 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 221           |
| ItrTime                 | 29.3          |
| LossAfter               | -0.0095825195 |
| LossBefore              | 0.020001123   |
| Time                    | 7.01e+03      |
| Time-Optimization       | 1.42          |
| Time-SampleProc         | 0.196         |
| Time-Sampling           | 27.7          |
| n_timesteps             | 2220000       |
| train-AverageDiscoun... | 49.8          |
| train-AverageReturn     | 87            |
| train-EnvExecTime       | 9.52          |
| train-MaxReturn         | 111           |
| train-MinReturn         | 14.9          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 17.3          |
| train-StdReturn         | 12.2          |
-------------------------------------------

 ---------------- Iteration 222 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 222           |
| ItrTime                 | 29.4          |
| LossAfter               | -0.034944255  |
| LossBefore              | -0.0065399026 |
| Time                    | 7.04e+03      |
| Time-Optimization       | 1.68          |
| Time-SampleProc         | 0.129         |
| Time-Sampling           | 27.6          |
| n_timesteps             | 2230000       |
| train-AverageDiscoun... | 49.2          |
| train-AverageReturn     | 85.5          |
| train-EnvExecTime       | 9.4           |
| train-MaxReturn         | 111           |
| train-MinReturn         | -4.74         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 17.3          |
| train-StdReturn         | 16.4          |
-------------------------------------------

 ---------------- Iteration 223 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 223          |
| ItrTime                 | 27.8         |
| LossAfter               | -0.008610327 |
| LossBefore              | 0.027077863  |
| Time                    | 7.07e+03     |
| Time-Optimization       | 1.43         |
| Time-SampleProc         | 0.13         |
| Time-Sampling           | 26.2         |
| n_timesteps             | 2240000      |
| train-AverageDiscoun... | 50.4         |
| train-AverageReturn     | 87.5         |
| train-EnvExecTime       | 9.11         |
| train-MaxReturn         | 111          |
| train-MinReturn         | 8.62         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 16.3         |
| train-StdReturn         | 13.1         |
------------------------------------------

 ---------------- Iteration 224 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 224         |
| ItrTime                 | 28.2        |
| LossAfter               | 0.009208032 |
| LossBefore              | 0.026040295 |
| Time                    | 7.1e+03     |
| Time-Optimization       | 1.39        |
| Time-SampleProc         | 0.136       |
| Time-Sampling           | 26.6        |
| n_timesteps             | 2250000     |
| train-AverageDiscoun... | 49.5        |
| train-AverageReturn     | 86          |
| train-EnvExecTime       | 9.22        |
| train-MaxReturn         | 112         |
| train-MinReturn         | 48.1        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 16.6        |
| train-StdReturn         | 11.1        |
-----------------------------------------

 ---------------- Iteration 225 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 225          |
| ItrTime                 | 29.2         |
| LossAfter               | -0.009908972 |
| LossBefore              | 0.0023967652 |
| Time                    | 7.12e+03     |
| Time-Optimization       | 1.72         |
| Time-SampleProc         | 0.203        |
| Time-Sampling           | 27.2         |
| n_timesteps             | 2260000      |
| train-AverageDiscoun... | 47.3         |
| train-AverageReturn     | 83           |
| train-EnvExecTime       | 9.37         |
| train-MaxReturn         | 106          |
| train-MinReturn         | 12.6         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 17           |
| train-StdReturn         | 16.5         |
------------------------------------------

 ---------------- Iteration 226 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 226          |
| ItrTime                 | 29.2         |
| LossAfter               | -0.032501686 |
| LossBefore              | 0.0013478516 |
| Time                    | 7.15e+03     |
| Time-Optimization       | 1.57         |
| Time-SampleProc         | 0.181        |
| Time-Sampling           | 27.4         |
| n_timesteps             | 2270000      |
| train-AverageDiscoun... | 47.8         |
| train-AverageReturn     | 83.4         |
| train-EnvExecTime       | 9.38         |
| train-MaxReturn         | 113          |
| train-MinReturn         | -18.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 17.2         |
| train-StdReturn         | 17.7         |
------------------------------------------

 ---------------- Iteration 227 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
----------------------------------------
| Itr                     | 227        |
| ItrTime                 | 27         |
| LossAfter               | 0.03632466 |
| LossBefore              | 0.03431329 |
| Time                    | 7.18e+03   |
| Time-Optimization       | 1.2        |
| Time-SampleProc         | 0.12       |
| Time-Sampling           | 25.7       |
| n_timesteps             | 2280000    |
| train-AverageDiscoun... | 47.3       |
| train-AverageReturn     | 82.8       |
| train-EnvExecTime       | 8.95       |
| train-MaxReturn         | 112        |
| train-MinReturn         | 27.3       |
| train-NumTrajs          | 100        |
| train-PolicyExecTime    | 15.9       |
| train-StdReturn         | 16.1       |
----------------------------------------

 ---------------- Iteration 228 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 228          |
| ItrTime                 | 29.2         |
| LossAfter               | -0.033216003 |
| LossBefore              | 0.012447986  |
| Time                    | 7.21e+03     |
| Time-Optimization       | 2.17         |
| Time-SampleProc         | 0.247        |
| Time-Sampling           | 26.8         |
| n_timesteps             | 2290000      |
| train-AverageDiscoun... | 47.4         |
| train-AverageReturn     | 82.7         |
| train-EnvExecTime       | 9.3          |
| train-MaxReturn         | 111          |
| train-MinReturn         | -13.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 16.7         |
| train-StdReturn         | 17.9         |
------------------------------------------

 ---------------- Iteration 229 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 229          |
| ItrTime                 | 30.5         |
| LossAfter               | -0.057743654 |
| LossBefore              | -0.022754248 |
| Time                    | 7.24e+03     |
| Time-Optimization       | 1.42         |
| Time-SampleProc         | 0.141        |
| Time-Sampling           | 28.9         |
| n_timesteps             | 2300000      |
| train-AverageDiscoun... | 49.6         |
| train-AverageReturn     | 86.4         |
| train-EnvExecTime       | 9.87         |
| train-MaxReturn         | 105          |
| train-MinReturn         | 29.4         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 18.1         |
| train-StdReturn         | 12.8         |
------------------------------------------

 ---------------- Iteration 230 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 230          |
| ItrTime                 | 27.5         |
| LossAfter               | -0.028579101 |
| LossBefore              | -0.01284751  |
| Time                    | 7.27e+03     |
| Time-Optimization       | 1.3          |
| Time-SampleProc         | 0.159        |
| Time-Sampling           | 26.1         |
| n_timesteps             | 2310000      |
| train-AverageDiscoun... | 48.6         |
| train-AverageReturn     | 85.3         |
| train-EnvExecTime       | 9.02         |
| train-MaxReturn         | 113          |
| train-MinReturn         | -11.4        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 16.2         |
| train-StdReturn         | 16.9         |
------------------------------------------

 ---------------- Iteration 231 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 231         |
| ItrTime                 | 29          |
| LossAfter               | -0.04106797 |
| LossBefore              | 0.024755128 |
| Time                    | 7.3e+03     |
| Time-Optimization       | 1.26        |
| Time-SampleProc         | 0.133       |
| Time-Sampling           | 27.6        |
| n_timesteps             | 2320000     |
| train-AverageDiscoun... | 48.7        |
| train-AverageReturn     | 84.5        |
| train-EnvExecTime       | 9.44        |
| train-MaxReturn         | 115         |
| train-MinReturn         | 0.398       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 17.3        |
| train-StdReturn         | 16.6        |
-----------------------------------------

 ---------------- Iteration 232 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 232         |
| ItrTime                 | 27.9        |
| LossAfter               | -0.06454653 |
| LossBefore              | -0.0113672  |
| Time                    | 7.33e+03    |
| Time-Optimization       | 1.26        |
| Time-SampleProc         | 0.161       |
| Time-Sampling           | 26.5        |
| n_timesteps             | 2330000     |
| train-AverageDiscoun... | 46.4        |
| train-AverageReturn     | 82.4        |
| train-EnvExecTime       | 9.17        |
| train-MaxReturn         | 106         |
| train-MinReturn         | 9.41        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 16.5        |
| train-StdReturn         | 17          |
-----------------------------------------

 ---------------- Iteration 233 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 233           |
| ItrTime                 | 27.5          |
| LossAfter               | -0.0025864579 |
| LossBefore              | 0.0019935027  |
| Time                    | 7.35e+03      |
| Time-Optimization       | 1.34          |
| Time-SampleProc         | 0.119         |
| Time-Sampling           | 26            |
| n_timesteps             | 2340000       |
| train-AverageDiscoun... | 48.1          |
| train-AverageReturn     | 84.3          |
| train-EnvExecTime       | 9.15          |
| train-MaxReturn         | 106           |
| train-MinReturn         | -0.0351       |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 16.1          |
| train-StdReturn         | 15            |
-------------------------------------------

 ---------------- Iteration 234 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 234          |
| ItrTime                 | 28.3         |
| LossAfter               | 0.0010599854 |
| LossBefore              | 0.014738599  |
| Time                    | 7.38e+03     |
| Time-Optimization       | 1.34         |
| Time-SampleProc         | 0.126        |
| Time-Sampling           | 26.8         |
| n_timesteps             | 2350000      |
| train-AverageDiscoun... | 46.1         |
| train-AverageReturn     | 80.4         |
| train-EnvExecTime       | 9.26         |
| train-MaxReturn         | 114          |
| train-MinReturn         | -20.9        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 16.7         |
| train-StdReturn         | 23.4         |
------------------------------------------

 ---------------- Iteration 235 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 235          |
| ItrTime                 | 27.2         |
| LossAfter               | -0.05432578  |
| LossBefore              | -0.031121973 |
| Time                    | 7.41e+03     |
| Time-Optimization       | 1.26         |
| Time-SampleProc         | 0.155        |
| Time-Sampling           | 25.8         |
| n_timesteps             | 2360000      |
| train-AverageDiscoun... | 48.8         |
| train-AverageReturn     | 85.2         |
| train-EnvExecTime       | 8.97         |
| train-MaxReturn         | 109          |
| train-MinReturn         | 11.2         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 16           |
| train-StdReturn         | 14.1         |
------------------------------------------

 ---------------- Iteration 236 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 236          |
| ItrTime                 | 27.7         |
| LossAfter               | -0.005150476 |
| LossBefore              | 0.012524567  |
| Time                    | 7.44e+03     |
| Time-Optimization       | 1.21         |
| Time-SampleProc         | 0.134        |
| Time-Sampling           | 26.4         |
| n_timesteps             | 2370000      |
| train-AverageDiscoun... | 48.9         |
| train-AverageReturn     | 85.7         |
| train-EnvExecTime       | 9.14         |
| train-MaxReturn         | 112          |
| train-MinReturn         | 36.5         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 16.4         |
| train-StdReturn         | 10.5         |
------------------------------------------

 ---------------- Iteration 237 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 237          |
| ItrTime                 | 27.3         |
| LossAfter               | -0.046831567 |
| LossBefore              | -0.01858147  |
| Time                    | 7.46e+03     |
| Time-Optimization       | 1.34         |
| Time-SampleProc         | 0.164        |
| Time-Sampling           | 25.8         |
| n_timesteps             | 2380000      |
| train-AverageDiscoun... | 48.1         |
| train-AverageReturn     | 84.2         |
| train-EnvExecTime       | 9.08         |
| train-MaxReturn         | 107          |
| train-MinReturn         | -3.3         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 15.9         |
| train-StdReturn         | 15.3         |
------------------------------------------

 ---------------- Iteration 238 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 238          |
| ItrTime                 | 27.9         |
| LossAfter               | -0.031481177 |
| LossBefore              | -0.008175659 |
| Time                    | 7.49e+03     |
| Time-Optimization       | 1.26         |
| Time-SampleProc         | 0.148        |
| Time-Sampling           | 26.5         |
| n_timesteps             | 2390000      |
| train-AverageDiscoun... | 48.1         |
| train-AverageReturn     | 84.8         |
| train-EnvExecTime       | 9.16         |
| train-MaxReturn         | 112          |
| train-MinReturn         | 19.1         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 16.5         |
| train-StdReturn         | 11.9         |
------------------------------------------

 ---------------- Iteration 239 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 239          |
| ItrTime                 | 26.8         |
| LossAfter               | -0.013976709 |
| LossBefore              | 0.008582227  |
| Time                    | 7.52e+03     |
| Time-Optimization       | 1.25         |
| Time-SampleProc         | 0.123        |
| Time-Sampling           | 25.4         |
| n_timesteps             | 2400000      |
| train-AverageDiscoun... | 47.5         |
| train-AverageReturn     | 82.3         |
| train-EnvExecTime       | 8.88         |
| train-MaxReturn         | 117          |
| train-MinReturn         | -23.9        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 15.7         |
| train-StdReturn         | 20.9         |
------------------------------------------

 ---------------- Iteration 240 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 240          |
| ItrTime                 | 26.7         |
| LossAfter               | -0.014671045 |
| LossBefore              | 0.004000293  |
| Time                    | 7.55e+03     |
| Time-Optimization       | 1.26         |
| Time-SampleProc         | 0.119        |
| Time-Sampling           | 25.3         |
| n_timesteps             | 2410000      |
| train-AverageDiscoun... | 47.4         |
| train-AverageReturn     | 82.9         |
| train-EnvExecTime       | 8.84         |
| train-MaxReturn         | 111          |
| train-MinReturn         | 10.4         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 15.7         |
| train-StdReturn         | 16.5         |
------------------------------------------

 ---------------- Iteration 241 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 241          |
| ItrTime                 | 28           |
| LossAfter               | -0.055539552 |
| LossBefore              | -0.018151758 |
| Time                    | 7.57e+03     |
| Time-Optimization       | 1.22         |
| Time-SampleProc         | 0.137        |
| Time-Sampling           | 26.6         |
| n_timesteps             | 2420000      |
| train-AverageDiscoun... | 46.9         |
| train-AverageReturn     | 82.3         |
| train-EnvExecTime       | 9.16         |
| train-MaxReturn         | 115          |
| train-MinReturn         | 17.7         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 16.6         |
| train-StdReturn         | 14.9         |
------------------------------------------

 ---------------- Iteration 242 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 242          |
| ItrTime                 | 27.3         |
| LossAfter               | -0.021929687 |
| LossBefore              | 0.005480896  |
| Time                    | 7.6e+03      |
| Time-Optimization       | 1.24         |
| Time-SampleProc         | 0.153        |
| Time-Sampling           | 25.9         |
| n_timesteps             | 2430000      |
| train-AverageDiscoun... | 47.1         |
| train-AverageReturn     | 82.8         |
| train-EnvExecTime       | 9            |
| train-MaxReturn         | 109          |
| train-MinReturn         | -16.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 16.1         |
| train-StdReturn         | 17.4         |
------------------------------------------

 ---------------- Iteration 243 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 243          |
| ItrTime                 | 27.1         |
| LossAfter               | -0.05679697  |
| LossBefore              | -0.005945361 |
| Time                    | 7.63e+03     |
| Time-Optimization       | 1.24         |
| Time-SampleProc         | 0.117        |
| Time-Sampling           | 25.8         |
| n_timesteps             | 2440000      |
| train-AverageDiscoun... | 47.7         |
| train-AverageReturn     | 84.2         |
| train-EnvExecTime       | 9            |
| train-MaxReturn         | 105          |
| train-MinReturn         | 17.5         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 15.9         |
| train-StdReturn         | 14.1         |
------------------------------------------

 ---------------- Iteration 244 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 244         |
| ItrTime                 | 27.5        |
| LossAfter               | -0.02002013 |
| LossBefore              | 0.011285125 |
| Time                    | 7.66e+03    |
| Time-Optimization       | 1.36        |
| Time-SampleProc         | 0.135       |
| Time-Sampling           | 26          |
| n_timesteps             | 2450000     |
| train-AverageDiscoun... | 47.8        |
| train-AverageReturn     | 82.6        |
| train-EnvExecTime       | 9.03        |
| train-MaxReturn         | 108         |
| train-MinReturn         | -30.7       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 16.1        |
| train-StdReturn         | 20.1        |
-----------------------------------------

 ---------------- Iteration 245 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 245           |
| ItrTime                 | 27.4          |
| LossAfter               | -0.0036619385 |
| LossBefore              | 0.03063612    |
| Time                    | 7.68e+03      |
| Time-Optimization       | 1.23          |
| Time-SampleProc         | 0.139         |
| Time-Sampling           | 26            |
| n_timesteps             | 2460000       |
| train-AverageDiscoun... | 46.8          |
| train-AverageReturn     | 82.2          |
| train-EnvExecTime       | 9.01          |
| train-MaxReturn         | 107           |
| train-MinReturn         | 5.84          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 16.1          |
| train-StdReturn         | 17.3          |
-------------------------------------------

 ---------------- Iteration 246 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 246           |
| ItrTime                 | 27.2          |
| LossAfter               | -0.073266625  |
| LossBefore              | -0.0059276978 |
| Time                    | 7.71e+03      |
| Time-Optimization       | 1.26          |
| Time-SampleProc         | 0.185         |
| Time-Sampling           | 25.8          |
| n_timesteps             | 2470000       |
| train-AverageDiscoun... | 47.9          |
| train-AverageReturn     | 83.8          |
| train-EnvExecTime       | 8.94          |
| train-MaxReturn         | 107           |
| train-MinReturn         | 7.08          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 16            |
| train-StdReturn         | 14.6          |
-------------------------------------------

 ---------------- Iteration 247 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 247          |
| ItrTime                 | 27.1         |
| LossAfter               | -0.0658173   |
| LossBefore              | -0.005427533 |
| Time                    | 7.74e+03     |
| Time-Optimization       | 1.24         |
| Time-SampleProc         | 0.12         |
| Time-Sampling           | 25.8         |
| n_timesteps             | 2480000      |
| train-AverageDiscoun... | 48.3         |
| train-AverageReturn     | 84.5         |
| train-EnvExecTime       | 8.93         |
| train-MaxReturn         | 113          |
| train-MinReturn         | 9.92         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 16           |
| train-StdReturn         | 17.6         |
------------------------------------------

 ---------------- Iteration 248 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 248          |
| ItrTime                 | 27.3         |
| LossAfter               | -0.027690088 |
| LossBefore              | -0.00633667  |
| Time                    | 7.76e+03     |
| Time-Optimization       | 1.26         |
| Time-SampleProc         | 0.125        |
| Time-Sampling           | 25.9         |
| n_timesteps             | 2490000      |
| train-AverageDiscoun... | 48.5         |
| train-AverageReturn     | 84.8         |
| train-EnvExecTime       | 8.95         |
| train-MaxReturn         | 111          |
| train-MinReturn         | -29.1        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 16.1         |
| train-StdReturn         | 17.9         |
------------------------------------------

 ---------------- Iteration 249 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 249         |
| ItrTime                 | 26.8        |
| LossAfter               | 0.01398894  |
| LossBefore              | 0.027644336 |
| Time                    | 7.79e+03    |
| Time-Optimization       | 1.23        |
| Time-SampleProc         | 0.118       |
| Time-Sampling           | 25.4        |
| n_timesteps             | 2500000     |
| train-AverageDiscoun... | 49.2        |
| train-AverageReturn     | 86.3        |
| train-EnvExecTime       | 8.88        |
| train-MaxReturn         | 110         |
| train-MinReturn         | 44          |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 15.7        |
| train-StdReturn         | 10.2        |
-----------------------------------------

 ---------------- Iteration 250 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 250           |
| ItrTime                 | 27.9          |
| LossAfter               | -0.050447755  |
| LossBefore              | 0.00034604492 |
| Time                    | 7.82e+03      |
| Time-Optimization       | 1.22          |
| Time-SampleProc         | 0.121         |
| Time-Sampling           | 26.5          |
| n_timesteps             | 2510000       |
| train-AverageDiscoun... | 47.7          |
| train-AverageReturn     | 83.6          |
| train-EnvExecTime       | 9.19          |
| train-MaxReturn         | 111           |
| train-MinReturn         | -0.891        |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 16.5          |
| train-StdReturn         | 16.7          |
-------------------------------------------

 ---------------- Iteration 251 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 251         |
| ItrTime                 | 26.9        |
| LossAfter               | -0.08492656 |
| LossBefore              | -0.01977246 |
| Time                    | 7.85e+03    |
| Time-Optimization       | 1.27        |
| Time-SampleProc         | 0.148       |
| Time-Sampling           | 25.5        |
| n_timesteps             | 2520000     |
| train-AverageDiscoun... | 48.7        |
| train-AverageReturn     | 84.6        |
| train-EnvExecTime       | 8.89        |
| train-MaxReturn         | 105         |
| train-MinReturn         | 9.98        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 15.8        |
| train-StdReturn         | 13.6        |
-----------------------------------------

 ---------------- Iteration 252 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 252          |
| ItrTime                 | 28           |
| LossAfter               | 0.0073696715 |
| LossBefore              | 0.0044158692 |
| Time                    | 7.87e+03     |
| Time-Optimization       | 1.3          |
| Time-SampleProc         | 0.139        |
| Time-Sampling           | 26.6         |
| n_timesteps             | 2530000      |
| train-AverageDiscoun... | 49.1         |
| train-AverageReturn     | 85.4         |
| train-EnvExecTime       | 9.2          |
| train-MaxReturn         | 115          |
| train-MinReturn         | 29.7         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 16.6         |
| train-StdReturn         | 13.3         |
------------------------------------------

 ---------------- Iteration 253 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 253          |
| ItrTime                 | 27.1         |
| LossAfter               | -0.05111179  |
| LossBefore              | -0.008114673 |
| Time                    | 7.9e+03      |
| Time-Optimization       | 1.23         |
| Time-SampleProc         | 0.123        |
| Time-Sampling           | 25.7         |
| n_timesteps             | 2540000      |
| train-AverageDiscoun... | 50.1         |
| train-AverageReturn     | 86.9         |
| train-EnvExecTime       | 8.98         |
| train-MaxReturn         | 111          |
| train-MinReturn         | -1.3         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 15.9         |
| train-StdReturn         | 15.9         |
------------------------------------------

 ---------------- Iteration 254 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 254          |
| ItrTime                 | 26.7         |
| LossAfter               | -0.05638667  |
| LossBefore              | -0.013584912 |
| Time                    | 7.93e+03     |
| Time-Optimization       | 1.25         |
| Time-SampleProc         | 0.131        |
| Time-Sampling           | 25.4         |
| n_timesteps             | 2550000      |
| train-AverageDiscoun... | 49           |
| train-AverageReturn     | 85.5         |
| train-EnvExecTime       | 8.85         |
| train-MaxReturn         | 109          |
| train-MinReturn         | -0.18        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 15.7         |
| train-StdReturn         | 17.8         |
------------------------------------------

 ---------------- Iteration 255 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 255          |
| ItrTime                 | 27.7         |
| LossAfter               | -0.08003033  |
| LossBefore              | -0.031813502 |
| Time                    | 7.96e+03     |
| Time-Optimization       | 1.27         |
| Time-SampleProc         | 0.194        |
| Time-Sampling           | 26.2         |
| n_timesteps             | 2560000      |
| train-AverageDiscoun... | 46.8         |
| train-AverageReturn     | 81.8         |
| train-EnvExecTime       | 9.09         |
| train-MaxReturn         | 109          |
| train-MinReturn         | -24.5        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 16.2         |
| train-StdReturn         | 18.7         |
------------------------------------------

 ---------------- Iteration 256 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 256          |
| ItrTime                 | 27           |
| LossAfter               | -0.021824341 |
| LossBefore              | -0.024515942 |
| Time                    | 7.98e+03     |
| Time-Optimization       | 1.64         |
| Time-SampleProc         | 0.124        |
| Time-Sampling           | 25.2         |
| n_timesteps             | 2570000      |
| train-AverageDiscoun... | 48.5         |
| train-AverageReturn     | 84.3         |
| train-EnvExecTime       | 8.88         |
| train-MaxReturn         | 115          |
| train-MinReturn         | 31.5         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 15.5         |
| train-StdReturn         | 13.8         |
------------------------------------------

 ---------------- Iteration 257 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 257          |
| ItrTime                 | 26.6         |
| LossAfter               | -0.054604493 |
| LossBefore              | -0.022948463 |
| Time                    | 8.01e+03     |
| Time-Optimization       | 1.34         |
| Time-SampleProc         | 0.143        |
| Time-Sampling           | 25.2         |
| n_timesteps             | 2580000      |
| train-AverageDiscoun... | 48.6         |
| train-AverageReturn     | 84.5         |
| train-EnvExecTime       | 8.83         |
| train-MaxReturn         | 121          |
| train-MinReturn         | 11.5         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 15.5         |
| train-StdReturn         | 16.3         |
------------------------------------------

 ---------------- Iteration 258 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 258          |
| ItrTime                 | 27.7         |
| LossAfter               | 0.0064644776 |
| LossBefore              | 0.018470837  |
| Time                    | 8.04e+03     |
| Time-Optimization       | 1.27         |
| Time-SampleProc         | 0.126        |
| Time-Sampling           | 26.3         |
| n_timesteps             | 2590000      |
| train-AverageDiscoun... | 48.5         |
| train-AverageReturn     | 84.2         |
| train-EnvExecTime       | 9.15         |
| train-MaxReturn         | 105          |
| train-MinReturn         | 11.1         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 16.3         |
| train-StdReturn         | 16.3         |
------------------------------------------

 ---------------- Iteration 259 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 259          |
| ItrTime                 | 27.2         |
| LossAfter               | -0.06482075  |
| LossBefore              | 0.0007234863 |
| Time                    | 8.07e+03     |
| Time-Optimization       | 1.23         |
| Time-SampleProc         | 0.122        |
| Time-Sampling           | 25.8         |
| n_timesteps             | 2600000      |
| train-AverageDiscoun... | 47.8         |
| train-AverageReturn     | 83.6         |
| train-EnvExecTime       | 9.03         |
| train-MaxReturn         | 111          |
| train-MinReturn         | 6.44         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 16           |
| train-StdReturn         | 15.3         |
------------------------------------------

 ---------------- Iteration 260 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 260           |
| ItrTime                 | 27.3          |
| LossAfter               | -0.07468325   |
| LossBefore              | 0.00040947265 |
| Time                    | 8.09e+03      |
| Time-Optimization       | 1.3           |
| Time-SampleProc         | 0.148         |
| Time-Sampling           | 25.8          |
| n_timesteps             | 2610000       |
| train-AverageDiscoun... | 50.1          |
| train-AverageReturn     | 87            |
| train-EnvExecTime       | 8.99          |
| train-MaxReturn         | 111           |
| train-MinReturn         | 18.3          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 16            |
| train-StdReturn         | 11            |
-------------------------------------------

 ---------------- Iteration 261 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 261         |
| ItrTime                 | 27.5        |
| LossAfter               | -0.02175005 |
| LossBefore              | 0.011686078 |
| Time                    | 8.12e+03    |
| Time-Optimization       | 1.24        |
| Time-SampleProc         | 0.125       |
| Time-Sampling           | 26.1        |
| n_timesteps             | 2620000     |
| train-AverageDiscoun... | 48.5        |
| train-AverageReturn     | 85.1        |
| train-EnvExecTime       | 9.03        |
| train-MaxReturn         | 114         |
| train-MinReturn         | 20.7        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 16.2        |
| train-StdReturn         | 12.4        |
-----------------------------------------

 ---------------- Iteration 262 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 262          |
| ItrTime                 | 27.1         |
| LossAfter               | -0.06547284  |
| LossBefore              | -0.030081896 |
| Time                    | 8.15e+03     |
| Time-Optimization       | 1.25         |
| Time-SampleProc         | 0.156        |
| Time-Sampling           | 25.7         |
| n_timesteps             | 2630000      |
| train-AverageDiscoun... | 48           |
| train-AverageReturn     | 83.9         |
| train-EnvExecTime       | 9            |
| train-MaxReturn         | 109          |
| train-MinReturn         | -0.187       |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 15.9         |
| train-StdReturn         | 14.8         |
------------------------------------------

 ---------------- Iteration 263 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 263           |
| ItrTime                 | 27.2          |
| LossAfter               | -0.09559243   |
| LossBefore              | -0.0012805787 |
| Time                    | 8.17e+03      |
| Time-Optimization       | 1.27          |
| Time-SampleProc         | 0.133         |
| Time-Sampling           | 25.8          |
| n_timesteps             | 2640000       |
| train-AverageDiscoun... | 48.5          |
| train-AverageReturn     | 84.6          |
| train-EnvExecTime       | 8.97          |
| train-MaxReturn         | 108           |
| train-MinReturn         | 14.7          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 16            |
| train-StdReturn         | 12.7          |
-------------------------------------------

 ---------------- Iteration 264 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 264            |
| ItrTime                 | 27.3           |
| LossAfter               | 0.005991846    |
| LossBefore              | -0.00037329103 |
| Time                    | 8.2e+03        |
| Time-Optimization       | 1.25           |
| Time-SampleProc         | 0.127          |
| Time-Sampling           | 25.9           |
| n_timesteps             | 2650000        |
| train-AverageDiscoun... | 49.5           |
| train-AverageReturn     | 86.4           |
| train-EnvExecTime       | 9.02           |
| train-MaxReturn         | 113            |
| train-MinReturn         | 22.5           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 16             |
| train-StdReturn         | 12.2           |
--------------------------------------------

 ---------------- Iteration 265 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 265         |
| ItrTime                 | 28.9        |
| LossAfter               | 0.002697754 |
| LossBefore              | 0.031594288 |
| Time                    | 8.23e+03    |
| Time-Optimization       | 1.51        |
| Time-SampleProc         | 0.148       |
| Time-Sampling           | 27.3        |
| n_timesteps             | 2660000     |
| train-AverageDiscoun... | 47.7        |
| train-AverageReturn     | 83.3        |
| train-EnvExecTime       | 9.31        |
| train-MaxReturn         | 113         |
| train-MinReturn         | -30.8       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 17.1        |
| train-StdReturn         | 17.3        |
-----------------------------------------

 ---------------- Iteration 266 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 266           |
| ItrTime                 | 31.9          |
| LossAfter               | -0.0012185059 |
| LossBefore              | 0.042997506   |
| Time                    | 8.26e+03      |
| Time-Optimization       | 1.46          |
| Time-SampleProc         | 0.126         |
| Time-Sampling           | 30.3          |
| n_timesteps             | 2670000       |
| train-AverageDiscoun... | 48.4          |
| train-AverageReturn     | 85            |
| train-EnvExecTime       | 10.2          |
| train-MaxReturn         | 105           |
| train-MinReturn         | 30.3          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 19.2          |
| train-StdReturn         | 11.6          |
-------------------------------------------

 ---------------- Iteration 267 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 267          |
| ItrTime                 | 29.4         |
| LossAfter               | -0.07799993  |
| LossBefore              | -0.009984253 |
| Time                    | 8.29e+03     |
| Time-Optimization       | 1.41         |
| Time-SampleProc         | 0.139        |
| Time-Sampling           | 27.9         |
| n_timesteps             | 2680000      |
| train-AverageDiscoun... | 48           |
| train-AverageReturn     | 84           |
| train-EnvExecTime       | 9.46         |
| train-MaxReturn         | 106          |
| train-MinReturn         | 5.31         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 17.5         |
| train-StdReturn         | 14.5         |
------------------------------------------

 ---------------- Iteration 268 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 268          |
| ItrTime                 | 31.3         |
| LossAfter               | 0.0062269773 |
| LossBefore              | 0.007774774  |
| Time                    | 8.32e+03     |
| Time-Optimization       | 1.58         |
| Time-SampleProc         | 0.139        |
| Time-Sampling           | 29.6         |
| n_timesteps             | 2690000      |
| train-AverageDiscoun... | 47.2         |
| train-AverageReturn     | 82.8         |
| train-EnvExecTime       | 9.92         |
| train-MaxReturn         | 115          |
| train-MinReturn         | 16.1         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 18.7         |
| train-StdReturn         | 12.8         |
------------------------------------------

 ---------------- Iteration 269 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 269          |
| ItrTime                 | 29.6         |
| LossAfter               | -0.061169505 |
| LossBefore              | -0.004089856 |
| Time                    | 8.35e+03     |
| Time-Optimization       | 1.42         |
| Time-SampleProc         | 0.134        |
| Time-Sampling           | 28.1         |
| n_timesteps             | 2700000      |
| train-AverageDiscoun... | 46.8         |
| train-AverageReturn     | 81.6         |
| train-EnvExecTime       | 9.58         |
| train-MaxReturn         | 108          |
| train-MinReturn         | -6.59        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 17.6         |
| train-StdReturn         | 20.2         |
------------------------------------------

 ---------------- Iteration 270 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
----------------------------------------
| Itr                     | 270        |
| ItrTime                 | 29.2       |
| LossAfter               | -0.1207259 |
| LossBefore              | -0.0402102 |
| Time                    | 8.38e+03   |
| Time-Optimization       | 1.43       |
| Time-SampleProc         | 0.175      |
| Time-Sampling           | 27.6       |
| n_timesteps             | 2710000    |
| train-AverageDiscoun... | 47.1       |
| train-AverageReturn     | 82.5       |
| train-EnvExecTime       | 9.4        |
| train-MaxReturn         | 107        |
| train-MinReturn         | 3.26       |
| train-NumTrajs          | 100        |
| train-PolicyExecTime    | 17.3       |
| train-StdReturn         | 15.4       |
----------------------------------------

 ---------------- Iteration 271 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 271          |
| ItrTime                 | 29.4         |
| LossAfter               | -0.020962402 |
| LossBefore              | 0.02155857   |
| Time                    | 8.41e+03     |
| Time-Optimization       | 1.42         |
| Time-SampleProc         | 0.14         |
| Time-Sampling           | 27.9         |
| n_timesteps             | 2720000      |
| train-AverageDiscoun... | 34.4         |
| train-AverageReturn     | 62.2         |
| train-EnvExecTime       | 9.46         |
| train-MaxReturn         | 106          |
| train-MinReturn         | -40.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 17.5         |
| train-StdReturn         | 22.4         |
------------------------------------------

 ---------------- Iteration 272 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 272         |
| ItrTime                 | 29.8        |
| LossAfter               | -0.88329786 |
| LossBefore              | 0.002802295 |
| Time                    | 8.44e+03    |
| Time-Optimization       | 1.36        |
| Time-SampleProc         | 0.124       |
| Time-Sampling           | 28.3        |
| n_timesteps             | 2730000     |
| train-AverageDiscoun... | 21.9        |
| train-AverageReturn     | 40.3        |
| train-EnvExecTime       | 9.62        |
| train-MaxReturn         | 88.9        |
| train-MinReturn         | -53.4       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 17.8        |
| train-StdReturn         | 26.1        |
-----------------------------------------

 ---------------- Iteration 273 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 273          |
| ItrTime                 | 27.1         |
| LossAfter               | -0.5089996   |
| LossBefore              | -0.008083319 |
| Time                    | 8.47e+03     |
| Time-Optimization       | 1.28         |
| Time-SampleProc         | 0.132        |
| Time-Sampling           | 25.7         |
| n_timesteps             | 2740000      |
| train-AverageDiscoun... | 36           |
| train-AverageReturn     | 65.4         |
| train-EnvExecTime       | 9.02         |
| train-MaxReturn         | 113          |
| train-MinReturn         | 15.4         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 15.9         |
| train-StdReturn         | 16.8         |
------------------------------------------

 ---------------- Iteration 274 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 274         |
| ItrTime                 | 25.9        |
| LossAfter               | -0.05371638 |
| LossBefore              | 0.01109834  |
| Time                    | 8.5e+03     |
| Time-Optimization       | 1.2         |
| Time-SampleProc         | 0.137       |
| Time-Sampling           | 24.6        |
| n_timesteps             | 2750000     |
| train-AverageDiscoun... | 44.4        |
| train-AverageReturn     | 78.3        |
| train-EnvExecTime       | 8.69        |
| train-MaxReturn         | 106         |
| train-MinReturn         | -3.64       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 15.1        |
| train-StdReturn         | 21.7        |
-----------------------------------------

 ---------------- Iteration 275 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 275          |
| ItrTime                 | 25.3         |
| LossAfter               | -0.10862195  |
| LossBefore              | -0.016155079 |
| Time                    | 8.52e+03     |
| Time-Optimization       | 1.14         |
| Time-SampleProc         | 0.119        |
| Time-Sampling           | 24           |
| n_timesteps             | 2760000      |
| train-AverageDiscoun... | 49.1         |
| train-AverageReturn     | 85.2         |
| train-EnvExecTime       | 8.5          |
| train-MaxReturn         | 108          |
| train-MinReturn         | 13.3         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.8         |
| train-StdReturn         | 12.6         |
------------------------------------------

 ---------------- Iteration 276 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 276          |
| ItrTime                 | 24.8         |
| LossAfter               | -0.019653989 |
| LossBefore              | -0.024545038 |
| Time                    | 8.55e+03     |
| Time-Optimization       | 1.15         |
| Time-SampleProc         | 0.13         |
| Time-Sampling           | 23.6         |
| n_timesteps             | 2770000      |
| train-AverageDiscoun... | 49.3         |
| train-AverageReturn     | 85.9         |
| train-EnvExecTime       | 8.36         |
| train-MaxReturn         | 110          |
| train-MinReturn         | 30.2         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.4         |
| train-StdReturn         | 11.9         |
------------------------------------------

 ---------------- Iteration 277 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 277          |
| ItrTime                 | 24.8         |
| LossAfter               | -0.024838915 |
| LossBefore              | 0.006063306  |
| Time                    | 8.57e+03     |
| Time-Optimization       | 1.13         |
| Time-SampleProc         | 0.116        |
| Time-Sampling           | 23.6         |
| n_timesteps             | 2780000      |
| train-AverageDiscoun... | 48.3         |
| train-AverageReturn     | 83.9         |
| train-EnvExecTime       | 8.33         |
| train-MaxReturn         | 105          |
| train-MinReturn         | 21.4         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.5         |
| train-StdReturn         | 14.1         |
------------------------------------------

 ---------------- Iteration 278 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 278          |
| ItrTime                 | 25           |
| LossAfter               | -0.034618814 |
| LossBefore              | 0.015387573  |
| Time                    | 8.6e+03      |
| Time-Optimization       | 1.15         |
| Time-SampleProc         | 0.121        |
| Time-Sampling           | 23.7         |
| n_timesteps             | 2790000      |
| train-AverageDiscoun... | 48.4         |
| train-AverageReturn     | 84.5         |
| train-EnvExecTime       | 8.41         |
| train-MaxReturn         | 114          |
| train-MinReturn         | 20.9         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.6         |
| train-StdReturn         | 14.4         |
------------------------------------------

 ---------------- Iteration 279 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 279         |
| ItrTime                 | 24.9        |
| LossAfter               | -0.02524895 |
| LossBefore              | 0.022508899 |
| Time                    | 8.62e+03    |
| Time-Optimization       | 1.11        |
| Time-SampleProc         | 0.138       |
| Time-Sampling           | 23.7        |
| n_timesteps             | 2800000     |
| train-AverageDiscoun... | 47.7        |
| train-AverageReturn     | 82.5        |
| train-EnvExecTime       | 8.38        |
| train-MaxReturn         | 121         |
| train-MinReturn         | -5.05       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.5        |
| train-StdReturn         | 18.6        |
-----------------------------------------

 ---------------- Iteration 280 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 280         |
| ItrTime                 | 24.9        |
| LossAfter               | -0.03115249 |
| LossBefore              | 0.011571497 |
| Time                    | 8.65e+03    |
| Time-Optimization       | 1.11        |
| Time-SampleProc         | 0.118       |
| Time-Sampling           | 23.7        |
| n_timesteps             | 2810000     |
| train-AverageDiscoun... | 46.5        |
| train-AverageReturn     | 81.8        |
| train-EnvExecTime       | 8.39        |
| train-MaxReturn         | 104         |
| train-MinReturn         | 10.3        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.6        |
| train-StdReturn         | 17.5        |
-----------------------------------------

 ---------------- Iteration 281 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 281         |
| ItrTime                 | 24.8        |
| LossAfter               | -0.07207434 |
| LossBefore              | 0.006834143 |
| Time                    | 8.67e+03    |
| Time-Optimization       | 1.12        |
| Time-SampleProc         | 0.148       |
| Time-Sampling           | 23.5        |
| n_timesteps             | 2820000     |
| train-AverageDiscoun... | 49          |
| train-AverageReturn     | 85.7        |
| train-EnvExecTime       | 8.35        |
| train-MaxReturn         | 110         |
| train-MinReturn         | 48.3        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.5        |
| train-StdReturn         | 11.4        |
-----------------------------------------

 ---------------- Iteration 282 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 282         |
| ItrTime                 | 24.8        |
| LossAfter               | -0.12076874 |
| LossBefore              | 0.009408838 |
| Time                    | 8.7e+03     |
| Time-Optimization       | 1.11        |
| Time-SampleProc         | 0.126       |
| Time-Sampling           | 23.6        |
| n_timesteps             | 2830000     |
| train-AverageDiscoun... | 47.8        |
| train-AverageReturn     | 83.6        |
| train-EnvExecTime       | 8.4         |
| train-MaxReturn         | 108         |
| train-MinReturn         | -14.8       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.4        |
| train-StdReturn         | 19.3        |
-----------------------------------------

 ---------------- Iteration 283 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 283         |
| ItrTime                 | 24.8        |
| LossAfter               | -0.48543602 |
| LossBefore              | 0.016771412 |
| Time                    | 8.72e+03    |
| Time-Optimization       | 1.15        |
| Time-SampleProc         | 0.147       |
| Time-Sampling           | 23.5        |
| n_timesteps             | 2840000     |
| train-AverageDiscoun... | 47.9        |
| train-AverageReturn     | 83.4        |
| train-EnvExecTime       | 8.33        |
| train-MaxReturn         | 105         |
| train-MinReturn         | 1.85        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.4        |
| train-StdReturn         | 16.9        |
-----------------------------------------

 ---------------- Iteration 284 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 284          |
| ItrTime                 | 25           |
| LossAfter               | -0.07225098  |
| LossBefore              | -0.022295533 |
| Time                    | 8.75e+03     |
| Time-Optimization       | 1.11         |
| Time-SampleProc         | 0.128        |
| Time-Sampling           | 23.7         |
| n_timesteps             | 2850000      |
| train-AverageDiscoun... | 49           |
| train-AverageReturn     | 85.8         |
| train-EnvExecTime       | 8.38         |
| train-MaxReturn         | 112          |
| train-MinReturn         | 34.2         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.6         |
| train-StdReturn         | 11.9         |
------------------------------------------

 ---------------- Iteration 285 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 285          |
| ItrTime                 | 24.9         |
| LossAfter               | -0.02921831  |
| LossBefore              | -0.011513196 |
| Time                    | 8.77e+03     |
| Time-Optimization       | 1.43         |
| Time-SampleProc         | 0.177        |
| Time-Sampling           | 23.3         |
| n_timesteps             | 2860000      |
| train-AverageDiscoun... | 47.7         |
| train-AverageReturn     | 83.5         |
| train-EnvExecTime       | 8.3          |
| train-MaxReturn         | 108          |
| train-MinReturn         | 15.6         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 15.4         |
------------------------------------------

 ---------------- Iteration 286 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 286          |
| ItrTime                 | 24.4         |
| LossAfter               | -0.031255662 |
| LossBefore              | 0.0051336912 |
| Time                    | 8.79e+03     |
| Time-Optimization       | 1.31         |
| Time-SampleProc         | 0.116        |
| Time-Sampling           | 23           |
| n_timesteps             | 2870000      |
| train-AverageDiscoun... | 48.4         |
| train-AverageReturn     | 84.8         |
| train-EnvExecTime       | 8.23         |
| train-MaxReturn         | 110          |
| train-MinReturn         | -5.6         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14           |
| train-StdReturn         | 14.2         |
------------------------------------------

 ---------------- Iteration 287 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 287          |
| ItrTime                 | 24.6         |
| LossAfter               | -0.0295599   |
| LossBefore              | 0.0077517396 |
| Time                    | 8.82e+03     |
| Time-Optimization       | 1.12         |
| Time-SampleProc         | 0.134        |
| Time-Sampling           | 23.3         |
| n_timesteps             | 2880000      |
| train-AverageDiscoun... | 47.5         |
| train-AverageReturn     | 82.3         |
| train-EnvExecTime       | 8.29         |
| train-MaxReturn         | 110          |
| train-MinReturn         | 2.3          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.3         |
| train-StdReturn         | 17.6         |
------------------------------------------

 ---------------- Iteration 288 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 288          |
| ItrTime                 | 25           |
| LossAfter               | -0.004590869 |
| LossBefore              | 0.004206006  |
| Time                    | 8.84e+03     |
| Time-Optimization       | 1.14         |
| Time-SampleProc         | 0.127        |
| Time-Sampling           | 23.7         |
| n_timesteps             | 2890000      |
| train-AverageDiscoun... | 48.8         |
| train-AverageReturn     | 84.9         |
| train-EnvExecTime       | 8.37         |
| train-MaxReturn         | 106          |
| train-MinReturn         | 35.1         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.6         |
| train-StdReturn         | 12.7         |
------------------------------------------

 ---------------- Iteration 289 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 289           |
| ItrTime                 | 25.2          |
| LossAfter               | -0.0014886963 |
| LossBefore              | 0.004515454   |
| Time                    | 8.87e+03      |
| Time-Optimization       | 1.15          |
| Time-SampleProc         | 0.119         |
| Time-Sampling           | 23.9          |
| n_timesteps             | 2900000       |
| train-AverageDiscoun... | 47.8          |
| train-AverageReturn     | 84            |
| train-EnvExecTime       | 8.48          |
| train-MaxReturn         | 115           |
| train-MinReturn         | -14.1         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.7          |
| train-StdReturn         | 17.3          |
-------------------------------------------

 ---------------- Iteration 290 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 290          |
| ItrTime                 | 24.9         |
| LossAfter               | -0.07878698  |
| LossBefore              | 0.0073380554 |
| Time                    | 8.89e+03     |
| Time-Optimization       | 1.12         |
| Time-SampleProc         | 0.125        |
| Time-Sampling           | 23.6         |
| n_timesteps             | 2910000      |
| train-AverageDiscoun... | 48.4         |
| train-AverageReturn     | 85.3         |
| train-EnvExecTime       | 8.37         |
| train-MaxReturn         | 113          |
| train-MinReturn         | -6.53        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.5         |
| train-StdReturn         | 16.9         |
------------------------------------------

 ---------------- Iteration 291 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 291          |
| ItrTime                 | 24.9         |
| LossAfter               | -0.013685107 |
| LossBefore              | -0.010526953 |
| Time                    | 8.92e+03     |
| Time-Optimization       | 1.11         |
| Time-SampleProc         | 0.12         |
| Time-Sampling           | 23.6         |
| n_timesteps             | 2920000      |
| train-AverageDiscoun... | 48.2         |
| train-AverageReturn     | 84.1         |
| train-EnvExecTime       | 8.41         |
| train-MaxReturn         | 105          |
| train-MinReturn         | 24.6         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.5         |
| train-StdReturn         | 15.5         |
------------------------------------------

 ---------------- Iteration 292 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 292          |
| ItrTime                 | 24.7         |
| LossAfter               | -0.044002343 |
| LossBefore              | 0.0012616944 |
| Time                    | 8.94e+03     |
| Time-Optimization       | 1.1          |
| Time-SampleProc         | 0.126        |
| Time-Sampling           | 23.5         |
| n_timesteps             | 2930000      |
| train-AverageDiscoun... | 47.3         |
| train-AverageReturn     | 83           |
| train-EnvExecTime       | 8.35         |
| train-MaxReturn         | 114          |
| train-MinReturn         | 1.31         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.4         |
| train-StdReturn         | 18.7         |
------------------------------------------

 ---------------- Iteration 293 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 293         |
| ItrTime                 | 24.9        |
| LossAfter               | -0.04535892 |
| LossBefore              | 0.007710985 |
| Time                    | 8.97e+03    |
| Time-Optimization       | 1.12        |
| Time-SampleProc         | 0.127       |
| Time-Sampling           | 23.6        |
| n_timesteps             | 2940000     |
| train-AverageDiscoun... | 47.9        |
| train-AverageReturn     | 83.6        |
| train-EnvExecTime       | 8.41        |
| train-MaxReturn         | 107         |
| train-MinReturn         | 7.7         |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.5        |
| train-StdReturn         | 14.3        |
-----------------------------------------

 ---------------- Iteration 294 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 294          |
| ItrTime                 | 24.8         |
| LossAfter               | -0.07606717  |
| LossBefore              | -0.023309045 |
| Time                    | 8.99e+03     |
| Time-Optimization       | 1.14         |
| Time-SampleProc         | 0.154        |
| Time-Sampling           | 23.5         |
| n_timesteps             | 2950000      |
| train-AverageDiscoun... | 47.8         |
| train-AverageReturn     | 83.7         |
| train-EnvExecTime       | 8.35         |
| train-MaxReturn         | 108          |
| train-MinReturn         | 1.31         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.4         |
| train-StdReturn         | 14.9         |
------------------------------------------

 ---------------- Iteration 295 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 295           |
| ItrTime                 | 24.7          |
| LossAfter               | -0.02727871   |
| LossBefore              | 0.00041743164 |
| Time                    | 9.02e+03      |
| Time-Optimization       | 1.23          |
| Time-SampleProc         | 0.181         |
| Time-Sampling           | 23.2          |
| n_timesteps             | 2960000       |
| train-AverageDiscoun... | 48.1          |
| train-AverageReturn     | 84.7          |
| train-EnvExecTime       | 8.3           |
| train-MaxReturn         | 109           |
| train-MinReturn         | 9.03          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.2          |
| train-StdReturn         | 15            |
-------------------------------------------

 ---------------- Iteration 296 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 296         |
| ItrTime                 | 25.1        |
| LossAfter               | -0.01968169 |
| LossBefore              | 0.025799097 |
| Time                    | 9.04e+03    |
| Time-Optimization       | 1.44        |
| Time-SampleProc         | 0.153       |
| Time-Sampling           | 23.5        |
| n_timesteps             | 2970000     |
| train-AverageDiscoun... | 48          |
| train-AverageReturn     | 83.9        |
| train-EnvExecTime       | 8.34        |
| train-MaxReturn         | 111         |
| train-MinReturn         | 10.5        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.4        |
| train-StdReturn         | 16.7        |
-----------------------------------------

 ---------------- Iteration 297 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 297         |
| ItrTime                 | 24.8        |
| LossAfter               | -0.01570961 |
| LossBefore              | 0.01882513  |
| Time                    | 9.07e+03    |
| Time-Optimization       | 1.71        |
| Time-SampleProc         | 0.124       |
| Time-Sampling           | 23          |
| n_timesteps             | 2980000     |
| train-AverageDiscoun... | 47          |
| train-AverageReturn     | 82.1        |
| train-EnvExecTime       | 8.24        |
| train-MaxReturn         | 118         |
| train-MinReturn         | -28.3       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14          |
| train-StdReturn         | 21.8        |
-----------------------------------------

 ---------------- Iteration 298 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 298          |
| ItrTime                 | 24.5         |
| LossAfter               | -0.04743745  |
| LossBefore              | -0.007522461 |
| Time                    | 9.09e+03     |
| Time-Optimization       | 1.4          |
| Time-SampleProc         | 0.119        |
| Time-Sampling           | 23           |
| n_timesteps             | 2990000      |
| train-AverageDiscoun... | 47.6         |
| train-AverageReturn     | 82.8         |
| train-EnvExecTime       | 8.29         |
| train-MaxReturn         | 108          |
| train-MinReturn         | -5.72        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14           |
| train-StdReturn         | 19.6         |
------------------------------------------

 ---------------- Iteration 299 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 299         |
| ItrTime                 | 24.7        |
| LossAfter               | -0.03141865 |
| LossBefore              | 0.02158413  |
| Time                    | 9.12e+03    |
| Time-Optimization       | 1.22        |
| Time-SampleProc         | 0.121       |
| Time-Sampling           | 23.3        |
| n_timesteps             | 3000000     |
| train-AverageDiscoun... | 48.7        |
| train-AverageReturn     | 86          |
| train-EnvExecTime       | 8.34        |
| train-MaxReturn         | 107         |
| train-MinReturn         | 26.5        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.3        |
| train-StdReturn         | 13.1        |
-----------------------------------------
Training finished
